<!doctype html><html lang=zh-CN data-theme=light><head><meta charset=UTF-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: light)"><meta name=generator content="Hugo 0.143.1"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="CUDA by Example: Chapter 01-05"><meta itemprop=description content="个人博客，主要是零散的笔记。"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="https://hxhue.github.io/imgs/371907.jpg"><meta itemprop=keywords content="cuda,cuda-by-example"><link type=text/css rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css><link rel=stylesheet href=/css/main.min.bea76f574a755574e17d42bea39502a74ca3ca4db65807b8c82d3e26dcec8420.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><link rel=stylesheet type=text/css href=/css/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/github-markdown-css@5.3.0/github-markdown-dark.css><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script><script>MathJax={tex:{displayMath:[["$$","$$"],["\\[","\\]"]],inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: false });
  mermaid.mermaidAPI.initialize();
  window.mermaid = mermaid;
</script><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"path":"CUDA-by-Example-chapter01-05","permalink":"https://hxhue.github.io/cuda-by-example/CUDA-by-Example-chapter01-05/","title":"CUDA by Example: Chapter 01-05","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>CUDA by Example: Chapter 01-05 - Bluegill</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Bluegill</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description></p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about/ class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档</a></li><li class="menu-item menu-item-categories"><a href=/categories/ class=hvr-icon-pulse rel=section><i class="fa fa-th hvr-icon"></i>分类</a></li><li class="menu-item menu-item-tags"><a href=/tags/ class=hvr-icon-pulse rel=section><i class="fa fa-hashtag hvr-icon"></i>标签</a></li><li class="menu-item menu-item-daily"><a href=/daily/ class=hvr-icon-pulse rel=section><i class="fa fa-newspaper hvr-icon"></i>随笔</a></li><li class="menu-item menu-item-discovery"><a href=https://rift-fear-f2c.notion.site/2025-1e354a33cfb1802c841bdf29f2f3dab3 class=hvr-icon-pulse rel=section><i class="fa fa-compass hvr-icon"></i>发现</a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><a href=#第-3-章-cuda-源文件>第 3 章 CUDA 源文件</a></li><li><a href=#第-4-章-核函数>第 4 章 核函数</a></li><li><a href=#第-5-章-高维-dim3-和共享内存>第 5 章 高维 dim3 和共享内存</a><ul><li><a href=#按照输出的形状对线程分组>按照输出的形状对线程分组</a></li><li><a href=#共享内存>共享内存</a></li></ul></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=🤖 src=/imgs/371907.jpg><p class=site-author-name itemprop=name>🤖</p><div class=site-description itemprop=description>个人博客，主要是零散的笔记。</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>433</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>12</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>86</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/hxhue title="Github → https://github.com/hxhue" rel=noopener target=_blank><i class="fab fa-github fa-fw"></i>
Github
</a></span><span class=links-of-social-item><a href=/rss.xml title="RSS 订阅 → /rss.xml" rel=noopener target=_blank><i class="fa fa-rss fa-fw"></i>
RSS 订阅</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>
友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://shuai.guru/ title=https://shuai.guru/ target=_blank>shuai.guru</a></li></ul></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=https://hxhue.github.io/cuda-by-example/CUDA-by-Example-chapter01-05/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/imgs/371907.jpg"><meta itemprop=name content="🤖"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="🤖"><meta itemprop=description content="个人博客，主要是零散的笔记。"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="CUDA by Example: Chapter 01-05"><meta itemprop=description content="源码可以参考 https://github.com/yottaawesome/cuda-by-example/ ，官网的源码链接挂了。
书中的代码有些需要用 opengl 来跑。安装了 freeglut3-dev 和 mesa-utils。（不确定 libgl1-mesa-dev 是否是必要的。）然后 cmake 规则中要 link 对应的库："></span><header class=post-header><h1 class=post-title itemprop="name headline">CUDA by Example: Chapter 01-05</h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i>
</span><span class=post-meta-item-text title=发表于>发表于：
</span><time title="创建时间：2024-02-06 00:00:00 +0800 CST" itemprop="dateCreated datePublished" datetime="2024-02-06 00:00:00 +0800 CST">2024-02-06
</time></span><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar-check"></i>
</span><span class=post-meta-item-text title=更新于>更新于：
</span><time title=修改时间：2024-04-08T00:00:00+08:00 itemprop=dateModified datetime=2024-04-08T00:00:00+08:00>2024-04-08</time>
</span><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i>
</span><span class=post-meta-item-text title=分类于>分类于：
</span><span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/cuda-by-example itemprop=url rel=index><span itemprop=name>cuda-by-example</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i>
</span><span class=post-meta-item-text>字数：</span>
<span>1304</span>
</span><span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i>
</span><span class=post-meta-item-text>阅读：&ap;</span>
<span>3分钟</span></span></div></div></header><div class=post-body itemprop=articleBody><p>源码可以参考 <a href=https://github.com/yottaawesome/cuda-by-example/ title=https://github.com/yottaawesome/cuda-by-example/ rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://github.com/yottaawesome/cuda-by-example/<i class="fa fa-external-link-alt"></i></a> ，官网的源码链接挂了。</p><p>书中的代码有些需要用 opengl 来跑。安装了 <code>freeglut3-dev</code> 和 <code>mesa-utils</code>。（不确定 <code>libgl1-mesa-dev</code> 是否是必要的。）然后 cmake 规则中要 link 对应的库：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cmake data-lang=cmake><span style=display:flex><span><span style=color:#b58900>cmake_minimum_required</span>(<span style=color:#2aa198>VERSION</span> <span style=color:#2aa198>3.20.1</span>)
</span></span><span style=display:flex><span><span style=color:#b58900>project</span>(<span style=color:#2aa198>chapter3</span> <span style=color:#2aa198>LANGUAGES</span> <span style=color:#2aa198>CXX</span> <span style=color:#2aa198>CUDA</span>)
</span></span><span style=display:flex><span><span style=color:#b58900>set</span>(<span style=color:#2aa198>CMAKE_CUDA_STANDARD</span> <span style=color:#2aa198>17</span>)
</span></span><span style=display:flex><span><span style=color:#b58900>set</span>(<span style=color:#2aa198>CMAKE_CUDA_STANDARD_REQUIRED</span> <span style=color:#2aa198>ON</span>)
</span></span><span style=display:flex><span><span style=color:#b58900>set</span>(<span style=color:#2aa198>CMAKE_CUDA_EXTENSIONS</span> <span style=color:#2aa198>OFF</span>)
</span></span><span style=display:flex><span><span style=color:#b58900>add_executable</span>(<span style=color:#2aa198>ray</span> <span style=color:#2aa198>ray_global.cu</span>)
</span></span><span style=display:flex><span><span style=color:#b58900>target_link_libraries</span>(<span style=color:#2aa198>ray</span> <span style=color:#2aa198>GL</span> <span style=color:#2aa198>glut</span>)
</span></span><span style=display:flex><span><span style=color:#586e75>#                         ^^^^^^^
</span></span></span></code></pre></div><h1 id=第-3-章-cuda-源文件>第 3 章 CUDA 源文件
<a class=header-anchor href=#%e7%ac%ac-3-%e7%ab%a0-cuda-%e6%ba%90%e6%96%87%e4%bb%b6></a></h1><p>用 nvcc 编译时不需要为 cuda 内置函数额外包含头文件。这些头文件是在 host 端才需要的。</p><p><a href=https://stackoverflow.com/questions/6302695/difference-between-cuda-h-cuda-runtime-h-cuda-runtime-api-h title=https://stackoverflow.com/questions/6302695/difference-between-cuda-h-cuda-runtime-h-cuda-runtime-api-h rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://stackoverflow.com/questions/6302695/difference-between-cuda-h-cuda-runtime-h-cuda-runtime-api-h<i class="fa fa-external-link-alt"></i></a></p><blockquote><p>In very broad terms:</p><ul><li><code>cuda.h</code> defines the public host functions and types for the CUDA <strong>driver</strong> API.</li><li><code>cuda_runtime_api.h</code> defines the public host functions and types for the CUDA <strong>runtime</strong> API</li><li><code>cuda_runtime.h</code> defines everything <code>cuda_runtime_api.h</code> does, as well as built-in type definitions and function overlays for the CUDA language extensions and device intrinsic functions.</li></ul><p>If you were writing host code to be compiled with the host compiler which includes API calls, you would include either <code>cuda.h</code> or <code>cuda_runtime_api.h</code>. If you needed other CUDA language built-ins, like types, and were using the runtime API and compiling with the host compiler, you would include <code>cuda_runtime.h</code>. If you are writing code which will be compiled using nvcc, it is all irrelevant, because nvcc takes care of inclusion of all the required headers automatically without programmer intervention.</p></blockquote><div class="markdown-alert markdown-alert-warning"><p class=markdown-alert-title><svg class="octicon octicon-alert mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M6.457 1.047c.659-1.234 2.427-1.234 3.086.0l6.082 11.378A1.75 1.75.0 0114.082 15H1.918A1.75 1.75.0 01.375 12.425zm1.763.707a.25.25.0 00-.44.0L1.698 13.132a.25.25.0 00.22.368h12.164a.25.25.0 00.22-.368zm.53 3.996v2.5a.75.75.0 01-1.5.0v-2.5a.75.75.0 011.5.0zM9 11a1 1 0 11-2 0 1 1 0 012 0z"/></svg>Warning</p><p>书中没讲如何编译，需要预备知识。至少要会像 gcc 一样用 nvcc。</p></div><div class="markdown-alert markdown-alert-note"><p class=markdown-alert-title><svg class="octicon octicon-info mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1116 0A8 8 0 010 8zm8-6.5a6.5 6.5.0 100 13 6.5 6.5.0 000-13zM6.5 7.75A.75.75.0 017.25 7h1a.75.75.0 01.75.75v2.75h.25a.75.75.0 010 1.5h-2a.75.75.0 010-1.5h.25v-2h-.25a.75.75.0 01-.75-.75zM8 6a1 1 0 110-2 1 1 0 010 2z"/></svg>Note</p><p>没有 compile_commands.json 时 clangd 反而能够为 cu 文件提供诊断？好像是生成的 compile_commands.json 有太多 clang 无法理解的选项，但是 clang 没有忽略它们，导致了诊断问题。</p></div><div class="markdown-alert markdown-alert-note"><p class=markdown-alert-title><svg class="octicon octicon-info mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1116 0A8 8 0 010 8zm8-6.5a6.5 6.5.0 100 13 6.5 6.5.0 000-13zM6.5 7.75A.75.75.0 017.25 7h1a.75.75.0 01.75.75v2.75h.25a.75.75.0 010 1.5h-2a.75.75.0 010-1.5h.25v-2h-.25a.75.75.0 01-.75-.75zM8 6a1 1 0 110-2 1 1 0 010 2z"/></svg>Note</p><p>遇到了 wsl 中无法在 cmake 中使用 debug（可以直接 run）的情况，原来是没有安装 C/C++ intellisense。同时也只有安装了这个才能在 <code>.cu</code> 文件中打断点。</p><p>不过怎么会没有安装呢？可能是上次 compact 虚拟磁盘之后出现的后遗症。</p></div><h1 id=第-4-章-核函数>第 4 章 核函数
<a class=header-anchor href=#%e7%ac%ac-4-%e7%ab%a0-%e6%a0%b8%e5%87%bd%e6%95%b0></a></h1><blockquote><p>With <code>kernel&lt;&lt;&lt;256,1>>>()</code>, you would get 256 blocks running on the GPU.</p></blockquote><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-c data-lang=c><span style=display:flex><span>dim3 <span style=color:#268bd2>grid</span>(DIM,DIM);
</span></span><span style=display:flex><span>kernel<span style=color:#719e07>&lt;&lt;&lt;</span>grid,<span style=color:#2aa198>1</span><span style=color:#719e07>&gt;&gt;&gt;</span>( dev_bitmap );
</span></span><span style=display:flex><span><span style=color:#586e75>//       ^^^  ^
</span></span></span><span style=display:flex><span><span style=color:#586e75>//  gridDim  blockDim
</span></span></span><span style=display:flex><span><span style=color:#586e75>// =blocks  =threads
</span></span></span><span style=display:flex><span><span style=color:#586e75>//  都是 dim3 类型
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>
</span></span><span style=display:flex><span><span style=color:#586e75>// 用 gridDim.{x,y,z} 来访问 blocks 在该方向上的宽度
</span></span></span><span style=display:flex><span><span style=color:#586e75>// 用 blockIdx.{x,y,z} 来访问从 0 开始的下标
</span></span></span><span style=display:flex><span><span style=color:#586e75>// dim 对应维度，idx 对应下标
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>
</span></span><span style=display:flex><span><span style=color:#586e75>// 这是不是说明一个 kernel 只能在一个 grid 上跑？
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>
</span></span><span style=display:flex><span><span style=color:#586e75>// ...
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>__global__ <span style=color:#dc322f>void</span> <span style=color:#268bd2>kernel</span>( <span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>char</span> <span style=color:#719e07>*</span>ptr ) {
</span></span><span style=display:flex><span>  <span style=color:#586e75>// map from threadIdx/BlockIdx to pixel position
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>  <span style=color:#dc322f>int</span> x <span style=color:#719e07>=</span> blockIdx.x;
</span></span><span style=display:flex><span>  <span style=color:#dc322f>int</span> y <span style=color:#719e07>=</span> blockIdx.y;
</span></span><span style=display:flex><span>  <span style=color:#dc322f>int</span> offset <span style=color:#719e07>=</span> x <span style=color:#719e07>+</span> y <span style=color:#719e07>*</span> gridDim.x;
</span></span><span style=display:flex><span>  <span style=color:#586e75>// ...
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>}
</span></span></code></pre></div><h1 id=第-5-章-高维-dim3-和共享内存>第 5 章 高维 dim3 和共享内存
<a class=header-anchor href=#%e7%ac%ac-5-%e7%ab%a0-%e9%ab%98%e7%bb%b4-dim3-%e5%92%8c%e5%85%b1%e4%ba%ab%e5%86%85%e5%ad%98></a></h1><p><img src=/assets/2524b11c36956aae3baf9bfa59cfe4c5.webp></p><p>每个 block 中的最大线程数是比较小的，在我的 1050 Ti 上是 1024。而 blocks 的数量却可以指定相当多（一般不用担心超限）。所以只用一个 block 完成不了任务时有必要使用多个 blocks。</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#dc322f>int</span> tid <span style=color:#719e07>=</span> threadIdx.x <span style=color:#719e07>+</span> blockIdx.x <span style=color:#719e07>*</span> blockDim.x;
</span></span></code></pre></div><p>创建数量刚刚好的 blocks 和 threads（假设 threadsPerBlock 已经确定为 128）：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-c data-lang=c><span style=display:flex><span>add<span style=color:#719e07>&lt;&lt;&lt;</span> (N<span style=color:#719e07>+</span><span style=color:#2aa198>127</span>)<span style=color:#719e07>/</span><span style=color:#2aa198>128</span>, <span style=color:#2aa198>128</span> <span style=color:#719e07>&gt;&gt;&gt;</span>( dev_a, dev_b, dev_c );
</span></span></code></pre></div><p>如果总线程的数量还是不够，就改成循环，每个线程处理一个以上的元素：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-c data-lang=c><span style=display:flex><span>__global__ <span style=color:#dc322f>void</span> <span style=color:#268bd2>add</span>( <span style=color:#dc322f>int</span> <span style=color:#719e07>*</span>a, <span style=color:#dc322f>int</span> <span style=color:#719e07>*</span>b, <span style=color:#dc322f>int</span> <span style=color:#719e07>*</span>c ) {
</span></span><span style=display:flex><span>  <span style=color:#dc322f>int</span> tid <span style=color:#719e07>=</span> threadIdx.x <span style=color:#719e07>+</span> blockIdx.x <span style=color:#719e07>*</span> blockDim.x;
</span></span><span style=display:flex><span>  <span style=color:#719e07>while</span> (tid <span style=color:#719e07>&lt;</span> N) {
</span></span><span style=display:flex><span>    c[tid] <span style=color:#719e07>=</span> a[tid] <span style=color:#719e07>+</span> b[tid];
</span></span><span style=display:flex><span>    tid <span style=color:#719e07>+=</span> blockDim.x <span style=color:#719e07>*</span> gridDim.x;
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><h2 id=按照输出的形状对线程分组>按照输出的形状对线程分组
<a class=header-anchor href=#%e6%8c%89%e7%85%a7%e8%be%93%e5%87%ba%e7%9a%84%e5%bd%a2%e7%8a%b6%e5%af%b9%e7%ba%bf%e7%a8%8b%e5%88%86%e7%bb%84></a></h2><p>在用上 dim3 的第二维时的偏置计算方式如下（以计算图像上 (x, y) 点的像素颜色为例）：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#dc322f>int</span> x <span style=color:#719e07>=</span> threadIdx.x <span style=color:#719e07>+</span> blockIdx.x <span style=color:#719e07>*</span> blockDim.x;
</span></span><span style=display:flex><span><span style=color:#dc322f>int</span> y <span style=color:#719e07>=</span> threadIdx.y <span style=color:#719e07>+</span> blockIdx.y <span style=color:#719e07>*</span> blockDim.y;
</span></span><span style=display:flex><span><span style=color:#dc322f>int</span> offset <span style=color:#719e07>=</span> x <span style=color:#719e07>+</span> y <span style=color:#719e07>*</span> blockDim.x <span style=color:#719e07>*</span> gridDim.x;
</span></span><span style=display:flex><span><span style=color:#586e75>// 线程的形状是 (gridDim.x, gridDim.y, blockDim.x, blockDim.y)
</span></span></span><span style=display:flex><span><span style=color:#586e75>// 计算任务的输出形状是 (gridDim.x * blockDim.x, gridDim.y * gridDim.y)
</span></span></span></code></pre></div><p><strong>这样看起来计算任务要处理几维就分配几维，这样比较方便</strong>。书中的例子最后巧妙地将 <code>.x</code> 都分给了输出形状的第 0 维，而 <code>.y</code> 是第 1 维。但是维数最多只有 3 维，复杂的计算任务只能用 1 维自己计算映射关系了。</p><p>2024 年 2 月 13 日：注意 offset 的计算方式是 y * &mldr; 而不是 x *，这是因为 CUDA 中线程的分组方式是 z 在 y 的外围，y 在 x 的外围。</p><h2 id=共享内存>共享内存
<a class=header-anchor href=#%e5%85%b1%e4%ba%ab%e5%86%85%e5%ad%98></a></h2><p>用 <code>__shared__</code> 声明要存储在共享内存上的变量。共享内存允许同一个 block 上的线程的同步（<code>__syncthreads()</code>），快于全局内存。也就是 几十 KB 的样子。<strong>共享内存是在核函数中对变量声明的</strong>。</p><p>每个块都有共享内存中变量的私有副本，不同块之间是不能相互访问共享内存的。</p><blockquote><p>Every thread in that block shares the memory, but threads cannot see or modify the copy of this variable that is seen within other blocks.</p></blockquote><p>例子：dot 操作。<mark>略</mark></p><p>比较经典。</p><p>例子：dot 操作的错误优化。<mark>略</mark></p><div class="markdown-alert markdown-alert-note"><p class=markdown-alert-title><svg class="octicon octicon-info mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1116 0A8 8 0 010 8zm8-6.5a6.5 6.5.0 100 13 6.5 6.5.0 000-13zM6.5 7.75A.75.75.0 017.25 7h1a.75.75.0 01.75.75v2.75h.25a.75.75.0 010 1.5h-2a.75.75.0 010-1.5h.25v-2h-.25a.75.75.0 01-.75-.75zM8 6a1 1 0 110-2 1 1 0 010 2z"/></svg>Note</p><p>也有 <code>__syncwarp</code> 函数。</p><p>为什么需要 sync warp，warp 中的线程不是按照一个步调执行的吗？这个特性在 CUDA 9 出现，它对于 divergent warps 有用，并且 Volta 架构已经支持了 warp 内的乱序执行。</p></div></div><footer class=post-footer><div class=post-tags><a href=/tags/cuda>cuda
</a><a href=/tags/cuda-by-example>cuda-by-example</a></div><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/cuda-by-example/CUDA-by-Example-%E9%99%84%E5%BD%95/ rel=next title="CUDA by Example: Appendex"><i class="fa fa-chevron-left"></i> CUDA by Example: Appendex</a></div><div class="post-nav-prev post-nav-item"><a href=/cuda-by-example/CUDA-by-Example-chapter06-08/ rel=prev title="CUDA by Example: Chapter 06-08">CUDA by Example: Chapter 06-08
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>&copy;
<span itemprop=copyrightYear>2023 - 2025
</span><span class=with-love><i class="fa fa-heart"></i>
</span><span class=author itemprop=copyrightHolder>🤖</span></div><div class=powered-by>由 <a href=https://gohugo.io title=0.143.1 target=_blank>Hugo</a> & <a href=https://github.com/hugo-next/hugo-theme-next title=4.5.3 target=_blank>Hugo NexT.Gemini</a> 强力驱动</div></div></footer><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js defer></script><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js defer></script><script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":false,"save":"manual"},"copybtn":true,"darkmode":false,"hostname":"https://hxhue.github.io/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"找到 ${hits} 个搜索结果","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"limit":1e3,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":false,"transition":{"collheader":"fadeInLeft","menu_item":"fadeInDown","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"postmeta":{"comments":{"enable":false,"plugin":"waline"},"views":{"enable":false,"plugin":"busuanzi"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"vendor":{"plugins":"cdnjs","router":"https://cdnjs.cloudflare.com/ajax/libs"},"version":"4.5.3"}</script><script type=text/javascript src=/js/main.min.37ba8b54f9d4d784d08028c45eea93b5d4e13eda8ee7fb0d2edd6f3fac66cfd2.js defer></script></body></html>