<!doctype html><html lang=zh-CN data-theme=light><head><meta charset=UTF-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: light)"><meta name=generator content="Hugo 0.143.1"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="5.1 libstdc++ 对共享指针原子操作的支持"><meta itemprop=description content="个人博客，主要是零散的笔记。"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="https://hxhue.github.io/imgs/371907.jpg"><meta itemprop=keywords content="cpp,cpp-concurrency-in-action,libstdcxx"><link type=text/css rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css><link rel=stylesheet href=/css/main.min.bea76f574a755574e17d42bea39502a74ca3ca4db65807b8c82d3e26dcec8420.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><link rel=stylesheet type=text/css href=/css/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/github-markdown-css@5.3.0/github-markdown-dark.css><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script><script>MathJax={tex:{displayMath:[["$$","$$"],["\\[","\\]"]],inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: false });
  mermaid.mermaidAPI.initialize();
  window.mermaid = mermaid;
</script><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"path":"5.1-libstdc++-%E5%AF%B9%E5%85%B1%E4%BA%AB%E6%8C%87%E9%92%88%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%9A%84%E6%94%AF%E6%8C%81","permalink":"https://hxhue.github.io/cpp-concurrency-in-action/5.1-libstdc++-%E5%AF%B9%E5%85%B1%E4%BA%AB%E6%8C%87%E9%92%88%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%9A%84%E6%94%AF%E6%8C%81/","title":"5.1 libstdc++ 对共享指针原子操作的支持","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>5.1 libstdc++ 对共享指针原子操作的支持 - Bluegill</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Bluegill</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description></p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about/ class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档</a></li><li class="menu-item menu-item-categories"><a href=/categories/ class=hvr-icon-pulse rel=section><i class="fa fa-th hvr-icon"></i>分类</a></li><li class="menu-item menu-item-tags"><a href=/tags/ class=hvr-icon-pulse rel=section><i class="fa fa-hashtag hvr-icon"></i>标签</a></li><li class="menu-item menu-item-daily"><a href=/daily/ class=hvr-icon-pulse rel=section><i class="fa fa-newspaper hvr-icon"></i>随笔</a></li><li class="menu-item menu-item-discovery"><a href=https://rift-fear-f2c.notion.site/2025-1e354a33cfb1802c841bdf29f2f3dab3 class=hvr-icon-pulse rel=section><i class="fa fa-compass hvr-icon"></i>发现</a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><a href=#引言>引言</a></li><li><a href=#原子操作自由函数>原子操作自由函数</a></li><li><a href=#原子模板类对共享指针的偏特化>原子模板类对共享指针的偏特化</a></li><li><a href=#benchmark-实验>Benchmark 实验</a><ul><li><a href=#两种实现的性能比较>两种实现的性能比较</a></li><li><a href=#互斥量池对性能的影响>互斥量池对性能的影响</a></li><li><a href=#画折线图看趋势>画折线图看趋势</a></li></ul></li><li><a href=#perf-实验>Perf 实验</a></li><li><a href=#总结>总结</a></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=🤖 src=/imgs/371907.jpg><p class=site-author-name itemprop=name>🤖</p><div class=site-description itemprop=description>个人博客，主要是零散的笔记。</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>433</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>12</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>86</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/hxhue title="Github → https://github.com/hxhue" rel=noopener target=_blank><i class="fab fa-github fa-fw"></i>
Github
</a></span><span class=links-of-social-item><a href=/rss.xml title="RSS 订阅 → /rss.xml" rel=noopener target=_blank><i class="fa fa-rss fa-fw"></i>
RSS 订阅</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>
友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://shuai.guru/ title=https://shuai.guru/ target=_blank>shuai.guru</a></li></ul></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=https://hxhue.github.io/cpp-concurrency-in-action/5.1-libstdc++-%E5%AF%B9%E5%85%B1%E4%BA%AB%E6%8C%87%E9%92%88%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%9A%84%E6%94%AF%E6%8C%81/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/imgs/371907.jpg"><meta itemprop=name content="🤖"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="🤖"><meta itemprop=description content="个人博客，主要是零散的笔记。"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="5.1 libstdc++ 对共享指针原子操作的支持"><meta itemprop=description content="引言

这篇笔记是承接 
  
  
    
    
    
    
    
    
    
    
    
    
    
    CppCon 2023 Lock-free Atomic Shared Pointers Without a Split Reference Count 和 
  
  
    
    
    
    
    
    
    
    
    
    
    
    内存模型基础、标准原子类型、自旋锁 来写的。
C++20 有 std::atomic<std::shared_ptr> 和 std::atomic<std::weak_ptr> 的偏特化，之前连这两个偏特化都没有，因而会编译错误（std::atomic requires a trivially copyable type），只能使用对共享指针提供的原子操作自由函数（std::atomic_*）。但是这样的类型并不是无锁的，可以通过 is_lock_free() 的返回值看出来，见 https://godbolt.org/z/b5P84jM9f 。根据 Daniel1 的幻灯片，MSVC 和 libstdc++ 中这两个类型都是有锁；根据我的查证，libc++ 截至 2025 年 1 月 5 日还没有实现这两个偏特化。"></span><header class=post-header><h1 class=post-title itemprop="name headline">5.1 libstdc++ 对共享指针原子操作的支持</h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i>
</span><span class=post-meta-item-text title=发表于>发表于：
</span><time title="创建时间：2025-01-05 00:00:00 +0800 CST" itemprop="dateCreated datePublished" datetime="2025-01-05 00:00:00 +0800 CST">2025-01-05
</time></span><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar-check"></i>
</span><span class=post-meta-item-text title=更新于>更新于：
</span><time title=修改时间：2025-01-25T00:00:00+08:00 itemprop=dateModified datetime=2025-01-25T00:00:00+08:00>2025-01-25</time>
</span><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i>
</span><span class=post-meta-item-text title=分类于>分类于：
</span><span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/cpp-concurrency-in-action itemprop=url rel=index><span itemprop=name>cpp-concurrency-in-action</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i>
</span><span class=post-meta-item-text>字数：</span>
<span>3928</span>
</span><span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i>
</span><span class=post-meta-item-text>阅读：&ap;</span>
<span>8分钟</span></span></div></div></header><div class=post-body itemprop=articleBody><h1 id=引言>引言
<a class=header-anchor href=#%e5%bc%95%e8%a8%80></a></h1><p>这篇笔记是承接
<a href=/cppcon-talks/CppCon-2023-Lock-free-Atomic-Shared-Pointers-Without-a-Split-Reference-Count/ title="CppCon 2023 Lock-free Atomic Shared Pointers Without a Split Reference Count">CppCon 2023 Lock-free Atomic Shared Pointers Without a Split Reference Count</a> 和
<a href=/cpp-concurrency-in-action/5.-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E6%A0%87%E5%87%86%E5%8E%9F%E5%AD%90%E7%B1%BB%E5%9E%8B%E8%87%AA%E6%97%8B%E9%94%81/ title=内存模型基础、标准原子类型、自旋锁>内存模型基础、标准原子类型、自旋锁</a> 来写的。</p><p>C++20 有 <a href=https://en.cppreference.com/w/cpp/memory/shared_ptr/atomic2 title="std::atomic<std::shared_ptr>" rel="noopener external nofollow noreferrer" target=_blank class=exturl><code>std::atomic&lt;std::shared_ptr></code><i class="fa fa-external-link-alt"></i></a> 和 <a href=https://en.cppreference.com/w/cpp/memory/weak_ptr/atomic2 title="std::atomic<std::weak_ptr>" rel="noopener external nofollow noreferrer" target=_blank class=exturl><code>std::atomic&lt;std::weak_ptr></code><i class="fa fa-external-link-alt"></i></a> 的偏特化，之前连这两个偏特化都没有，因而会编译错误（<code>std::atomic</code> requires a trivially copyable type），只能使用对共享指针提供的<strong>原子操作自由函数</strong>（<code>std::atomic_*</code>）。但是这样的类型并不是无锁的，可以通过 <code>is_lock_free()</code> 的返回值看出来，见 <a href=https://godbolt.org/z/b5P84jM9f title=https://godbolt.org/z/b5P84jM9f rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://godbolt.org/z/b5P84jM9f<i class="fa fa-external-link-alt"></i></a> 。根据 Daniel<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup> 的幻灯片，MSVC 和 libstdc++ 中这两个类型都是有锁；根据我的查证，libc++ 截至 2025 年 1 月 5 日还没有实现这两个偏特化。</p><p>既然知道有锁了，libstdc++ 是怎么实现共享指针原子变量的线程安全访问的呢？</p><h1 id=原子操作自由函数>原子操作自由函数
<a class=header-anchor href=#%e5%8e%9f%e5%ad%90%e6%93%8d%e4%bd%9c%e8%87%aa%e7%94%b1%e5%87%bd%e6%95%b0></a></h1><p>C++20 之前原子操作自由函数对 <code>std::shared_ptr&lt;T></code> 的支持可见 <a href=https://github.com/gcc-mirror/gcc/blob/a0aa30fc920dffdb114de8a9b1bec54dcf7590af/libstdc%2B%2B-v3/include/bits/shared_ptr_atomic.h#L133 title=atomic_load_explicit rel="noopener external nofollow noreferrer" target=_blank class=exturl><code>atomic_load_explicit</code><i class="fa fa-external-link-alt"></i></a> 和 <a href=https://github.com/gcc-mirror/gcc/blob/a0aa30fc920dffdb114de8a9b1bec54dcf7590af/libstdc%2B%2B-v3/src/c%2B%2B11/shared_ptr.cc#L69-L78 title=_Sp_locker rel="noopener external nofollow noreferrer" target=_blank class=exturl><code>_Sp_locker</code><i class="fa fa-external-link-alt"></i></a>，<strong>它对指针值做 hash，得到互斥量池里的一个下标，从而获取一个 <code>__gnu_cxx::__mutex</code> 的引用</strong>。可以参考 <a href=https://github.com/gcc-mirror/gcc/blob/a0aa30fc920dffdb114de8a9b1bec54dcf7590af/libstdc%2B%2B-v3/src/c%2B%2B11/shared_ptr.cc#L27-L50 title=以下代码 rel="noopener external nofollow noreferrer" target=_blank class=exturl>以下代码<i class="fa fa-external-link-alt"></i></a>。</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#586e75>// shared_ptr.cc
</span></span></span><span style=display:flex><span><span style=color:#586e75></span><span style=color:#719e07>#include</span> <span style=color:#719e07>&#34;mutex_pool.h&#34;</span><span style=color:#719e07>
</span></span></span><span style=display:flex><span><span style=color:#719e07></span>
</span></span><span style=display:flex><span><span style=color:#719e07>namespace</span> __gnu_internal <span style=color:#268bd2>_GLIBCXX_VISIBILITY</span>(hidden)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#586e75>/* Returns different instances of __mutex depending on the passed index
</span></span></span><span style=display:flex><span><span style=color:#586e75>   * in order to limit contention.
</span></span></span><span style=display:flex><span><span style=color:#586e75>   */</span>
</span></span><span style=display:flex><span>  __gnu_cxx<span style=color:#719e07>::</span>__mutex<span style=color:#719e07>&amp;</span>
</span></span><span style=display:flex><span>  get_mutex(<span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>char</span> i)
</span></span><span style=display:flex><span>  {
</span></span><span style=display:flex><span><span style=color:#719e07>#ifdef _GLIBCXX_CAN_ALIGNAS_DESTRUCTIVE_SIZE
</span></span></span><span style=display:flex><span><span style=color:#719e07></span>    <span style=color:#586e75>// Increase alignment to put each lock on a separate cache line.
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#719e07>struct</span> <span style=color:#268bd2>alignas</span>(__GCC_DESTRUCTIVE_SIZE) M : __gnu_cxx<span style=color:#719e07>::</span>__mutex { };
</span></span><span style=display:flex><span><span style=color:#719e07>#else
</span></span></span><span style=display:flex><span><span style=color:#719e07></span>    <span style=color:#719e07>using</span> M <span style=color:#719e07>=</span> __gnu_cxx<span style=color:#719e07>::</span>__mutex;
</span></span><span style=display:flex><span><span style=color:#719e07>#endif
</span></span></span><span style=display:flex><span><span style=color:#719e07></span>    <span style=color:#586e75>// Use a static buffer, so that the mutexes are not destructed
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#586e75>// before potential users (or at all)
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#719e07>static</span> __attribute__ ((aligned(__alignof__(M))))
</span></span><span style=display:flex><span>      <span style=color:#dc322f>char</span> buffer[(<span style=color:#719e07>sizeof</span> (M)) <span style=color:#719e07>*</span> (mask <span style=color:#719e07>+</span> <span style=color:#2aa198>1</span>)];
</span></span><span style=display:flex><span>    <span style=color:#719e07>static</span> M <span style=color:#719e07>*</span>m <span style=color:#719e07>=</span> <span style=color:#719e07>new</span> (buffer) M[mask <span style=color:#719e07>+</span> <span style=color:#2aa198>1</span>];
</span></span><span style=display:flex><span>    <span style=color:#719e07>return</span> m[i];
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#586e75>// mutex_pool.h
</span></span></span><span style=display:flex><span><span style=color:#586e75></span><span style=color:#719e07>namespace</span> __gnu_internal <span style=color:#268bd2>_GLIBCXX_VISIBILITY</span>(hidden)
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#719e07>const</span> <span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>char</span> mask <span style=color:#719e07>=</span> <span style=color:#2aa198>0xf</span>;
</span></span><span style=display:flex><span>  <span style=color:#719e07>const</span> <span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>char</span> invalid <span style=color:#719e07>=</span> mask <span style=color:#719e07>+</span> <span style=color:#2aa198>1</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  <span style=color:#586e75>/* Returns different instances of __mutex depending on the passed index
</span></span></span><span style=display:flex><span><span style=color:#586e75>   * in order to limit contention.
</span></span></span><span style=display:flex><span><span style=color:#586e75>   */</span>
</span></span><span style=display:flex><span>  __gnu_cxx<span style=color:#719e07>::</span>__mutex<span style=color:#719e07>&amp;</span> get_mutex(<span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>char</span> i);
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>在这段代码里面，<code>unsigned char i</code> 限制了互斥量池的最大大小为 256。而实际上 <code>mask</code> 为 <code>0xf</code>，说明<strong>互斥量池的大小为 16</strong>。哈希 + 池化的模式还可见于
<a href=/cpp-concurrency-in-action/5.0.2-%E9%98%85%E8%AF%BB-libstdc++-%E4%B8%AD%E5%8E%9F%E5%AD%90%E5%8F%98%E9%87%8F-wait-%E5%92%8C-notify-%E6%8E%A5%E5%8F%A3/#notify-%e7%9a%84%e5%ae%9e%e7%8e%b0 title="libstdc++ 原子变量 wait 和 notify 的实现">libstdc++ 原子变量 <code>wait</code> 和 <code>notify</code> 的实现</a>。</p><h1 id=原子模板类对共享指针的偏特化>原子模板类对共享指针的偏特化
<a class=header-anchor href=#%e5%8e%9f%e5%ad%90%e6%a8%a1%e6%9d%bf%e7%b1%bb%e5%af%b9%e5%85%b1%e4%ba%ab%e6%8c%87%e9%92%88%e7%9a%84%e5%81%8f%e7%89%b9%e5%8c%96></a></h1><p>C++20 <code>std::atomic&lt;std::shared_ptr&lt;T>></code> 的实现参考 <a href=https://github.com/gcc-mirror/gcc/blob/a0aa30fc920dffdb114de8a9b1bec54dcf7590af/libstdc%2B%2B-v3/include/bits/shared_ptr_atomic.h#L391-L400 title=shared_ptr_atomic.h rel="noopener external nofollow noreferrer" target=_blank class=exturl><code>shared_ptr_atomic.h</code><i class="fa fa-external-link-alt"></i></a>。</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#719e07>template</span><span style=color:#719e07>&lt;</span><span style=color:#719e07>typename</span> _Tp<span style=color:#719e07>&gt;</span>
</span></span><span style=display:flex><span><span style=color:#719e07>struct</span> <span style=color:#268bd2>_Sp_atomic</span> { <span style=color:#586e75>// 假设 64 位环境，16 字节
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#586e75>// ...
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#586e75>// An atomic version of __shared_count&lt;&gt; and __weak_count&lt;&gt;.
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#586e75>// Stores a _Sp_counted_base&lt;&gt;* but uses the LSB as a lock.
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#719e07>struct</span> <span style=color:#268bd2>_Atomic_count</span> <span style=color:#586e75>// 8 字节
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>      {
</span></span><span style=display:flex><span>      <span style=color:#719e07>private</span><span style=color:#719e07>:</span>
</span></span><span style=display:flex><span>        <span style=color:#586e75>// 里面实际上是存储了一个指针，并且最低位有特殊含义。
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>        <span style=color:#586e75>// 因为 atomic 模板类对指针类型有偏特化，而这里需要直接操作位表示，
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>        <span style=color:#586e75>// 所以存储选择 uintptr_t 类型。
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    	<span style=color:#719e07>mutable</span> __atomic_base<span style=color:#719e07>&lt;</span>uintptr_t<span style=color:#719e07>&gt;</span> _M_val{<span style=color:#2aa198>0</span>}; <span style=color:#586e75>// 8 字节
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    	<span style=color:#719e07>static</span> <span style=color:#719e07>constexpr</span> uintptr_t _S_lock_bit{<span style=color:#2aa198>1</span>};  <span style=color:#586e75>// 注意是静态，在实例中不占空间
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>      };
</span></span><span style=display:flex><span><span style=color:#719e07>private</span><span style=color:#719e07>:</span>
</span></span><span style=display:flex><span>    <span style=color:#719e07>typename</span> _Tp<span style=color:#719e07>::</span>element_type<span style=color:#719e07>*</span> _M_ptr <span style=color:#719e07>=</span> <span style=color:#719e07>nullptr</span>; <span style=color:#586e75>// 8 字节
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    _Atomic_count _M_refcount;                    <span style=color:#586e75>// 8 字节
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>};
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#719e07>template</span><span style=color:#719e07>&lt;</span><span style=color:#719e07>typename</span> _Tp<span style=color:#719e07>&gt;</span>
</span></span><span style=display:flex><span><span style=color:#719e07>struct</span> <span style=color:#268bd2>atomic</span><span style=color:#719e07>&lt;</span>shared_ptr<span style=color:#719e07>&lt;</span>_Tp<span style=color:#719e07>&gt;&gt;</span> {
</span></span><span style=display:flex><span>    <span style=color:#586e75>// ...
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#586e75>// 将实现转发到 _M_impl 上
</span></span></span><span style=display:flex><span><span style=color:#586e75></span><span style=color:#719e07>private</span><span style=color:#719e07>:</span>
</span></span><span style=display:flex><span>    _Sp_atomic<span style=color:#719e07>&lt;</span>shared_ptr<span style=color:#719e07>&lt;</span>_Tp<span style=color:#719e07>&gt;&gt;</span> _M_impl;
</span></span><span style=display:flex><span>};
</span></span></code></pre></div><p>每次对 <code>_Sp_atomic</code> 操作都要调用 <code>_M_refcount.lock()</code> 来上锁。上锁的过程首先是循环等待锁空闲，然后是在循环中调用 <a href=https://github.com/gcc-mirror/gcc/blob/a0aa30fc920dffdb114de8a9b1bec54dcf7590af/libstdc%2B%2B-v3/include/bits/shared_ptr_atomic.h#L456-L459 title=compare_exchange_strong rel="noopener external nofollow noreferrer" target=_blank class=exturl><code>compare_exchange_strong</code><i class="fa fa-external-link-alt"></i></a>，<strong>可以看出是自旋锁</strong>。对引用计数块上锁之后才能得到其指针，此时 <code>__atomic_base&lt;uintptr_t></code> 的锁标志已被去除，以指针的形式从 <code>lock()</code> 中返回。</p><h1 id=benchmark-实验>Benchmark 实验
<a class=header-anchor href=#benchmark-%e5%ae%9e%e9%aa%8c></a></h1><h2 id=两种实现的性能比较>两种实现的性能比较
<a class=header-anchor href=#%e4%b8%a4%e7%a7%8d%e5%ae%9e%e7%8e%b0%e7%9a%84%e6%80%a7%e8%83%bd%e6%af%94%e8%be%83></a></h2><p>现在来比较一下原子操作自由函数（互斥量）和原子变量偏特化（自旋锁）两种方案的性能。先创建多个线程，每个线程都会进行若干次先读后写的操作，测量两种方案下的执行时间。</p><p>在 quick-bench 下进行测试，在单线程或者循环次数比较少的时候，都是互斥量的性能更优。好像这个网站没有给多核？而且 benchmark 的 CPU 时间应该不能和程序实际运行时间等价。虽然结果没多大意义，但既然做过实验了还是放一下结果。（代码也在链接里面，就不单独列代码了。）</p><div style=overflow-x:auto><table><thead><tr><th>线程数</th><th>循环次数</th><th>原子操作自由函数 CPU 时间</th><th>原子变量偏特化 CPU 时间</th><th>链接</th></tr></thead><tbody><tr><td>1</td><td>1000</td><td><strong>47,210.516</strong></td><td>48,898.659</td><td><a href=https://quick-bench.com/q/-GlB8zwmpVm0wxUHqMD1flX8S80 title=https://quick-bench.com/q/-GlB8zwmpVm0wxUHqMD1flX8S80 rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://quick-bench.com/q/-GlB8zwmpVm0wxUHqMD1flX8S80<i class="fa fa-external-link-alt"></i></a></td></tr><tr><td>2</td><td>1000</td><td>90,009.0489</td><td><strong>81,656.665</strong></td><td><a href=https://quick-bench.com/q/jtVQkUQCDV9ZqkJpTHdqJZ1X-fY title=https://quick-bench.com/q/jtVQkUQCDV9ZqkJpTHdqJZ1X-fY rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://quick-bench.com/q/jtVQkUQCDV9ZqkJpTHdqJZ1X-fY<i class="fa fa-external-link-alt"></i></a></td></tr><tr><td>4</td><td>1000</td><td>230,958.147</td><td><strong>208,060.813</strong></td><td><a href=https://quick-bench.com/q/Zq3g98LNhSXXFcK_162RNjb-FtM title=https://quick-bench.com/q/Zq3g98LNhSXXFcK_162RNjb-FtM rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://quick-bench.com/q/Zq3g98LNhSXXFcK_162RNjb-FtM<i class="fa fa-external-link-alt"></i></a></td></tr><tr><td>8</td><td>1000</td><td>672,488.446</td><td><strong>664,635.097</strong></td><td><a href=https://quick-bench.com/q/r07L7P2jwAJxU8CPXb81gV-uoJo title=https://quick-bench.com/q/r07L7P2jwAJxU8CPXb81gV-uoJo rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://quick-bench.com/q/r07L7P2jwAJxU8CPXb81gV-uoJo<i class="fa fa-external-link-alt"></i></a></td></tr><tr><td>10</td><td>1</td><td><strong>620,372.601</strong></td><td>638,603.319</td><td><a href=https://quick-bench.com/q/AnEMoJYRCGnTZyzmiIRB8n6zpCE title=https://quick-bench.com/q/AnEMoJYRCGnTZyzmiIRB8n6zpCE rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://quick-bench.com/q/AnEMoJYRCGnTZyzmiIRB8n6zpCE<i class="fa fa-external-link-alt"></i></a></td></tr><tr><td>10</td><td>10</td><td>752,338.154</td><td><strong>719,752.91</strong></td><td><a href=https://quick-bench.com/q/8Ee42qG9eRaT6p5Ykj-FuBM-WPQ title=https://quick-bench.com/q/8Ee42qG9eRaT6p5Ykj-FuBM-WPQ rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://quick-bench.com/q/8Ee42qG9eRaT6p5Ykj-FuBM-WPQ<i class="fa fa-external-link-alt"></i></a></td></tr><tr><td>10</td><td>100</td><td>646,976.937</td><td><strong>637,434.736</strong></td><td><a href=https://quick-bench.com/q/we2LIuMsreMqNRAAE0BzxDp_3ZI title=https://quick-bench.com/q/we2LIuMsreMqNRAAE0BzxDp_3ZI rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://quick-bench.com/q/we2LIuMsreMqNRAAE0BzxDp_3ZI<i class="fa fa-external-link-alt"></i></a></td></tr><tr><td>10</td><td>1000</td><td>682,937.478</td><td><strong>652,523.314</strong></td><td><a href=https://quick-bench.com/q/xNdy-7OXeRTvoBh82i7LmUMk8cw title=https://quick-bench.com/q/xNdy-7OXeRTvoBh82i7LmUMk8cw rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://quick-bench.com/q/xNdy-7OXeRTvoBh82i7LmUMk8cw<i class="fa fa-external-link-alt"></i></a></td></tr><tr><td>10</td><td>10000</td><td>🚀 <strong>844,765.936</strong></td><td>1,098,030.509</td><td><a href=https://quick-bench.com/q/5Gjos6rN3K2H94PFde5tc_VFmO8 title=https://quick-bench.com/q/5Gjos6rN3K2H94PFde5tc_VFmO8 rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://quick-bench.com/q/5Gjos6rN3K2H94PFde5tc_VFmO8<i class="fa fa-external-link-alt"></i></a></td></tr></tbody></table></div><p>为了验证多核环境下的情况，我在笔记本上重新了试了一下。CPU 是 6 + 8 + 2 的第一代 Ultra 9，环境是 WSL2 + Debian 12，GCC 版本为 12.2.0。编译使用 CMake 的 Release 配置，即 <code>-O3</code>。安装 benchmark 库或者将其作为 CMake 的第三方依赖都可以。</p><div style=overflow-x:auto><table><thead><tr><th>线程数</th><th>循环次数</th><th>原子操作自由函数实际时间</th><th>原子变量偏特化实际时间</th></tr></thead><tbody><tr><td>1</td><td>1000</td><td>90960 ns</td><td>🚀 <strong>79325 ns</strong></td></tr><tr><td>2</td><td>1000</td><td>313173 ns</td><td>🚀 <strong>218804 ns</strong></td></tr><tr><td>4</td><td>1000</td><td>🚀 <strong>553431 ns</strong></td><td>930307 ns</td></tr><tr><td>8</td><td>1000</td><td>🚀 <strong>1382092 ns</strong></td><td>3317335 ns</td></tr><tr><td>10</td><td>1</td><td><strong>305089 ns</strong></td><td>316985 ns</td></tr><tr><td>10</td><td>10</td><td><strong>326326 ns</strong></td><td>342686 ns</td></tr><tr><td>10</td><td>100</td><td>314011 ns</td><td><strong>311332 ns</strong></td></tr><tr><td>10</td><td>1000</td><td>🚀 <strong>1974462 ns</strong></td><td>4842926 ns</td></tr><tr><td>10</td><td>10000</td><td>🚀 <strong>22828557 ns</strong></td><td>60812315 ns</td></tr></tbody></table></div><p>竞争稍微增多一点就是互斥量实现性能更优，基本印证了
<a href=/cpp-concurrency-in-action/5.-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E6%A0%87%E5%87%86%E5%8E%9F%E5%AD%90%E7%B1%BB%E5%9E%8B%E8%87%AA%E6%97%8B%E9%94%81/#%e8%a6%81%e4%b8%8d%e8%a6%81%e4%bd%bf%e7%94%a8%e8%87%aa%e6%97%8b%e9%94%81 title=要不要使用自旋锁>要不要使用自旋锁</a> 中的说法：在用户空间实现自旋锁还不如使用 <code>std::mutex</code>。</p><h2 id=互斥量池对性能的影响>互斥量池对性能的影响
<a class=header-anchor href=#%e4%ba%92%e6%96%a5%e9%87%8f%e6%b1%a0%e5%af%b9%e6%80%a7%e8%83%bd%e7%9a%84%e5%bd%b1%e5%93%8d></a></h2><p>之前共享指针的原子操作自由函数还有一点令人在意，就是我看到的 libstdc++ 代码里面用了互斥量池。所有共享指针使用同一个互斥量池，而不是每个共享指针实例独占一个互斥量，是否会对性能产生影响？</p><p>代码如下：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#719e07>#include</span> <span style=color:#719e07>&lt;benchmark/benchmark.h&gt;</span><span style=color:#719e07>
</span></span></span><span style=display:flex><span><span style=color:#719e07>#include</span> <span style=color:#719e07>&lt;memory&gt;</span><span style=color:#719e07>
</span></span></span><span style=display:flex><span><span style=color:#719e07>#include</span> <span style=color:#719e07>&lt;atomic&gt;</span><span style=color:#719e07>
</span></span></span><span style=display:flex><span><span style=color:#719e07>#include</span> <span style=color:#719e07>&lt;thread&gt;</span><span style=color:#719e07>
</span></span></span><span style=display:flex><span><span style=color:#719e07>#include</span> <span style=color:#719e07>&lt;vector&gt;</span><span style=color:#719e07>
</span></span></span><span style=display:flex><span><span style=color:#719e07>#include</span> <span style=color:#719e07>&lt;mutex&gt;</span><span style=color:#719e07>
</span></span></span><span style=display:flex><span><span style=color:#719e07></span>
</span></span><span style=display:flex><span><span style=color:#586e75>// 可调整的常量
</span></span></span><span style=display:flex><span><span style=color:#586e75></span><span style=color:#719e07>const</span> <span style=color:#dc322f>int</span> N_THREADS <span style=color:#719e07>=</span> <span style=color:#2aa198>8</span>;       <span style=color:#586e75>// 线程数
</span></span></span><span style=display:flex><span><span style=color:#586e75></span><span style=color:#719e07>const</span> <span style=color:#dc322f>int</span> N_SHARED_PTRS <span style=color:#719e07>=</span> <span style=color:#2aa198>4</span>;   <span style=color:#586e75>// 共享指针数
</span></span></span><span style=display:flex><span><span style=color:#586e75></span><span style=color:#719e07>const</span> <span style=color:#dc322f>int</span> N_OPERATIONS <span style=color:#719e07>=</span> <span style=color:#2aa198>1000</span>; <span style=color:#586e75>// 每个线程的操作次数
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>
</span></span><span style=display:flex><span><span style=color:#586e75>// 共享指针数组
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>std<span style=color:#719e07>::</span>vector<span style=color:#719e07>&lt;</span>std<span style=color:#719e07>::</span>shared_ptr<span style=color:#719e07>&lt;</span><span style=color:#dc322f>int</span><span style=color:#719e07>&gt;&gt;</span> shared_ptrs(N_SHARED_PTRS);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75>// 用于保护共享指针的互斥锁数组
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>std<span style=color:#719e07>::</span>vector<span style=color:#719e07>&lt;</span>std<span style=color:#719e07>::</span>mutex<span style=color:#719e07>&gt;</span> mutexes(N_SHARED_PTRS);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75>// 初始化共享指针（只执行一次）
</span></span></span><span style=display:flex><span><span style=color:#586e75></span><span style=color:#dc322f>void</span> <span style=color:#268bd2>initialize_shared_ptrs</span>() {
</span></span><span style=display:flex><span>    <span style=color:#719e07>for</span> (<span style=color:#dc322f>int</span> i <span style=color:#719e07>=</span> <span style=color:#2aa198>0</span>; i <span style=color:#719e07>&lt;</span> N_SHARED_PTRS; <span style=color:#719e07>++</span>i) {
</span></span><span style=display:flex><span>        shared_ptrs[i] <span style=color:#719e07>=</span> std<span style=color:#719e07>::</span>make_shared<span style=color:#719e07>&lt;</span><span style=color:#dc322f>int</span><span style=color:#719e07>&gt;</span>(<span style=color:#2aa198>0</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75>// 使用 std::atomic_load 和 std::atomic_store
</span></span></span><span style=display:flex><span><span style=color:#586e75></span><span style=color:#719e07>static</span> <span style=color:#dc322f>void</span> <span style=color:#268bd2>BM_AtomicLoadStore</span>(benchmark<span style=color:#719e07>::</span>State<span style=color:#719e07>&amp;</span> state) {
</span></span><span style=display:flex><span>    <span style=color:#586e75>// 初始化共享指针（只执行一次）
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    initialize_shared_ptrs();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#719e07>for</span> (<span style=color:#719e07>auto</span> _ : state) {
</span></span><span style=display:flex><span>        std<span style=color:#719e07>::</span>vector<span style=color:#719e07>&lt;</span>std<span style=color:#719e07>::</span><span style=color:#268bd2>thread</span><span style=color:#719e07>&gt;</span> threads;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#586e75>// 创建线程
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>        <span style=color:#719e07>for</span> (<span style=color:#dc322f>int</span> i <span style=color:#719e07>=</span> <span style=color:#2aa198>0</span>; i <span style=color:#719e07>&lt;</span> N_THREADS; <span style=color:#719e07>++</span>i) {
</span></span><span style=display:flex><span>            threads.emplace_back([i]() {
</span></span><span style=display:flex><span>                <span style=color:#dc322f>int</span> ptr_index <span style=color:#719e07>=</span> i <span style=color:#719e07>%</span> N_SHARED_PTRS; <span style=color:#586e75>// 分配给线程的共享指针索引
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>                <span style=color:#719e07>for</span> (<span style=color:#dc322f>int</span> j <span style=color:#719e07>=</span> <span style=color:#2aa198>0</span>; j <span style=color:#719e07>&lt;</span> N_OPERATIONS; <span style=color:#719e07>++</span>j) {
</span></span><span style=display:flex><span>                    <span style=color:#719e07>auto</span> local_ptr <span style=color:#719e07>=</span> std<span style=color:#719e07>::</span>atomic_load(<span style=color:#719e07>&amp;</span>shared_ptrs[ptr_index]);
</span></span><span style=display:flex><span>                    std<span style=color:#719e07>::</span>atomic_store(<span style=color:#719e07>&amp;</span>shared_ptrs[ptr_index], 
</span></span><span style=display:flex><span>                        std<span style=color:#719e07>::</span>make_shared<span style=color:#719e07>&lt;</span><span style=color:#dc322f>int</span><span style=color:#719e07>&gt;</span>(<span style=color:#719e07>*</span>local_ptr <span style=color:#719e07>+</span> <span style=color:#2aa198>1</span>));
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>            });
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#586e75>// 等待所有线程完成
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>        <span style=color:#719e07>for</span> (<span style=color:#719e07>auto</span><span style=color:#719e07>&amp;</span> t : threads) {
</span></span><span style=display:flex><span>            t.join();
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>BENCHMARK(BM_AtomicLoadStore);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75>// 使用 std::mutex 保护共享指针
</span></span></span><span style=display:flex><span><span style=color:#586e75></span><span style=color:#719e07>static</span> <span style=color:#dc322f>void</span> <span style=color:#268bd2>BM_MutexProtected</span>(benchmark<span style=color:#719e07>::</span>State<span style=color:#719e07>&amp;</span> state) {
</span></span><span style=display:flex><span>    <span style=color:#586e75>// 初始化共享指针（只执行一次）
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    initialize_shared_ptrs();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#719e07>for</span> (<span style=color:#719e07>auto</span> _ : state) {
</span></span><span style=display:flex><span>        std<span style=color:#719e07>::</span>vector<span style=color:#719e07>&lt;</span>std<span style=color:#719e07>::</span><span style=color:#268bd2>thread</span><span style=color:#719e07>&gt;</span> threads;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#586e75>// 创建线程
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>        <span style=color:#719e07>for</span> (<span style=color:#dc322f>int</span> i <span style=color:#719e07>=</span> <span style=color:#2aa198>0</span>; i <span style=color:#719e07>&lt;</span> N_THREADS; <span style=color:#719e07>++</span>i) {
</span></span><span style=display:flex><span>            threads.emplace_back([i]() {
</span></span><span style=display:flex><span>                <span style=color:#dc322f>int</span> ptr_index <span style=color:#719e07>=</span> i <span style=color:#719e07>%</span> N_SHARED_PTRS; <span style=color:#586e75>// 分配给线程的共享指针索引
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>                <span style=color:#719e07>for</span> (<span style=color:#dc322f>int</span> j <span style=color:#719e07>=</span> <span style=color:#2aa198>0</span>; j <span style=color:#719e07>&lt;</span> N_OPERATIONS; <span style=color:#719e07>++</span>j) {
</span></span><span style=display:flex><span>                    <span style=color:#586e75>// Not exactly equivalent to std::atomic_load + std::atomic_store
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>                    <span style=color:#586e75>// ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>                    <span style=color:#586e75>// std::lock_guard&lt;std::mutex&gt; lock(mutexes[ptr_index]);
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>                    <span style=color:#586e75>// auto local_ptr = shared_ptrs[ptr_index];
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>                    <span style=color:#586e75>// shared_ptrs[ptr_index] = std::make_shared&lt;int&gt;(*local_ptr + 1);
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>                    std<span style=color:#719e07>::</span>shared_ptr<span style=color:#719e07>&lt;</span><span style=color:#dc322f>int</span><span style=color:#719e07>&gt;</span> local_ptr;
</span></span><span style=display:flex><span>                    {
</span></span><span style=display:flex><span>                        std<span style=color:#719e07>::</span>lock_guard<span style=color:#719e07>&lt;</span>std<span style=color:#719e07>::</span>mutex<span style=color:#719e07>&gt;</span> lock(mutexes[ptr_index]);
</span></span><span style=display:flex><span>                        local_ptr <span style=color:#719e07>=</span> shared_ptrs[ptr_index];
</span></span><span style=display:flex><span>                    }
</span></span><span style=display:flex><span>                    {
</span></span><span style=display:flex><span>                        std<span style=color:#719e07>::</span>lock_guard<span style=color:#719e07>&lt;</span>std<span style=color:#719e07>::</span>mutex<span style=color:#719e07>&gt;</span> lock(mutexes[ptr_index]);
</span></span><span style=display:flex><span>                        shared_ptrs[ptr_index] <span style=color:#719e07>=</span> std<span style=color:#719e07>::</span>make_shared<span style=color:#719e07>&lt;</span><span style=color:#dc322f>int</span><span style=color:#719e07>&gt;</span>(<span style=color:#719e07>*</span>local_ptr <span style=color:#719e07>+</span> <span style=color:#2aa198>1</span>);
</span></span><span style=display:flex><span>                    }
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>            });
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#586e75>// 等待所有线程完成
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>        <span style=color:#719e07>for</span> (<span style=color:#719e07>auto</span><span style=color:#719e07>&amp;</span> t : threads) {
</span></span><span style=display:flex><span>            t.join();
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>BENCHMARK(BM_MutexProtected);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>BENCHMARK_MAIN();
</span></span></code></pre></div><p>结果：</p><div style=overflow-x:auto><table><thead><tr><th>线程数</th><th>共享指针总数</th><th>循环次数</th><th>原子操作自由函数耗时</th><th><code>std::mutex</code> 耗时</th></tr></thead><tbody><tr><td>1</td><td>4</td><td>1000</td><td>89058 ns</td><td><strong>80306 ns</strong></td></tr><tr><td>2</td><td>4</td><td>1000</td><td>🚀 <strong>105798 ns</strong></td><td>228047 ns</td></tr><tr><td>4</td><td>4</td><td>1000</td><td>🚀 <strong>268838 ns</strong></td><td>387156 ns</td></tr><tr><td>8</td><td>4</td><td>1000</td><td>🚀 <strong>588483 ns</strong></td><td>656299 ns</td></tr><tr><td>16</td><td>4</td><td>1000</td><td>🚀 <strong>1189470 ns</strong></td><td>1379560 ns</td></tr><tr><td>32</td><td>4</td><td>1000</td><td>🚀 <strong>2693715 ns</strong></td><td>3517673 ns</td></tr><tr><td>64</td><td>4</td><td>1000</td><td>🚀 <strong>6599134 ns</strong></td><td>8734254 ns</td></tr><tr><td>128</td><td>4</td><td>1000</td><td>🚀 <strong>14365890 ns</strong></td><td>20750675 ns</td></tr></tbody></table></div><p>在共享指针总数为 4 时，自行维护互斥量的性能更差！<strong>这可能是因为我们自行对互斥量上锁，会有共享指针赋值操作符中原子操作的开销，而共享指针原子操作的读写将上锁的过程合并到了一起，效率更高</strong>。</p><p>考虑到共享指针为 4 时互斥量池哈希冲突可能不够大，为了体现使用互斥量池的劣势，接下来增大共享指针总数，测试结果反过来了🤯：</p><div style=overflow-x:auto><table><thead><tr><th>线程数</th><th>共享指针总数</th><th>循环次数</th><th>原子操作自由函数耗时</th><th><code>std::mutex</code> 耗时</th></tr></thead><tbody><tr><td>128</td><td>8</td><td>1000</td><td>11025946 ns</td><td>🚀 <strong>8755322 ns</strong></td></tr><tr><td>128</td><td>16</td><td>1000</td><td>6816762 ns</td><td>🚀 <strong>5489590 ns</strong></td></tr><tr><td>128</td><td>32</td><td>1000</td><td>5502325 ns</td><td><strong>5297484 ns</strong></td></tr><tr><td>128</td><td>64</td><td>1000</td><td>5625533 ns</td><td><strong>5377507 ns</strong></td></tr><tr><td>1024</td><td>32</td><td>1000</td><td>54262267 ns</td><td>🚀 <strong>37587115 ns</strong></td></tr><tr><td>1024</td><td>64</td><td>1000</td><td>42344566 ns</td><td>🚀 <strong>36543750 ns</strong></td></tr><tr><td>1024</td><td>128</td><td>1000</td><td>42877169 ns</td><td>🚀 <strong>36769052 ns</strong></td></tr><tr><td>1024</td><td>256</td><td>1000</td><td>39072114 ns</td><td><strong>38813602 ns</strong></td></tr><tr><td>1024</td><td>512</td><td>1000</td><td>37306563 ns</td><td><strong>36461196 ns</strong></td></tr><tr><td>1024</td><td>1024</td><td>1000</td><td>39054127 ns</td><td><strong>38676024 ns</strong></td></tr><tr><td>8092</td><td>512</td><td>1000</td><td>270409075 ns</td><td>🚀 <strong>238338752 ns</strong></td></tr><tr><td>8092</td><td>2048</td><td>1000</td><td>281548516 ns</td><td>🚀 <strong>242187529 ns</strong></td></tr><tr><td>8092</td><td>8092</td><td>1000</td><td>275440750 ns</td><td>🚀 <strong>236298876 ns</strong></td></tr></tbody></table></div><p>当线程总数超过线程池大小时，原子操作自由函数的耗时确实比外部的 <code>std::mutex</code> 多。</p><div class="markdown-alert markdown-alert-note"><p class=markdown-alert-title><svg class="octicon octicon-info mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1116 0A8 8 0 010 8zm8-6.5a6.5 6.5.0 100 13 6.5 6.5.0 000-13zM6.5 7.75A.75.75.0 017.25 7h1a.75.75.0 01.75.75v2.75h.25a.75.75.0 010 1.5h-2a.75.75.0 010-1.5h.25v-2h-.25a.75.75.0 01-.75-.75zM8 6a1 1 0 110-2 1 1 0 010 2z"/></svg>Note</p><p>多试几次可能会出现测出来的结果相差很大的情况（有时候耗时差不多，有时候耗时比接近 2），有可能是哈希结果随着共享指针地址变化，每次启动程序时共享指针分配互斥量的均匀程度不同。</p></div><h2 id=画折线图看趋势>画折线图看趋势
<a class=header-anchor href=#%e7%94%bb%e6%8a%98%e7%ba%bf%e5%9b%be%e7%9c%8b%e8%b6%8b%e5%8a%bf></a></h2><p>固定线程数为 1024，操作次数为 1000，<code>#n</code> 表示共享指针总数是 n。将实验数据整理成这样的格式：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-txt data-lang=txt><span style=display:flex><span>#1
</span></span><span style=display:flex><span>-------------------------------------------------------------
</span></span><span style=display:flex><span>Benchmark                   Time             CPU   Iterations
</span></span><span style=display:flex><span>-------------------------------------------------------------
</span></span><span style=display:flex><span>BM_AtomicLoadStore  248032779 ns     28470177 ns           13
</span></span><span style=display:flex><span>BM_MutexProtected   237027562 ns     28843112 ns           25
</span></span><span style=display:flex><span>BM_AtomicSharedPtr 1.8736e+10 ns     43095100 ns            1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>#2
</span></span><span style=display:flex><span>-------------------------------------------------------------
</span></span><span style=display:flex><span>Benchmark                   Time             CPU   Iterations
</span></span><span style=display:flex><span>-------------------------------------------------------------
</span></span><span style=display:flex><span>BM_AtomicLoadStore  168213275 ns     46402056 ns           16
</span></span><span style=display:flex><span>BM_MutexProtected   320855445 ns     39238330 ns           10
</span></span><span style=display:flex><span>BM_AtomicSharedPtr 8455017155 ns     32803500 ns            1
</span></span></code></pre></div><p>画图代码：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#719e07>import</span> matplotlib.pyplot <span style=color:#719e07>as</span> plt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75># 读取文件并提取数据</span>
</span></span><span style=display:flex><span><span style=color:#719e07>with</span> <span style=color:#b58900>open</span>(<span style=color:#2aa198>&#39;benchmark.log&#39;</span>, <span style=color:#2aa198>&#39;r&#39;</span>) <span style=color:#719e07>as</span> file:
</span></span><span style=display:flex><span>    lines <span style=color:#719e07>=</span> file<span style=color:#719e07>.</span>readlines()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75># 初始化存储数据的字典</span>
</span></span><span style=display:flex><span>data <span style=color:#719e07>=</span> {
</span></span><span style=display:flex><span>    <span style=color:#2aa198>&#39;BM_AtomicLoadStore&#39;</span>: {<span style=color:#2aa198>&#39;n&#39;</span>: [], <span style=color:#2aa198>&#39;time&#39;</span>: []},
</span></span><span style=display:flex><span>    <span style=color:#2aa198>&#39;BM_MutexProtected&#39;</span>: {<span style=color:#2aa198>&#39;n&#39;</span>: [], <span style=color:#2aa198>&#39;time&#39;</span>: []},
</span></span><span style=display:flex><span>    <span style=color:#2aa198>&#39;BM_AtomicSharedPtr&#39;</span>: {<span style=color:#2aa198>&#39;n&#39;</span>: [], <span style=color:#2aa198>&#39;time&#39;</span>: []}
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75># 解析数据</span>
</span></span><span style=display:flex><span>current_n <span style=color:#719e07>=</span> <span style=color:#cb4b16>None</span>
</span></span><span style=display:flex><span><span style=color:#719e07>for</span> line <span style=color:#719e07>in</span> lines:
</span></span><span style=display:flex><span>    <span style=color:#719e07>if</span> line<span style=color:#719e07>.</span>startswith(<span style=color:#2aa198>&#39;#&#39;</span>):
</span></span><span style=display:flex><span>        current_n <span style=color:#719e07>=</span> <span style=color:#b58900>int</span>(line<span style=color:#719e07>.</span>strip()<span style=color:#719e07>.</span>replace(<span style=color:#2aa198>&#39;#&#39;</span>, <span style=color:#2aa198>&#39;&#39;</span>))
</span></span><span style=display:flex><span>    <span style=color:#719e07>elif</span> <span style=color:#2aa198>&#39;BM_&#39;</span> <span style=color:#719e07>in</span> line:
</span></span><span style=display:flex><span>        parts <span style=color:#719e07>=</span> line<span style=color:#719e07>.</span>split()
</span></span><span style=display:flex><span>        benchmark_name <span style=color:#719e07>=</span> parts[<span style=color:#2aa198>0</span>]
</span></span><span style=display:flex><span>        time_ns <span style=color:#719e07>=</span> <span style=color:#b58900>float</span>(parts[<span style=color:#2aa198>1</span>]<span style=color:#719e07>.</span>replace(<span style=color:#2aa198>&#39;ns&#39;</span>, <span style=color:#2aa198>&#39;&#39;</span>))
</span></span><span style=display:flex><span>        data[benchmark_name][<span style=color:#2aa198>&#39;n&#39;</span>]<span style=color:#719e07>.</span>append(current_n)
</span></span><span style=display:flex><span>        data[benchmark_name][<span style=color:#2aa198>&#39;time&#39;</span>]<span style=color:#719e07>.</span>append(time_ns)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75># 绘制图形</span>
</span></span><span style=display:flex><span>plt<span style=color:#719e07>.</span>figure(figsize<span style=color:#719e07>=</span>(<span style=color:#2aa198>10</span>, <span style=color:#2aa198>6</span>))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#586e75># 极端大的数据影响画图，头两个数据就不要了</span>
</span></span><span style=display:flex><span>data[<span style=color:#2aa198>&#39;BM_AtomicSharedPtr&#39;</span>][<span style=color:#2aa198>&#39;time&#39;</span>][<span style=color:#2aa198>0</span>] <span style=color:#719e07>=</span> <span style=color:#b58900>float</span>(<span style=color:#2aa198>&#39;nan&#39;</span>)
</span></span><span style=display:flex><span>data[<span style=color:#2aa198>&#39;BM_AtomicSharedPtr&#39;</span>][<span style=color:#2aa198>&#39;time&#39;</span>][<span style=color:#2aa198>1</span>] <span style=color:#719e07>=</span> <span style=color:#b58900>float</span>(<span style=color:#2aa198>&#39;nan&#39;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#719e07>for</span> benchmark_name, values <span style=color:#719e07>in</span> data<span style=color:#719e07>.</span>items():
</span></span><span style=display:flex><span>    plt<span style=color:#719e07>.</span>plot(values[<span style=color:#2aa198>&#39;n&#39;</span>], values[<span style=color:#2aa198>&#39;time&#39;</span>], marker<span style=color:#719e07>=</span><span style=color:#2aa198>&#39;o&#39;</span>, markersize<span style=color:#719e07>=</span><span style=color:#2aa198>5</span>, label<span style=color:#719e07>=</span>benchmark_name)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>plt<span style=color:#719e07>.</span>xlabel(<span style=color:#2aa198>&#39;n&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#719e07>.</span>ylabel(<span style=color:#2aa198>&#39;Time (ns)&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#719e07>.</span>title(<span style=color:#2aa198>&#39;Benchmark Time vs n&#39;</span>)
</span></span><span style=display:flex><span>plt<span style=color:#719e07>.</span>legend()
</span></span><span style=display:flex><span>plt<span style=color:#719e07>.</span>grid(<span style=color:#cb4b16>True</span>)
</span></span><span style=display:flex><span>plt<span style=color:#719e07>.</span>show()
</span></span></code></pre></div><p>结果：</p><p><img src=/cpp-concurrency-in-action/assets/Pasted%20image%2020250106145518.webp></p><p>自变量 n 即共享指针总数（即锁的数量），越大竞争越少。对上图做出以下观察：</p><ol><li>BM_AtomicSharedPtr 基本上总是不如 BM_MutexProtected 性能好。前者是自旋锁，后者使用了 pthread 的 mutex。</li><li>BM_AtomicLoadStore 在 n 比较小的时候性能比 BM_MutexProtected 好。可能是因为它<strong>能在上锁后直接获取共享指针的控制块</strong>，在控制块上就只需要做平凡操作而不是原子操作。</li><li>BM_AtomicLoadStore 在 n 增大时性能不如 BM_MutexProtected。这时其性能已经受到了互斥量池容量大小的限制。</li><li>在 n 非常大时，BM_AtomicLoadStore 尽管仍不如 BM_MutexProtected，但是也没有显著地更差。可能是因为<strong>个人电脑的核心数并不多</strong>，测试中互斥量池大小受限最多只允许 16 个线程同时操作，但我的笔记本加上超线程（不算超小核）也才 20 个线程。</li></ol><h1 id=perf-实验>Perf 实验
<a class=header-anchor href=#perf-%e5%ae%9e%e9%aa%8c></a></h1><p>再试试 perf（perf 在 WSL2 上的安装参考
<a href=/posts/systems/Windows/WSL2-%E4%B8%AD%E5%AE%89%E8%A3%85-perf/ title="WSL2 中安装 perf">WSL2 中安装 perf</a>）。每次注释掉其他代码，只对单个测试跑 perf：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-bash data-lang=bash><span style=display:flex><span>$ perf record ./build/main
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>$ perf report --demangle
</span></span><span style=display:flex><span>... <span style=color:#586e75># 这里会在终端中显示不同函数运行占用的 CPU 时间</span>
</span></span></code></pre></div><p>实际测试发现在有 perf 的情况下，维护外部互斥量的 benchmark 耗时会增加，说明 perf 也会影响 benchmark，那这个时候我们就只看 perf 结果不看 Google Benchmark 的结果了。实验选定的线程数为 1024，共享指针总数为 32，每个线程要执行的操作数为 1000。新增对共享指针用例的测试：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#586e75>// 新增：atomic shared_ptr 数组
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>std<span style=color:#719e07>::</span>vector<span style=color:#719e07>&lt;</span>std<span style=color:#719e07>::</span>atomic<span style=color:#719e07>&lt;</span>std<span style=color:#719e07>::</span>shared_ptr<span style=color:#719e07>&lt;</span><span style=color:#dc322f>int</span><span style=color:#719e07>&gt;&gt;&gt;</span> atomic_shared_ptrs(N_SHARED_PTRS);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#719e07>static</span> <span style=color:#dc322f>void</span> <span style=color:#268bd2>BM_AtomicSharedPtr</span>(benchmark<span style=color:#719e07>::</span>State<span style=color:#719e07>&amp;</span> state) {
</span></span><span style=display:flex><span>    <span style=color:#586e75>// 初始化共享指针（只执行一次）
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    initialize_shared_ptrs();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#719e07>for</span> (<span style=color:#719e07>auto</span> _ : state) {
</span></span><span style=display:flex><span>        std<span style=color:#719e07>::</span>vector<span style=color:#719e07>&lt;</span>std<span style=color:#719e07>::</span><span style=color:#268bd2>thread</span><span style=color:#719e07>&gt;</span> threads;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#586e75>// 创建线程
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>        <span style=color:#719e07>for</span> (<span style=color:#dc322f>int</span> i <span style=color:#719e07>=</span> <span style=color:#2aa198>0</span>; i <span style=color:#719e07>&lt;</span> N_THREADS; <span style=color:#719e07>++</span>i) {
</span></span><span style=display:flex><span>            threads.emplace_back([i]() {
</span></span><span style=display:flex><span>                <span style=color:#dc322f>int</span> ptr_index <span style=color:#719e07>=</span> i <span style=color:#719e07>%</span> N_SHARED_PTRS; <span style=color:#586e75>// 分配给线程的共享指针索引
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>                <span style=color:#719e07>for</span> (<span style=color:#dc322f>int</span> j <span style=color:#719e07>=</span> <span style=color:#2aa198>0</span>; j <span style=color:#719e07>&lt;</span> N_OPERATIONS; <span style=color:#719e07>++</span>j) {
</span></span><span style=display:flex><span>                    <span style=color:#719e07>auto</span> local_ptr <span style=color:#719e07>=</span> atomic_shared_ptrs[ptr_index].load(); <span style=color:#586e75>// load
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>                    atomic_shared_ptrs[ptr_index].store(
</span></span><span style=display:flex><span>                        std<span style=color:#719e07>::</span>make_shared<span style=color:#719e07>&lt;</span><span style=color:#dc322f>int</span><span style=color:#719e07>&gt;</span>(<span style=color:#719e07>*</span>local_ptr <span style=color:#719e07>+</span> <span style=color:#2aa198>1</span>)); <span style=color:#586e75>// store
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>                }
</span></span><span style=display:flex><span>            });
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#586e75>// 等待所有线程完成
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>        <span style=color:#719e07>for</span> (<span style=color:#719e07>auto</span><span style=color:#719e07>&amp;</span> t : threads) {
</span></span><span style=display:flex><span>            t.join();
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>BENCHMARK(BM_AtomicSharedPtr);
</span></span></code></pre></div><p>结果：</p><p><img src=/cpp-concurrency-in-action/assets/Pasted%20image%2020250106120650.webp></p><p><img src=/cpp-concurrency-in-action/assets/Pasted%20image%2020250106132714.webp></p><p><img src=/cpp-concurrency-in-action/assets/Pasted%20image%2020250106134917.webp></p><p>这个比 benchmark 的结果稳定一些，多试几次基本一样。耗时最多的 lambda 函数就是启动 thread 时创建的工作函数。</p><ol><li>看起来 ExternalMutex 在工作函数内以及 mutex 操作耗费的 CPU 时间占比更多，可能表明其休眠比 AtomicLoadStore 少，从而表明其互斥量竞争不如 AtomicLoadStore 严重。</li><li>AtomicSharedPtr 实验中超过 92% 的 CPU 时间都花在了工作函数里面，体现了其自旋性质。因为 <code>-O3</code> 将很多操作都内联了，所有原子操作耗时都加在了一个函数里面。</li><li>这组运行参数是自旋锁的甜点配置，虽然这里没有列出来，但实际性能是 ExternalMutex > AtomicSharedPtr &#187; AtomicLoadStore，说明 1024 个线程均匀分配到 32 个锁上对于自旋锁来说竞争并不算激烈。不过考虑到自旋锁依然不如 <code>std::mutex</code> 的性能好，所以建议还是直接用 <code>std::mutex</code>。</li></ol><h1 id=总结>总结
<a class=header-anchor href=#%e6%80%bb%e7%bb%93></a></h1><p>C++20 之前可以用 <code>std::atomic_*</code> 这些自由函数对共享指针做原子操作，在 libstdc++ 中依靠的是一个互斥量池，有些共享指针可能会映射到同一个互斥量。C++20 之后这些自由函数被标记为过时，同时 <code>std::atomic&lt;></code> 对共享指针有了偏特化，在 libstdc++ 中实质是自旋锁。系统负载增大时，互斥量版的实现比自旋锁版的实现性能好。</p><p><code>std::atomic_*</code> 对共享指针操作时使用互斥量池，其大小只有 16，效果竟惊人地好。在<strong>低负载</strong>的情况下，其性能比对每个共享指针手动创建一个互斥量好；在<strong>高负载</strong>的情况下，尽管互斥量池的冲突增加，其性能也只是略低于手动创建互斥量。只有在<strong>中等负载</strong>情况下，即 $线程数 / 共享指针总数$ 适中时，手动维护互斥量的收益更大，有时候能达到 1.7 倍的性能差距。原因可见前文的猜测（
<a href=/cpp-concurrency-in-action/5.1-libstdc++-%E5%AF%B9%E5%85%B1%E4%BA%AB%E6%8C%87%E9%92%88%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%9A%84%E6%94%AF%E6%8C%81#%e7%94%bb%e6%8a%98%e7%ba%bf%e5%9b%be%e7%9c%8b%e8%b6%8b%e5%8a%bf title=画折线图看趋势>画折线图看趋势</a>）。</p><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>Daniel 是
<a href=/cppcon-talks/CppCon-2023-Lock-free-Atomic-Shared-Pointers-Without-a-Split-Reference-Count/ title="CppCon 2023 Lock-free Atomic Shared Pointers Without a Split Reference Count">CppCon 2023 Lock-free Atomic Shared Pointers Without a Split Reference Count</a> 的演讲者。&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><footer class=post-footer><div class=post-tags><a href=/tags/cpp>cpp
</a><a href=/tags/cpp-concurrency-in-action>cpp-concurrency-in-action
</a><a href=/tags/libstdcxx>libstdcxx</a></div><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/cpp-concurrency-in-action/8.-Designing-concurrent-code/ rel=next title="8. Designing concurrent code"><i class="fa fa-chevron-left"></i> 8. Designing concurrent code</a></div><div class="post-nav-prev post-nav-item"><a href=/cpp-concurrency-in-action/7.-%E8%AE%BE%E8%AE%A1%E6%97%A0%E9%94%81%E5%B9%B6%E5%8F%91%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/ rel=prev title="7. 设计无锁并发数据结构">7. 设计无锁并发数据结构
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>&copy;
<span itemprop=copyrightYear>2023 - 2025
</span><span class=with-love><i class="fa fa-heart"></i>
</span><span class=author itemprop=copyrightHolder>🤖</span></div><div class=powered-by>由 <a href=https://gohugo.io title=0.143.1 target=_blank>Hugo</a> & <a href=https://github.com/hugo-next/hugo-theme-next title=4.5.3 target=_blank>Hugo NexT.Gemini</a> 强力驱动</div></div></footer><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js defer></script><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js defer></script><script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":false,"save":"manual"},"copybtn":true,"darkmode":false,"hostname":"https://hxhue.github.io/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"找到 ${hits} 个搜索结果","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"limit":1e3,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":false,"transition":{"collheader":"fadeInLeft","menu_item":"fadeInDown","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"postmeta":{"comments":{"enable":false,"plugin":"waline"},"views":{"enable":false,"plugin":"busuanzi"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"vendor":{"plugins":"cdnjs","router":"https://cdnjs.cloudflare.com/ajax/libs"},"version":"4.5.3"}</script><script type=text/javascript src=/js/main.min.37ba8b54f9d4d784d08028c45eea93b5d4e13eda8ee7fb0d2edd6f3fac66cfd2.js defer></script></body></html>