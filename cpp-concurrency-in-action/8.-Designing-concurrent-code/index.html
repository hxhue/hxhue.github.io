<!doctype html><html lang=zh-CN data-theme=light><head><meta charset=UTF-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: light)"><meta name=generator content="Hugo 0.143.1"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="8. Designing concurrent code"><meta itemprop=description content="个人博客，主要是零散的笔记。"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="https://hxhue.github.io/imgs/371907.jpg"><meta itemprop=keywords content="cpp,cpp-concurrency-in-action"><link type=text/css rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css><link rel=stylesheet href=/css/main.min.bea76f574a755574e17d42bea39502a74ca3ca4db65807b8c82d3e26dcec8420.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><link rel=stylesheet type=text/css href=/css/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/github-markdown-css@5.3.0/github-markdown-dark.css><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script><script>MathJax={tex:{displayMath:[["$$","$$"],["\\[","\\]"]],inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: false });
  mermaid.mermaidAPI.initialize();
  window.mermaid = mermaid;
</script><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"path":"8.-Designing-concurrent-code","permalink":"https://hxhue.github.io/cpp-concurrency-in-action/8.-Designing-concurrent-code/","title":"8. Designing concurrent code","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>8. Designing concurrent code - Bluegill</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Bluegill</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description></p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about/ class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档</a></li><li class="menu-item menu-item-categories"><a href=/categories/ class=hvr-icon-pulse rel=section><i class="fa fa-th hvr-icon"></i>分类</a></li><li class="menu-item menu-item-tags"><a href=/tags/ class=hvr-icon-pulse rel=section><i class="fa fa-hashtag hvr-icon"></i>标签</a></li><li class="menu-item menu-item-daily"><a href=/daily/ class=hvr-icon-pulse rel=section><i class="fa fa-newspaper hvr-icon"></i>随笔</a></li><li class="menu-item menu-item-discovery"><a href=https://rift-fear-f2c.notion.site/2025-1e354a33cfb1802c841bdf29f2f3dab3 class=hvr-icon-pulse rel=section><i class="fa fa-compass hvr-icon"></i>发现</a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents><ul><li><a href=#false-sharing>False sharing</a><ul><li><a href=#stdhardware_destructive_interference_sizehttpsencppreferencecomwcppthreadhardware_destructive_interference_size><a href=https://en.cppreference.com/w/cpp/thread/hardware_destructive_interference_size><code>std::hardware_destructive_interference_size</code></a></a></li></ul></li><li><a href=#例子矩阵计算>例子：矩阵计算</a></li><li><a href=#data-access-patterns-in-other-data-structures>Data access patterns in other data structures</a><ul><li><a href=#例树状结构>例：树状结构</a></li><li><a href=#例mutex>例：Mutex</a></li></ul></li><li><a href=#exception-safety-in-parallel-algorithms>Exception safety in parallel algorithms</a><ul><li><a href=#stdterminate><code>std::terminate()</code></a></li><li><a href=#stdabort><code>std::abort</code></a></li><li><a href=#stdmem_fn><code>std::mem_fn</code></a></li></ul></li><li><a href=#并行化-stdaccumulate>并行化 <code>std::accumulate</code></a><ul><li><a href=#用-stdpackaged_task-保障异常安全>用 <code>std::packaged_task</code> 保障异常安全</a></li><li><a href=#用-stdasync-保障异常安全>用 <code>std::async</code> 保障异常安全</a></li></ul></li><li><a href=#并行化-stdfor_each>并行化 <code>std::for_each</code></a></li><li><a href=#并行化-stdfind>并行化 <code>std::find</code></a><ul><li><a href=#用-stdthread--stdpromise-实现>用 <code>std::thread</code> + <code>std::promise</code> 实现</a></li><li><a href=#用-stdasync-实现>用 <code>std::async</code> 实现</a></li></ul></li><li><a href=#并行化-stdpartial_sum>并行化 <code>std::partial_sum</code></a><ul><li><a href=#方法一每个线程各自负责一个-chunk>方法一：每个线程各自负责一个 chunk</a></li><li><a href=#方法二the-incremental-pairwise-algorithm>方法二：The incremental pairwise algorithm</a><ul><li><a href=#两本书里面用的是什么算法>两本书里面用的是什么算法？</a><ul><li><a href=#koggle-stone-算法>Koggle-Stone 算法</a></li><li><a href=#brent-kung-算法>Brent-Kung 算法</a></li></ul></li><li><a href=#双缓冲>双缓冲</a></li><li><a href=#barrier-的使用>Barrier 的使用</a></li><li><a href=#线程的提前退出>线程的提前退出</a></li><li><a href=#segmented-scan-和-stream-based-scan>Segmented scan 和 stream-based scan</a></li></ul></li></ul></li></ul></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=🤖 src=/imgs/371907.jpg><p class=site-author-name itemprop=name>🤖</p><div class=site-description itemprop=description>个人博客，主要是零散的笔记。</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>433</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>12</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>86</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/hxhue title="Github → https://github.com/hxhue" rel=noopener target=_blank><i class="fab fa-github fa-fw"></i>
Github
</a></span><span class=links-of-social-item><a href=/rss.xml title="RSS 订阅 → /rss.xml" rel=noopener target=_blank><i class="fa fa-rss fa-fw"></i>
RSS 订阅</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>
友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://shuai.guru/ title=https://shuai.guru/ target=_blank>shuai.guru</a></li></ul></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=https://hxhue.github.io/cpp-concurrency-in-action/8.-Designing-concurrent-code/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/imgs/371907.jpg"><meta itemprop=name content="🤖"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="🤖"><meta itemprop=description content="个人博客，主要是零散的笔记。"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="8. Designing concurrent code"><meta itemprop=description content="False sharing


Cache ping-pong

std::hardware_destructive_interference_size

还有 std::hardware_constructive_interference_size。在大多数情况下这两个值相等，而且都等于 cache line 的大小。"></span><header class=post-header><h1 class=post-title itemprop="name headline">8. Designing concurrent code</h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i>
</span><span class=post-meta-item-text title=发表于>发表于：
</span><time title="创建时间：2025-01-16 00:00:00 +0800 CST" itemprop="dateCreated datePublished" datetime="2025-01-16 00:00:00 +0800 CST">2025-01-16
</time></span><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar-check"></i>
</span><span class=post-meta-item-text title=更新于>更新于：
</span><time title=修改时间：2025-03-07T00:00:00+08:00 itemprop=dateModified datetime=2025-03-07T00:00:00+08:00>2025-03-07</time>
</span><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-folder-open"></i>
</span><span class=post-meta-item-text title=分类于>分类于：
</span><span itemprop=about itemscope itemtype=http://schema.org/Thing><a href=/categories/cpp-concurrency-in-action itemprop=url rel=index><span itemprop=name>cpp-concurrency-in-action</span></a></span></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i>
</span><span class=post-meta-item-text>字数：</span>
<span>6011</span>
</span><span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i>
</span><span class=post-meta-item-text>阅读：&ap;</span>
<span>12分钟</span></span></div></div></header><div class=post-body itemprop=articleBody><h1 id=false-sharing>False sharing
<a class=header-anchor href=#false-sharing></a></h1><ul><li>Cache ping-pong</li></ul><h2 id=stdhardware_destructive_interference_sizehttpsencppreferencecomwcppthreadhardware_destructive_interference_size><a href=https://en.cppreference.com/w/cpp/thread/hardware_destructive_interference_size title=std::hardware_destructive_interference_size rel="noopener external nofollow noreferrer" target=_blank class=exturl><code>std::hardware_destructive_interference_size</code><i class="fa fa-external-link-alt"></i></a>
<a class=header-anchor href=#stdhardware_destructive_interference_sizehttpsencppreferencecomwcppthreadhardware_destructive_interference_size></a></h2><p>还有 <code>std::hardware_constructive_interference_size</code>。在大多数情况下这两个值相等，而且都等于 cache line 的大小。</p><p><a href=https://stackoverflow.com/questions/39680206/understanding-stdhardware-destructive-interference-size-and-stdhardware-cons title=https://stackoverflow.com/questions/39680206/understanding-stdhardware-destructive-interference-size-and-stdhardware-cons rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://stackoverflow.com/questions/39680206/understanding-stdhardware-destructive-interference-size-and-stdhardware-cons<i class="fa fa-external-link-alt"></i></a> 第一个回答的评论里面指出如果目标平台有多个，那么为了兼容性，这两个常量可能是不同的。在特定架构上这两个常量应该是相同的。</p><h1 id=例子矩阵计算>例子：矩阵计算
<a class=header-anchor href=#%e4%be%8b%e5%ad%90%e7%9f%a9%e9%98%b5%e8%ae%a1%e7%ae%97></a></h1><p><img src=/cpp-concurrency-in-action/assets/Pasted%20image%2020250116084034.webp></p><ol><li>每个线程计算一组列。列可以先加载到当前线程，每次都读一整行，对 cache 友好。</li><li>每个线程计算一组行。相比于方案 1，读的 false sharing 更多，但是<strong>写操作</strong>的 false sharing 会更少。</li><li>分块矩阵。<strong>访问输入矩阵元素的数量减少了</strong>，同时保持计算出来的元素数相同，因而效率更高。</li></ol><h1 id=data-access-patterns-in-other-data-structures>Data access patterns in other data structures
<a class=header-anchor href=#data-access-patterns-in-other-data-structures></a></h1><h2 id=例树状结构>例：树状结构
<a class=header-anchor href=#%e4%be%8b%e6%a0%91%e7%8a%b6%e7%bb%93%e6%9e%84></a></h2><p>树状结构结点小，不同线程如果访问不同结点，cache line 重叠概率小，对 false sharing 有利。</p><h2 id=例mutex>例：Mutex
<a class=header-anchor href=#%e4%be%8bmutex></a></h2><p>Mutex 和受保护数据在同一个 cache line 时，其他线程尝试上锁对持有锁的线程性能有影响。</p><blockquote><p>Mutex locks are typically implemented as a read-modify-write atomic operation on a memory location within the mutex to try to acquire the mutex, followed by a call to the operating system kernel if the mutex is already locked.</p></blockquote><p>当 mutex 和受保护数据要存在一起时，可以在数据结构中增加 padding 以隔开两者。</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#719e07>struct</span> <span style=color:#268bd2>protected_data</span>
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    std<span style=color:#719e07>::</span>mutex m;
</span></span><span style=display:flex><span>    <span style=color:#dc322f>char</span> padding[std<span style=color:#719e07>::</span>hardware_destructive_interference_size];
</span></span><span style=display:flex><span>    my_data data_to_protect;
</span></span><span style=display:flex><span>};
</span></span></code></pre></div><p>或者像 cppreference 这样对要区分的两段数据用 <code>alignas</code>：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#719e07>struct</span> <span style=color:#268bd2>keep_apart</span>
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#719e07>alignas</span>(std<span style=color:#719e07>::</span>hardware_destructive_interference_size) std<span style=color:#719e07>::</span>atomic<span style=color:#719e07>&lt;</span><span style=color:#dc322f>int</span><span style=color:#719e07>&gt;</span> cat;
</span></span><span style=display:flex><span>    <span style=color:#719e07>alignas</span>(std<span style=color:#719e07>::</span>hardware_destructive_interference_size) std<span style=color:#719e07>::</span>atomic<span style=color:#719e07>&lt;</span><span style=color:#dc322f>int</span><span style=color:#719e07>&gt;</span> dog;
</span></span><span style=display:flex><span>};
</span></span></code></pre></div><div class="markdown-alert markdown-alert-tip"><p class=markdown-alert-title><svg class="octicon octicon-light-bulb mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M8 1.5c-2.363.0-4 1.69-4 3.75.0.984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75.0 01-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456.0 00-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863.0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751.0 01-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304.0-2.06-1.637-3.75-4-3.75zM5.75 12h4.5a.75.75.0 010 1.5h-4.5a.75.75.0 010-1.5zM6 15.25a.75.75.0 01.75-.75h2.5a.75.75.0 010 1.5h-2.5A.75.75.0 016 15.25z"/></svg>Tip</p><p><code>std::hardware_destructive_interference_size</code> 表示避免 false sharing 的最小大小。<code>std::hardware_constructive_interference_size</code> 表示积极使用 true sharing 的最大大小。</p></div><p>除了 <code>hardware_destructive_interference_size</code> 和 <code>hardware_constructive_interference_size</code> 暗示了 cache line 的大小之外，在 Linux 下我们还能用 /sys 文件系统下的信息得到 cache line 大小：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#719e07>(</span>base<span style=color:#719e07>)</span> ➜  main cat /sys/devices/system/cpu/cpu0/cache/index0/coherency_line_size
</span></span><span style=display:flex><span><span style=color:#2aa198>64</span>
</span></span></code></pre></div><h1 id=exception-safety-in-parallel-algorithms>Exception safety in parallel algorithms
<a class=header-anchor href=#exception-safety-in-parallel-algorithms></a></h1><h2 id=stdterminate><code>std::terminate()</code>
<a class=header-anchor href=#stdterminate></a></h2><blockquote><p>By contrast, in a parallel algorithm many of the operations will be running on separate threads. In this case, the exception can’t be allowed to propagate because it’s on the wrong call stack.</p></blockquote><p>如果不正确处理多线程环境下的异常，任何线程抛出未处理的异常都会导致 <code>std::terminate()</code> 被调用，整个进程被终止，见 <a href=https://godbolt.org/z/czPe8dbe8 title=https://godbolt.org/z/czPe8dbe8 rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://godbolt.org/z/czPe8dbe8<i class="fa fa-external-link-alt"></i></a> 。输出可能像这样：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-txt data-lang=txt><span style=display:flex><span>terminate called after throwing an instance of &#39;std::runtime_error&#39;
</span></span><span style=display:flex><span>  what():  Exception from Thread B
</span></span><span style=display:flex><span>Program terminated with signal: SIGSEGV
</span></span></code></pre></div><p><code>std::terminate()</code> 会先打印当前的异常，再退出程序。如果当前没有异常，控制台输出可能为：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-txt data-lang=txt><span style=display:flex><span>terminate called without an active exception
</span></span><span style=display:flex><span>Program terminated with signal: SIGSEGV
</span></span></code></pre></div><p><strong>这其实是默认的 terminate handler 做的事情</strong>，它先打印异常再调用 <code>std::abort()</code>，代码可参考 GCC 源码的 libstdc++-v3/libsupc++/vterminate.cc。我们也可以修改 terminate handler，它是一个全局的 handler，而且 <code>set_terminate</code> 和 <code>get_terminate</code> 都是线程安全的。</p><blockquote><p>In any case, <code>std::terminate</code> calls the currently installed <a href=https://en.cppreference.com/w/cpp/error/terminate_handler title=std::terminate_handler rel="noopener external nofollow noreferrer" target=_blank class=exturl>std::terminate_handler<i class="fa fa-external-link-alt"></i></a>. The default <a href=https://en.cppreference.com/w/cpp/error/terminate_handler title=std::terminate_handler rel="noopener external nofollow noreferrer" target=_blank class=exturl>std::terminate_handler<i class="fa fa-external-link-alt"></i></a> calls <a href=https://en.cppreference.com/w/cpp/utility/program/abort title=std::abort rel="noopener external nofollow noreferrer" target=_blank class=exturl>std::abort<i class="fa fa-external-link-alt"></i></a>. &ndash; <a href=https://en.cppreference.com/w/cpp/error/terminate title=https://en.cppreference.com/w/cpp/error/terminate rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://en.cppreference.com/w/cpp/error/terminate<i class="fa fa-external-link-alt"></i></a></p></blockquote><p>尽管能用 <code>std::set_terminate</code> 来修改 <code>std::terminate_handler</code>，但标准规定 handler 不能返回到 caller，否则<strong>未定义</strong>，所以一般只能做一些日志或清理操作，然后终止程序。</p><blockquote><p>f shall terminate execution of the program without returning to its caller, otherwise the behavior is undefined. &ndash; <a href=https://en.cppreference.com/w/cpp/error/set_terminate title=https://en.cppreference.com/w/cpp/error/set_terminate rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://en.cppreference.com/w/cpp/error/set_terminate<i class="fa fa-external-link-alt"></i></a></p></blockquote><h2 id=stdabort><code>std::abort</code>
<a class=header-anchor href=#stdabort></a></h2><p><code>std::abort</code>（来自 cstdlib）通过 SIGABRT 信号终止程序，不会清理资源：</p><ol><li>析构函数不会被调用。</li><li><code>std::atexit()</code> 和 <code>std::at_quick_exit()</code> 注册的函数不会被调用。</li><li>文件等被打开的资源是否被关闭由实现定义。</li></ol><p><del>虽然 C++ 标准没有说明如果 SIGABRT 信号被捕获是否还能终止程序</del>，POSIX 标准说明了 <code>abort()</code> 会 override 对信号的阻塞或者忽略。C++ 标准说的是（C 语言标准类似）：</p><blockquote><p>Causes abnormal program termination unless <a href=https://en.cppreference.com/w/cpp/utility/program/SIG_types title=SIGABRT rel="noopener external nofollow noreferrer" target=_blank class=exturl>SIGABRT<i class="fa fa-external-link-alt"></i></a> is being caught by a signal handler passed to <a href=https://en.cppreference.com/w/cpp/utility/program/signal title=std::signal rel="noopener external nofollow noreferrer" target=_blank class=exturl>std::signal<i class="fa fa-external-link-alt"></i></a> and the handler does not return.</p></blockquote><p>即如果 SIGABRT 被捕获了而且该信号处理器返回了，那么还是会强制终止程序。</p><p>从 <a href=https://en.cppreference.com/w/cpp/utility/program/abort title="C++ 标准" rel="noopener external nofollow noreferrer" target=_blank class=exturl>C++ 标准<i class="fa fa-external-link-alt"></i></a> 来看 <code>std::abort</code> 使用的信号是 SIGABRT，但是为什么退出时显示的信号是 SIGSEGV 呢？<a href=https://www.reddit.com/r/Cplusplus/comments/14n0kh3/why_do_my_unhandledexceptionprogram_result_in/ title="Reddit 帖子" rel="noopener external nofollow noreferrer" target=_blank class=exturl>Reddit 帖子<i class="fa fa-external-link-alt"></i></a> 说这个是 compiler explorer 沙盒的问题，我在 WSL 中重新尝试就确实看到了程序以 134 退出码结束（$128 + 6 = 134$，从 <code>kill -l</code> 中可以看到 6 号信号就是 SIGABRT）。</p><h2 id=stdmem_fn><code>std::mem_fn</code>
<a class=header-anchor href=#stdmem_fn></a></h2><p><a href=https://en.cppreference.com/w/cpp/utility/functional/mem_fn title=https://en.cppreference.com/w/cpp/utility/functional/mem_fn rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://en.cppreference.com/w/cpp/utility/functional/mem_fn<i class="fa fa-external-link-alt"></i></a> 给人一种可以把成员函数转换成 UFCS 的感觉。如果一个模板函数期望普通 unary 函数，而不会专门处理无参<strong>成员函数</strong>，那么可以将无参成员函数转换成普通 unary 函数，比如：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span>for_each(v.begin(), v.end(), mem_fn(<span style=color:#719e07>&amp;</span>Item<span style=color:#719e07>::</span>Foo));
</span></span></code></pre></div><p>这样比自己写一个 lambda 更加简洁。</p><h1 id=并行化-stdaccumulate>并行化 <code>std::accumulate</code>
<a class=header-anchor href=#%e5%b9%b6%e8%a1%8c%e5%8c%96-stdaccumulate></a></h1><div class="markdown-alert markdown-alert-important"><p class=markdown-alert-title><svg class="octicon octicon-report mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M0 1.75C0 .784.784.0 1.75.0h12.5C15.216.0 16 .784 16 1.75v9.5A1.75 1.75.0 0114.25 13H8.06l-2.573 2.573A1.458 1.458.0 013 14.543V13H1.75A1.75 1.75.0 010 11.25zm1.75-.25a.25.25.0 00-.25.25v9.5c0 .138.112.25.25.25h2a.75.75.0 01.75.75v2.19l2.72-2.72a.749.749.0 01.53-.22h6.5a.25.25.0 00.25-.25v-9.5a.25.25.0 00-.25-.25zm7 2.25v2.5a.75.75.0 01-1.5.0v-2.5a.75.75.0 011.5.0zM9 9A1 1 0 117 9a1 1 0 012 0z"/></svg>Important</p><p>书上的实现没有保证结合顺序，但是 <code>std::accumulate</code> 是要求保证结合顺序是从左到右的，所以书上实现的更接近 <code>std::reduce</code>。</p></div><div class="markdown-alert markdown-alert-note"><p class=markdown-alert-title><svg class="octicon octicon-info mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1116 0A8 8 0 010 8zm8-6.5a6.5 6.5.0 100 13 6.5 6.5.0 000-13zM6.5 7.75A.75.75.0 017.25 7h1a.75.75.0 01.75.75v2.75h.25a.75.75.0 010 1.5h-2a.75.75.0 010-1.5h.25v-2h-.25a.75.75.0 01-.75-.75zM8 6a1 1 0 110-2 1 1 0 010 2z"/></svg>Note</p><p><code>std::accumulate</code> 并不在 <code>&lt;algorithm></code> 头文件中，而在 <code>&lt;numeric></code> 头文件中。它也没有接受 ExecutionPolicy 参数的重载。（不可以认为所有 <code>&lt;numeric></code> 头文件中的算法都不接受执行策略，有些是接受的，比如 <code>std::reduce</code> / <code>std::inclusive_scan</code> / <code>std::transform_exclusive_scan</code> / <code>std::transform_reduce</code> 等。）</p></div><h2 id=用-stdpackaged_task-保障异常安全>用 <code>std::packaged_task</code> 保障异常安全
<a class=header-anchor href=#%e7%94%a8-stdpackaged_task-%e4%bf%9d%e9%9a%9c%e5%bc%82%e5%b8%b8%e5%ae%89%e5%85%a8></a></h2><p><code>std::packaged_task</code> 创建的线程会安全地处理异常，并将异常记录在 <code>std::future</code> 中，由 <code>std::future</code> 的获取这来处理。</p><blockquote><p>The key thing to note for exception safety is that if you destroy the future without waiting for it, the destructor will wait for the thread to complete. This neatly avoids the problem of leaked threads that are still executing and holding references to the data.</p></blockquote><p>书里面用了 <code>join_threads</code> 这个自定义的类，用来在离开作用域时检查给定 <code>vector</code> 中的 threads 是否 <code>joinable()</code>，如果是的话则发起 <code>join()</code>。这样可以防止在后面的代码用 <code>std::future</code> 获取结果时抛出异常，而有 <code>std::thread</code> 离开作用域还没有 <code>join()</code> 或 <code>detach()</code>，导致 <code>std::terminate</code> 被调用、程序终止。<strong>在 C++20 中可以用 <code>std::jthread</code> 来替代这种写法</strong>。</p><h2 id=用-stdasync-保障异常安全>用 <code>std::async</code> 保障异常安全
<a class=header-anchor href=#%e7%94%a8-stdasync-%e4%bf%9d%e9%9a%9c%e5%bc%82%e5%b8%b8%e5%ae%89%e5%85%a8></a></h2><p>用 <code>std::async</code> 来代替前面的 <code>std::packaged_task</code> 和 <code>std::thread</code> 的写法会更简单，而且可以避免忘记在发生异常离开当前作用域时对 <code>std::thread</code> 进行 <code>join()</code> 的问题（成书时还没有 <code>std::jthread</code>）。</p><p>使用 <code>std::packaged_task</code> 时，书上是预先划分了多个 chunk；在使用 <code>std::async</code> 时，书上是二分递归调用 <code>std::async</code>，因此代码进一步变得简洁。不是说 <code>std::packaged_task</code> 不能二分，只是书上只展示了这样的写法。</p><h1 id=并行化-stdfor_each>并行化 <code>std::for_each</code>
<a class=header-anchor href=#%e5%b9%b6%e8%a1%8c%e5%8c%96-stdfor_each></a></h1><p>略。</p><h1 id=并行化-stdfind>并行化 <code>std::find</code>
<a class=header-anchor href=#%e5%b9%b6%e8%a1%8c%e5%8c%96-stdfind></a></h1><h2 id=用-stdthread--stdpromise-实现>用 <code>std::thread</code> + <code>std::promise</code> 实现
<a class=header-anchor href=#%e7%94%a8-stdthread--stdpromise-%e5%ae%9e%e7%8e%b0></a></h2><div class="markdown-alert markdown-alert-important"><p class=markdown-alert-title><svg class="octicon octicon-report mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M0 1.75C0 .784.784.0 1.75.0h12.5C15.216.0 16 .784 16 1.75v9.5A1.75 1.75.0 0114.25 13H8.06l-2.573 2.573A1.458 1.458.0 013 14.543V13H1.75A1.75 1.75.0 010 11.25zm1.75-.25a.25.25.0 00-.25.25v9.5c0 .138.112.25.25.25h2a.75.75.0 01.75.75v2.19l2.72-2.72a.749.749.0 01.53-.22h6.5a.25.25.0 00.25-.25v-9.5a.25.25.0 00-.25-.25zm7 2.25v2.5a.75.75.0 01-1.5.0v-2.5a.75.75.0 011.5.0zM9 9A1 1 0 117 9a1 1 0 012 0z"/></svg>Important</p><p>书上实现的 <code>find</code> 函数是找到任何一个和给定参数相等的元素，但是 <code>std::find</code> 找到的是范围中的第一个和参数相等的元素，含义是不同的。</p></div><p>为了和标准库的接口一致，<code>find</code> 函数只需要一个结果，因此书上选择使用 <code>std::promise</code> 而不是 <code>std::packaged_task</code>。同样是创建一组线程，每个线程执行各自的搜索任务，但是<strong>现在不需要为每个线程都创建一个 future</strong>，只需要使用同一个 promise 与和它关联的一个 future。</p><div class="markdown-alert markdown-alert-note"><p class=markdown-alert-title><svg class="octicon octicon-info mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1116 0A8 8 0 010 8zm8-6.5a6.5 6.5.0 100 13 6.5 6.5.0 000-13zM6.5 7.75A.75.75.0 017.25 7h1a.75.75.0 01.75.75v2.75h.25a.75.75.0 010 1.5h-2a.75.75.0 010-1.5h.25v-2h-.25a.75.75.0 01-.75-.75zM8 6a1 1 0 110-2 1 1 0 010 2z"/></svg>Note</p><p>书上用 <code>std::vector&lt;std::threads></code> + 自定义的 <code>join_threads</code> 来处理异常，如果有 <code>std::jthreads</code>（C++20）就更简单了。</p></div><p>书上是每个元素遍历前都检查一下所有线程可见的原子标志 <code>done_flag</code>，如果该标志为真则不再继续搜索。如果有线程先找到了元素或者出现了异常，这个 <code>done_flag</code> 都会被设置为真。我个人认为这个检查频率应该变小一点，不然容易影响搜索性能。</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#719e07>struct</span> <span style=color:#268bd2>find_element</span>
</span></span><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#dc322f>void</span> <span style=color:#268bd2>operator</span>()(Iterator begin, Iterator end,
</span></span><span style=display:flex><span>                    MatchType match,
</span></span><span style=display:flex><span>                    std<span style=color:#719e07>::</span>promise<span style=color:#719e07>&lt;</span>Iterator<span style=color:#719e07>&gt;*</span> result,
</span></span><span style=display:flex><span>                    std<span style=color:#719e07>::</span>atomic<span style=color:#719e07>&lt;</span><span style=color:#dc322f>bool</span><span style=color:#719e07>&gt;*</span> done_flag)
</span></span><span style=display:flex><span>    {
</span></span><span style=display:flex><span>        <span style=color:#719e07>try</span>
</span></span><span style=display:flex><span>        {
</span></span><span style=display:flex><span>            <span style=color:#719e07>for</span> (; (begin <span style=color:#719e07>!=</span> end) <span style=color:#719e07>&amp;&amp;</span> <span style=color:#719e07>!</span>done_flag<span style=color:#719e07>-&gt;</span>load(); <span style=color:#719e07>++</span>begin)
</span></span><span style=display:flex><span>            {
</span></span><span style=display:flex><span>                <span style=color:#719e07>if</span> (<span style=color:#719e07>*</span>begin <span style=color:#719e07>==</span> match)
</span></span><span style=display:flex><span>                {
</span></span><span style=display:flex><span>                    result<span style=color:#719e07>-&gt;</span>set_value(begin);
</span></span><span style=display:flex><span>                    done_flag<span style=color:#719e07>-&gt;</span>store(<span style=color:#b58900>true</span>);
</span></span><span style=display:flex><span>                    <span style=color:#719e07>return</span>;
</span></span><span style=display:flex><span>                }
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        <span style=color:#719e07>catch</span> (...)
</span></span><span style=display:flex><span>        {
</span></span><span style=display:flex><span>            <span style=color:#719e07>try</span> <span style=color:#586e75>// 注意这里
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>            {
</span></span><span style=display:flex><span>                result<span style=color:#719e07>-&gt;</span>set_exception(std<span style=color:#719e07>::</span>current_exception());
</span></span><span style=display:flex><span>                done_flag<span style=color:#719e07>-&gt;</span>store(<span style=color:#b58900>true</span>);
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>            <span style=color:#719e07>catch</span> (...)
</span></span><span style=display:flex><span>            {
</span></span><span style=display:flex><span>            }
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>};
</span></span></code></pre></div><p>每个线程找到结果或者发生异常之后都会尝试将结果写入 future，但是只有第一个线程能成功，其他线程会遇到异常。尤其是尝试 <code>set_value()</code> 的线程会遇到异常，从而进入下面 catch 块中并调用 <code>set_exception()</code>，但是这个调用依然会发生异常，因此外面还要包一层 try-catch。<strong>书上的代码通过双重 try-catch 简单处理了线程设置结果的数据竞争问题</strong>。</p><h2 id=用-stdasync-实现>用 <code>std::async</code> 实现
<a class=header-anchor href=#%e7%94%a8-stdasync-%e5%ae%9e%e7%8e%b0></a></h2><p>前面用 <code>std::thread</code> + <code>std::promise</code> 实现是为了替代 <code>std::thread</code> + <code>std::packaged_task</code>。现在换成 <code>std::async</code>，不用专门使用 <code>std::promise</code>。每次进行二分后先检查前一半的结果（在本线程进行搜索），如果前一半没有找到才去检查后一半的结果。</p><h1 id=并行化-stdpartial_sum>并行化 <code>std::partial_sum</code>
<a class=header-anchor href=#%e5%b9%b6%e8%a1%8c%e5%8c%96-stdpartial_sum></a></h1><div class="markdown-alert markdown-alert-important"><p class=markdown-alert-title><svg class="octicon octicon-report mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M0 1.75C0 .784.784.0 1.75.0h12.5C15.216.0 16 .784 16 1.75v9.5A1.75 1.75.0 0114.25 13H8.06l-2.573 2.573A1.458 1.458.0 013 14.543V13H1.75A1.75 1.75.0 010 11.25zm1.75-.25a.25.25.0 00-.25.25v9.5c0 .138.112.25.25.25h2a.75.75.0 01.75.75v2.19l2.72-2.72a.749.749.0 01.53-.22h6.5a.25.25.0 00.25-.25v-9.5a.25.25.0 00-.25-.25zm7 2.25v2.5a.75.75.0 01-1.5.0v-2.5a.75.75.0 011.5.0zM9 9A1 1 0 117 9a1 1 0 012 0z"/></svg>Important</p><p><code>std::partial_sum</code> 还保证了结合顺序，所以书上实现的其实是 <code>std::inclusive_scan</code>。</p></div><div class="markdown-alert markdown-alert-note"><p class=markdown-alert-title><svg class="octicon octicon-info mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M0 8a8 8 0 1116 0A8 8 0 010 8zm8-6.5a6.5 6.5.0 100 13 6.5 6.5.0 000-13zM6.5 7.75A.75.75.0 017.25 7h1a.75.75.0 01.75.75v2.75h.25a.75.75.0 010 1.5h-2a.75.75.0 010-1.5h.25v-2h-.25a.75.75.0 01-.75-.75zM8 6a1 1 0 110-2 1 1 0 010 2z"/></svg>Note</p><p><code>std::partial_sum</code> 并不在 <code>&lt;algorithm></code> 头文件中，而在 <code>&lt;numeric></code> 头文件中。它也没有接受 ExecutionPolicy 参数的重载。</p></div><h2 id=方法一每个线程各自负责一个-chunk>方法一：每个线程各自负责一个 chunk
<a class=header-anchor href=#%e6%96%b9%e6%b3%95%e4%b8%80%e6%af%8f%e4%b8%aa%e7%ba%bf%e7%a8%8b%e5%90%84%e8%87%aa%e8%b4%9f%e8%b4%a3%e4%b8%80%e4%b8%aa-chunk></a></h2><p>把数组分成 chunk，每个线程为一个 chunk 计算 partial sum（并行），然后不同线程通信得到上一 chunk 末尾的值 $x_{i-1}$（串行），最后每个线程各自给整个 chunk 加上 $x_{i-1}$（并行）。</p><p><img src=/cpp-concurrency-in-action/assets/6059ec33aa14ad75d98444e1e443cf40.webp width=600></p><p>这个方法中相邻 chunk 通信是使用 <code>std::promise</code> 和 <code>std::future</code> 来完成的。<strong>图中有一点没有反映真实情况的是：只要当前线程将结果传给后面的线程了，就可以给自己负责的 chunk 中的每一个元素加上偏移，不需要整条链路的同步完成</strong>。</p><h2 id=方法二the-incremental-pairwise-algorithm>方法二：The incremental pairwise algorithm
<a class=header-anchor href=#%e6%96%b9%e6%b3%95%e4%ba%8cthe-incremental-pairwise-algorithm></a></h2><blockquote><p>This second approach to calculating the partial sums by adding elements increasingly further away works best where your processors can execute the additions in lockstep.</p></blockquote><p>我记得 <em>Programming Massively Parallel Processors</em> 里面也讲过对折迭代，<em>C++ Concurrency in Action</em> 这里要在 CPU 上实现类似的算法。接下来把两本书介绍的算法进行比较。</p><h3 id=两本书里面用的是什么算法>两本书里面用的是什么算法？
<a class=header-anchor href=#%e4%b8%a4%e6%9c%ac%e4%b9%a6%e9%87%8c%e9%9d%a2%e7%94%a8%e7%9a%84%e6%98%af%e4%bb%80%e4%b9%88%e7%ae%97%e6%b3%95></a></h3><p><em>Programming Massively Parallel Processors</em> 先介绍了 <strong>Kogge-Stone</strong> 算法，然后介绍了更加高效的 <strong>Brent-Kung</strong> 算法。书上也提到了存在基于 warp shuffle 的更高效的算法，但是没有做详细介绍。</p><p><em>C++ Concurrency in Action</em> 中的算法是 Kogge-Stone 算法。</p><h4 id=koggle-stone-算法>Koggle-Stone 算法
<a class=header-anchor href=#koggle-stone-%e7%ae%97%e6%b3%95></a></h4><p>在 Koggle-Stone 算法中，第一次迭代后前 2 个元素的 partial sum 已经算好，第二次迭代后前 4 个元素的 partial sum 已经算好，第三次迭代后前 8 个元素的 partial sum 已经算好……Koggle-Stone 算法的总操作数为 $N \mathit{log}_{2}(N) - (N - 1)$。因为在一个迭代中要读一次、写一次，所以在没有双缓冲的情况下一个迭代需要做两次同步。</p><p><img src=/cpp-concurrency-in-action/assets/Pasted%20image%2020250118220105.webp width=600></p><h4 id=brent-kung-算法>Brent-Kung 算法
<a class=header-anchor href=#brent-kung-%e7%ae%97%e6%b3%95></a></h4><p>在 Brent-Kung 算法中，reduction tree 操作数为 $N-1$，reverse tree 操作数为 $N-1-\mathit{log}_2(N)$，总操作数为 $2N-2-\mathit{log}_2(N)$。</p><p><img src=/cpp-concurrency-in-action/assets/Pasted%20image%2020250118220441.webp width=600></p><p><strong>Reduction tree</strong>: （从 1 开始计数）2 的幂的位置的元素在 reduction tree 结束后可以得到最终的 partial sum。从下图中读写示意图来看，读的位置和写的位置并没有相互交错，所以<strong>一个迭代中只需要进行一次同步</strong>。</p><div class="markdown-alert markdown-alert-tip"><p class=markdown-alert-title><svg class="octicon octicon-light-bulb mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M8 1.5c-2.363.0-4 1.69-4 3.75.0.984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75.0 01-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456.0 00-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863.0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751.0 01-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304.0-2.06-1.637-3.75-4-3.75zM5.75 12h4.5a.75.75.0 010 1.5h-4.5a.75.75.0 010-1.5zM6 15.25a.75.75.0 01.75-.75h2.5a.75.75.0 010 1.5h-2.5A.75.75.0 016 15.25z"/></svg>Tip</p><p>Reduction tree 阶段是形成 <a href=https://oi-wiki.org/ds/fenwick/ title=树状数组 rel="noopener external nofollow noreferrer" target=_blank class=exturl>树状数组<i class="fa fa-external-link-alt"></i></a>。若下标从 1 开始，只有下标为 $2^i$ 的元素完成了计算。</p></div><p>一种做法是让每个线程都处理对应位置上的元素，为其判断是否需要将 <code>XY[i-stride]</code> 的值加到 <code>XY[i]</code> 上面来。但是每个 warp 中有的线程不进 if，有的线程进 if，control divergence 比较多。</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#586e75>// blockDim.x 是分段扫描的数组段大小的一半，也就是说只要一半的线程就能计算该数组段
</span></span></span><span style=display:flex><span><span style=color:#586e75></span><span style=color:#719e07>for</span>(<span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>int</span> stride <span style=color:#719e07>=</span> <span style=color:#2aa198>1</span>; stride <span style=color:#719e07>&lt;=</span> blockDim.x; stride <span style=color:#719e07>*=</span> <span style=color:#2aa198>2</span>) {
</span></span><span style=display:flex><span>    __syncthreads();
</span></span><span style=display:flex><span>    <span style=color:#586e75>// 这里对 (2 * stride) 取模而不是对 stride 取模，是因为算的是 inclusive scan，
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#586e75>// 0 号元素并不需要进行叠加操作。
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#719e07>if</span> ((threadIdx.x <span style=color:#719e07>+</span> <span style=color:#2aa198>1</span>) <span style=color:#719e07>%</span> (<span style=color:#2aa198>2</span> <span style=color:#719e07>*</span> stride) <span style=color:#719e07>==</span> <span style=color:#2aa198>0</span>) {
</span></span><span style=display:flex><span>        XY[threadIdx.x] <span style=color:#719e07>+=</span> XY[threadIdx.x <span style=color:#719e07>-</span> stride];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>另一种做法是将工作线程集中到 block 头部的若干 warp 中，线程号（<code>threadIdx.x</code> 并不对应要处理的元素的下标号），这样做减少了控制分歧，性能更好。观察上图，如果下标从 1 开始，每一轮分别是 2 的倍数、4 的倍数、8 的倍数…… 下标处的元素参与计算。因此可以直接算出来第 $i$ 个会参与计算的下标是 $i * (2 * \mathit{stride})$，实际上数组下标从 0 计算、线程 ID（$i$）也从 0 开始，那么表达式就变成了 $(i+1) * (2 * \mathit{stride})-1$。最后做一下数组越界检查。</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#719e07>for</span>(<span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>int</span> stride <span style=color:#719e07>=</span> <span style=color:#2aa198>1</span>; stride <span style=color:#719e07>&lt;=</span> blockDim.x; stride <span style=color:#719e07>*=</span> <span style=color:#2aa198>2</span>) {
</span></span><span style=display:flex><span>    __syncthreads();
</span></span><span style=display:flex><span>    <span style=color:#dc322f>int</span> index <span style=color:#719e07>=</span> (threadIdx.x <span style=color:#719e07>+</span> <span style=color:#2aa198>1</span>) <span style=color:#719e07>*</span> <span style=color:#2aa198>2</span> <span style=color:#719e07>*</span> stride <span style=color:#719e07>-</span> <span style=color:#2aa198>1</span>;
</span></span><span style=display:flex><span>    <span style=color:#719e07>if</span>(index <span style=color:#719e07>&lt;</span> SECTION_SIZE) { <span style=color:#586e75>// 书中的 SECTION_SIZE 是对分段数组大小
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>        XY[index] <span style=color:#719e07>+=</span> XY[index <span style=color:#719e07>-</span> stride];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>Reduction tree 结束之后，$\mathit{lowbit}(i+1)$ 能计算出 $XY[i]$ 已经包含了前面（含自己）几个数的和。令 $sum[-1] = 0$，有：</p>$$XY[i] = sum[i] - sum[i-\mathit{lowbit}(i+1)]$$<ul><li>例子 1：如图，$XY[11]$ 是原 $XY[8...11]$ 的和。</li><li>例子 2：按照公式，所有从 1 计数的 2 的幂的位置都已经得到了最终 sum。</li></ul><p>这其实完成了一个树状数组。</p><p><strong>Reverse tree</strong>: 对于 $XY[i]$，我们希望把 $sum[i-\mathit{lowbit}(i+1)]$ 加回来。刚开始时只有满足 $i = 2^n-1(n=0,1,2...)$ 的 $XY[i]$ 和 $sum[i]$ 相等，所以只能把这些数作为加数往后加。（$XY[i]$ 是最终计算目标，而 $sum[i]$ 是当前计算结果。）</p><div class="markdown-alert markdown-alert-tip"><p class=markdown-alert-title><svg class="octicon octicon-light-bulb mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M8 1.5c-2.363.0-4 1.69-4 3.75.0.984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75.0 01-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456.0 00-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863.0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751.0 01-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304.0-2.06-1.637-3.75-4-3.75zM5.75 12h4.5a.75.75.0 010 1.5h-4.5a.75.75.0 010-1.5zM6 15.25a.75.75.0 01.75-.75h2.5a.75.75.0 010 1.5h-2.5A.75.75.0 016 15.25z"/></svg>Tip</p><p>Reverse tree 阶段是把树状数组转换成部分和（partial sum）。</p></div><p>有一种方案可以满足所有元素的依赖关系：<strong>首先计算 $popcount(i+1)$ 小的那些元素 $XY[i]$</strong>，其中 popcount 操作表示对整数二进制表示中的 1 计数。图中 $XY[11]$ 和 $XY[5]$ 分别对应 12 号和 6 号，他们都只有 6 位，计算是可以同时进行的。这种方法还是从线程 $i$ 对应下标 $i$ 的角度来思考的，不仅需要调用 $popcount()$ 函数，还有控制分歧。书上给出了一种效率更高的、基于 stride 倍减的向后叠加算法，在满足计算依赖的情况下保持了代码简单。</p><p><strong>最终代码</strong>。书上还进行了“线程减半”的优化：虽然每个块处理了一块大小为 <code>SECTION_SIZE</code> 的内存区域，但是实际上使用的线程数最多为 <code>SECTION_SIZE/2</code>（可以看上面的图，斜线表示数据操作，每一行斜线都不超过元素总数的一半），所以在启动 kernel 的时候给的块内线程数只要 <code>SECTION_SIZE/2</code> 就行。换句话说，如果想要减少段数（增大段大小），可以将块内线程数开满，并将 <code>SECTION_SIZE</code> 设置为它的 2 倍。</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span>__global__ <span style=color:#dc322f>void</span> <span style=color:#268bd2>Brent_Kung_scan_kernel</span>(<span style=color:#dc322f>float</span> <span style=color:#719e07>*</span>X, <span style=color:#dc322f>float</span> <span style=color:#719e07>*</span>Y, <span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>int</span> N) {
</span></span><span style=display:flex><span>    __shared__ <span style=color:#dc322f>float</span> XY[SECTION_SIZE];
</span></span><span style=display:flex><span>    <span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>int</span> i <span style=color:#719e07>=</span> <span style=color:#2aa198>2</span><span style=color:#719e07>*</span>blockIdx.x<span style=color:#719e07>*</span>blockDim.x <span style=color:#719e07>+</span> threadIdx.x;
</span></span><span style=display:flex><span>    <span style=color:#586e75>// 有 SECTION_SIZE == 2 * blockDim.x。
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#586e75>// 下面将 X 的数据加载到共享内存中以加快访问。看上去复杂了一点，实际上只是因为
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#586e75>// 现在一个 SECTION_SIZE 等于两倍块内线程数，所以需要多做一些处理。
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#719e07>if</span>(i <span style=color:#719e07>&lt;</span> N) XY[threadIdx.x] <span style=color:#719e07>=</span> X[i];
</span></span><span style=display:flex><span>    <span style=color:#719e07>if</span>(i <span style=color:#719e07>+</span> blockDim.x <span style=color:#719e07>&lt;</span> N) XY[threadIdx.x <span style=color:#719e07>+</span> blockDim.x] <span style=color:#719e07>=</span> X[i <span style=color:#719e07>+</span> blockDim.x];
</span></span><span style=display:flex><span>    <span style=color:#586e75>// Reduction tree.
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#719e07>for</span>(<span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>int</span> stride <span style=color:#719e07>=</span> <span style=color:#2aa198>1</span>; stride <span style=color:#719e07>&lt;=</span> blockDim.x; stride <span style=color:#719e07>*=</span> <span style=color:#2aa198>2</span>) {
</span></span><span style=display:flex><span>        __syncthreads();
</span></span><span style=display:flex><span>        <span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>int</span> index <span style=color:#719e07>=</span> (threadIdx.x <span style=color:#719e07>+</span> <span style=color:#2aa198>1</span>)<span style=color:#719e07>*</span><span style=color:#2aa198>2</span><span style=color:#719e07>*</span>stride <span style=color:#719e07>-</span> <span style=color:#2aa198>1</span>;
</span></span><span style=display:flex><span>        <span style=color:#719e07>if</span>(index <span style=color:#719e07>&lt;</span> SECTION_SIZE) {
</span></span><span style=display:flex><span>            XY[index] <span style=color:#719e07>+=</span> XY[index <span style=color:#719e07>-</span> stride];
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#586e75>// Reverse tree.
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#719e07>for</span> (<span style=color:#dc322f>int</span> stride <span style=color:#719e07>=</span> SECTION_SIZE<span style=color:#719e07>/</span><span style=color:#2aa198>4</span>; stride <span style=color:#719e07>&gt;</span> <span style=color:#2aa198>0</span>; stride <span style=color:#719e07>/=</span> <span style=color:#2aa198>2</span>) {
</span></span><span style=display:flex><span>        __syncthreads();
</span></span><span style=display:flex><span>        <span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>int</span> index <span style=color:#719e07>=</span> (threadIdx.x <span style=color:#719e07>+</span> <span style=color:#2aa198>1</span>)<span style=color:#719e07>*</span>stride<span style=color:#719e07>*</span><span style=color:#2aa198>2</span> <span style=color:#719e07>-</span> <span style=color:#2aa198>1</span>;
</span></span><span style=display:flex><span>        <span style=color:#719e07>if</span>(index <span style=color:#719e07>+</span> stride <span style=color:#719e07>&lt;</span> SECTION_SIZE) {
</span></span><span style=display:flex><span>            XY[index <span style=color:#719e07>+</span> stride] <span style=color:#719e07>+=</span> XY[index];
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    __syncthreads();
</span></span><span style=display:flex><span>    <span style=color:#586e75>// 将共享缓存上的结果写回结果数组。
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#719e07>if</span> (i <span style=color:#719e07>&lt;</span> N) Y[i] <span style=color:#719e07>=</span> XY[threadIdx.x];
</span></span><span style=display:flex><span>    <span style=color:#719e07>if</span> (i <span style=color:#719e07>+</span> blockDim.x <span style=color:#719e07>&lt;</span> N) Y[i <span style=color:#719e07>+</span> blockDim.x] <span style=color:#719e07>=</span> XY[threadIdx.x <span style=color:#719e07>+</span> blockDim.x];
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>注意到 Brent-Kung 算法每个迭代只同步一次。</p><h3 id=双缓冲>双缓冲
<a class=header-anchor href=#%e5%8f%8c%e7%bc%93%e5%86%b2></a></h3><p>使用 Kogge-Stone 算法时，GPU 和 CPU 都能使用双缓冲提高效率。<em>C++ Concurrency in Action</em> 示例使用了一个输入区间一样大的工作区，然后和输入区间轮替保存每次迭代的结果。线程们通过<strong>全局双缓冲区</strong>共享数据，而不是各自用变量暂存要写入的结果，将每个迭代要同步的次数从 2 次减少到了 1 次。</p><p>使用 Brent-Kung 算法时，不需要双缓冲，每个迭代只同步 1 次。</p><h3 id=barrier-的使用>Barrier 的使用
<a class=header-anchor href=#barrier-%e7%9a%84%e4%bd%bf%e7%94%a8></a></h3><p>无论是 GPU 上的计算还是 CPU 上的计算，都要用 barrier 来同步。CUDA 中直接使用 <code>__syncthreads()</code> 就好，而 CPU 算法要使用 <code>std::barrier</code>。由于 <code>std::barrier</code> 在 C++20 才被加入，书上给了一个简单的基于原子变量的忙等待的实现。</p><h3 id=线程的提前退出>线程的提前退出
<a class=header-anchor href=#%e7%ba%bf%e7%a8%8b%e7%9a%84%e6%8f%90%e5%89%8d%e9%80%80%e5%87%ba></a></h3><p>CUDA 中 <code>__syncthreads()</code> 不会让参与同步的 GPU 线程退出，而 C++ <code>std::barrier</code> 允许当前线程用 <code>arrive_and_drop()</code> 来退出同步，这一方面是因为在 CPU 上计算可以控制更加精细，另一方面是因为操作系统的线程资源很宝贵，有必要及时释放。参考下面两份代码（忽略是否使用双缓冲这一点的差异）：</p><p>CUDA 中的 Koggle Stone 算法：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span>__global__ <span style=color:#dc322f>void</span> <span style=color:#268bd2>Kogge_Stone_scan_kernel</span>(<span style=color:#dc322f>float</span> <span style=color:#719e07>*</span>X, <span style=color:#dc322f>float</span> <span style=color:#719e07>*</span>Y, <span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>int</span> N) {
</span></span><span style=display:flex><span>    __shared__ <span style=color:#dc322f>float</span> XY[SECTION_SIZE];
</span></span><span style=display:flex><span>    <span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>int</span> i <span style=color:#719e07>=</span> blockIdx.x <span style=color:#719e07>*</span> blockDim.x <span style=color:#719e07>+</span> threadIdx.x;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#719e07>if</span> (i <span style=color:#719e07>&lt;</span> N) {
</span></span><span style=display:flex><span>        XY[threadIdx.x] <span style=color:#719e07>=</span> X[i];
</span></span><span style=display:flex><span>    } <span style=color:#719e07>else</span> {
</span></span><span style=display:flex><span>        XY[threadIdx.x] <span style=color:#719e07>=</span> <span style=color:#2aa198>0.0f</span>;
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#586e75>// 注意 stride &lt; blockDim.x 保证了所有线程要经历相同的迭代次数
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#719e07>for</span> (<span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>int</span> stride <span style=color:#719e07>=</span> <span style=color:#2aa198>1</span>; stride <span style=color:#719e07>&lt;</span> blockDim.x; stride <span style=color:#719e07>*=</span> <span style=color:#2aa198>2</span>) {
</span></span><span style=display:flex><span>        __syncthreads();
</span></span><span style=display:flex><span>        <span style=color:#dc322f>float</span> temp;
</span></span><span style=display:flex><span>        <span style=color:#719e07>if</span> (threadIdx.x <span style=color:#719e07>&gt;=</span> stride) {
</span></span><span style=display:flex><span>            temp <span style=color:#719e07>=</span> XY[threadIdx.x] <span style=color:#719e07>+</span> XY[threadIdx.x <span style=color:#719e07>-</span> stride];
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        __syncthreads();
</span></span><span style=display:flex><span>        <span style=color:#719e07>if</span> (threadIdx.x <span style=color:#719e07>&gt;=</span> stride) {
</span></span><span style=display:flex><span>            XY[threadIdx.x] <span style=color:#719e07>=</span> temp;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#719e07>if</span> (i <span style=color:#719e07>&lt;</span> N) {
</span></span><span style=display:flex><span>        Y[i] <span style=color:#719e07>=</span> XY[threadIdx.x];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>C++ 中的 Koggle Stone 算法（有线程提前退出 barrier）：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#dc322f>void</span> <span style=color:#268bd2>operator</span>()(Iterator first, Iterator last, 
</span></span><span style=display:flex><span>                std<span style=color:#719e07>::</span>vector<span style=color:#719e07>&lt;</span>value_type<span style=color:#719e07>&gt;&amp;</span> buffer, <span style=color:#dc322f>unsigned</span> i, barrier<span style=color:#719e07>&amp;</span> b) {
</span></span><span style=display:flex><span>    value_type<span style=color:#719e07>&amp;</span> ith_element <span style=color:#719e07>=</span> <span style=color:#719e07>*</span>(first <span style=color:#719e07>+</span> i);
</span></span><span style=display:flex><span>    <span style=color:#dc322f>bool</span> update_source <span style=color:#719e07>=</span> <span style=color:#b58900>false</span>;
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#586e75>// stride &lt;= i 而不是 stride &lt; std::distance(first, last)
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#586e75>// 使得不同线程的迭代次数不同，有些线程比其他线程更早离开循环
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#719e07>for</span> (<span style=color:#dc322f>unsigned</span> step <span style=color:#719e07>=</span> <span style=color:#2aa198>0</span>, stride <span style=color:#719e07>=</span> <span style=color:#2aa198>1</span>; stride <span style=color:#719e07>&lt;=</span> i; <span style=color:#719e07>++</span>step, stride <span style=color:#719e07>*=</span> <span style=color:#2aa198>2</span>) {
</span></span><span style=display:flex><span>        value_type <span style=color:#719e07>const</span><span style=color:#719e07>&amp;</span> source <span style=color:#719e07>=</span> (step <span style=color:#719e07>%</span> <span style=color:#2aa198>2</span>) <span style=color:#719e07>?</span> buffer[i] <span style=color:#719e07>:</span> ith_element;
</span></span><span style=display:flex><span>        value_type<span style=color:#719e07>&amp;</span> dest <span style=color:#719e07>=</span> (step <span style=color:#719e07>%</span> <span style=color:#2aa198>2</span>) <span style=color:#719e07>?</span> ith_element : buffer[i];
</span></span><span style=display:flex><span>        value_type <span style=color:#719e07>const</span><span style=color:#719e07>&amp;</span> addend <span style=color:#719e07>=</span> (step <span style=color:#719e07>%</span> <span style=color:#2aa198>2</span>) <span style=color:#719e07>?</span> buffer[i <span style=color:#719e07>-</span> stride] <span style=color:#719e07>:</span> <span style=color:#719e07>*</span>(first <span style=color:#719e07>+</span> i <span style=color:#719e07>-</span> stride);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        dest <span style=color:#719e07>=</span> source <span style=color:#719e07>+</span> addend;
</span></span><span style=display:flex><span>        update_source <span style=color:#719e07>=</span> <span style=color:#719e07>!</span>(step <span style=color:#719e07>%</span> <span style=color:#2aa198>2</span>);
</span></span><span style=display:flex><span>        b.wait(); <span style=color:#586e75>// 相当于 std::barrier::arrive_and_wait
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    }
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#719e07>if</span> (update_source) {
</span></span><span style=display:flex><span>        ith_element <span style=color:#719e07>=</span> buffer[i];
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#586e75>// 必须离开线程组，否则其他线程会卡在 lockstep 中
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    b.done_waiting(); <span style=color:#586e75>// 相当于 std::barrier::arrive_and_drop
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>}
</span></span></code></pre></div><h3 id=segmented-scan-和-stream-based-scan>Segmented scan 和 stream-based scan
<a class=header-anchor href=#segmented-scan-%e5%92%8c-stream-based-scan></a></h3><p><em>C++ Concurrency in Action</em> 示例对每个元素专门创建了一个线程（代码简单但效率低），尽管系统内的线程数有上限（在我的 wsl2 中，<code>cat /proc/sys/kernel/threads-max</code> 结果为 <code>125610</code>），但这仍然比 CUDA 中允许的一个 block 中的最大线程数 1024 要多，因此实现的是一个不分段的 scan 算法，或者说没有对数据量极大的情况做分段处理。</p><p>在 GPU 上，因为一个 block 中线程数量有限，可以：①先做分段的 scan（无论是 inclusive 还是 exclusive），在最后一步中将每个段的元素总和（block sums）写回到一个辅助数组中；②对 block sums 做 exclusive scan，得到每个 block 上应该加多少值作为补偿；③将这些值加回到第 ① 步算出来的结果上。</p><p>如果要在 GPU 上避免分段，可以借用“Chunks 之间通信”的思路实现一趟的算法。<strong>这样可以避免先将中间结果写到全局内存再读取的开销</strong>。这被称为 stream-based scan algorithm。<em>Programming Massively Parallel Processors</em> 中介绍了以原子变量来同步的方法：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span>__shared__ <span style=color:#dc322f>float</span> previous_sum;
</span></span><span style=display:flex><span><span style=color:#719e07>if</span> (threadIdx.x <span style=color:#719e07>==</span> <span style=color:#2aa198>0</span>){
</span></span><span style=display:flex><span>    <span style=color:#586e75>// Wait for previous flag
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#719e07>while</span>(atomicAdd(<span style=color:#719e07>&amp;</span>flags[bid], <span style=color:#2aa198>0</span>) <span style=color:#719e07>==</span> <span style=color:#2aa198>0</span>) { }
</span></span><span style=display:flex><span>    <span style=color:#586e75>// Read previous partial sum
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    previous_sum <span style=color:#719e07>=</span> scan_value[bid];
</span></span><span style=display:flex><span>    <span style=color:#586e75>// Propagate partial sum
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    scan_value[bid <span style=color:#719e07>+</span> <span style=color:#2aa198>1</span>] <span style=color:#719e07>=</span> previous_sum <span style=color:#719e07>+</span> local_sum;
</span></span><span style=display:flex><span>    <span style=color:#586e75>// Memory fence
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    __threadfence();
</span></span><span style=display:flex><span>    <span style=color:#586e75>// Set flag
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    atomicAdd(<span style=color:#719e07>&amp;</span>flags[bid <span style=color:#719e07>+</span> <span style=color:#2aa198>1</span>], <span style=color:#2aa198>1</span>);
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>__syncthreads();
</span></span></code></pre></div><p>上面这种方法有个问题是：GPU 上块并不是（按照 <code>blockIdx.x</code>）先后执行的，有可能前一个块没有被执行，而后一个块开始执行了。这样可能导致性能下降或者死锁。书上说如果 block i 到 i+N 占用了所有的 SM，那么 block i-1 不能得到调度，block i 到 i+N 只能无限等待下去。</p><p>一种补救的办法是 dynamic block index assignment，也就是不使用 <code>blockIdx.x</code>，而是通过原子变量来动态获取 block 编号：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-cpp data-lang=cpp><span style=display:flex><span>__shared__ <span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>int</span> bid_s;
</span></span><span style=display:flex><span><span style=color:#719e07>if</span> (threadIdx.x <span style=color:#719e07>==</span> <span style=color:#2aa198>0</span>) {
</span></span><span style=display:flex><span>    bid_s <span style=color:#719e07>=</span> atomicAdd(blockCounter, <span style=color:#2aa198>1</span>);
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>__syncthreads();
</span></span><span style=display:flex><span><span style=color:#dc322f>unsigned</span> <span style=color:#dc322f>int</span> bid <span style=color:#719e07>=</span> bid_s;
</span></span></code></pre></div></div><footer class=post-footer><div class=post-tags><a href=/tags/cpp>cpp
</a><a href=/tags/cpp-concurrency-in-action>cpp-concurrency-in-action</a></div><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/cpp-concurrency-in-action/9.-Advanced-thread-management/ rel=next title="9. Advanced thread management"><i class="fa fa-chevron-left"></i> 9. Advanced thread management</a></div><div class="post-nav-prev post-nav-item"><a href=/cpp-concurrency-in-action/5.1-libstdc++-%E5%AF%B9%E5%85%B1%E4%BA%AB%E6%8C%87%E9%92%88%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%9A%84%E6%94%AF%E6%8C%81/ rel=prev title="5.1 libstdc++ 对共享指针原子操作的支持">5.1 libstdc++ 对共享指针原子操作的支持
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>&copy;
<span itemprop=copyrightYear>2023 - 2025
</span><span class=with-love><i class="fa fa-heart"></i>
</span><span class=author itemprop=copyrightHolder>🤖</span></div><div class=powered-by>由 <a href=https://gohugo.io title=0.143.1 target=_blank>Hugo</a> & <a href=https://github.com/hugo-next/hugo-theme-next title=4.5.3 target=_blank>Hugo NexT.Gemini</a> 强力驱动</div></div></footer><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js defer></script><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js defer></script><script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":false,"save":"manual"},"copybtn":true,"darkmode":false,"hostname":"https://hxhue.github.io/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"找到 ${hits} 个搜索结果","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"limit":1e3,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":false,"transition":{"collheader":"fadeInLeft","menu_item":"fadeInDown","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"postmeta":{"comments":{"enable":false,"plugin":"waline"},"views":{"enable":false,"plugin":"busuanzi"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"vendor":{"plugins":"cdnjs","router":"https://cdnjs.cloudflare.com/ajax/libs"},"version":"4.5.3"}</script><script type=text/javascript src=/js/main.min.37ba8b54f9d4d784d08028c45eea93b5d4e13eda8ee7fb0d2edd6f3fac66cfd2.js defer></script></body></html>