<!doctype html><html lang=zh-CN data-theme=light><head><meta charset=UTF-8><meta name=viewport content="width=device-width"><meta name=theme-color content="#222" media="(prefers-color-scheme: light)"><meta name=generator content="Hugo 0.143.1"><link rel="shortcut icon" type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/x-icon href=/imgs/icons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=/imgs/icons/favicon_16x16_next.png><link rel=icon type=image/png sizes=32x32 href=/imgs/icons/favicon_32_32_next.png><link rel=apple-touch-icon sizes=180x180 href=/imgs/icons/apple_touch_icon_next.png><meta itemprop=name content="PyTorch 的 CPU 计算为什么使用 double 作为 32 位浮点数的累加类型？"><meta itemprop=description content="个人博客，主要是零散的笔记。"><meta itemprop=datePublished zgotmplz><meta itemprop=dateModified zgotmplz><meta itemprop=image content="https://hxhue.github.io/imgs/371907.jpg"><meta itemprop=keywords content="torch"><link type=text/css rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css><link type=text/css rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css><link rel=stylesheet href=/css/main.min.bea76f574a755574e17d42bea39502a74ca3ca4db65807b8c82d3e26dcec8420.css><style type=text/css>.post-footer,.flinks-list-footer hr:after{content:"~ 我可是有底线的哟 ~"}</style><link rel=stylesheet type=text/css href=/css/style.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/github-markdown-css@5.3.0/github-markdown-dark.css><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js></script><script>MathJax={tex:{displayMath:[["$$","$$"],["\\[","\\]"]],inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=module>
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: false });
  mermaid.mermaidAPI.initialize();
  window.mermaid = mermaid;
</script><script type=text/javascript>(function(){localDB={set:function(e,t,n){if(n===0)return;const s=new Date,o=n*864e5,i={value:t,expiry:s.getTime()+o};localStorage.setItem(e,JSON.stringify(i))},get:function(e){const t=localStorage.getItem(e);if(!t)return void 0;const n=JSON.parse(t),s=new Date;return s.getTime()>n.expiry?(localStorage.removeItem(e),void 0):n.value}},theme={active:function(){const e=localDB.get("theme");if(e==null)return;theme.toggle(e),window.matchMedia("(prefers-color-scheme: dark)").addListener(function(e){theme.toggle(e.matches?"dark":"light")})},toggle:function(e){document.documentElement.setAttribute("data-theme",e),localDB.set("theme",e,2);const t=document.querySelector("iframe.giscus-frame");if(t){const n={setConfig:{theme:e}};t.contentWindow.postMessage({giscus:n},"https://giscus.app")}}},theme.active()})(window)</script><script class=next-config data-name=page type=application/json>{"comments":false,"isHome":false,"isPage":true,"path":"PyTorch-%E7%9A%84-CPU-%E8%AE%A1%E7%AE%97%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8-double-%E4%BD%9C%E4%B8%BA-32-%E4%BD%8D%E6%B5%AE%E7%82%B9%E6%95%B0%E7%9A%84%E7%B4%AF%E5%8A%A0%E7%B1%BB%E5%9E%8B","permalink":"https://hxhue.github.io/posts/programming/python/PyTorch-%E7%9A%84-CPU-%E8%AE%A1%E7%AE%97%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8-double-%E4%BD%9C%E4%B8%BA-32-%E4%BD%8D%E6%B5%AE%E7%82%B9%E6%95%B0%E7%9A%84%E7%B4%AF%E5%8A%A0%E7%B1%BB%E5%9E%8B/","title":"PyTorch 的 CPU 计算为什么使用 double 作为 32 位浮点数的累加类型？","waline":{"js":[{"alias":"waline","alias_name":"@waline/client","file":"dist/pageview.js","name":"pageview","version":"2.13.0"},{"alias":"waline","alias_name":"@waline/client","file":"dist/comment.js","name":"comment","version":"2.13.0"}]}}</script><script type=text/javascript>document.addEventListener("DOMContentLoaded",()=>{var e=document.createElement("script");e.charset="UTF-8",e.src="",e.async=!1,e.defer=!0,document.head.appendChild(e),e.onload=function(){NexT.utils.fmtBusuanzi()}})</script><title>PyTorch 的 CPU 计算为什么使用 double 作为 32 位浮点数的累加类型？ - Bluegill</title><noscript><link rel=stylesheet href=/css/noscript.css></noscript></head><body itemscope itemtype=http://schema.org/WebPage><div class=headband></div><main class=main><header class=header itemscope itemtype=http://schema.org/WPHeader><div class=header-inner><div class=site-brand-container><div class=site-nav-toggle><div class=toggle aria-label role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div></div><div class=site-meta><a href=/ class=brand rel=start><i class=logo-line></i><h1 class=site-title>Bluegill</h1><i class=logo-line></i></a><p class=site-subtitle itemprop=description></p></div><div class=site-nav-right><div class="toggle popup-trigger"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class=site-nav><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href=/ class=hvr-icon-pulse rel=section><i class="fa fa-home hvr-icon"></i>首页</a></li><li class="menu-item menu-item-about"><a href=/about/ class=hvr-icon-pulse rel=section><i class="fa fa-user hvr-icon"></i>关于</a></li><li class="menu-item menu-item-archives"><a href=/archives/ class=hvr-icon-pulse rel=section><i class="fa fa-archive hvr-icon"></i>归档</a></li><li class="menu-item menu-item-categories"><a href=/categories/ class=hvr-icon-pulse rel=section><i class="fa fa-th hvr-icon"></i>分类</a></li><li class="menu-item menu-item-tags"><a href=/tags/ class=hvr-icon-pulse rel=section><i class="fa fa-hashtag hvr-icon"></i>标签</a></li><li class="menu-item menu-item-daily"><a href=/daily/ class=hvr-icon-pulse rel=section><i class="fa fa-newspaper hvr-icon"></i>随笔</a></li><li class="menu-item menu-item-discovery"><a href=https://rift-fear-f2c.notion.site/2025-1e354a33cfb1802c841bdf29f2f3dab3 class=hvr-icon-pulse rel=section><i class="fa fa-compass hvr-icon"></i>发现</a></li><li class="menu-item menu-item-search"><a role=button class="popup-trigger hvr-icon-pulse"><i class="fa fa-search fa-fw hvr-icon"></i>搜索</a></li></ul></nav><div class=search-pop-overlay><div class="popup search-popup"><div class=search-header><span class=search-icon><i class="fa fa-search"></i></span><div class=search-input-container><input autocomplete=off autocapitalize=off maxlength=80 placeholder=搜索... spellcheck=false type=search class=search-input></div><span class=popup-btn-close role=button><i class="fa fa-times-circle"></i></span></div><div class="search-result-container no-result"><div class=search-result-icon><i class="fa fa-spinner fa-pulse fa-5x"></i></div></div></div></div></div><div class="toggle sidebar-toggle" role=button><span class=toggle-line></span>
<span class=toggle-line></span>
<span class=toggle-line></span></div><aside class=sidebar><div class="sidebar-inner sidebar-nav-active sidebar-toc-active"><ul class=sidebar-nav><li class=sidebar-nav-toc>文章目录</li><li class=sidebar-nav-overview>站点概览</li></ul><div class=sidebar-panel-container><div class="post-toc-wrap sidebar-panel"><div class="post-toc animated"><nav id=TableOfContents></nav></div></div><div class="site-overview-wrap sidebar-panel"><div class="site-author site-overview-item animated" itemprop=author itemscope itemtype=http://schema.org/Person><img class=site-author-image itemprop=image alt=🤖 src=/imgs/371907.jpg><p class=site-author-name itemprop=name>🤖</p><div class=site-description itemprop=description>个人博客，主要是零散的笔记。</div></div><div class="site-state-wrap site-overview-item animated"><nav class=site-state><div class="site-state-item site-state-posts"><a href=/archives/><span class=site-state-item-count>433</span>
<span class=site-state-item-name>日志</span></a></div><div class="site-state-item site-state-categories"><a href=/categories/><span class=site-state-item-count>12</span>
<span class=site-state-item-name>分类</span></a></div><div class="site-state-item site-state-tags"><a href=/tags/><span class=site-state-item-count>86</span>
<span class=site-state-item-name>标签</span></a></div></nav></div><div class="links-of-social site-overview-item animated"><span class=links-of-social-item><a href=https://github.com/hxhue title="Github → https://github.com/hxhue" rel=noopener target=_blank><i class="fab fa-github fa-fw"></i>
Github
</a></span><span class=links-of-social-item><a href=/rss.xml title="RSS 订阅 → /rss.xml" rel=noopener target=_blank><i class="fa fa-rss fa-fw"></i>
RSS 订阅</a></span></div><div class="cc-license animated" itemprop=license><a href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh class=cc-opacity rel=noopener target=_blank title=共享知识><img src=/imgs/cc/big/by_nc_sa.svg alt=共享知识></a></div><div class="links-of-blogroll site-overview-item animated"><div class=links-of-blogroll-title><i class="fa fa-globe fa-fw"></i>
友情链接</div><ul class=links-of-blogroll-list><li class=links-of-blogroll-item><a href=https://shuai.guru/ title=https://shuai.guru/ target=_blank>shuai.guru</a></li></ul></div></div></div></div></aside><div class=sidebar-dimmer></div></header><div class=tool-buttons><div id=toggle-theme class=button title=深浅模式切换><i class="fas fa-adjust"></i></div><div class=back-to-top role=button title=返回顶部><i class="fa fa-arrow-up"></i>
<span>0%</span></div></div><div class=reading-progress-bar></div><noscript><div class=noscript-warning>Theme NexT works best with JavaScript enabled</div></noscript><div class="main-inner post posts-expand"><div class=post-block><article itemscope itemtype=http://schema.org/Article class=post-content lang><link itemprop=mainEntityOfPage href=https://hxhue.github.io/posts/programming/python/PyTorch-%E7%9A%84-CPU-%E8%AE%A1%E7%AE%97%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8-double-%E4%BD%9C%E4%B8%BA-32-%E4%BD%8D%E6%B5%AE%E7%82%B9%E6%95%B0%E7%9A%84%E7%B4%AF%E5%8A%A0%E7%B1%BB%E5%9E%8B/><span hidden itemprop=author itemscope itemtype=http://schema.org/Person><meta itemprop=image content="/imgs/371907.jpg"><meta itemprop=name content="🤖"></span><span hidden itemprop=publisher itemscope itemtype=http://schema.org/Organization><meta itemprop=name content="🤖"><meta itemprop=description content="个人博客，主要是零散的笔记。"></span><span hidden itemprop=post itemscope itemtype=http://schema.org/CreativeWork><meta itemprop=name content="PyTorch 的 CPU 计算为什么使用 double 作为 32 位浮点数的累加类型？"><meta itemprop=description content="
  
    
      
      
    Tip
  本文没有得到最终结论，只是一些个人猜想。"></span><header class=post-header><h1 class=post-title itemprop="name headline">PyTorch 的 CPU 计算为什么使用 double 作为 32 位浮点数的累加类型？</h1><div class=post-meta-container><div class=post-meta-items><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar"></i>
</span><span class=post-meta-item-text title=发表于>发表于：
</span><time title="创建时间：2024-08-10 00:00:00 +0800 CST" itemprop="dateCreated datePublished" datetime="2024-08-10 00:00:00 +0800 CST">2024-08-10
</time></span><span class=post-meta-item><span class=post-meta-item-icon><i class="far fa-calendar-check"></i>
</span><span class=post-meta-item-text title=更新于>更新于：
</span><time title=修改时间：2024-08-27T00:00:00+08:00 itemprop=dateModified datetime=2024-08-27T00:00:00+08:00>2024-08-27</time></span></div><div class=post-meta-items><span class=post-meta-item title=字数><span class=post-meta-item-icon><i class="far fa-file-word"></i>
</span><span class=post-meta-item-text>字数：</span>
<span>847</span>
</span><span class=post-meta-item title=阅读><span class=post-meta-item-icon><i class="far fa-clock"></i>
</span><span class=post-meta-item-text>阅读：&ap;</span>
<span>2分钟</span></span></div></div></header><div class=post-body itemprop=articleBody><div class="markdown-alert markdown-alert-tip"><p class=markdown-alert-title><svg class="octicon octicon-light-bulb mr-2" viewBox="0 0 16 16" width="16" height="16" aria-hidden="true"><path d="M8 1.5c-2.363.0-4 1.69-4 3.75.0.984.424 1.625.984 2.304l.214.253c.223.264.47.556.673.848.284.411.537.896.621 1.49a.75.75.0 01-1.484.211c-.04-.282-.163-.547-.37-.847a8.456 8.456.0 00-.542-.68c-.084-.1-.173-.205-.268-.32C3.201 7.75 2.5 6.766 2.5 5.25 2.5 2.31 4.863.0 8 0s5.5 2.31 5.5 5.25c0 1.516-.701 2.5-1.328 3.259-.095.115-.184.22-.268.319-.207.245-.383.453-.541.681-.208.3-.33.565-.37.847a.751.751.0 01-1.485-.212c.084-.593.337-1.078.621-1.489.203-.292.45-.584.673-.848.075-.088.147-.173.213-.253.561-.679.985-1.32.985-2.304.0-2.06-1.637-3.75-4-3.75zM5.75 12h4.5a.75.75.0 010 1.5h-4.5a.75.75.0 010-1.5zM6 15.25a.75.75.0 01.75-.75h2.5a.75.75.0 010 1.5h-2.5A.75.75.0 016 15.25z"/></svg>Tip</p><p>本文没有得到最终结论，只是一些个人猜想。</p></div><p><a href=/posts/programming/cuda/CUDA-Kernel-%E5%B8%B8%E7%94%A8-float-%E7%B1%BB%E5%9E%8B%E8%BF%99%E4%BB%B6%E4%BA%8B/ title="CUDA Kernel 常用 float 类型这件事">CUDA Kernel 常用 float 类型这件事</a> 这篇笔记提到一个 issue 里面说 ATen 使用 double 作为 32 位浮点数的累加类型是因为用 float 会挂掉一个 batchnorm 的测试。这在我看来不可思议，因为 GPU 上面测试都没有挂，为什么 CPU 上面反而会挂呢？本文记录笔者看 batchnorm 的实现、试图找到原因的过程。</p><p>PyTorch 的 batchnorm 要对每一轮的输入计算均值和标准差，其中计算均值就需要将输入都加起来（再除以元素总数），这中间就可能产生累加误差。标准差的计算也类似，会有累加产生的误差。</p><p>从 aten/src/ATen/native/native_functions.yaml 中可以找到 <code>native_batch_norm()</code> 函数是在哪里实现的：</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-yaml data-lang=yaml><span style=display:flex><span>- <span style=color:#268bd2>func</span>: native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -&gt; (Tensor, Tensor, Tensor)
</span></span><span style=display:flex><span>  <span style=color:#268bd2>dispatch</span>:
</span></span><span style=display:flex><span>    <span style=color:#268bd2>CPU</span>: batch_norm_cpu
</span></span><span style=display:flex><span>    <span style=color:#268bd2>CUDA</span>: batch_norm_cuda
</span></span><span style=display:flex><span>    <span style=color:#268bd2>MPS</span>: batch_norm_mps
</span></span><span style=display:flex><span>    <span style=color:#268bd2>MkldnnCPU</span>: mkldnn_batch_norm
</span></span></code></pre></div><p>CUDA 中的累加函数是 <a href=https://github.com/pytorch/pytorch/blob/2ad011ca73f68185783ec9afeb730615769a3fca/aten/src/ATen/native/cuda/Normalization.cuh#L269 title=batch_norm_collect_statistics_kernel() rel="noopener external nofollow noreferrer" target=_blank class=exturl><code>batch_norm_collect_statistics_kernel()</code><i class="fa fa-external-link-alt"></i></a>。计算方差时用了 Welford 算法，看不懂。Welford 算法是一种只进行一次遍历的在线计算方差的方法，能够有效降低舍入误差。可以参考 <a href=https://shuai.guru/welford-variance/ title=https://shuai.guru/welford-variance/ rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://shuai.guru/welford-variance/<i class="fa fa-external-link-alt"></i></a> 和 <a href=https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance title=https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance<i class="fa fa-external-link-alt"></i></a> 。</p><p>CPU 中的累加函数是 <a href=https://github.com/pytorch/pytorch/blob/2ad011ca73f68185783ec9afeb730615769a3fca/aten/src/ATen/native/cpu/batch_norm_kernel.cpp#L1352 title=batch_norm_cpu_collect_stats_kernel() rel="noopener external nofollow noreferrer" target=_blank class=exturl><code>batch_norm_cpu_collect_stats_kernel()</code><i class="fa fa-external-link-alt"></i></a>。该函数又分情况调用了很多函数，可以先参考 <a href=https://github.com/pytorch/pytorch/blob/2ad011ca73f68185783ec9afeb730615769a3fca/aten/src/ATen/native/cpu/batch_norm_kernel.cpp#L193-L217 title=batch_norm_cpu_collect_stats_contiguous_impl() rel="noopener external nofollow noreferrer" target=_blank class=exturl><code>batch_norm_cpu_collect_stats_contiguous_impl()</code><i class="fa fa-external-link-alt"></i></a>（代码如下），可以看出并行是在多通道层面上的，每个通道上是把每个像素的值一个一个加起来的。<strong>按照 <a href=https://en.wikipedia.org/wiki/Pairwise_summation title=https://en.wikipedia.org/wiki/Pairwise_summation rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://en.wikipedia.org/wiki/Pairwise_summation<i class="fa fa-external-link-alt"></i></a> 的说法，这样的 naive 累加误差会比 pairwise 的算法误差大</strong>。而算方差的时候，这段代码又进行了第二次遍历，没有使用一次遍历算法，误差应该是会比 Welford 更小一点？</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#586e75>// batch_norm_cpu_collect_stats_contiguous_impl() 函数中的代码
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>at<span style=color:#719e07>::</span><span style=color:#268bd2>parallel_for</span>(<span style=color:#2aa198>0</span>, n_channel, <span style=color:#2aa198>1</span>, [<span style=color:#719e07>&amp;</span>](<span style=color:#dc322f>int64_t</span> begin, <span style=color:#dc322f>int64_t</span> end) {
</span></span><span style=display:flex><span>  <span style=color:#719e07>for</span> (<span style=color:#719e07>const</span> <span style=color:#719e07>auto</span> c : c10<span style=color:#719e07>::</span><span style=color:#268bd2>irange</span>(begin, end)) {
</span></span><span style=display:flex><span>    <span style=color:#586e75>// compute mean per input
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#dc322f>accscalar_t</span> sum <span style=color:#719e07>=</span> <span style=color:#2aa198>0</span>;
</span></span><span style=display:flex><span>    <span style=color:#719e07>for</span> (<span style=color:#719e07>const</span> <span style=color:#719e07>auto</span> n : c10<span style=color:#719e07>::</span><span style=color:#268bd2>irange</span>(n_batch)) {
</span></span><span style=display:flex><span>      <span style=color:#719e07>for</span> (<span style=color:#719e07>const</span> <span style=color:#719e07>auto</span> i : c10<span style=color:#719e07>::</span><span style=color:#268bd2>irange</span>(image_size)) {
</span></span><span style=display:flex><span>        <span style=color:#719e07>auto</span> offset <span style=color:#719e07>=</span> n <span style=color:#719e07>*</span> n_channel <span style=color:#719e07>*</span> image_size <span style=color:#719e07>+</span> c <span style=color:#719e07>*</span> image_size <span style=color:#719e07>+</span> i;
</span></span><span style=display:flex><span>        sum <span style=color:#719e07>+=</span> input_data[offset];
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    <span style=color:#dc322f>scalar_t</span> mean <span style=color:#719e07>=</span> sum <span style=color:#719e07>/</span> N;
</span></span><span style=display:flex><span>    mean_data[c] <span style=color:#719e07>=</span> mean;
</span></span><span style=display:flex><span>  
</span></span><span style=display:flex><span>    <span style=color:#586e75>// compute variance per input
</span></span></span><span style=display:flex><span><span style=color:#586e75></span>    <span style=color:#dc322f>accscalar_t</span> _var_sum <span style=color:#719e07>=</span> <span style=color:#2aa198>0</span>;
</span></span><span style=display:flex><span>    <span style=color:#719e07>for</span> (<span style=color:#719e07>const</span> <span style=color:#719e07>auto</span> n : c10<span style=color:#719e07>::</span><span style=color:#268bd2>irange</span>(n_batch)) {
</span></span><span style=display:flex><span>      <span style=color:#719e07>for</span> (<span style=color:#719e07>const</span> <span style=color:#719e07>auto</span> i : c10<span style=color:#719e07>::</span><span style=color:#268bd2>irange</span>(image_size)) {
</span></span><span style=display:flex><span>        <span style=color:#719e07>auto</span> offset <span style=color:#719e07>=</span> n <span style=color:#719e07>*</span> n_channel <span style=color:#719e07>*</span> image_size <span style=color:#719e07>+</span> c <span style=color:#719e07>*</span> image_size <span style=color:#719e07>+</span> i;
</span></span><span style=display:flex><span>        <span style=color:#719e07>auto</span> x <span style=color:#719e07>=</span> input_data[offset];
</span></span><span style=display:flex><span>        _var_sum <span style=color:#719e07>+=</span> (x <span style=color:#719e07>-</span> mean) <span style=color:#719e07>*</span> (x <span style=color:#719e07>-</span> mean);
</span></span><span style=display:flex><span>      }
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>    var_sum_data[c] <span style=color:#719e07>=</span> _var_sum;
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>});
</span></span></code></pre></div><p><a href=https://github.com/pytorch/pytorch/issues/113414#issuecomment-1809470317 title=https://github.com/pytorch/pytorch/issues/113414#issuecomment-1809470317 rel="noopener external nofollow noreferrer" target=_blank class=exturl>https://github.com/pytorch/pytorch/issues/113414#issuecomment-1809470317<i class="fa fa-external-link-alt"></i></a> 中说 CPU 上 batchnorm 在单精度计算时使用 float 类型而不是 double 类型作为累加类型，会导致一个单元测试失败，是不是因为 CPU 在计算均值和方差的求和过程中没有用 pairwise 或者 kahan 算法？（2024 年 8 月 27 日：可能是相比于 pairwise，按顺序加对 cache 更友好；kahan 会慢。）</p></div><footer class=post-footer><div class=post-tags><a href=/tags/torch>torch</a></div><div class=addthis_inline_share_toolbox style=text-align:center></div><hr><div class=post-nav><div class="post-nav-next post-nav-item"><a href=/posts/systems/Windows/%E6%8D%A2%E6%96%B0%E7%AC%94%E8%AE%B0%E6%9C%AC%E4%B9%8B%E5%90%8E-OneDrive-%E6%B2%A1%E6%9C%89%E6%8A%8A%E6%A1%8C%E9%9D%A2%E5%90%8C%E6%AD%A5%E8%BF%87%E6%9D%A5/ rel=next title="换新笔记本之后 OneDrive 没有把桌面同步过来"><i class="fa fa-chevron-left"></i> 换新笔记本之后 OneDrive 没有把桌面同步过来</a></div><div class="post-nav-prev post-nav-item"><a href=/posts/programming/cuda/CUDA-Kernel-%E5%B8%B8%E7%94%A8-float-%E7%B1%BB%E5%9E%8B%E8%BF%99%E4%BB%B6%E4%BA%8B/ rel=prev title="CUDA Kernel 常用 float 类型这件事">CUDA Kernel 常用 float 类型这件事
<i class="fa fa-chevron-right"></i></a></div></div></footer></article></div></div></main><footer class=footer><div class=footer-inner><div class=copyright>&copy;
<span itemprop=copyrightYear>2023 - 2025
</span><span class=with-love><i class="fa fa-heart"></i>
</span><span class=author itemprop=copyrightHolder>🤖</span></div><div class=powered-by>由 <a href=https://gohugo.io title=0.143.1 target=_blank>Hugo</a> & <a href=https://github.com/hugo-next/hugo-theme-next title=4.5.3 target=_blank>Hugo NexT.Gemini</a> 强力驱动</div></div></footer><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js defer></script><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js defer></script><script class=next-config data-name=main type=application/json>{"bookmark":{"color":"#222","enable":false,"save":"manual"},"copybtn":true,"darkmode":false,"hostname":"https://hxhue.github.io/","i18n":{"ds_day":" 天前","ds_days":" 天 ","ds_hour":" 小时前","ds_hours":" 小时 ","ds_just":"刚刚","ds_min":" 分钟前","ds_mins":" 分钟","ds_month":" 个月前","ds_years":" 年 ","empty":"没有找到任何搜索结果：${query}","hits":"找到 ${hits} 个搜索结果","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","placeholder":"搜索..."},"lang":"zh-CN","lazyload":false,"localSearch":{"enable":true,"limit":1e3,"path":"/searchindexes.xml","preload":false,"topnperarticle":-1,"trigger":"auto","unescape":false},"motion":{"async":true,"enable":false,"transition":{"collheader":"fadeInLeft","menu_item":"fadeInDown","postblock":"fadeIn","postbody":"fadeInDown","postheader":"fadeInDown","sidebar":"fadeInUp"}},"postmeta":{"comments":{"enable":false,"plugin":"waline"},"views":{"enable":false,"plugin":"busuanzi"}},"root":"/","scheme":"Gemini","sidebar":{"display":"post","offset":12,"padding":18,"position":"left","width":256},"vendor":{"plugins":"cdnjs","router":"https://cdnjs.cloudflare.com/ajax/libs"},"version":"4.5.3"}</script><script type=text/javascript src=/js/main.min.37ba8b54f9d4d784d08028c45eea93b5d4e13eda8ee7fb0d2edd6f3fac66cfd2.js defer></script></body></html>