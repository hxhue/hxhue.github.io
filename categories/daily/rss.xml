<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Daily on Bluegill</title><link>https://hxhue.github.io/categories/daily/</link><description>Recent content in Daily on Bluegill</description><generator>Hugo</generator><language>zh-CN</language><lastBuildDate>Thu, 18 Sep 2025 00:00:00 +0800</lastBuildDate><atom:link href="https://hxhue.github.io/categories/daily/rss.xml" rel="self" type="application/rss+xml"/><item><title>2025-04-21 PyTorch 编译架构中没有 sm_89</title><link>https://hxhue.github.io/daily/2025-04-21-PyTorch-%E7%BC%96%E8%AF%91%E6%9E%B6%E6%9E%84%E4%B8%AD%E6%B2%A1%E6%9C%89-sm_89/</link><pubDate>Mon, 21 Apr 2025 00:00:00 +0800</pubDate><guid>https://hxhue.github.io/daily/2025-04-21-PyTorch-%E7%BC%96%E8%AF%91%E6%9E%B6%E6%9E%84%E4%B8%AD%E6%B2%A1%E6%9C%89-sm_89/</guid><description>&lt;p>今天发现很有意思的一件事情：配备 4090 显卡的服务器上安装 torch 之后，显示的架构并没有 sm_89，也没有 PTX（&lt;code>compute_xx&lt;/code>）来支持 JIT。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#93a1a1;background-color:#002b36;-moz-tab-size:2;-o-tab-size:2;tab-size:2;">&lt;code class="language-bash" data-lang="bash">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#719e07">(&lt;/span>minimind&lt;span style="color:#719e07">)&lt;/span> ➜ ~ python -c &lt;span style="color:#2aa198">&amp;#39;import torch;print(torch.cuda.get_arch_list())&amp;#39;&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#719e07">[&lt;/span>&lt;span style="color:#2aa198">&amp;#39;sm_50&amp;#39;&lt;/span>, &lt;span style="color:#2aa198">&amp;#39;sm_60&amp;#39;&lt;/span>, &lt;span style="color:#2aa198">&amp;#39;sm_70&amp;#39;&lt;/span>, &lt;span style="color:#2aa198">&amp;#39;sm_75&amp;#39;&lt;/span>, &lt;span style="color:#2aa198">&amp;#39;sm_80&amp;#39;&lt;/span>, &lt;span style="color:#2aa198">&amp;#39;sm_86&amp;#39;&lt;/span>, &lt;span style="color:#2aa198">&amp;#39;sm_90&amp;#39;&lt;/span>&lt;span style="color:#719e07">]&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#719e07">(&lt;/span>minimind&lt;span style="color:#719e07">)&lt;/span> ➜ ~
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;a href="https://discuss.pytorch.org/t/sm-89-not-listed-in-the-torch-cuda-get-arch-list/215827/5" title="sm_89 not listed in the torch.cuda.get_arch_list() - PyTorch Forums" rel="noopener external nofollow noreferrer"
 target="_blank" class=" exturl" >&lt;code>sm_89&lt;/code> not listed in the &lt;code>torch.cuda.get_arch_list()&lt;/code> - PyTorch Forums&lt;i class="fa fa-external-link-alt">&lt;/i>&lt;/a> 这个讨论说明 sm_89 和 sm_86 是完全兼容的，除了 FP8 支持，这些 kernels 被专门处理。&lt;/p></description></item><item><title>2025-04-19 Microsoft Copilot 和 Windsurf 体验</title><link>https://hxhue.github.io/daily/2025-04-19-Microsoft-Copilot-%E5%92%8C-Windsurf-%E4%BD%93%E9%AA%8C/</link><pubDate>Sat, 19 Apr 2025 00:00:00 +0800</pubDate><guid>https://hxhue.github.io/daily/2025-04-19-Microsoft-Copilot-%E5%92%8C-Windsurf-%E4%BD%93%E9%AA%8C/</guid><description>&lt;h1 id="开头">开头
&lt;a class="header-anchor" href="#%e5%bc%80%e5%a4%b4">&lt;/a>
&lt;/h1>&lt;p>今天在尝试 Microsoft Copilot 和 Windsurf。&lt;/p>
&lt;h1 id="microsoft-copilot-体验">Microsoft Copilot 体验
&lt;a class="header-anchor" href="#microsoft-copilot-%e4%bd%93%e9%aa%8c">&lt;/a>
&lt;/h1>&lt;p>参考 &lt;a href="https://linux.do/t/topic/480869/" title="https://linux.do/t/topic/480869/" rel="noopener external nofollow noreferrer"
 target="_blank" class=" exturl" >https://linux.do/t/topic/480869/&lt;i class="fa fa-external-link-alt">&lt;/i>&lt;/a> ，解读大模型官网和 IDE 的各种额度限制。里面提到了 Microsoft Copilot 使用了 GPT-4o 和 GPT-o3 mini，之前对 Microsoft Copilot 的感受是比较负面的，看到这个新消息后我也查找了对应的资料（有一说一，Microsoft Copilot 查资料还不如 Grok 做的好）：&lt;/p></description></item><item><title>2025-03-17 新闻和博客</title><link>https://hxhue.github.io/daily/2025-03-17-%E6%96%B0%E9%97%BB%E5%92%8C%E5%8D%9A%E5%AE%A2/</link><pubDate>Mon, 17 Mar 2025 00:00:00 +0800</pubDate><guid>https://hxhue.github.io/daily/2025-03-17-%E6%96%B0%E9%97%BB%E5%92%8C%E5%8D%9A%E5%AE%A2/</guid><description>&lt;h1 id="triton-源码教程的-softmax-实现中不做-warmup-的朴素实现快得多">Triton 源码教程的 softmax 实现中，不做 warmup 的朴素实现快得多？！
&lt;a class="header-anchor" href="#triton-%e6%ba%90%e7%a0%81%e6%95%99%e7%a8%8b%e7%9a%84-softmax-%e5%ae%9e%e7%8e%b0%e4%b8%ad%e4%b8%8d%e5%81%9a-warmup-%e7%9a%84%e6%9c%b4%e7%b4%a0%e5%ae%9e%e7%8e%b0%e5%bf%ab%e5%be%97%e5%a4%9a">&lt;/a>
&lt;/h1>&lt;p>






&lt;img src="https://hxhue.github.io/daily/assets/f13024f26beb54889e4de20cc9fb7ec4.webp" width="600">&lt;/p>
&lt;p>我就只是去掉 warmup，其他啥都没做，代码是新下的（今天的日期是 2025/3/7）。感觉是虽然朴素实现没有同时塞下所有任务（任务多了），但是每个任务的计算量变小了。&lt;/p></description></item><item><title>2025-02-16 Compiler Explorer 使用了沙盒</title><link>https://hxhue.github.io/daily/2025-02-16-Compiler-Explorer-%E4%BD%BF%E7%94%A8%E4%BA%86%E6%B2%99%E7%9B%92/</link><pubDate>Sun, 16 Feb 2025 00:00:00 +0800</pubDate><guid>https://hxhue.github.io/daily/2025-02-16-Compiler-Explorer-%E4%BD%BF%E7%94%A8%E4%BA%86%E6%B2%99%E7%9B%92/</guid><description>&lt;p>OP 的程序收到了 SIGABRT 信号，但是从 Compiler Explorer 上观察到进程是因为 SIGSEGV 信号退出。原因是 Compiler Explorer 使用了沙盒，无法完全正确地反映程序因何种信号退出。&lt;/p>
&lt;p>&lt;a href="https://www.reddit.com/r/Cplusplus/comments/14n0kh3/why_do_my_unhandledexceptionprogram_result_in/" title="Reddit 帖子" rel="noopener external nofollow noreferrer"
 target="_blank" class=" exturl" >Reddit 帖子&lt;i class="fa fa-external-link-alt">&lt;/i>&lt;/a>。&lt;/p></description></item><item><title>2025-01-14 Intel 大小核调度</title><link>https://hxhue.github.io/daily/2025-01-14-Intel-%E5%A4%A7%E5%B0%8F%E6%A0%B8%E8%B0%83%E5%BA%A6/</link><pubDate>Tue, 14 Jan 2025 00:00:00 +0800</pubDate><guid>https://hxhue.github.io/daily/2025-01-14-Intel-%E5%A4%A7%E5%B0%8F%E6%A0%B8%E8%B0%83%E5%BA%A6/</guid><description>&lt;p>今天看到一篇介绍 &lt;a href="https://blog.xzr.moe/archives/352/" title="Intel 大小核在 Windows 上面的调度策略" rel="noopener external nofollow noreferrer"
 target="_blank" class=" exturl" >Intel 大小核在 Windows 上面的调度策略&lt;i class="fa fa-external-link-alt">&lt;/i>&lt;/a> 的比较好的帖子。帖子中提到：&lt;/p>
&lt;blockquote>
 &lt;p>单纯将“最大处理器状态”设为 99% 只能关掉小核的睿频，大核仍然是跑满的。&lt;/p></description></item><item><title>2024-12-28 插件：Mouse Pinch-To-Zoom Chrome</title><link>https://hxhue.github.io/daily/2024-12-28-%E6%8F%92%E4%BB%B6Mouse-Pinch-To-Zoom-Chrome/</link><pubDate>Sat, 28 Dec 2024 00:00:00 +0800</pubDate><guid>https://hxhue.github.io/daily/2024-12-28-%E6%8F%92%E4%BB%B6Mouse-Pinch-To-Zoom-Chrome/</guid><description>&lt;h1 id="mouse-pinch-to-zoom-chrome-插件">Mouse Pinch-To-Zoom Chrome 插件
&lt;a class="header-anchor" href="#mouse-pinch-to-zoom-chrome-%e6%8f%92%e4%bb%b6">&lt;/a>
&lt;/h1>&lt;p>按下 alt 就能像有触控板一样缩放网页了。不会改变网页本身的缩放等级，在有图片全屏显示，但仍需要观察细节时非常有用。安装后已经打开的网页需要重新载入才能生效。&lt;/p></description></item><item><title>2024-09-16 教程和工具</title><link>https://hxhue.github.io/daily/2024-09-16-%E6%95%99%E7%A8%8B%E5%92%8C%E5%B7%A5%E5%85%B7/</link><pubDate>Mon, 16 Sep 2024 00:00:00 +0800</pubDate><guid>https://hxhue.github.io/daily/2024-09-16-%E6%95%99%E7%A8%8B%E5%92%8C%E5%B7%A5%E5%85%B7/</guid><description>&lt;h1 id="教程">教程
&lt;a class="header-anchor" href="#%e6%95%99%e7%a8%8b">&lt;/a>
&lt;/h1>&lt;p>&lt;a href="https://www.bilibili.com/video/BV1jwHhebE8o/" title="https://www.bilibili.com/video/BV1jwHhebE8o/" rel="noopener external nofollow noreferrer"
 target="_blank" class=" exturl" >https://www.bilibili.com/video/BV1jwHhebE8o/&lt;i class="fa fa-external-link-alt">&lt;/i>&lt;/a> 【系统设计需要知道的延迟等级】&lt;/p>
&lt;p>&lt;a href="https://github.com/rasbt/LLMs-from-scratch" title="https://github.com/rasbt/LLMs-from-scratch" rel="noopener external nofollow noreferrer"
 target="_blank" class=" exturl" >https://github.com/rasbt/LLMs-from-scratch&lt;i class="fa fa-external-link-alt">&lt;/i>&lt;/a> LLM 原理讲解，虽然印刷和电子书籍是要付费的，但是 ipynb 版本都是免费的&lt;/p>
&lt;p>&lt;a href="http://www.uinio.com/Linux/Vim/" title="http://www.uinio.com/Linux/Vim/" rel="noopener external nofollow noreferrer"
 target="_blank" class=" exturl" >http://www.uinio.com/Linux/Vim/&lt;i class="fa fa-external-link-alt">&lt;/i>&lt;/a> Vim 速查，作者是嵌入式大牛，博客也很有意思&lt;/p>
&lt;h1 id="工具">工具
&lt;a class="header-anchor" href="#%e5%b7%a5%e5%85%b7">&lt;/a>
&lt;/h1>&lt;p>&lt;a href="https://github.com/chen08209/FlClash" title="https://github.com/chen08209/FlClash" rel="noopener external nofollow noreferrer"
 target="_blank" class=" exturl" >https://github.com/chen08209/FlClash&lt;i class="fa fa-external-link-alt">&lt;/i>&lt;/a> 又一个基于 Clash Core 的 GUI 代理软件&lt;/p></description></item></channel></rss>