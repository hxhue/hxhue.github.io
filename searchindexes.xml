<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>2025-09-18 使用美国节点访问 kimi.com</title><url>/daily/2025-09-18-%E4%BD%BF%E7%94%A8%E7%BE%8E%E5%9B%BD%E8%8A%82%E7%82%B9%E8%AE%BF%E9%97%AE-kimi.com/</url><categories/><tags><tag>llm</tag></tags><content type="html">  偶然发现使用美国节点并且界面为英文访问 kimi.com 时，能触发不同的搜索源，在某些场景下可能带来更好的搜索效果。
但有时候效果会变差：
  </content></entry><entry><title>CUDA_DEVICE_MAX_CONNECTIONS</title><url>/posts/ai-infra/CUDA_DEVICE_MAX_CONNECTIONS/</url><categories/><tags><tag>ai-infra</tag></tags><content type="html">  环境变量解释CUDA_DEVICE_MAX_CONNECTIONS 这个环境变量在 Megatron-LM 源码中经常见到，主要是用来控制硬件调度 kernel 的顺序，以尽可能提高通信计算重叠场景的重叠率。
英伟达文档 cuda-environment-variables 说明了 CUDA_DEVICE_MAX_CONNECTIONS 默认为 8，可以设置为 1 到 32 的整数值，表示计算和拷贝队列的数量。（同样还有 CUDA_DEVICE_MAX_COPY_CONNECTIONS 表示对拷贝队列的设置（优先级高于 CUDA_DEVICE_MAX_CONNECTION）。）论坛回复 指出这个环境变量表示有多少个硬件队列和 CUDA 流发生映射关系。（如果这个值不够大则流之间存在虚假依赖。这样一来，设置为 1 就能完全保证 kernel 执行顺序和发起顺序一致。设置为 32 则尽可能设法让不同的流并发执行 kernels。）
Megatron-LM 1F1B + EP A2A overlapMegatron-LM 2025.8.1 的提交支持了 1F1B + EP A2A overlap，也对 CUDA_DEVICE_MAX_CONNECTIONS 环境变量有描述。
代码：
思考：
警告信息中暗示 Blackwell 可能更好处理同时开启 TP/CP 和 EP overlap 的情况。这个或许和 Blackwell 的 cluster launch control 功能有关。 对通信计算重叠使用 CUDA_DEVICE_MAX_CONNECTIONS=32，是说明两个一前一后的 microbatch 中各通信、计算 kernels 并不是精心重叠的、需要依赖硬件的并发调度提高效率吗？ Tip
1F1B + EP A2A overlap 的发展：
2025.3 小红书和英伟达中国发 博客 介绍了这个方案。 2025.6 dots.llm1 使用了这一方案。 2025.7 Kimi K2 使用了这一方案。 2025.8 Megatron-LM 将这个方案 提交 到主分支。 也可以看出来 Megatron-LM 在流水线调度问题上始终不愿放弃 1F1B，就像 CP 方案不愿接入 Ulysses SP 一样。可能是代码上有较多对 1F1B 的依赖，比如 TP …  </content></entry><entry><title>Megatron-LM 论文 PP 和 VPP 画法疑问</title><url>/posts/ai-infra/Megatron-LM-%E8%AE%BA%E6%96%87-PP-%E5%92%8C-VPP-%E7%94%BB%E6%B3%95%E7%96%91%E9%97%AE/</url><categories/><tags><tag>ai-infra</tag></tags><content type="html">  问题见到过两种画法：一是 device 1 调度到 PP*VPP 个微批次之后继续调度，二是 device 1 调度到 PP*VPP 微批次之后就停下了。
来源 1：Megatron-LM 论文这个是 Megatron 的论文 Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM 第 3 页 https://arxiv.org/pdf/2104.04473 ，同时显示了交错和非交错状态下 1F1B 的调度方式。
来源 2：Pangu Ultra 论文这个是盘古的论文 Pangu Ultra: Pushing the Limits of Dense Large Language Models on Ascend NPUs 第 7 页 https://arxiv.org/pdf/2504.07866 。无论是交错还是非交错 1F1B 均和 Megatron 论文画法有差异。
来源 3：ZeRO Bubble 论文这个是 ZeRO bubble 论文 ZERO BUBBLE PIPELINE PARALLELISM 第 3 页 https://arxiv.org/pdf/2401.10241 ，其中的 1F1B 画法和 Megatron 论文有差异。
来源 4：英伟达中文博客https://developer.nvidia.com/zh-cn/blog/1f1b-moe-a2a-computing-overlap/ 本文由小红书团队和英伟达中国一同贡献，在英文区找不到？
这张图表示加大 warmup 微批次数，上面的图是 baseline 的非交错 1F1B，用的是 device 1 到 PP 个微批次就停下来的画法（和 Megatron 论文不一致）。
下面这张图的上图是 baseline 的交错 1F1B，用的是 device 1 到 PP 个微批次不停下的画法（和 Megatron 论文一致）。
来源 5：Megatron-LM 仓库READMEMegatron-LM 仓库的 README 也说开了 VPP 之后显存占用会变大，和自己论文的交错 1F1B 画图对应。
1F1B1F1B warmup：每个 rank 循环 num_warmup_microbatches 次 1F1B 计算 num_warmup_microbatches：每个 rank 的 warmup 数不同，和 Megatron 在论文中画的图不一致
交错 1F1B交错 1F1B warmup 次数由 get_pp_rank_microbatches() 决定 交错 1F1B 计算 num_warmup_microbatches 这张图来看，每个 rank 的预热阶段微批次数应该依次 -2。 从以上信息来看：
Megatron 论文给的非交错 1F1B 图不对。 盘古给的交错 1F1B 图不对。 小红书 x 英伟达博客给的图更合理一些。   </content></entry><entry><title>大模型训练通信要解决哪些问题？（个人总结）</title><url>/posts/ai-infra/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%80%9A%E4%BF%A1%E8%A6%81%E8%A7%A3%E5%86%B3%E5%93%AA%E4%BA%9B%E9%97%AE%E9%A2%98%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93/</url><categories/><tags><tag>ai-infra</tag></tags><content type="html">  结构图加速通信减少给定操作的通信量 低精度训练 先量化再通信 DeepSeek V3 dispatch 时先把 BF16 量化到 FP8，通信量减少一半。但因为 combine 通信中带有规约，所以不适合用 FP8。 MegaScale-MoE 在 AllGather 派发器的 combine 阶段用 (a) 量化到 FP8 + (b) AlltoAll + (c) FP32 累加器规约 来代替原先的 ReduceScatter 通信，通信量减少一半、loss 正常。ReduceScatter 时每个 rank 只需要收到自己分区的所有数据并完成规约即可（不像 AllGather 接口需要所有数据），用 AlltoAll + 接收后本地规约也能替代。 通信去重 DeepEP 减少通信 尽可能使用效率更高的并行方式，比如用 Ulysses SP 代替 TP 可以从理论上大大降低通信。 保持计算流忙碌通信计算重叠 Megatron-LM 现在对 DP/TP/CP/PP/EP 均有通信重叠功能 部分选项依赖 CUDA_DEVICE_MAX_CONNECTIONS 部分选项依赖交错 1F1B 调度 Megatron CP 的通信计算重叠强制打开、无选项可以关闭 Megatron 1F1B + EP A2A overlap 是 2025.8 才加入的新功能，但在 2025.3 已有人提出 DualPipe 用前反向两个微批次的前后向来重叠 负载均衡 DP/PP 负载均衡 ByteScale 的工作很有启发性 Ernie 4.5 也做了 DP 上的子序列重排 EP 负载均衡 token drop、辅助 loss、expert bias 专家动态调整，这一类工作很多 样本动态调整，如 NetMoE CP 负载均衡 Ulysses SP Megatron CP 未考虑子序列打包的问题，ByteScale 做了一些处理 消除卡间同步 ZeroBubble 后校验   </content></entry><entry><title>DeepSeek V3 MLA</title><url>/posts/ai-infra/DeepSeek-V3-MLA/</url><categories/><tags><tag>ai-infra</tag></tags><content type="html">  下图标注了 MLA 的一种计算方式，橙色虚线部分可以被包裹到重计算中，入口为 q1，kv1 和 k_rope1（不保存 kv1 和 k_rope1 而是保存 kv1_and_k_rope 也可以，它们的大小一样，没区别）。flash_attn 比较特殊，除了保存输入之外还会保存输出。
如果要做 TP，需要保持 down_proj 为完整矩阵，在 up_proj 矩阵做列切分，在 o_proj 做行切分。如果要做 CP，需要在 attention 的位置插入 CP 策略。
MLA 推荐阅读： https://www.cnblogs.com/rossiXYZ/p/18827618
  </content></entry><entry><title>MoE Parallel Folding、ETP 和 DeepEP</title><url>/posts/ai-infra/MoE-Parallel-FoldingETP-%E5%92%8C-DeepEP/</url><categories/><tags><tag>ai-infra</tag></tags><content type="html">  DeepEP 假设了本地 node 用 NVLINK 连接的卡数为 8，因此 EP 必须在最内层。Megatron 在 MoEFlexTokenDispatcher 接入 DeepEP，也必须满足这个假设。
在 MoE Parallel Folding 下，MoE 层的 CP 消失，排在 EP 内层的只有 TP，Megatron 是如何处理 ETP &amp;gt; 1 的情况的？它将 routing map 展开了 tp_size 份，直接用 DeepEP 分发（这个时候使用 TP-EP 组而不是 EP 组，大小为 ep_size * tp_size），这样就满足了 DeepEP 的假设，实质上利用 DeepEP 把 TP 的通信也做了。
我认为 MoE Parallel Folding 的优势是：1. 兼容 DeepEP；2. 把 Attention 和 MoE 的 TP 数解耦；3. 为 EP 让出了 CP 的范围，使得 EP 通信组排列更局部，通信效率更高。
一般来说 MoE 层的 ETP 通信是先做 AlltoAll 再做 AllGather。因为 AllGather 会在 TP 组内形成冗余（大家都拿到一模一样的输入），所以应该只在真正需要用到之前才做 AllGather，将 AllGather 放在 AlltoAll 后可以减少 AlltoAll 的通信量（图片来自 MoE Parallel Folding 论文，上文已给出链接）：
MoEFlexTokenDispatcher 有底气把 TP 交给 EP 去做，是因为 DeepEP 有去重的能力，机内 TP 冗余可以自动去除、然后通过 NVLINK 转发，等效于我们 AlltoAll 完成后 TP 组机内 AllGather。
MoEAllGatherTokenDispatcher 是直接在 ETP 组做 AllGather，见 megatron/core/transformer/moe/token_dispatcher.py#L258-L260 。
MoEAlltoAllTokenDispatcher 则是和上图一样先 AlltoAll 再 AllGather，见 megatron/core/transformer/moe/token_dispatcher.py#L650-L660 中的 dispatch_postprocess。
  </content></entry><entry><title>NVIDIA 博客：NCCL 2.12 PXN 优化</title><url>/posts/ai-infra/NVIDIA-%E5%8D%9A%E5%AE%A2NCCL-2.12-PXN-%E4%BC%98%E5%8C%96/</url><categories/><tags><tag>ai-infra</tag></tags><content type="html">  文章总结https://developer.nvidia.com/blog/doubling-all2all-performance-with-nvidia-collective-communication-library-2-12/
内容由 AI 生成
NCCL 2.12 的核心改进包括：
PXN (PCI × NVLink)： 这是一项新功能，它允许 GPU 直接通过 NVLink 和 PCI 与节点上的网卡 (NIC) 进行通信，从而绕过 CPU。这带来了更高效的数据传输和更高的带宽。 优化的消息聚合： PXN 使得节点上的所有 GPU 能够将它们的数据汇总到一个 GPU 上，以发送到特定目的地。这样，网络层可以将多个消息作为一个整体发送，提高了消息速率并减少了连接开销。 轨道优化的网络拓扑： PXN 利用 NVSwitch 连接将数据移动到与目的地位于同一网络轨道上的 GPU，避免了通过第二层主干交换机进行的效率较低的流量。 这些进步使 all2all 性能提升了两倍以上，并为复杂的 GPU 拓扑中的模型并行性提供了更大的灵活性。
虽然看上去是三项功能，但是从描述来看都是 PXN 使得它们得以实现，所以实际上主要改进还是 PXN 的引入。
PXN 对 alltoall 的改进GPU 不是在其本地内存中为本地 NIC 发送数据准备缓冲区，而是在中间 GPU 上准备缓冲区，通过 NVLink 写入。然后它通知管理该 NIC 的 CPU 代理数据已准备好，而不是通知其自己的 CPU 代理。GPU-CPU 同步可能会稍微慢一些，因为它可能需要跨越 CPU 插槽，但数据本身仅使用 NVLink 和 PCI 交换机，确保最大带宽。
原来的 alltoall 传输前是要在发送方准备数据缓冲区的，local rank 0 如果想要发给 peer rank 3 就需要先在自己这里准备数据，然后经过多层路由传输给 peer rank 3。现在是在 local rank 3 上准备数据缓冲区（应该是 RDMA 用），local rank 0 通过 nvlink 将数据传输给 local rank 3，然后 local rank 3 发给 peer rank 3。因为后两者属于同一个 rail，所以只需要经过 L 层次的 switch，减少了路由延迟。
如图，深紫色的线（上面） …  </content></entry><entry><title>diff 两个文件夹</title><url>/posts/cli/bash/diff-%E4%B8%A4%E4%B8%AA%E6%96%87%E4%BB%B6%E5%A4%B9/</url><categories/><tags><tag>bash</tag></tags><content type="html">  diff -bur folderA/ folderB/ -r 表示递归，-b 表示忽略空白字符，-u 表示输出统一样式（也就是 git diff 常见的样式，会比默认样式容易阅读）。
  </content></entry><entry><title>PyTorch C++ 代码生成</title><url>/posts/programming/python/2.-PyTorch-C++-%E4%BB%A3%E7%A0%81%E7%94%9F%E6%88%90/</url><categories/><tags><tag>torch</tag></tags><content type="html"><![CDATA[  一些问题为什么有些会生成 at::cuda 名字空间的函数，有些不会？（待解决）
提要本文说明了 m.impl(&amp;quot;index_put.out&amp;quot;, ...) 到 at::native::index_put 的调用路径。结合 PyTorch C++ 函数派发 中 at::native::index_put_ → at::_index_put_impl_ → index_put_stub 的调用路径，补全了从 m.impl 到 stub 的全路径。
本文说明了 m.impl / at::cuda::index_out → index_stub 的调用路径。准确来说是介绍了 at::cuda::index_out 调用 meta 和 impl 的过程，meta 中对下标做预处理（包括 kBool 转 kLong 下标），impl 中调用 index_stub 进行计算。和 index_out 不同，index_put_ 函数没有出现在 at::cuda 名字空间中，取而代之的是 at::cuda::_index_put_impl_。
在这两个例子中，能找到的函数有：
理解 native_functions.yaml 中的函数定义在哪里 非 structured 情况： - func: index_put_(...) dispatch: CompositeExplicitAutograd: index_put_ # 默认名字空间是 aten \ at::index_put_ (build/aten/src/ATen/Functions.h) \ at::_ops::index_put_::call (build/aten/src/ATen/OperatorsEverything.cpp) \ c10::Dispatcher::singleton() | .findSchemaOrThrow(index_put_::name, index_put_::overload_name) | .typed&amp;lt;index_put_::schema&amp;gt;().call |struct TORCH_API index_put_ (build/aten/src/ATen/MethodOperators.h) | ... name = …  ]]></content></entry><entry><title>PyTorch C++ 函数派发</title><url>/posts/programming/python/1.-PyTorch-C++-%E5%87%BD%E6%95%B0%E6%B4%BE%E5%8F%91/</url><categories/><tags><tag>torch</tag></tags><content type="html"><![CDATA[  Stub 注册流程所有的 stub 定义几乎都在 aten/src/ATen/native/DispatchStub.h 文件，可以慢慢看。里面有段注释：
// Implements instruction set specific function dispatch. // // Kernels that may make use of specialized instruction sets (e.g. AVX2) are // compiled multiple times with different compiler flags (e.g. -mavx2). A // DispatchStub contains a table of function pointers for a kernel. At runtime, // the fastest available kernel is chosen based on the features reported by // cpuinfo. // // Example: // // In native/MyKernel.h: // using fn_type = void(*)(const Tensor&amp;amp; x); // DECLARE_DISPATCH(fn_type, stub) // // In native/MyKernel.cpp // DEFINE_DISPATCH(stub); // // In native/cpu/MyKernel.cpp: // namespace { // // use anonymous namespace so that different cpu versions won&amp;#39;t conflict // void kernel(const Tensor&amp;amp; x) { ... } // } // REGISTER_DISPATCH(stub, &amp;amp;kernel); // // To call: // stub(kCPU, tensor); // // TODO: CPU instruction set selection should be folded into whatever // the main dispatch …  ]]></content></entry><entry><title>在服务器上使用 sing-box 代理</title><url>/posts/cli/%E5%9C%A8%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E4%BD%BF%E7%94%A8-sing-box-%E4%BB%A3%E7%90%86/</url><categories/><tags><tag>linux</tag><tag>proxy</tag></tags><content type="html"><![CDATA[  背景服务器上面不能科学上网。以前都是直接 用 ssh 做代理转发 的，但是现在在校外只能使用 rvpn，连接非常不稳定，也无法大流量传输文件，只能考虑在服务器上直接上网。
平时使用 Windows 上的 v2rayN 上网，考虑将其配置迁移到服务器上。由于服务器是多人共享，我有以下需求：
不用 systemd 启动。 配置私有化，且其他人不能看到配置。 用的时候临时启动，用完之后就退出进程。 服务器上的准备服务器上 下载安装 sing-box。 服务器上创建一个文件夹 sing-box。 在 v2rayN 中点“设置 &gt; 打开存储所在的位置”，文件夹中的 bin\srss 中包含大量 geo* 文件。将 srss 文件夹拷贝到服务器上的 sing-box 文件夹中。 这一步下载了 sing-box 并且将一些公开配置复制到了服务器上。
准备好配置文件在 v2rayN 中切换到 sing_box 模式，调整好配置。配置包括：代理服务器、DNS、规则、是否运行局域网访问等。 在 v2rayN 中点“设置 &gt; 打开存储所在的位置”，文件夹中的 binConfigs\config.json 就是可用的文件。 复制一份文件，将 experiment.clash_api 字段删掉。 把所有 geo 文件的路径引用全都改成 ./srss/geo*。只要在 sing-box 文件夹启动服务，就可以相对于这个路径访问。 把 cache 路径改成 ./cache.db。 这一步得到了一个文件 config.json，先别上传。
对配置文件加密将处理好的配置文件保存为 config.json，使用 openssl（WSL 中有）对其加密。参考 https://askubuntu.com/a/160334/ ，不过 des3 加密强度不够，要换一下。
openssl des3 -pbkdf2 -iter 100000 &lt; config.json &gt; config.json.des3 现在得到了新的文件 config.json.des3。将这个文件复制到服务器上的 sing-box 文件夹内。
运行首先来到 sing-box 文件夹中，然后运行：
openssl des3 -pbkdf2 -iter 100000 -d &lt; config.json.des3 \ | sing-box run -c /dev/stdin 有个在 tmux 中就无法成功运行的问题（提示有 $\mu$ 字符），我个人感觉还是 Windows Terminal 不识别转义序列的问题。进入 tmux 之后别用初始的 panel，开启一个新的 panel 就能用了。参考 tmux attach 的时候出现转义字符序列。
用 ss 验证是否成功：
Tip
输出不一定带有 sing-box 名字（我不确定），如果查不出来可以去掉 grep，看看列表里面是否出现了期望的端口号。
  ]]></content></entry><entry><title>📌新增“发现”板块</title><url>/daily/2024-04-28-%E6%96%B0%E5%A2%9E%E5%8F%91%E7%8E%B0%E6%9D%BF%E5%9D%97/</url><categories/><tags/><content type="html">  一些在 Notion 上分享的内容现在可以从侧边栏的“发现”标签打开，这些内容比博客本身编辑起来更方便（指📱编辑），所以我也能更加频繁地创作。它们通常为较短的内容，可以当作周报来看！
  </content></entry><entry><title>实验室服务器故障（续）</title><url>/posts/systems/Linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BD%91%E7%BB%9C%E6%95%85%E9%9A%9C/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%95%85%E9%9A%9C%E7%BB%AD/</url><categories/><tags><tag>linux</tag></tags><content type="html">  背景本文是 实验室服务器 ssh 无法连接 的后续。
今天同学又告诉我发生了类似的情况，师兄已经在找人维修。
我连接上去看了服务器重启时间约 10 点。又看了几个信息：
sar 监控 journalctl 日志 磁盘信息 sar 监控之前设置的 sar 监控频率是默认的，即 10 分钟采样一次。sar 怎么安装和配置可以参考 安装 sysstat 获取 CPU/ 磁盘 / 网络统计日志。
查看今天所有的资源统计（主要是晃过去看看哪些是红色）：
S_COLORS=always sar -A | less -R 一些观察到的情况：
CPU（相当于 sar -u）：观察到 %usr 只有几个核心在较高水平（70% 以上，有的能达到 100%），其他核心基本上是 idle。
内存（sar -r）：1:50 到 4:50 之间 %commit 都在 80% 以上，之后退下来。
分页统计（相当于 sar -B）：观察到 %vmeff 有红色（极大值）和蓝色（小值）。注意 sar 输出为红色并不代表不好，只是表示数值大。
%vmeff（虚拟内存效率）表示内存回收效率，计算公式为 (pgsteal / (pgscank + pgscand)) * 100，其中：
pgsteal：每秒回收的页面数。 pgscank：由 kswapd 守护进程扫描的页面数。 pgscand：直接由进程扫描的页面数。 按照我的理解，%vmeff 反映回收性能，如果低也可能说明这段时间没有回收活动。在有回收活动的时候数值低则暗示回收效率低下。这些数据表明凌晨运行的程序导致了大量的页面换出。（结合 1:50 之前内存还充足，可以考虑主要是磁盘 I/O 引发的，而不是进程的内存页面？）
磁盘写入（sar -n DEV）：可以看到运行的程序在大量写磁盘，在凌晨的几个小时写的非常多，而在被迫关机的这段时间写的比较少。
journalctl 日志一是大段的 GPU 设备查询报错，不知道是否良性，二是和上一次一样有某些内核功能卡住了 CPU 太久。都在下图。
三是 sar 日志写不进去，还伴随着其他警告。后面的 major:minor 是设备号，可能表示显卡。
磁盘想要开启 tmux，说无法创建文件。
xx@yy-Rack-Server:~$ tmux couldn&amp;#39;t create directory /tmp/tmux-1001 (No space left on device) 磁盘满了。
$ df -h Filesystem Size Used Avail Use% Mounted on tmpfs 51G 4.1M 51G 1% /run /dev/nvme0n1p2 3.5T 3.3T 0 100% / tmpfs 252G 0 252G 0% /dev/shm tmpfs 5.0M 4.0K 5.0M 1% /run/lock efivarfs 128K 16K 108K 13% /sys/firmware/efi/efivars /dev/nvme0n1p1 511M 6.1M 505M 2% /boot/efi tmpfs 51G 184K 51G 1% /run/user/1007 tmpfs 51G 68K 51G 1% /run/user/1013 tmpfs 51G 68K 51G 1% /run/user/1001 tmpfs 51G 68K 51G 1% /run/user/1012 结论运行的程序是 I/O 密集型的，可能是磁盘写满导致很多功能异常？
  </content></entry><entry><title>2025-04-21 PyTorch 编译架构中没有 sm_89</title><url>/daily/2025-04-21-PyTorch-%E7%BC%96%E8%AF%91%E6%9E%B6%E6%9E%84%E4%B8%AD%E6%B2%A1%E6%9C%89-sm_89/</url><categories><category>daily</category></categories><tags><tag>torch</tag></tags><content type="html"><![CDATA[  今天发现很有意思的一件事情：配备 4090 显卡的服务器上安装 torch 之后，显示的架构并没有 sm_89，也没有 PTX（compute_xx）来支持 JIT。
(minimind) ➜ ~ python -c &#39;import torch;print(torch.cuda.get_arch_list())&#39; [&#39;sm_50&#39;, &#39;sm_60&#39;, &#39;sm_70&#39;, &#39;sm_75&#39;, &#39;sm_80&#39;, &#39;sm_86&#39;, &#39;sm_90&#39;] (minimind) ➜ ~ sm_89 not listed in the torch.cuda.get_arch_list() - PyTorch Forums 这个讨论说明 sm_89 和 sm_86 是完全兼容的，除了 FP8 支持，这些 kernels 被专门处理。
  ]]></content></entry><entry><title>验证父进程被杀死后僵尸会被 init 进程收养</title><url>/posts/systems/Linux/%E9%AA%8C%E8%AF%81%E7%88%B6%E8%BF%9B%E7%A8%8B%E8%A2%AB%E6%9D%80%E6%AD%BB%E5%90%8E%E5%83%B5%E5%B0%B8%E4%BC%9A%E8%A2%AB-init-%E8%BF%9B%E7%A8%8B%E6%94%B6%E5%85%BB/</url><categories/><tags><tag>linux</tag><tag>os</tag></tags><content type="html"><![CDATA[  过程首先，创建一个 docker 容器，其 entrypoint 不是可回收子进程（init-like）的命令，也不要加上 --init 选项。这样即便僵尸被 init 进程收养，也不会被马上回收，方便观察。
在容器内部进行以下操作：
// parent.c #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/types.h&gt; int main() { pid_t pid = fork(); if (pid &lt; 0) { perror(&#34;fork failed&#34;); exit(1); } if (pid == 0) { // 子进程 printf(&#34;Child process (PID: %d) exiting immediately.\n&#34;, getpid()); exit(0); // 快速退出，变成僵尸 } else { // 父进程 printf(&#34;Parent process (PID: %d), child PID: %d\n&#34;, getpid(), pid); printf(&#34;Sleeping 60 seconds without wait() to create zombie...\n&#34;); sleep(60); // 不调用 wait()，让子进程变成僵尸 printf(&#34;Parent exiting.\n&#34;); } return 0; } 编译运行，然后在另外一个窗口将父进程 kill 掉。
root@677e804cc08c:/workspace/zombie# gcc -o parent parent.c root@677e804cc08c:/workspace/zombie# ./parent Parent process (PID: 308506), child PID: 308507 Sleeping 60 seconds without wait() to create zombie... Child process (PID: 308507) exiting immediately. Terminated 检查发现子进程成了僵尸，而且父进程成了 1 号进程。
root@677e804cc08c:/workspace/zombie $ ps -o pid,ppid,stat,cmd -p 308507 PID PPID STAT CMD 308507 1 Z [parent] &lt;defunct&gt; 这样的进程不会被自动清理，重启或关闭容器可以释放其资源。
相关文章NVIDIA 显卡显存占用高但是 nvidia-smi 查不到 torch 分布式程序产生僵尸进程 26 监控子进程 wait() Python 多进程脚本的常见问题 其他资料Choosing an init process for multi-process containers 为你的容器选择合适的 init 进程。   ]]></content></entry><entry><title>Python 多进程脚本的常见问题</title><url>/posts/programming/python/Python-%E5%A4%9A%E8%BF%9B%E7%A8%8B%E8%84%9A%E6%9C%AC%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/</url><categories/><tags><tag>python</tag><tag>linux</tag></tags><content type="html"><![CDATA[  占用过多内存TL;DR：大多是具体脚本的问题，不好处理。有的是没有及时 gc，有的是把所有数据全部载入内存之后（假设了内存足够大）才开始处理。
我是遇到了这样一个问题：megatron-lm huggingface 教程运行时资源占用大、有僵尸（2025/4/22 文章还在修改中，尚未公开）。
o4-mini 建议我调整启动方式：multiprocessing — Process-based parallelism — Python 3.13.3 documentation
方法描述特征spawn创建新的解释器并运行，干净但慢，是 Windows、macOS 的默认方法。大量 python -c from multiprocessing.spawn import spawn_main; 进程fork直接 fork。除了 macOS 之外的 POSIX 的默认方法，Python 3.14 之后默认方法改成 forkserver。大量命令参数（cmd）和启动命令相同的进程，例子 python tools/preprocess_data.py --input ...forkserver首次用 forkserver 方法创建进程会启动一个单线程（除非 import 的库导致了多线程）的 server，每次调用 os.fork() 都是干净的，不会有冗余线程。大量 python -c from multiprocessing.forkserver import ... 进程但是我觉得调整启动方式对内存占用的影响很难观察到，但 fork 比 forkserver 的速度快一点（可能是我的用例如此）。
相关：Excessive memory buildup when merging text datasets in Megatron core · Issue #12993 · NVIDIA/NeMo，不过我操作之后还是会占用大量内存。后来发现其实是这个脚本把所有数据全部放在内存中，然后一次性处理，所以是脚本本身没有考虑到内存不够的场景。
产生大量睡眠进程使用 forkserver 很容易出现大量 S 进程（睡眠状态），占用大量内存。可以使用以下方法来杀：
sudo kill -9 $(ps aux | grep multiprocessing.forkserver | grep -v grep | awk &#39;{print $2}&#39; |less) 这也许是快速连续按下 ctrl+c，导致程序没有来得及做清理工作导致的？
产生大量僵尸相关资料：
PyTorch causes zombie processes on multi-GPU system - PyTorch Forums PyTorch doesn&rsquo;t free GPU&rsquo;s memory of it gets aborted due to out-of-memory error - PyTorch Forums 快速检查：ps aux | grep Z。示例：
如果要在脚本中查找僵尸，需要严格检查第 8 个域（如果 ps 选项更改，这个位置也可能会变化），以免出现 USER 或者 COMMAND 出现 Z 字母造成误伤。
ps aux | awk &#39;match($8, &#34;.*Z.*&#34;)&#39; 如果还想要找到具体的 pid：
ps aux | awk &#39;match($8, &#34;.*Z.*&#34;)&#39; | awk &#39;{print $2}&#39; 僵尸怎么杀？杀父进程，让 init 来收养并 reap。
但是，我使用的是容器环境，它的 init 不具备处理 SIGCHLD 信号的功能！
(base) ➜ ~ ps ax --sort=ppid -o user,pid,ppid,%cpu,%mem,stat,start,time,command |awk &#39;match($6, &#34;.*Z.*&#34;)&#39; |awk &#39;{print $3}&#39;|sort -u 2260730 (base) ➜ ~ sudo kill -SIGCHLD 2260730 (base) ➜ ~ ps ax --sort=ppid -o user,pid,ppid,%cpu,%mem,stat,start,time,command |awk &#39;match($6, &#34;.*Z.*&#34;)&#39; |awk &#39;{print $3}&#39;|sort -u 2260730 (base) ➜ ~ # kill -SIGCHLD 没有任何效果！ 这个确实是我启动 docker 容器时的失误😅。我是想要创建一个持久的容器，然后 docker exec 进入执行具体任务。应该这样启动容器：
docker run --init image_name tail -f /dev/null 如果已经出现了大量僵尸，但不想销毁容器，可以重启：
docker restart container_name   ]]></content></entry><entry><title>tmux attach 的时候出现转义字符序列</title><url>/posts/developer/tmux-attach-%E7%9A%84%E6%97%B6%E5%80%99%E5%87%BA%E7%8E%B0%E8%BD%AC%E4%B9%89%E5%AD%97%E7%AC%A6%E5%BA%8F%E5%88%97/</url><categories/><tags><tag>tmux</tag><tag>linux</tag><tag>terminal</tag></tags><content type="html">  Windows Terminal 的问题，换成 Alacritty 就好了。
不过 Alacritty 又有别的问题，在 vim 中粘贴文本的时候 \r\n 会被转换成 \n\n，导致换行数量加倍，每两行中间会多出来一个空行。参考 WSL + ConPTY + vim -&amp;gt; paste with blanks lines · Issue #2324 · alacritty/alacritty 在 vim 中 ：set term=ansi 可以工作。
  </content></entry><entry><title>2025-04-19 Microsoft Copilot 和 Windsurf 体验</title><url>/daily/2025-04-19-Microsoft-Copilot-%E5%92%8C-Windsurf-%E4%BD%93%E9%AA%8C/</url><categories><category>daily</category></categories><tags><tag>linux</tag><tag>bash</tag><tag>ssh</tag></tags><content type="html">  开头今天在尝试 Microsoft Copilot 和 Windsurf。
Microsoft Copilot 体验参考 https://linux.do/t/topic/480869/ ，解读大模型官网和 IDE 的各种额度限制。里面提到了 Microsoft Copilot 使用了 GPT-4o 和 GPT-o3 mini，之前对 Microsoft Copilot 的感受是比较负面的，看到这个新消息后我也查找了对应的资料（有一说一，Microsoft Copilot 查资料还不如 Grok 做的好）：
Table: Summary of Models and Their Uses（来自 Grok3）
ModelPrimary UseConfirmed ByGPT-4oStandard chat functionalityMicrosoft Learn documentation (Microsoft Learn: Overview of Microsoft 365 Copilot Chat)o3-mini highThink Deeper feature for complex queriesMicrosoft Copilot blog release notes, March 19, 2025 (Microsoft Copilot Blog: Release Notes - March 19, 2025)最后的感觉是，Microsoft Copilot 的模型其实是不如 ChatGPT 官网的，感觉会笨一点。Mircosoft Copilot 早期响应慢的情况现在也好了很多（不会是因为现在是白天吧）。智力在一众模型中算是垫底的，做点指令遵循任务还行。
2025/4/23 Microsoft Learn: Overview of Microsoft 365 Copilot Chat 说的是 Microsoft 365 Copilot Chat，应该其实不是网页的 copilot。从博客列表 The Copilot Team, Author at Microsoft Copilot Blog 来看，没有任何证据表明目前 Microsoft Copilot 使用了 4o。
Windsurf听说 tab 补全不限量才下载的，先体验一段时间看 …  </content></entry><entry><title>bash 加载配置文件</title><url>/01-llm-generated/bash-%E5%8A%A0%E8%BD%BD%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E9%A1%BA%E5%BA%8F/</url><categories/><tags><tag>bash</tag><tag>llm-generated</tag></tags><content type="html"><![CDATA[  Caution
由 Gemini 2.5 Pro 生成。
👶 服务器：我在 ~/.bashrc 中填写好代理（在 -i 的检查之前），我没有 ~/.bash_profile 文件。本机：我尝试连接服务器 ssh server，可以进入到交互界面，且有正常的代理设置；但是如果我用 ssh server bash -c &amp;quot;env | grep http&amp;quot;，就发现没有代理，请问这是为什么？
🤖 简单来说：
ssh server：当你这样连接时，你在服务器上启动的是一个 交互式登录 Shell (Interactive Login Shell)。 它会首先尝试加载 /etc/profile。 然后会查找并加载用户家目录下的 ~/.bash_profile、~/.bash_login 或 ~/.profile 文件中的 第一个 存在且可读的文件。 很多 Linux 发行版的默认 ~/.profile (或者如果你创建了 ~/.bash_profile) 文件里会包含一段逻辑，如果 ~/.bashrc 文件存在，就去加载 (source) 它。这就是为什么你的 ~/.bashrc 在交互式登录时生效了（即使理论上 .bashrc 主要用于非登录交互式 Shell）。 你提到将代理设置放在了 -i 检查（通常是类似 [ -z &amp;quot;$PS1&amp;quot; ] &amp;amp;&amp;amp; return 的语句，用于判断是否是交互式 Shell）之前，这确保了即使是通过 ~/.profile 间接加载 .bashrc，代理设置也会被执行。 ssh server bash -c &amp;quot;command&amp;quot;：当你这样执行远程命令时，你在服务器上启动的是一个 非交互式 Shell (Non-interactive Shell)。 非交互式 Shell 默认不会加载 /etc/profile 或 ~/.profile 或 ~/.bash_profile 或 ~/.bash_login 这些登录 Shell 的配置文件。 默认情况下，非交互式 Shell 也不会加载 ~/.bashrc 文件。Bash 这样做是为了避免 .bashrc 中那些为交互式会话设计的设置（如别名、提示符设置、函数等）干扰脚本的执行或产生不必要的输出。 因此，你在 ~/.bashrc 中 …  ]]></content></entry><entry><title>Gemini 对 NetworkManager 配置文件的解读</title><url>/01-llm-generated/Gemini-%E5%AF%B9-NetworkManager-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E8%A7%A3%E8%AF%BB/</url><categories/><tags><tag>llm-generated</tag></tags><content type="html">  Caution
由 Gemini 2.5 Pro 生成。
👶 我发现 NetworkManager 活跃而 systemd-networkd 仅仅加载而不活跃。同时我有以下日志：
xx@xx-Rack-Server:~$ NetworkManager --print-config # NetworkManager configuration: /etc/NetworkManager/NetworkManager.conf (lib: 10-dns-resolved.conf, 10-globally-managed-devices.conf, 20-connectivity-ubuntu.conf, no-mac-addr-change.conf) (etc: 10-ubuntu-fan.conf, default-wifi-powersave-on.conf) [main] # rc-manager= # auth-polkit=true # dhcp=internal # iwd-config-path= dns=systemd-resolved plugins=ifupdown,keyfile configure-and-quit=no [connectivity] uri=http://connectivity-check.ubuntu.com./ [ifupdown] managed=false [keyfile] unmanaged-devices=*,except:type:wifi,except:type:gsm,except:type:cdma,interface-name:fan-* [logging] # backend=journal # audit=true [device] # wifi.backend=wpa_supplicant wifi.scan-rand-mac-address=no [device] # wifi.backend=wpa_supplicant wifi.scan-rand-mac-address=no [device-31-mac-addr-change] match-device=driver:eagle_sdio,driver:wl wifi.scan-rand-mac-address=no …  </content></entry><entry><title>实验室服务器 ssh 无法连接</title><url>/posts/systems/Linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%BD%91%E7%BB%9C%E6%95%85%E9%9A%9C/%E5%AE%9E%E9%AA%8C%E5%AE%A4%E6%9C%8D%E5%8A%A1%E5%99%A8-ssh-%E6%97%A0%E6%B3%95%E8%BF%9E%E6%8E%A5/</url><categories/><tags><tag>linux</tag></tags><content type="html">  事情由来实验室在今年初安装了两台新的服务器，IP 最后一个段分别为 149 和 150，后文将用这两个数字来指代服务器。据说 149 服务器网络出现故障。
检查网络配置（非原因，可以跳过）用 journalctl 看日志说 dhcp4 失败。包失败的，服务器都是静态 ip，没有配置 dhcp 服务器。为什么明明是静态 ip 却要尝试使用 dhcp 服务器呢？
禁用异常的网络接口考虑到安装的是桌面版，起作用的是 NetworkManager。
再检查一下，systemd-networkd 果然不活跃，确实应该是去检查 NetworkManager。
检查一下 NetworkManager 的配置：
xx@yy-Rack-Server:~$ NetworkManager --print-config # NetworkManager configuration: /etc/NetworkManager/NetworkManager.conf (lib: 10-dns-resolved.conf, 10-globally-managed-devices.conf, 20-connectivity-ubuntu.conf, no-mac-addr-change.conf) (etc: 10-ubuntu-fan.conf, default-wifi-powersave-on.conf) [main] # rc-manager= # auth-polkit=true # dhcp=internal # iwd-config-path= dns=systemd-resolved plugins=ifupdown,keyfile configure-and-quit=no [connectivity] uri=http://connectivity-check.ubuntu.com./ [ifupdown] managed=false [keyfile] unmanaged-devices=*,except:type:wifi,except:type:gsm,except:type:cdma,interface-name:fan-* [logging] # backend=journal # audit=true [device] # …  </content></entry><entry><title>VS Code 远程文件传输慢，寻找替代方案</title><url>/posts/cli/ssh/VS-Code-%E8%BF%9C%E7%A8%8B%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E6%85%A2%E5%AF%BB%E6%89%BE%E6%9B%BF%E4%BB%A3%E6%96%B9%E6%A1%88/</url><categories/><tags><tag>vscode</tag><tag>ssh</tag><tag>rsync</tag><tag>scp</tag><tag>windows</tag></tags><content type="html"><![CDATA[  说明从 Windows 的资源管理器拖动文件到连接到远程服务器的 VS Code 窗口，或者从 VS Code 文件目录下载文件，速度都比 scp 慢得多（3M/s VS 20M/s）。此文章尝试寻求其他替代方案。
rsyncmacOS/Linux参考 Remote Development Tips and Tricks，在 Linux/macOS 上面比较方便。
rsync -rlptzv --progress --delete --exclude=.git &#34;user@hostname:/remote/source/code/path&#34; . Windows 使用 WSL 的 rsync在 Windows 上面比较麻烦，VS Code 给出的教程是：
wsl rsync -rlptzv --progress --delete --exclude=.git &#34;user@hostname:/remote/source/code/path&#34; &#34;`$(wslpath -a &#39;$PWD&#39;)&#34; 有问题：Windows 的 ssh 配置和 wsl 并不相通。参考其他资料：
https://superuser.com/a/1357395/ ssh 使用不同的配置文件。 https://serverfault.com/a/378950/ rsync 传递参数给 ssh。 结果改成：
# Powershell wsl rsync -rlptzv --progress --delete --exclude=.git \ -e &#34;ssh -F /mnt/c/Users/alex/.ssh/config&#34; \ amax150-xx:/home/xx/projects/minimind/images \ &#34;`$(wslpath -a &#39;$PWD&#39;)&#34; # WSL rsync -rlptzv --progress --delete --exclude=.git \ -e &#34;ssh -F /mnt/c/Users/alex/.ssh/config&#34; \ amax150-xx:/home/xx/projects/minimind/images . 但现在还有问题，找不到公钥，只有配置文件，导致登录时需要输入密码。
Windows 上尝试 MSYS2 的 rsync同样是用不了默认的配置文件。
rsync -rlptzv --progress --delete --exclude=.git \ -e &#34;ssh -F /c/Users/alex/.ssh/config&#34; \ amax150-xx:/home/xx/projects/minimind/images . 还是会让输入密码，和 WSL 差不多。
Windows 上尝试 scoop 的 rsync优点是可以用默认的配置文件。
scoop install cwrsync 命令在 C:\Users\alex\scoop\apps\cwrsync\current\bin\rsync。出错：
参考 ssh - rsync error: error in rsync protocol data stream (code 12) at io.c(600) sender=3.0.6 - Server Fault 尝试：
检查对端是否安装 rsync（已安装）。 对端 rsync 路径是否标准（标准），不然要加 --rsync-path 参数。 本机 rsync 和 ssh 是否配套。✔ 第 3 点确实能解决一部分问题。保证 rsync 和 ssh 配套要加上 -e 选项给定绝对路径。
rsync -e &#39;C:\Users\alex\scoop\apps\cwrsync\6.4.0\bin\ssh.exe&#39; yourserver:/tmp/abc.txt . 直接登录的成功了：
使用跳板机的失败了（这里给 ssh 加了 -vv 选项观察原因）：
发现找不到密钥，然而密钥是从 ssh 配置文件中指定的。登录第一个服务器的时候能解析出来其密钥，把第二个服务器当成跳板登录第二个服务器的时候就无法从配置文件中解析出来密钥路径了。
尝试添加 -F 选项指定配置路径，结果没有变化。总体上来说更加不顺利，用跳板机连密码都不让输入就失败了。
scp先把文件打包成 tar 然后用 scp 进行传输。Windows 的 scp 支持是正常的，能正常解析 hostname 和处理密钥，但是会有压缩和解压的额外操作。
如果不愿意压缩，scp 会对每个文件都发起一次 ssh 请求，这样多文件传输的速度会比较慢。
总结macOS 和 Linux 上面直接用 rsync 就可以。
Windows 上面：
WSL 和 MSYS2 的 rsync 涉及到不使用相同配置的问题，需要手动指定配置文件，并且密钥无法识别，需要输入密码。 Scoop 中的 rsync 使用起来更加麻烦，效果也不好。 先打包再用 scp 传输。   ]]></content></entry><entry><title>draw.io 图像导出的几个问题</title><url>/posts/unsorted/draw.io-%E5%9B%BE%E5%83%8F%E5%AF%BC%E5%87%BA%E7%9A%84%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98/</url><categories/><tags><tag>drawio</tag><tag>pdf</tag><tag>latex</tag></tags><content type="html">  起因今天同门遇到了一些 draw.io 图像导出的问题，我和他一起分析定位了原因。
draw.io 论文画图三宗罪截至 2025/4/13：
导出 pdf 兼容性不好，得用旧版或者 ghostscript 转换。 把 px 和 pt 混为一谈。 px 的单位支持小数，导出时四舍五入，导致和预览时效果不一致。 我确实也承认 draw.io 方便，但有些地方还是很痛苦的。其他备选项：PowerPoint、Visio。
draw.io 导出 pdf 过大使用脚本对图像压缩实际上是一个 draw.io 文件中有大量的图片，每张图片体积过大，一个 draw.io 文件总体积达到 50M 以上。先导出之后再用 pdf 压缩工具图像会糊得厉害，但如果对每张图片分别压缩，再导出即可在保持图像高质量的同时显著降低 draw.io（以及之后导出的 pdf）的 文件体积。
脚本见 Compressing images in a draw.io file without modifying other attributes accidentally。这个脚本由 Gemini 生成，仅供参考，需求不同或 draw.io 版本不同可能需要修改代码。
效果：在给定的 draw.io 文件上做测试，50,178 KB 降低到了 2,388 KB。导出为 pdf 之后，文件体积还是涨到了 4MB，不过这也显著优于之前的导出结果。
新问题：图像压缩之后 pdf 无法插入 latex收到另外一个同学反馈说这样虽然可以导出来 pdf，但是在 xelatex 中无法插入，会编译错误。换成 pdflatex 可以成功插入。有的 pdf 导出后则是 xelatex 和 pdflatex 均无法正常插入，并且编译器会报错 TeX capacity exceeded, sorry [PDF object stream buffer=5000000]，尽管 pdf 文件小于 5M（我试的时候是 3.6M）。
这个是 draw.io 自己导出 pdf 的问题，有以下方法：
👍导出 pdf 之后先用 ghostscript 转换一次，保持版本不变也可以，降低版本也可以。 🤔使用网页版本，但可能只对某些文件有效。 👍使用 24.2.5 版本客户端导出。 使用 ghostscript 对 pdf …  </content></entry><entry><title>Python 的绝对导入和相对导入</title><url>/posts/programming/python/Python-%E7%9A%84%E7%BB%9D%E5%AF%B9%E5%AF%BC%E5%85%A5%E5%92%8C%E7%9B%B8%E5%AF%B9%E5%AF%BC%E5%85%A5/</url><categories/><tags><tag>python</tag></tags><content type="html">  绝对导入需要包在 sys.path 中，可以通过环境变量 PYTHONPATH 来增加一些搜索路径。
相对导入需要当前在一个子包内。Relative imports in Python 3 - Stack Overflow 这个回答就说明如果直接运行一个包含了 import .xx 或者 from .xx import xx 的脚本就会失败，我的直观感受是这样的文件只能出现在比 main 文件（__name__ 为 __main__ 的那个文件，也就是入口文件）更深的文件夹下。相对导入有助于避免 sys.path 中出现更靠前的搜索路径，且该路径包含同名包，导致真正要导入的包被覆盖。
例子（什么时候相对导入会出错）：
main.py mypackage/ __init__.py mymodule.py myothermodule.py # from .mymodule import xx 直接运行 main.py 和 mymodule.py 都 OK，但是运行 myothermodule.py 则报错说没有 parent module。通过 python -m 来将文件视为一个模块运行，则可以将文件所在的文件夹作为 module 来运行，提供了 module 环境，但是该文件所在的文件夹并不会被加入 sys.path 中。
例子（直接运行脚本和视为模块运行的差异）：
(tiny-llm-zh) ➜ tiny-llm-zh git:(main) ✗ tree test0 test0 ├── __pycache__ │ └── test.cpython-310.pyc └── test.py 2 directories, 2 files (tiny-llm-zh) ➜ tiny-llm-zh git:(main) ✗ cat test0/test.py import sys print(&amp;#39;\n&amp;#39;.join(sys.path)) (tiny-llm-zh) ➜ tiny-llm-zh git:(main) ✗ python test0/test.py /home/xx/projects/tiny-llm-zh/test0 /home/xx/micromamba/envs/tiny-llm-zh/lib/python310.zip /home/xx/micromamba/envs/tiny-llm-zh/lib/python3.10 /home/xx/micromamba/envs/tiny-llm-zh/lib/python3.10/lib-dynload /home/xx/micromamba/envs/tiny-llm-zh/lib/python3.10/site-packages (tiny-llm-zh) ➜ tiny-llm-zh git:(main) ✗ python -m test0.test /home/xx/projects/tiny-llm-zh /home/xx/micromamba/envs/tiny-llm-zh/lib/python310.zip /home/xx/micromamba/envs/tiny-llm-zh/lib/python3.10 /home/xx/micromamba/envs/tiny-llm-zh/lib/python3.10/lib-dynload /home/xx/micromamba/envs/tiny-llm-zh/lib/python3.10/site-packages 可以看到 python test0/test.py 将文件所在文件夹加入了 sys.path，而 python -m test0.test 将 cwd（当前工作路径）加入了 sys.path。
  </content></entry><entry><title>zsh 中添加命令执行计时</title><url>/posts/cli/zsh/zsh-%E4%B8%AD%E6%B7%BB%E5%8A%A0%E5%91%BD%E4%BB%A4%E6%89%A7%E8%A1%8C%E8%AE%A1%E6%97%B6/</url><categories/><tags><tag>zsh</tag></tags><content type="html">  Elapsed and execution time for commands in ZSH
在 ~/.zshrc 文件中添加：
function preexec() { timer=$(($(date +%s%0N)/1000000)) } function precmd() { if [ $timer ]; then now=$(($(date +%s%0N)/1000000)) elapsed=$(($now-$timer)) export RPROMPT=&amp;#34;%F{cyan}${elapsed}ms %{$reset_color%}&amp;#34; unset timer fi } 2025/4/20 缺点：计时显示在一行最后，每次复制终端文本会把这个时间一并复制了，而且这一行相当长导致时间显示在第二行（折行），让人摸不着头脑这个多余的文本是哪里来的。
  </content></entry><entry><title>libstdc++ 和 libc++ 中字符串倍增比较</title><url>/posts/programming/cpp/libstdc++-%E5%92%8C-libc++-%E4%B8%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%80%8D%E5%A2%9E%E6%AF%94%E8%BE%83/</url><categories/><tags><tag>cpp</tag><tag>libstdcxx</tag><tag>libcxx</tag></tags><content type="html"><![CDATA[  https://godbolt.org/z/n8hns47M8
#include &lt;iostream&gt; #include &lt;string&gt; int main() { std::string str = &#34;hello&#34;; std::cout &lt;&lt; &#34;String: \&#34;&#34; &lt;&lt; str &lt;&lt; &#34;\&#34;&#34; &lt;&lt; std::endl; std::cout &lt;&lt; &#34;Length: &#34; &lt;&lt; str.length() &lt;&lt; std::endl; std::cout &lt;&lt; &#34;Capacity: &#34; &lt;&lt; str.capacity() &lt;&lt; std::endl; std::cout &lt;&lt; &#34;Size: &#34; &lt;&lt; sizeof(str) &lt;&lt; std::endl; str += &#34; world!。。。。&#34;; std::cout &lt;&lt; &#34;\nString: \&#34;&#34; &lt;&lt; str &lt;&lt; &#34;\&#34;&#34; &lt;&lt; std::endl; std::cout &lt;&lt; &#34;Length: &#34; &lt;&lt; str.length() &lt;&lt; std::endl; std::cout &lt;&lt; &#34;Capacity: &#34; &lt;&lt; str.capacity() &lt;&lt; std::endl; std::cout &lt;&lt; &#34;Size: &#34; &lt;&lt; sizeof(str) &lt;&lt; std::endl; str += str; std::cout &lt;&lt; &#34;\nString: \&#34;&#34; &lt;&lt; str &lt;&lt; &#34;\&#34;&#34; &lt;&lt; std::endl; std::cout &lt;&lt; &#34;Length: &#34; &lt;&lt; str.length() &lt;&lt; std::endl; std::cout &lt;&lt; &#34;Capacity: &#34; &lt;&lt; str.capacity() &lt;&lt; std::endl; std::cout &lt;&lt; &#34;Size: &#34; &lt;&lt; sizeof(str) &lt;&lt; std::endl; return 0; } 可以看到 libstdc++ 中的 capacity 的增长方式是 15 → 30 → 60。一开始 SSO 缓冲区只能容纳 16 个字符，最后一个字符是 '\0'，因此初始状态下只能容纳 15 个非空字符，capacity 为 15。而后面倍增的时候会直接按照非 '\0' 字符的最大容量来做倍增，而非按照实际缓冲区容量做倍增（即 15 → 31 → 63 这样的路径）。
而 libc++ 中 capacity 的后续倍增是考虑了空字符的：22 → 47 → 95。一开始并不是按照缓冲区容量 23 去倍增，而是用的 24，可能是认为 23 这个数字不够规整。
  ]]></content></entry><entry><title>博客主题选择、个性化设置</title><url>/posts/unsorted/%E4%B8%BB%E9%A2%98%E9%80%89%E6%8B%A9%E4%B8%AA%E6%80%A7%E5%8C%96%E8%AE%BE%E7%BD%AE/</url><categories/><tags/><content type="html"><![CDATA[  主题是 Hugo-theme-next，有一些修改。虽然支持夜间模式，但是不太会调色，有一些自定义的样式在夜间模式下效果不好。所有颜色都是保证在日间模式下易读而选择的，如果夜间模式难以阅读可以切换回来。因为动画速率太慢，调快也觉得晃眼，就关掉了。
2025.10.3 验证需要用 Release v0.143.1 · gohugoio/hugo 来渲染。已验证到 v0.146.x 开始不可用，v150.0 可用。参考 New template system in Hugo v0.146.0 。 2025.10.4 通过将一些模板中的 partials/ 前缀去除，兼容 v0.146.x，但是 achives/ 无法显示列表了。魔改了旧主题还没适配，目前暂时使用 hugo v0.143.1，不做调整。 ✨ 一些改动改变了左侧 TOC 的行距，使得多行标题能够更容易被区分开。 增加了 GitHub 风格警告支持。以前使用脚本支持，现在使用钩子重写。 为 Compiler Explorer 链接启用代码预览，把鼠标悬停在链接上就能看到代码文本。 Markdown 相对路径链接（其他文章或图片）。以前使用 404.html 支持，现在使用钩子重写。新增 Obsidian 风格的 [| width] 宽度标记支持。 按照顶级元素数量来摘取文章在首页的总结。 💥 Hugo 写作的坑YAML Front Matter 的类别要使用 categories 而不是 category，而且类型一定要是字符串的列表，而不是单个字符串（不然有些 html 模板不能正确处理）。
文本高亮（==文本== 渲染成 &amp;lt;mark&amp;gt;文本&amp;lt;/mark&amp;gt;）这是 2024 年 5 月更新的功能，升级 Hugo-extended 到 0.126.0 以上的版本并修改配置即可。
markup: goldmark: extensions: # https://github.com/goHugoio/Hugo/commit/ca9a77ef92eb0cb7bb5193e4e3afa4abb26d577c extras: insert: enable: false mark: enable: true subscript: enable: false superscript: …  ]]></content></entry><entry><title>从按下开机键起，操作系统启动过程</title><url>/posts/systems/Linux/%E4%BB%8E%E6%8C%89%E4%B8%8B%E5%BC%80%E6%9C%BA%E9%94%AE%E8%B5%B7%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/</url><categories/><tags><tag>os</tag><tag>linux</tag><tag>八股</tag></tags><content type="html"><![CDATA[  揭秘linux系统启动流程，面试官问起来再也不怕了-阿里云开发者社区
BIOS -&gt; MBR -&gt; Boot Loader (e.g. GRUB) -&gt; kernel -&gt; mount initramfs as / -&gt; /init / \ / | UEFI -&gt; GPT ----+ +----&gt; initramfs --+ | (memory) V 1 load drivers run /sbin/init &lt;--- 2 mount root 3 switch root 运行 BIOS（现代系统是 UEFI）。 进行开机自检（POST，即 Power-On Self-Test）。 寻找启动设备，依次检查存储设备，如果前 512 字节最后两个字节是 0x55 和 0xaa，那么这个块就是 MBR（主引导记录，Master Boot Record），这个存储设备就含有操作系统。然后根据 MBR 的信息找到 Boot Loader 位置，将其加载并运行。如果是 UEFI，UEFI 固件会读取磁盘上的 GPT (GUID Partition Table)。GPT 中有一个特殊的 EFI 系统分区 (ESP, EFI System Partition)，通常格式化为 FAT32。UEFI 固件会直接在该分区中查找并执行引导加载程序文件（通常是 .efi 文件，例如 \EFI\ubuntu\grubx64.efi 或 \EFI\BOOT\BOOTX64.EFI）。它不依赖 MBR 的 0x55AA 签名来启动。 Linux 常见的 Boot Loader 是 GRUB。Boot Loader 能理解文件系统，能显示操作系统选择菜单和加载 Linux 内核。 GRUB 加载 (load) 内核 (vmlinuz-&hellip;) 和 initrd/initramfs 文件 到内存。加载完成后，GRUB 将执行控制权转交给已加载到内存中的内核。然后，内核会找到内存中的 initrd/initramfs 镜像，并将其解压（如果是压缩格式，如 gzip, xz），然后将其挂载为一个 临时的根文件系统 (rootfs)。 内核执行位于 initramfs 根目录下的 /init 程序 (通常是一个脚本或小程序，如 dracut 或 mkinitcpio 生成的)，这个程序会加载必要的驱动模块，找到真正的根设备（可能是 /dev/sda2，或者 /dev/nvme0n1p3 等），将真正的根设备挂到临时路径如 /sysroot 上，然后切换根目录并释放 initramfs 的内存。 现在根目录已经切换好了，运行 /sbin/init 成为系统的第一个进程。内核引导阶段结束，用户空间初始化开始。   ]]></content></entry><entry><title>动态链接原理</title><url>/posts/systems/Linux/%E5%8A%A8%E6%80%81%E9%93%BE%E6%8E%A5%E5%8E%9F%E7%90%86/</url><categories/><tags><tag>动态链接</tag><tag>linux</tag><tag>八股</tag></tags><content type="html"><![CDATA[  阶段静态编辑 动态加载 延迟绑定 一、静态编辑链接器（ld）在生成可执行文件时，会记录可执行文件所依赖的共享库的名称以及需要的符号，并将这些信息存储在特定的段中（例如 .dynamic 段）。同时，它会创建 PLT（Procedure Linkage Table，过程链接表）和 GOT（Global Offset Table，全局偏移表）作为占位符，用于后续的动态链接过程。GOT 表初始时包含的是用于延迟绑定的地址，而非实际的函数地址。
二、动态加载加载可执行文件时，从其 .interp 字段找到解释器（也就是 loader，一般是 /lib64/ld-linux-x86-64.so.2，可以用 ldd &amp;lt;prog&amp;gt; 或者 readelf -l &amp;lt;prog&amp;gt; | grep &amp;quot;interp&amp;quot; 来检查）。让解释器来加载它。
动态链接器会从 搜索路径（例如 LD_LIBRARY_PATH 环境变量、/etc/ld.so.conf 配置的路径、默认系统路径 /lib, /usr/lib 等）搜索可执行文件所依赖的共享库，并将这些库映射到进程的虚拟地址空间中。在开启了 -fPIC 编译的情况下，动态链接器会解析全局变量和函数的地址，并将解析后的地址填充到 GOT 表中。如果程序编译时使用了 -fno-plt 选项，则所有函数调用都将直接通过 GOT 表进行，而不再依赖 PLT。在这种情况下，所有函数的 GOT 表项在加载时都会被解析并填充实际地址。
如果没有开启 -fPIC 编译，则动态链接器在加载进程时会直接修改 .text 段中的地址，导致 .text 变得私有而不在系统范围内共享。
三、延迟绑定如果程序使用了 PLT (默认行为)，当第一次调用某个外部函数时，会跳转到该函数在 PLT 中的条目。PLT 中的代码会调用动态链接器，动态链接器会查找该函数在共享库中的实际地址，并将该地址写入到 GOT 表中对应的条目。此后，对该函数的调用将直接通过 GOT 表跳转到实际地址，避免了重复的动态链接开销。
细节共享库函数的三种绑定方式绑定方式编译选项GOTPLT绑定时机备注延迟绑定-fPIC有有第一次调用时加载时立即绑定-fPIC -fno-plt有无加载时加载时修改 .text …  ]]></content></entry><entry><title>能不能解释一下 Linux 中的 IFUNC 机制？</title><url>/01-llm-generated/%E8%83%BD%E4%B8%8D%E8%83%BD%E8%A7%A3%E9%87%8A%E4%B8%80%E4%B8%8B-Linux-%E4%B8%AD%E7%9A%84-IFUNC-%E6%9C%BA%E5%88%B6/</url><categories/><tags><tag>linux</tag><tag>动态链接</tag><tag>glibc</tag><tag>llm-generated</tag><tag>IFUNC</tag></tags><content type="html"><![CDATA[  Caution
由 gemini-2.0-flash-001 生成。
我们来解释一下 Linux 中的 IFUNC (Indirect Function) 机制，以及它与 PLT 的关系。
IFUNC 机制解释:
IFUNC，全称 Indirect Function，是 GNU C 库（glibc）引入的一种机制，允许在运行时动态选择函数的实现。 简单来说，IFUNC 允许你根据运行时的条件（例如 CPU 特性、操作系统版本等）选择一个函数的不同版本或实现。
工作原理:
定义 IFUNC 解析函数： 你需要定义一个特殊的函数，称为 IFUNC 解析函数（resolver function）。这个函数负责在运行时确定应该使用哪个版本的函数实现。 声明 IFUNC 函数： 使用 __attribute__((ifunc(&amp;quot;resolver_function_name&amp;quot;))) 属性来声明一个 IFUNC 函数。这个属性告诉链接器，该函数是一个 IFUNC 函数，并且需要使用指定的解析函数来确定其实现。 动态链接器介入： 当程序第一次调用 IFUNC 函数时，动态链接器会调用该函数的解析函数。 解析函数选择实现： 解析函数根据运行时的条件选择一个合适的函数实现，并将该实现的地址返回给动态链接器。 更新 GOT 表： 动态链接器将解析函数返回的地址写入到 IFUNC 函数在 GOT 表中对应的条目。 后续调用： 后续对 IFUNC 函数的调用将直接通过 GOT 表跳转到选择的函数实现，而不再需要调用解析函数。 示例：
// 不同的函数实现 int add_sse(int a, int b) { // 使用 SSE 指令集的实现 return a + b; } int add_generic(int a, int b) { // 通用的实现 return a + b; } // IFUNC 解析函数 void *add_resolver() { if (__builtin_cpu_supports(&amp;#34;sse&amp;#34;)) { return add_sse; } else { return add_generic; } } // IFUNC 函数声明 int add(int a, int b) …  ]]></content></entry><entry><title>GCC 的 -fno-plt 选项</title><url>/01-llm-generated/GCC-%E7%9A%84-fno-plt-%E9%80%89%E9%A1%B9/</url><categories/><tags><tag>gcc</tag><tag>动态链接</tag><tag>llm-generated</tag></tags><content type="html">  Caution
由 gemini-2.5-pro-exp-03-25 生成。
gcc 的 -fno-plt 是什么含义？-fno-plt 是 GCC 编译器的一个选项，它与程序如何处理函数调用相关，特别是对共享库函数的调用。
作用和含义-fno-plt 选项禁用 PLT（Procedure Linkage Table，过程链接表）的使用。具体来说：
PLT 的工作原理： 在标准的动态链接中，对外部函数的调用通过 PLT 和 GOT（Global Offset Table，全局偏移表）间接进行 PLT 包含一小段代码，负责在第一次调用函数时解析其实际地址，并将该地址缓存在 GOT 中 后续对同一函数的调用可以直接使用 GOT 中缓存的地址 禁用 PLT 的效果： 使用 -fno-plt 后，编译器会为每次外部函数调用生成直接的代码 函数地址会在程序加载时由动态链接器解析，而不是在第一次调用时解析 所有对外部函数的调用将直接通过 GOT 进行 使用场景这个选项主要在以下场景中使用：
性能优化： 消除 PLT 的查找和间接跳转开销 对于频繁调用共享库函数的程序可能会有性能提升 在 PIE（Position Independent Executable）中： 在使用 -fPIE 构建的可执行文件中，-fno-plt 可以减少代码大小和提高性能 安全增强： 在某些安全敏感的应用中，移除 PLT 可以减少某些类型的攻击面 特别是与 GOT 劫持相关的攻击 潜在缺点使用 -fno-plt 也有一些潜在的缺点：
可能增加程序大小：对于调用许多外部函数的程序来说，可能会增加代码大小（其实并不是很明显） 影响动态链接器的延迟绑定优化：PLT 允许延迟绑定，只有在实际需要时才解析函数地址 这个选项通常与其他性能或安全相关的编译选项一起使用，如 -fPIC、-fPIE 或各种安全加固选项。
  </content></entry><entry><title>2025-03-17 新闻和博客</title><url>/daily/2025-03-17-%E6%96%B0%E9%97%BB%E5%92%8C%E5%8D%9A%E5%AE%A2/</url><categories><category>daily</category></categories><tags/><content type="html">  Triton 源码教程的 softmax 实现中，不做 warmup 的朴素实现快得多？！我就只是去掉 warmup，其他啥都没做，代码是新下的（今天的日期是 2025/3/7）。感觉是虽然朴素实现没有同时塞下所有任务（任务多了），但是每个任务的计算量变小了。
感觉英伟达推 TensorRT-LLM 是在很努力巩固技术城池了我不喜欢垄断。
2025/3/19 看到 marlin kernel 中的 bit hack 反量化算法都来自 FasterTransformer，深感震撼。
火山引擎分享用户数据换取 0.5M/day tokens5 月 31 日结束，差不多是暑期实习要开始了，字节是要搞波大的？2025/3/19 刚发现这个已经是二期了。
B 站 up 主解读 DeepSeek 技术报告【EZ 撸 paper: DeepSeek-V3 技术报告详细解读 part2 | 开源最强模型 | 性价比之王的核心技术 MLA】 https://www.bilibili.com/video/BV1HqFQezEMt/?share_source=copy_web&amp;vd_source=2772e196cf84bbcdd0033756d77bfcce
发现了两个博客MLSys 相关的 https://www.mltalks.com/ 云原生大佬 https://www.chenshaowen.com/ 他的 slides 也很有启发性   </content></entry><entry><title>45.1 简单总结 Linux IPC 机制</title><url>/the-linux-programming-interface/45.1-%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93-Linux-IPC-%E6%9C%BA%E5%88%B6/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag><tag>八股</tag></tags><content type="html">  2025/3/8 个人理解：
socket：UNIX 域套接字还是网络套接字，这取决于通信进程是否属于同一个主机。 管道：包括匿名管道（pipe 系统调用）和命名管道（fifo 文件）。 System V IPC 三大件（POSIX 中也能找到这几个组件的替代物） 信号量 共享内存 消息队列 System V IPC 用 key 来访问，本质是命名的，IPC_PRIVATE 只是生成独一无二的名字而已；除了消息队列必须命名之外，POSIX 中其他两个既可以命名也可以匿名。 其他区别见 51 POSIX IPC 介绍。 mmap：单独用 mmap 可以实现匿名共享内存，但不能解决命名共享内存的问题。POSIX 共享内存可以解决命名共享内存的问题，但是要配合 mmap 才能附加到进程地址空间。mmap 因为很特殊所以单独放出来，没合并到共享内存里面去。 文件锁 futex 信号：信息传输效率低，一般用于操作系统给进程通知信息，或者用户交互式干预进程运行。   </content></entry><entry><title>LaTeX hyperref CJK 中文短语链接可点击范围只有其高度的一半</title><url>/posts/latex/LaTeX-hyperref-CJK-%E4%B8%AD%E6%96%87%E7%9F%AD%E8%AF%AD%E9%93%BE%E6%8E%A5%E5%8F%AF%E7%82%B9%E5%87%BB%E8%8C%83%E5%9B%B4%E5%8F%AA%E6%9C%89%E5%85%B6%E9%AB%98%E5%BA%A6%E7%9A%84%E4%B8%80%E5%8D%8A/</url><categories/><tags><tag>latex</tag></tags><content type="html">  LaTeX hyperref CJK 中文短语链接可点击范围只有其高度的一半。但凡其中加入了非 CJK 字符，可点击范围就会恢复正常。用 \vphantom 没有效果，大概是因为不会真正改变 baseline。有一种方法是强制 CJK 字符和其他字符的基线对齐，但是我觉得对齐之后肯定不好看。
我想到真正去渲染一个白色字符（可以改成透明颜色），然后再用 \hspace 减去其长度。最后结果勉强能看，缺点是复制的时候会多出来一个字符（用来打印和阅读的话问题不大）。
% https://tex.stackexchange.com/a/412555/ \newcommand{\nhphantom}[1]{\sbox0{#1}\hspace{-\the\wd0}} \newcommand{\overlay}[1]{{#1}\nhphantom{#1}} % \Url 命令是模板原先就有的命令，现在加上了一个 \overlay 来保证对中文的支持 \NewDocumentCommand{\Url}{mm} { \href{#1}{ { \CJKunderline{#2} \overlay{\textcolor{white}{.}} } } } 2025 年 3 月 5 日：今天投递简历发现很多网站会从 PDF 中抽取文字，这导致抽出来的文字多了一个 .，所以还是尽可能在链接显示文本中包含拉丁字符作为权宜之计 😂。
  </content></entry><entry><title>C++ 中哪些 STL 类型可以作为 map 或 unordered_map 的键？</title><url>/posts/programming/cpp/C++-%E4%B8%AD%E5%93%AA%E4%BA%9B-STL-%E7%B1%BB%E5%9E%8B%E5%8F%AF%E4%BB%A5%E4%BD%9C%E4%B8%BA-map-%E6%88%96-unordered_map-%E7%9A%84%E9%94%AE/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  其实是在问哪些类型有 hash 函数和重载了 &lt; 比较操作符。因为说的是 STL，所以不考虑内建类型。
可哈希和 == 比较常见的可以哈希和 == 比较的集合类型有（以下省略 std 命名空间）：
string / string_view bitset unique_ptr / shared_ptr 这样的标准库模板类其实非常少！通常，可以用于 hash 和相等的类型都能用于 &lt; 比较。
注意 map 和 set 通常不可哈希！包括：
flat_map / flat_set (C++23) map / set unordered_map / unordered_set 可 &lt; 比较常见的可以用于 &lt; 比较的集合类型除了 可哈希和 == 比较 给出的几个类型之外 ，还有：
vector pair / tuple / array（array 和 pair 都可以看成是特殊的 tuple） deque / queue / stack（不包括 priority_queue） list / forward_list map / set   ]]></content></entry><entry><title>2025-02-16 Compiler Explorer 使用了沙盒</title><url>/daily/2025-02-16-Compiler-Explorer-%E4%BD%BF%E7%94%A8%E4%BA%86%E6%B2%99%E7%9B%92/</url><categories><category>daily</category></categories><tags/><content type="html">  OP 的程序收到了 SIGABRT 信号，但是从 Compiler Explorer 上观察到进程是因为 SIGSEGV 信号退出。原因是 Compiler Explorer 使用了沙盒，无法完全正确地反映程序因何种信号退出。
Reddit 帖子。
  </content></entry><entry><title>Windows 禁用系统更新</title><url>/posts/systems/Windows/Windows-%E7%A6%81%E7%94%A8%E7%B3%BB%E7%BB%9F%E6%9B%B4%E6%96%B0/</url><categories/><tags><tag>windows</tag></tags><content type="html">  参考 B 站教程。
在注册表中，找到：
计算机\HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\WindowsUpdate\UX\Settings 新建 DWORD 值，名称为：
flightSettingsmaxpausedays 值设置大一点。这样在 Windows 更新页面的最大停止时间就可以选很长，几十周甚至几百周。不过这个数字设置太大了面板会卡住，设置到合理大就可以了，比如 3000。注意设置的时候选择十进制。
效果图：
其实和直接修改同项目（计算机\HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\WindowsUpdate\UX\Settings）下的另外几个项是一样的（这几个注册表值管理上次检查时间和下次强制检查时间），只是我觉得修改最长暂停更新时间错误率会低一点，不容易出现日期字符串编辑错误、导致系统出现故障的情况。
  </content></entry><entry><title>git log --remerge-diff</title><url>/posts/cli/git/git-log--remerge-diff/</url><categories/><tags><tag>git</tag></tags><content type="html"><![CDATA[  --remerge-diff 选项在 git log 和 git show 命令中都存在。它用更容易阅读的方式显示一个合并结点相对于两个 parent 的变化。
下图是一个例子（来源在这里）。没用这个选项的时候会显示三路的差异，有三种颜色。只看绿色部分就是最终解决了冲突后的代码，但是看红色还得看红色是来自哪一个 parent，不够方便。
用了这个选项之后修改被整合在了不同的代码段中，只使用一栏标志（就不用再从左边去寻找代码来自哪个 parent，只需要看它属于哪一个代码块）。将红色的部分视为注释，只看正常颜色的字体，就可以得知冲突解决后的结果是：
if (dwim_ref(cb.buf.buf, cb.buf.len, &amp;oid, &amp;ref, 1) == 1 &amp;&amp; /* oid is a commit? match without further lookup */ 通过三个区块仍然可以得到两个 parent 和自动合并后的结果。之前是无法得到自动合并后的结果的信息的。
  ]]></content></entry><entry><title>libstdc++ enable_shared_from_this 源码分析</title><url>/posts/programming/cpp/libstdc++-enable_shared_from_this-%E6%BA%90%E7%A0%81/</url><categories/><tags><tag>cpp</tag><tag>libstdcxx</tag></tags><content type="html">  继承 std::enable_shared_from_this 模板类之后就多了一个弱指针（_M_weak_this）。同时还多了一个 __enable_shared_from_this_base 方法，创建共享指针时该方法能被 ADL 找到，以关联和共享控制块。该方法是私有的，不过 __shared_ptr&amp;lt;typename, typename&amp;gt; 是友元类，因此能访问它。
共享指针模板类 __shared_ptr 有个私有方法 _M_enable_shared_from_this_with，它能通过 SFINAE 判断元素类型是否是继承自 enable_shared_from_this 的 CRTP 类，如果是则将自己的控制块关联给 enable_shared_from_this 中的弱指针。
按照这个逻辑，在创建共享指针的时候，_M_enable_shared_from_this_with 应该会被调用。这一点确实可以被验证（下面还有一些构造函数，就不展示了）：
std::make_shared 会将元素和控制块放在一起，减少内存申请的次数，那么它会对 enable_shared_from_this 进行特殊判断吗？从 libstdc++ 源码来看是不会的，这个函数通过特殊的 tag 直接调用了一个私有的 shared_ptr 构造函数，该构造函数包含了对 _M_enable_shared_from_this_with 的调用。
Note
使用 make_shared 时 allocator 是不能被指定的。
  </content></entry><entry><title>Windows 打不开服务、设备管理器等 .msc 文件</title><url>/posts/systems/Windows/Windows-%E6%89%93%E4%B8%8D%E5%BC%80%E6%9C%8D%E5%8A%A1%E8%AE%BE%E5%A4%87%E7%AE%A1%E7%90%86%E5%99%A8%E7%AD%89-.msc-%E6%96%87%E4%BB%B6/</url><categories/><tags><tag>windows</tag></tags><content type="html">  问题发现是 mmc.exe 不工作了，“.msc 文件打开方式”的系统注册项是正常的。
sfc/dism/chkdsk 三件套，无果sfc.exe /scannow DISM.exe /Online /Cleanup-image /scanhealth DISM.exe /Online /Cleanup-image /checkhealth DISM.exe /Online /Cleanup-image /restorehealth 确实是显示发现了问题并修复，但是结果还是打不开。
chkdsk /f /r 用 chkdsk 检查了半个小时，没效果。
尝试过注册 dll，无果此链接 建议加载必要的 dll：
Regsvr32 Msxml.dll Regsvr32 Msxml2.dll Regsvr32 Msxml3.dll 结果加载 msxml2.dll 时报错。重启之后加载 msxml.dll 也报错。只有 msxml3.dll 能成功加载。这个提问者描述了 一样的情况。
修复 Microsoft Visual C++ Redistributable最后是参考 这篇文章。
在“控制面板 &amp;gt; 卸载程序”里面，找到所有和 Microsoft Visual C++ Redistributable 相关的安装程序，点击修复。期间可能会发生修复错误，提示没有修改某个文件的权限。进 C:\Windows\system32 里面去看，发现里面有一些 exe 和 dll 文件是指向为空的 symlink。把这些文件全部删掉，然后对每个 Microsoft Visual C++ Redistributable 安装程序都点开修复，之后 mmc.exe 就能正常打开了。
  </content></entry><entry><title>5.0.2 阅读 libstdc++ 中原子变量 wait 和 notify 接口</title><url>/cpp-concurrency-in-action/5.0.2-%E9%98%85%E8%AF%BB-libstdc++-%E4%B8%AD%E5%8E%9F%E5%AD%90%E5%8F%98%E9%87%8F-wait-%E5%92%8C-notify-%E6%8E%A5%E5%8F%A3/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag><tag>libstdcxx</tag></tags><content type="html"><![CDATA[  Wait 和 notify 接口介绍std::atomic&amp;lt;T&amp;gt;::wait 用来等待原子变量值的改变，如果原子变量值和给定的参数 old 相同则阻塞，直到被 notify_all() 或者 notify_one() 通知，或者自发地解除阻塞。因此用 wait 要在循环中使用。
// std::atomic&amp;lt;T&amp;gt;::wait void wait( T old, std::memory_order order = std::memory_order_seq_cst ) const noexcept; void wait( T old, std::memory_order order = std::memory_order_seq_cst ) const volatile noexcept; Cppreference 上说这个接口通常比轮询和自旋锁更高效。看了一下 libstdc++ 的实现，实际上内部也是自旋锁，只是比我们在外面用自旋锁要高效一些。实现在 libstdc++-v3/include/bits/atomic_wait.h 文件中。
wait 的实现调用链路（同一缩进下函数的调用不区分顺序，不表示前者在后者之前调用）：
__atomic_wait_address_v __detail::__waiter&amp;lt;std::true_type&amp;gt;::_M_do_wait_v __detail::__waiter_pool::_M_do_spin_v 🔍 // do-while loop of: __detail::__waiter_pool::_M_do_wait 🔍 // and __detail::_S_do_spin_v __detail::__atomic_spin 🔍 注意到 __waiter&amp;lt;std::true_type&amp;gt; 在代码中有个别名为 __enters_wait，它的模板参数实际上只影响 __waiter 在构造和析构时是否分别调用 _M_enter_wait() 和 _M_leave_wait()，不影响其他函数的行为。
__detail::__waiter_pool::_M_do_spin_v 的实现：
template&amp;lt;typename _Tp, typename _ValFn&amp;gt; …  ]]></content></entry><entry><title>10. Parallel algorithms</title><url>/cpp-concurrency-in-action/10.-Parallel-algorithms/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag></tags><content type="html"><![CDATA[  执行策略（C++17）std::execution::seq std::execution::par std::execution::par_unseq std::execution::unseq (C++20) 它们分别属于以下类型，但是使用的时候不要自己创建类型，应该直接使用标准库中提供的执行策略对象。
std::execution::sequenced_policy std::execution::parallel_policy std::execution::parallel_unsequenced_policy std::execution::unsequenced_policy (C++20) 其中的并行策略仅仅是允许算法这样做，但不能强制算法按要求做。
Note that this is permission, not a requirement—the library may still execute the code on a single thread if it wishes.
如果指定了执行策略，那么抛出的异常将不会传播到当前线程，程序将会因为 std::terminate 的调用而终止。以下例子展示了为标准库算法模板指定 std::execution::seq 之后，抛出的异常就不再传播： https://godbolt.org/z/dTaKM4h6r 。这是指定 std::execution::seq 和不指定执行策略的一个显著的区别。打印结果中线程 ID 没有变化，说明这只是标准库为了满足标准做了专门处理，并不是为序列任务创建了一个新线程。
不同执行策略的比较除了书上的内容，还可以参考网页 execution_policy_tag_t 。
std::execution::seq序列化运行。
这也是一种执行策略，所以根据标准规定，异常不会传播到调用者。 保证操作按照某种顺序进行，但是这个顺序是未指定的（unspecified），而且在函数的不同次调用中可能操作顺序不同。 std::vector&amp;lt;int&amp;gt; v(1000); int count = 0; std::for_each(std::execution::seq, v.begin(), v.end(), [&amp;amp;](int&amp;amp; x) { x = …  ]]></content></entry><entry><title>11. 测试和调试多线程应用</title><url>/cpp-concurrency-in-action/11.-%E6%B5%8B%E8%AF%95%E5%92%8C%E8%B0%83%E8%AF%95%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%BA%94%E7%94%A8/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag></tags><content type="html">  Unwanted blockingDeadlock Livelock，和死锁的区别是在循环中积极检查条件，比如自旋锁，线程一直消耗 CPU 但始终无法前进 Blocking on I/O or other external input，线程在等待一个不定期的、可能永远不会到来的操作 Race conditionsData races Broken invariants Lifetime issues Code review在并发访问下，哪些数据需要保护？ 如何确保数据受到保护？ 此时其他线程可能位于代码的哪个部分？ 当前线程持有哪些互斥锁？ 其他线程可能持有哪些互斥锁？ 在当前线程中执行的操作与在其他线程中执行的操作之间是否存在顺序要求？如何确保这些要求得到满足？ 当前线程加载的数据是否仍然有效？是否可能已被其他线程修改？（比如 CAS、双重校验锁） 如果假设其他线程可能正在修改数据，这意味着什么？如何确保这种情况永远不会发生？ Testing书 P345 给出了一些对线程安全队列进行测试的测试点。
  </content></entry><entry><title>9. Advanced thread management</title><url>/cpp-concurrency-in-action/9.-Advanced-thread-management/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag></tags><content type="html"><![CDATA[  线程池实现可以 submit 任务并获取 future 的线程池有了 std::future 就能对提交的任务做等待。
线程池初始化时就创建指定数量的工作线程，每个线程的任务就是在循环中从线程安全队列上获取任务并运行。每个任务的类型是 std::packaged_task&amp;lt;result_type()&amp;gt; task，每次有工作要提交都会包装到 std::packaged_task，工作的提交者因而可以获取 std::future。
由于 C++23 才引入 std::move_only_function&amp;lt;&amp;gt;，书上实现了一个简单的替代。
修复 quicksort 工作线程的死锁书上给了一个 quicksort 的例子，指出划分完成时，本线程先递归做完 new_higher 段的工作，再去等待 new_lower 段的工作的 future。这个实现中线程池中工作线程数量是固定的，如果所有工作线程都需要等待 future，那么就没有剩余的工作线程去真正推进任务了！有限线程数 + 线程等待尚未排队的任务 = 死锁。
解决方案是让线程在等待期间不要休眠，而是主动处理其他任务：
while (new_lower.wait_for(std::chrono::seconds(0)) == std::future_status::timeout) { pool.run_pending_task(); } 为此，需要实现 run_pending_task()，它开放了线程池外执行线程池任务队列中任务的接口，避免其他线程做无意义的等待。
void thread_pool::run_pending_task() { function_wrapper task; if (work_queue.try_pop(task)) { task(); } else { std::this_thread::yield(); } } 用本地队列减少单一全局队列负担为每个工作线程创建一个本地队列：
class thread_pool { threadsafe_queue&amp;lt;function_wrapper&amp;gt; pool_work_queue; typedef std::queue&amp;lt;function_wrapper&amp;gt; local_queue_type; …  ]]></content></entry><entry><title>8. Designing concurrent code</title><url>/cpp-concurrency-in-action/8.-Designing-concurrent-code/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag></tags><content type="html">  False sharingCache ping-pong std::hardware_destructive_interference_size还有 std::hardware_constructive_interference_size。在大多数情况下这两个值相等，而且都等于 cache line 的大小。
https://stackoverflow.com/questions/39680206/understanding-stdhardware-destructive-interference-size-and-stdhardware-cons 第一个回答的评论里面指出如果目标平台有多个，那么为了兼容性，这两个常量可能是不同的。在特定架构上这两个常量应该是相同的。
例子：矩阵计算每个线程计算一组列。列可以先加载到当前线程，每次都读一整行，对 cache 友好。 每个线程计算一组行。相比于方案 1，读的 false sharing 更多，但是写操作的 false sharing 会更少。 分块矩阵。访问输入矩阵元素的数量减少了，同时保持计算出来的元素数相同，因而效率更高。 Data access patterns in other data structures例：树状结构树状结构结点小，不同线程如果访问不同结点，cache line 重叠概率小，对 false sharing 有利。
例：MutexMutex 和受保护数据在同一个 cache line 时，其他线程尝试上锁对持有锁的线程性能有影响。
Mutex locks are typically implemented as a read-modify-write atomic operation on a memory location within the mutex to try to acquire the mutex, followed by a call to the operating system kernel if the mutex is already locked.
当 mutex 和受保护数据要存在一起时，可以在数据结构中增加 padding 以隔开两者。
struct protected_data { std::mutex m; char …  </content></entry><entry><title>Nuphy 轴体质量差</title><url>/posts/life/2025%E5%B9%B41%E6%9C%8815%E6%97%A5-Nuphy-%E8%BD%B4%E4%BD%93%E8%B4%A8%E9%87%8F%E5%B7%AE/</url><categories/><tags><tag>键盘</tag></tags><content type="html">  如题，买的是 Nuphy Air75 V2 越橘轴，感觉按久了之后有几颗轴松松垮垮的，和其他轴体的紧致感是完全不一样的，而且有问题的轴体在小键上面还能听到剐蹭的声音。可惜包装里面送的是四种轴体各一个，而不是同一种轴体 4 个，不能方便替换（包装里面有一个越橘轴我已经拿来替换过了）。
我敲 ctrl 可能是要比其他按键稍微重一点，我的另一把键盘 ctrl 轴体没问题，定位板下陷了。但总不能因为我按 ctrl 键稍微重一点就导致轴体出问题吧，轴体本来从设计上就是要承受按压的。
2025 年 1 月 18 日补充：发现 I 字母对应的轴回弹慢一拍，有点像油导致的粘滞，又有点像回弹的时候剐蹭的摩擦力太大，难受了。
  </content></entry><entry><title>2025-01-14 Intel 大小核调度</title><url>/daily/2025-01-14-Intel-%E5%A4%A7%E5%B0%8F%E6%A0%B8%E8%B0%83%E5%BA%A6/</url><categories><category>daily</category></categories><tags/><content type="html">  今天看到一篇介绍 Intel 大小核在 Windows 上面的调度策略 的比较好的帖子。帖子中提到：
单纯将“最大处理器状态”设为 99% 只能关掉小核的睿频，大核仍然是跑满的。
在新时代，如果你想设置大核的“最大处理器状态”，首先你需要在注册表中解锁隐藏的电源选项“第 1 类处理器电源效率的最大处理器状态”（ PROCTHROTTLEMAX1 / bc5038f7-23e0-4960-96da-33abaf5935ed ），然后对其进行设置才有用。
其他大小核调度策略讲解的帖子：
https://www.bilibili.com/opus/920589157176180744   </content></entry><entry><title>无法从 huggingface 上下载模型</title><url>/posts/unsorted/%E6%97%A0%E6%B3%95%E4%BB%8E-huggingface-%E4%B8%8A%E4%B8%8B%E8%BD%BD%E6%A8%A1%E5%9E%8B/</url><categories/><tags/><content type="html">  可以设置环境变量来修改访问其他端点。
export HF_ENDPOINT=https://hf-mirror.com   </content></entry><entry><title>WSL2 中安装 perf</title><url>/posts/systems/Windows/WSL2-%E4%B8%AD%E5%AE%89%E8%A3%85-perf/</url><categories/><tags><tag>wsl</tag></tags><content type="html">  https://juanjose.garciaripoll.com/blog/installing-perf-on-WSL2/index.html
参考这个教程，直接下载 perf 并编译，编译报错。
https://gist.github.com/abel0b/b1881e41b9e1c4b16d84e5e083c38a13
从 WSL2 的仓库附属代码编译 perf。注意找到和自己内核版本对应的源码，可以用 uname -a 来查看自己的内核版本。
git clone https://github.com/microsoft/WSL2-Linux-Kernel.git \ --branch linux-msft-wsl-5.15.y --depth 1 把评论区的这些包也安装一下：
sudo apt install libdwarf-dev libelf-dev libnuma-dev libunwind-dev \ libnewt-dev libdwarf++0 libelf++0 libdw-dev libbfb0-dev \ systemtap-sdt-dev libssl-dev libperl-dev python-dev-is-python3 \ binutils-dev libiberty-dev libzstd-dev libcap-dev libbabeltrace-dev 还是会编译报错。
重新下载主分支并编译。主分支的内核版本会新一点，虽然很多内核的头文件对不上（对 ABI 有影响），但是没有编译错误了。也许是微软还没有处理 5.15 内核版本在 GCC 更新之后的带来的新的警告吧（-Werror 将警告转换成错误）。
现在运行找不到动态链接库：
$ ./perf --help ./perf: error while loading shared libraries: libcrypt.so.2: cannot open shared object file: No such file or directory 试了几个都是 conda 里面的，于是我退出 conda 环境重新编译就好了。
目前还没发现 ABI 变化导致的错误，运行 perf record 和 perf report 都是正常的。常用命令：
$ perf record ./executable ... # 这里会运行可执行文件，并且生成一个名为 perf.data 的文件 $ perf report --demangle ... # 这里会在终端中显示不同函数运行占用的 CPU 时间 2025 年 2 月 28 日：版本更新之后又编译不了了。可以试试这个 https://stackoverflow.com/a/65276025/ ，从 linux-tools-generic 的路径中去找 perf，比如 /usr/lib/linux-tools/&amp;lt;linux-version&amp;gt;-generic/perf。
  </content></entry><entry><title>5.1 libstdc++ 对共享指针原子操作的支持</title><url>/cpp-concurrency-in-action/5.1-libstdc++-%E5%AF%B9%E5%85%B1%E4%BA%AB%E6%8C%87%E9%92%88%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%9A%84%E6%94%AF%E6%8C%81/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag><tag>libstdcxx</tag></tags><content type="html"><![CDATA[  引言这篇笔记是承接 CppCon 2023 Lock-free Atomic Shared Pointers Without a Split Reference Count 和 内存模型基础、标准原子类型、自旋锁 来写的。
C++20 有 std::atomic&amp;lt;std::shared_ptr&amp;gt; 和 std::atomic&amp;lt;std::weak_ptr&amp;gt; 的偏特化，之前连这两个偏特化都没有，因而会编译错误（std::atomic requires a trivially copyable type），只能使用对共享指针提供的原子操作自由函数（std::atomic_*）。但是这样的类型并不是无锁的，可以通过 is_lock_free() 的返回值看出来，见 https://godbolt.org/z/b5P84jM9f 。根据 Daniel1 的幻灯片，MSVC 和 libstdc++ 中这两个类型都是有锁；根据我的查证，libc++ 截至 2025 年 1 月 5 日还没有实现这两个偏特化。
既然知道有锁了，libstdc++ 是怎么实现共享指针原子变量的线程安全访问的呢？
原子操作自由函数C++20 之前原子操作自由函数对 std::shared_ptr&amp;lt;T&amp;gt; 的支持可见 atomic_load_explicit 和 _Sp_locker，它对指针值做 hash，得到互斥量池里的一个下标，从而获取一个 __gnu_cxx::__mutex 的引用。可以参考 以下代码。
// shared_ptr.cc #include &amp;#34;mutex_pool.h&amp;#34; namespace __gnu_internal _GLIBCXX_VISIBILITY(hidden) { /* Returns different instances of __mutex depending on the passed index * in order to limit contention. */ __gnu_cxx::__mutex&amp;amp; get_mutex(unsigned char i) { #ifdef _GLIBCXX_CAN_ALIGNAS_DESTRUCTIVE_SIZE // Increase alignment to …  ]]></content></entry><entry><title>7. 设计无锁并发数据结构</title><url>/cpp-concurrency-in-action/7.-%E8%AE%BE%E8%AE%A1%E6%97%A0%E9%94%81%E5%B9%B6%E5%8F%91%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag></tags><content type="html">  非阻塞数据结构的分类书上给出了一个用 std::atomic_flag 实现自旋锁的代码片段：
class spinlock_mutex { std::atomic_flag flag; public: spinlock_mutex() : flag(ATOMIC_FLAG_INIT) {} void lock() { while (flag.test_and_set(std::memory_order_acquire)); } void unlock() { flag.clear(std::memory_order_release); } }; 自旋锁是一个 nonblocking 的例子（书上认为它没有任何阻塞调用，因此是非阻塞的），但是却不是 lock-free 的。
书上给出了下面几类数据结构：
Obstruction-free：如果其他线程都被暂停了，那么任何一个选定的线程都能在一定步数内完成操作。 Lock-free：多个线程同时在进行操作，有一个线程能在一定步数内完成操作。常见的范式是在循环中进行 CAS。可能有饥饿发生。 Wait-free：多个线程同时在进行操作，每个线程都能在一定步数内完成操作。 https://en.wikipedia.org/wiki/Non-blocking_algorithm 给出了更精炼的描述：
A non-blocking algorithm is lock-free if there is guaranteed system-wide progress, and wait-free if there is also guaranteed per-thread progress.
根据以上信息，用户空间下的自旋锁也不是 obstruction-free 的。2025 年 2 月 7 日：如果没有上下文切换，受自旋锁保护的操作又能在有上界的时间内完成，那么自旋锁当然是 lock-free 的（比如在内核中）。
由于 obstruction-free 的应用场景有限，而 wait-free 的算法相当难写，所以 lock-free 的算法比较常见。Lock-free 的算法不仅有并发优势，而且更鲁棒，不会出现持有锁的线程异常终止，导致其他线程无法继续前进的情况。Lock-free 算法可能会出现活锁（live …  </content></entry><entry><title>6. 设计基于锁的并发数据结构</title><url>/cpp-concurrency-in-action/6.-%E8%AE%BE%E8%AE%A1%E5%9F%BA%E4%BA%8E%E9%94%81%E7%9A%84%E5%B9%B6%E5%8F%91%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag></tags><content type="html"><![CDATA[  引入部分设计并发数据结构需要考虑两类问题：
如何保护数据？ 如何实现真正的并发？ 本章实现线程安全的栈（1 个全局互斥量）、队列（2 个全局互斥量，头尾各用一个）、哈希表（每个 slot 一个互斥量）、链表（每个结点一个互斥量）。
6.2.1-6.2.2 用互斥锁保护 std::stack 和 std::queue首先书上给了实现线程安全的栈和队列的例子。它们都是用 std::mutex 来保护对应的数据结构的。
在实现队列的时候，为了方便生产者 - 消费者问题的处理，添加了对条件变量的使用。条件变量的使用给异常安全带来了一个新的问题：
void threadsafe_queue::push(T new_value) { std::lock_guard&amp;lt;std::mutex&amp;gt; lk(mut); data_queue.push(std::move(new_value)); data_cond.notify_one(); } std::shared_ptr&amp;lt;T&amp;gt; threadsafe_queue::wait_and_pop() { std::unique_lock&amp;lt;std::mutex&amp;gt; lk(mut); data_cond.wait(lk, [this] { return !data_queue.empty(); }); std::shared_ptr&amp;lt;T&amp;gt; res(std::make_shared&amp;lt;T&amp;gt;(std::move(data_queue.front()))); data_queue.pop(); return res; } 在有数据被生产出来时，生产线程调用 push() 方法，进而使用 notify_one() 通知了一个消费者线程。如果这个消费者线程在拷贝数据到 std::shared_ptr&amp;lt;T&amp;gt; 时发生了异常，那么其他线程不会收到通知来处理这个新产生的数据。
Note
不用担心 std::make_shared 本身的异常安全，标准库已经处理好了。 这里返回共享指针是因为共享指针传给返回值是不会引发异常的，而 T 类型可能会在拷贝 / 移动时发生异常并让刚从队列中取出的数据丢失。详见 3. Sharing data between threads 中实现线程安全栈的案例。 书 …  ]]></content></entry><entry><title>5.1 原子操作的内存顺序</title><url>/cpp-concurrency-in-action/5.1-%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C%E7%9A%84%E5%86%85%E5%AD%98%E9%A1%BA%E5%BA%8F/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag></tags><content type="html"><![CDATA[  C++ 内存模型概念书上着重介绍了 synchronizes-with 和 happens-with 两个关系（relationship）。
Synchronizes-withThe synchronizes-with relationship is something that you can get only between operations on atomic types.
书上还说：一些操作的内部实现会使用原子操作（比如对 mutex 上锁），因此也能达到同步关系，但是同步关系从根本上是由原子操作提供的。
Synchronizes-with 关系提供一种跨线程的 happens-before 关系。
Happens-beforeSequenced-before（单线程）单个线程中排在前面的操作发生在排在后面的操作之前（比如前一个语句和后一个语句），而且是 strongly happens before。
For a single thread, it’s largely straightforward: if one operation is sequenced before（排在……之前）another, then it also happens before（发生在……之前）it, and strongly-happens-before it.
Tip
我个人觉得书里的 sequenced before 有种单线程的意味，强调单个线程中 A 操作发生在 B 操作之前，好像是在说“代码就是这么写的”。
如果两个操作发生在同一个语句中，那么一般无法确定他们执行的先后顺序。但是有例外：
逗号表达式中，左边的表达式发生在右边之前。 一个表达式的结果作为另外一个表达式的参数，那么这两个表达式的执行就有了先后关系。 需要注意函数参数列表不是逗号表达式。就算确定了函数参数传递顺序，每个参数的评估顺序也是未指定（unspecified）的。由于下面代码中的 get_num() 函数有副作用，因此其执行结果是未知的。
#include &amp;lt;iostream&amp;gt; void foo(int a, int b) { std::cout &amp;lt;&amp;lt; a &amp;lt;&amp;lt; &amp;#34;, &amp;#34; &amp;lt;&amp;lt; b &amp;lt;&amp;lt; …  ]]></content></entry><entry><title>GCC7 `std::atomic::is_lock_free` 的变化</title><url>/cpp-concurrency-in-action/5.0.1-GCC7-std-atomic-is_lock_free-%E7%9A%84%E5%8F%98%E5%8C%96/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag><tag>libstdcxx</tag></tags><content type="html">  GCC7 不再认为 x86 上的 16 字节原子变量无锁原因：GCC7 开始在 std::atomic&amp;amp;lt;T&amp;amp;gt;::is_always_lock_free 不满足时会调用 libatomic 的 __atomic_is_lock_free() 函数，但是 libatomic 对无锁的内涵理解不同。
https://godbolt.org/z/nc34E716Y 这里表明 gcc7 处理 is_lock_free 的行为发生了变化，即便有了 -mcx16 编译选项，也不认为 16 字节原子变量是无锁的，gcc6 则认为 16 字节原子变量在对齐满足时是无锁的（无论 -mcx16 标志是否存在）。Clang 则是在有无 -mcx16 选项时呈现出不同的结果。GitHub 上有个相关的 讨论 。简单来说是 gcc7 之后不会直接通过当前编译架构来直接决定一个类型是否无锁（clang 会），而是将这个逻辑转移到对 libatomic 的函数的调用上，而 libatomic 认为 16 字节原子变量在 x86 上不算无锁。
GCC 的 libatomic 对是否无锁的判断可见 glfree.c 。函数签名为 bool libat_is_lock_free (size_t n, void *ptr)。对于 2 的幂（case 0/1/2/4/8/16）先判断是否其大小是否可以做到无锁（稍后介绍），如果不行则放到一个更大的范围内去判断，在更大的范围内判断时要考虑其所占空间是否能刚好被更大的无锁原子类型覆盖。比如：
假设 8 字节的对齐访问是无锁的，那么以下 5 个字节的访问是无锁的： | . . . . . . . . | * * * * * ✔ 这也是无锁的： | . . . . . . . . | * * * * * ✔ 这是有锁的： | . . . . . . . . | . * * * * * 🔒 而 libatomic 判断一个大小是否能做到无锁，直接看代码注释就可以（C2 宏将两个 token 拼接起来，得到一个之前定义的宏）：
/* Accesses with a power-of-two size are not lock-free if we don&amp;amp;#39;t have an integer type of this size or if they …  </content></entry><entry><title>2024-12-28 插件：Mouse Pinch-To-Zoom Chrome</title><url>/daily/2024-12-28-%E6%8F%92%E4%BB%B6Mouse-Pinch-To-Zoom-Chrome/</url><categories><category>daily</category></categories><tags/><content type="html">  Mouse Pinch-To-Zoom Chrome 插件按下 alt 就能像有触控板一样缩放网页了。不会改变网页本身的缩放等级，在有图片全屏显示，但仍需要观察细节时非常有用。安装后已经打开的网页需要重新载入才能生效。
  </content></entry><entry><title>哥斯拉主题 Berry 键帽体验</title><url>/posts/life/2024%E5%B9%B412%E6%9C%8828%E6%97%A5-%E5%93%A5%E6%96%AF%E6%8B%89%E4%B8%BB%E9%A2%98-Berry-%E9%94%AE%E5%B8%BD%E4%BD%93%E9%AA%8C/</url><categories/><tags><tag>键盘</tag><tag>日常</tag></tags><content type="html">  说明以下的 nSA 键帽指的是 Nuphy 原装的键帽，而 Berry 键帽指的是指尖文创和 Nuphy 联名的哥斯拉主题矮轴键帽。注明这一点是因为有可能我的体验只适用于特定的键帽，我没买过其他键帽不好评价。
评价和我之前的主力键盘的合照：
新的 Berry 键帽和 nSA 原装键帽比：
虽然参数上写的没有高多少，但实际上感觉还是高了很多。 nSA 太低，小脚撑开上就差不多了，开大脚撑手感反而怪怪的。Berry 键帽设计有坡度，下面高一点，利好大脚撑。 声音变得更加脆响。不好听，duang duang duang 地响。一是因为按压之后键帽更靠下一点（从侧面可以看到），可能撞到键盘下面的结构了？二是键帽刚按下的时候就感觉会发出声音，但是 nSA 键帽就好很多。 形状变了，按压也更费力了。声音和手感变差可能是因为键帽的卡口变得更深，卡得更紧导致的。 空格有点漏轴。 而且空格键帽敲击的声音非常大。空格是声音差异最为明显的一个键，敲起来有不协调感。如果说其他按键敲起来只是有点不舒服之外，空格敲起来可以用毛骨悚然来形容了。 上面没有标识快捷键图案，不过我平时用的也少，只记住了音量键加减的键位。 太久没有换键帽了，这次没小心，拔键帽的时候把 backspace 弄得有纲丝音了。
我买 Berry 键帽的一个原因是遮住我的键盘变形。很多键盘容易变形（我买过的几个键盘或多或少有点变形，有些是刚买来就有点变形，有些是我自己使用过程中会变形），但是 Nuphy AIr75 V2 nSA 键帽太平，这样定位板变形带来的视觉感受非常明显。
我自己买键盘第一次用的就是矮轴，当时还不习惯高轴觉得高轴体型太夸张了。后来再买了 Nupy Air75 V2 觉得容易按错，现在给它换上了 Berry 键帽以为会好用一点，但从手感和声音来看还是不如两三百块钱的量产高轴键盘，反而还丢了矮轴的特色。我觉得矮原厂挺尴尬的，不如 nSA 贴合，而且高度差虽然比 nSA 大但也不是很明显，手在键盘面上滑动还是很难区分键帽，并没有明显减小误触概率。我在想这个键帽是不是只是为了营销而设计，没有充分考虑用户体验。
  </content></entry><entry><title>bash 字符串操作</title><url>/posts/cli/bash/bash-%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%93%8D%E4%BD%9C/</url><categories/><tags><tag>linux</tag><tag>bash</tag></tags><content type="html"><![CDATA[  反转字符串将每行内部颠倒用 rev：
$ printf &#39;1234 5678\nABC abc\n&#39; | rev 8765 4321 cba CBA 将不同行颠倒用 tac：
$ printf &#39;1234 5678\nABC abc\n&#39; | tac ABC abc 1234 5678   ]]></content></entry><entry><title>5. 内存模型基础、标准原子类型、自旋锁</title><url>/cpp-concurrency-in-action/5.-%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E6%A0%87%E5%87%86%E5%8E%9F%E5%AD%90%E7%B1%BB%E5%9E%8B%E8%87%AA%E6%97%8B%E9%94%81/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag></tags><content type="html"><![CDATA[  内存模型基础：对象和 内存位置书上给出了 4 点：
每个变量都是对象，包括对象中的成员。 每个对象有至少一个内存位置。 每个基本类型（int / char, &amp;hellip;）刚好占用一个内存位置。 连续位域是同一个内存位置的一部分。 一个标量类型，或者非 0 宽的连续位域构成一个 memory location。
struct S { char a; // memory location #1 int b : 5; // memory location #2 int c : 11, // memory location #2 (continued) : 0, d : 8; // memory location #3 struct { int ee : 8; // memory location #4 } e; } obj; // The object “obj” consists of 4 separate memory locations 可以参考 https://timsong-cpp.github.io/cppwp/n4868/basic.memobj ，这里有讲内存模型、对象模型、生命周期。
Warning
操作同一个内存位置时，就要小心并发安全问题。
标准原子类型头文件 &amp;lt;atomic&amp;gt; 中定义了一些标准的原子类型，包括 std::atomic_flag 和 std::atomic&amp;lt;T&amp;gt;。原子类型都是无法拷贝和移动的。
静态常量成员属性 std::atomic&amp;lt;T&amp;gt;::is_always_lock_free 标志着该原子类型是否始终是无锁的。而成员方法 std::atomic&amp;lt;T&amp;gt;::is_lock_free 返回当前对象是否是无锁的。标准允许一些原子类型在某些条件满足时（sometimes）无锁。GCC7 在 std::atomic&amp;lt;T&amp;gt;::is_always_lock_free 的行为上发生了变化，参见 5.0.1 GCC7 std atomic is_lock_free 的变化。
除了 std::atomic&amp;lt;T&amp;gt; 的静态成员属性之外，还有 ATOMIC_BOOL_LOCK_FREE、ATOMIC_INT_LOCK_FREE 等宏可以用来检查是否 lock-free。因为宏 …  ]]></content></entry><entry><title>联想小新睡眠唤醒后 ctrl 按键一直被按下</title><url>/posts/systems/Windows/%E8%81%94%E6%83%B3%E5%B0%8F%E6%96%B0%E7%9D%A1%E7%9C%A0%E5%94%A4%E9%86%92%E5%90%8E-ctrl-%E6%8C%89%E9%94%AE%E4%B8%80%E7%9B%B4%E8%A2%AB%E6%8C%89%E4%B8%8B/</url><categories/><tags><tag>windows</tag></tags><content type="html">  联想小新睡眠唤醒后 ctrl 按键一直被按下，完全没办法正常使用键盘，打字打不出来，每个字母按键都像是被 ctrl 修饰。按 esc + shift 不能启动任务管理器，但是按 esc + shift + ctrl 能，这很奇怪，又不完全是 ctrl 被按下。我的解决方式一直都是重启电脑，终于忍不住了，今天晚上花了很久去搜索相关资料。
这里有一篇类似问题的博客： https://www.zsbbo.com/bbo/70.html 。
另外在 superuser 上面有相关的问答： https://superuser.com/a/1243900/ 。
Q: Control key acts as if it is stuck periodically
A: Generic fix for this generic issue: (1) press stuck key or Ctrl+Alt+Del, (2) Esc.
从回答中来看，可能是驱动等问题导致 Windows 没能检测到 ctrl 的释放，这种情况多见于笔记本。可以尝试的解决方案包括：
按 ctrl + alt + del 打开安全选项（可以看到一闪而过的“正在准备安全选项”），然后用 esc 退出。打开安全选项理应将键盘复位。 按下左边 ctrl 和右边 ctrl 然后松开。不过我的键盘右边放的是 copilot 按键，没有 ctrl。 同时按下 ctrl + shift + alt + fn 然后松开。 等下次出问题的时候再试试。
2024 年 12 月 7 日：方法 1 有效。
  </content></entry><entry><title>在 Tex Studio 中配置 SumatraPDF 为外部 PDF 预览器</title><url>/posts/latex/%E5%9C%A8-Tex-Studio-%E4%B8%AD%E9%85%8D%E7%BD%AE-SumatraPDF-%E4%B8%BA%E5%A4%96%E9%83%A8-PDF-%E9%A2%84%E8%A7%88%E5%99%A8/</url><categories/><tags><tag>pdf</tag><tag>texstudio</tag></tags><content type="html"><![CDATA[  同时使用正向和反向搜索可以参考： https://tex.stackexchange.com/questions/579313/sumatratexstudio-inverse-search-not-working ，具体是在 Tex Studio 的 External PDF Viewer 填上：
&#34;C:\Program Files\SumatraPDF\SumatraPDF.exe&#34; -reuse-instance -inverse-search &#39;&#34;C:\Program Files\TeXstudio\texstudio.exe&#34; &#34;%%f&#34; -line %%l&#39; -forward-search &#34;?c:am.tex&#34; @ &#34;?am.pdf&#34; 如果 SumatraPDF 已经启动，要关闭之后重新被 Tex Studio 打开才能使用逆向搜索，因为逆向搜索的命令行是写在 SumatraPDF 启动时的命令行参数中的。
如果确定只用 Tex Studio，直接在 SumatraPDF 的选项中指定逆向搜索的命令会更加方便：
&#34;C:/Program Files/texstudio/texstudio.exe&#34; &#34;%f&#34; -line %l 逆向搜索命令来源： https://tex.stackexchange.com/a/587736/ 。
SumatraPDF 官方也有 整合教程，但是上面写的 Tex Studio 的似乎不能正常使用。
  ]]></content></entry><entry><title>获取 ssh 中已知公钥的指纹</title><url>/posts/systems/Linux/%E8%8E%B7%E5%8F%96-ssh-%E4%B8%AD%E6%AF%8F%E4%B8%AA%E5%85%AC%E9%92%A5%E7%9A%84%E6%8C%87%E7%BA%B9/</url><categories/><tags><tag>linux</tag><tag>ssh</tag></tags><content type="html"><![CDATA[  原因服务器上有异常登录现象，通过 /var/log/auth.log 找到了登录记录和公钥的指纹，但是不知道和哪个公钥对应，想要把这个公钥找出来。
步骤参考 https://serverfault.com/questions/291763/is-it-possible-to-get-openssh-to-log-the-public-key-that-was-used-in-authenticat 。
while IFS=$&#39;\n&#39; read key; do ssh-keygen -lf &lt;(echo $key); done &lt; ~/.ssh/authorized_keys 或者
cat ~/.ssh/authorized_keys | while IFS=$&#39;\n&#39; read key; do ssh-keygen -lf &lt;(echo $key); done 这种写法是不行的，会无限循环，而且永远只能读到第一行：
while IFS=$&#39;\n&#39; read key &lt; ~/.ssh/authorized_keys; do ssh-keygen -lf &lt;(echo $key); done   ]]></content></entry><entry><title>如何对齐 PyTorch 的除法运算？</title><url>/posts/programming/python/%E5%A6%82%E4%BD%95%E5%AF%B9%E9%BD%90-PyTorch-%E7%9A%84%E9%99%A4%E6%B3%95%E8%BF%90%E7%AE%97/</url><categories/><tags><tag>torch</tag><tag>python</tag></tags><content type="html"><![CDATA[  过程我遇到的情况是：a 为 64 位浮点数（FP64）标量，b 为 32 位浮点数（FP32）张量，要计算 a / b。
一种做法是：使用 1 / b * a 来代替 a / b。这样的结果看起来和 PyTorch 的计算是对齐的。
奇怪的是，在 aten/src/ATen/native/cuda/BinaryDivTrueKernel.cu 这个代码的判断条件中，只有分母是 CPU 上的标量时，才会将除法转换成乘法运算，而我的遇到的情况是分子是标量，分母是张量，不符合这个条件。代码：
namespace at::native { namespace binary_internal { CONSTEXPR_EXCEPT_WIN_CUDA char div_name[] = &amp;#34;div_kernel&amp;#34;; void div_true_kernel_cuda(TensorIteratorBase&amp;amp; iter) { auto common_dtype = iter.common_dtype(); if (iter.common_dtype() == kComplexHalf) { // 省略 } if (iter.is_cpu_scalar(2)) { // optimization for floating-point types: if the second operand is a CPU // scalar, compute a * reciprocal(b). Note that this may lose one bit of // precision compared to computing the division. AT_DISPATCH_FLOATING_AND_COMPLEX_TYPES_AND2( kHalf, kBFloat16, common_dtype, &amp;#34;div_true_cuda&amp;#34;, [&amp;amp;]() { using opmath_t = at::opmath_type&amp;lt;scalar_t&amp;gt;; auto inv_b = opmath_t(1.0) / iter.scalar_value&amp;lt;opmath_t&amp;gt;(2); iter.remove_operand(2); …  ]]></content></entry><entry><title>用 cv2 或 Pillow 保存 numpy 格式图片</title><url>/posts/programming/python/%E7%94%A8-cv2-%E6%88%96-Pillow-%E4%BF%9D%E5%AD%98-numpy-%E6%A0%BC%E5%BC%8F%E5%9B%BE%E7%89%87/</url><categories/><tags><tag>python</tag><tag>torch</tag><tag>numpy</tag></tags><content type="html"><![CDATA[  img = np.asarray(img) if len(img.shape) == 4: assert img.shape[0] == 1 img = img[0] assert len(img.shape) == 3 and img.shape[0] in (1, 3) img = img.transpose(1, 2, 0) # to channels-last #1 img = img[..., ::-1] # RGB to BGR img = (img * 255.0).astype(np.uint8) img = np.ascontiguousarray(img) assert cv2.imwrite(&#34;fused.jpg&#34;, img) #2 ## https://pytorch.org/vision/main/generated/torchvision.transforms.ToPILImage.html ## img.shape: (C x H x W) if img is torch.Tensor, (H x W x C) if img is np.ndarray. # img = transforms.ToPILImage()(img) # img.save(&#39;fused.jpg&#39;) 要么进行 RGB -&gt; BGR、将 0~1 缩放到 0~255、转换到 np.uint8 类型、将数组转连续等操作，要么直接使用 torchvision 的 transforms 工具。
  ]]></content></entry><entry><title>How to call "friends" properly?</title><url>/posts/programming/cpp/How-to-call-friends-properly/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  开头有一天看到类似这样的代码（隐藏了业务逻辑，对函数签名进行了简化）：
#include &amp;lt;cstdio&amp;gt; struct Foo { friend Foo max(Foo a, Foo b); }; Foo max(Foo a, Foo b) { printf(&amp;#34;friend max\n&amp;#34;); return a; } Foo max(Foo a, Foo b, int x = 0) { printf(&amp;#34;global max\n&amp;#34;); return a; } int main(int argc, char **argv) { Foo a; Foo b; Foo c = max(a, b); // ambiguous } 很明显无法编译：
error: call of overloaded &amp;#39;max(Foo&amp;amp;, Foo&amp;amp;)&amp;#39; is ambiguous 20 | Foo c = max(a, b); // ambiguous | ~~~^~~~~~ Tip
这个 max(Foo, Foo, int) 看起来有点奇怪，但是如果是 max(Foo, Foo, cudaStream_t)，你可能就理解了。没理解也没关系，不影响阅读。
用强制类型转换解决函数名字歧义想要选择第二个重载非常简单，只需要给出第三个参数即可。但是我当时需要选择第一个重载。GPT-4o 建议我完整地给出函数的签名：
#include &amp;lt;cstdio&amp;gt; struct Foo { friend Foo max(Foo a, Foo b); }; Foo max(Foo a, Foo b) { printf(&amp;#34;friend max\n&amp;#34;); return a; } Foo max(Foo a, Foo b, int x = 0) { printf(&amp;#34;global max\n&amp;#34;); return a; } int main(int argc, char **argv) { Foo a; Foo b; Foo c = ((Foo(*)(Foo, Foo))max)(a, b); // prints &amp;#34;friend max&amp;#34; } 很好，这成功了。
What if they are …  ]]></content></entry><entry><title>PyTorch `optimizer.step()` 影响 BatchNorm2d 权重的梯度</title><url>/posts/programming/python/PyTorch-optimizer.step-%E5%BD%B1%E5%93%8D-BatchNorm2d-%E6%9D%83%E9%87%8D%E7%9A%84%E6%A2%AF%E5%BA%A6/</url><categories/><tags><tag>torch</tag><tag>python</tag></tags><content type="html">  我发现 optimizer.step() 这一步会改变 torch.nn.BatchNorm2d 层的 weight 和 bias 的梯度（看上去是每个元素按照相同的比例进行了缩放）。如果想要比较梯度，应该在 optimizer.step() 之前来对比，想要对比更新后的权重，要在 optimizer.step() 之后对比。
这很不应该啊？
版本 2.4.1 + CUDA 11.7（自行构建）上和版本 2.2.2 + CUDA 11.8 上都验证过会出现这种情况。
  </content></entry><entry><title>在 VS Code 中从 C++ 调试 pybind</title><url>/posts/programming/python/%E5%9C%A8-VS-Code-%E4%B8%AD%E4%BB%8E-C++-%E8%B0%83%E8%AF%95-pybind/</url><categories/><tags><tag>vscode</tag><tag>pybind11</tag><tag>python</tag><tag>cpp</tag></tags><content type="html"><![CDATA[  使用 debugpy 调试在被 C++ 调用的 python 文件中加上这样的内容（端口可以随便选）：
import debugpy debugpy.listen(5678) debugpy.wait_for_client() 这样在第一次加载这个 python 模块的时候，这行代码就会暂停等待调试器连接。我们可以创建这样的 Python 调试配置，随后连接正在监听端口的 python 程序。
{ &#34;version&#34;: &#34;0.2.0&#34;, &#34;configurations&#34;: [ { &#34;name&#34;: &#34;Python attach&#34;, &#34;type&#34;: &#34;debugpy&#34;, &#34;request&#34;: &#34;attach&#34;, &#34;connect&#34;: { &#34;host&#34;: &#34;127.0.0.1&#34;, &#34;port&#34;: 5678 } } ] } 如果 C++ 程序的调试器还开着，工作区就会同时存在两个调试器。通过切换调试会话可以对 C++ 和 Python 同时调试。
打印异常信息如果直接运行，pybind 可能会捕获 python 侧的异常信息，给出的错误不明不白。锁定 python 脚本有错的位置之后，可以在代码周围加上 try-except 块，并打印对应的异常到标准输出流，这样就能根据报错信息进一步找到出错点。
  ]]></content></entry><entry><title>PyTorch 注册反向传播的钩子</title><url>/posts/programming/python/PyTorch-%E6%B3%A8%E5%86%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%9A%84%E9%92%A9%E5%AD%90/</url><categories/><tags><tag>torch</tag></tags><content type="html">  注册钩子通过注册钩子，收集模型运行时的输出，可以对每一层的输出值进行调试。
假设模型是 model，我们可以把每一层的输入的梯度和输出的梯度保存在字典中：
module_names = {v: k for k, v in model.named_modules()} grad_inputs = {} grad_outputs = {} def hook(m, grad_input, grad_output) -&amp;gt; Tuple[torch.Tensor] | None: nonlocal module_names, grad_inputs, grad_outputs name = module_names[m] grad_inputs[name] = grad_input grad_outputs[name] = grad_output for m in model.modules(): # 或者在这里遍历 named_modules() 并记录名称和模型的对应关系 m.register_full_backward_hook(hook) 注意 grad_input 的含义是输入的梯度，grad_output 的含义是输出的梯度。假设一个 module 的 forward() 函数负责计算 y = 2 * x，那么 grad_input 相当于 retain_grad() 之后的 x.grad，grad_output 相当于 retain_grad() 之后的 y.grad。
另外还要注意：
我们要遍历每个子模型（torch.nn.Module 对象），按需注册钩子，因为 register_full_backward_hook 本身是不会递归注册的。 钩子的注册要放在模型开始使用之前，不能在循环中反复注册钩子。 其他的观察打印 torch.nn.Module 时，其中的 torch.nn.parameter.Parameter 属性会被打印，torch.nn.Module 属性也会被递归打印出来。所以如果自己编写的模型带有非 nn.Module 的参数，最好存储为 torch.nn.parameter.Parameter 的形式。 torch.nn.Module 的 state_dict() 里的张量应该是 detach 过的，没有梯度。要利用梯度，可以用 named_parameters()。 state_dict() 包含 BatchNormalization 的 running_mean 和 running_var，但是这两个信息不是参数，所以在 named_parameters() 中是没有的。因此比较权重要用 state_dict()，比较梯度要用 named_parameters()。   </content></entry><entry><title>导出和导入 conda 环境</title><url>/00-failed/%E5%A4%B1%E8%B4%A5%E7%9A%84%E5%B0%9D%E8%AF%95%E5%AF%BC%E5%87%BA%E5%92%8C%E5%AF%BC%E5%85%A5-conda-%E7%8E%AF%E5%A2%83/</url><categories/><tags><tag>python</tag><tag>conda</tag></tags><content type="html"><![CDATA[  我在 conda 环境中自行构建了 PyTorch（见 用特定的 CUDA 版本构建 PyTorch 并打包 Conda 环境），所以导出为配置文件、再重新安装的方式行不通。考虑到 Conda 环境本质上是一个文件夹，我尝试将其完整导出。
直接导出整个文件夹导出首先先把环境 clone 一遍，这样就可以直接打包：
conda create -n torch241_build_copy --copy --clone torch241_build 但是因为服务器磁盘非常慢，想到之后还要再打包一次，所以放弃了。改成直接用 tar 进行打包，并且在遇到链接的时候解引用：
tar --zstd -cv --dereference --exclude=&#39;*.pyc&#39; -f torch241_build.tar.zst /opt/miniforge3/envs/torch241_build # 更建议用： # cd /opt/miniforge3/envs/ # tar --zstd -cv --dereference --exclude=&#39;*.pyc&#39; -f /tmp/torch241_build.tar.zst torch241_build --hard-dereference 不需要加，只用 --dereference 就可以。 https://unix.stackexchange.com/questions/43037/dereferencing-hard-links 回答了 tar 的硬链接记录功能：如果 tar 发现了文件有硬链接，会将这个信息记录在 .tar 文件中，解压的时候应该会重新链接起来。 之前没有注意加 --exclude='*.pyc' 这个排除规则，导致打包有很多时间都浪费在了 .pyc 上面。 加了这个规则之后生成 .tar.zst 文件的速度变快了。是因为 .pyc 不好压缩，拖累了 zstd 速度吗？ 导入创建一个同名环境，然后强制删除它（不用 conda 删除）：
mamba create -n torch241_build rm -rf /opt/miniforge3/envs/torch241_build/ 然后创建一个临时文件夹并进入，将之前打包的东西解压到这里来，看看打包的层次结果是什么样的，然后将 torch241_build 这一个文件夹移动到 /opt/miniforge3/envs/ 下。
mv torch241_build/ /opt/miniforge3/envs/ 如果创建的新环境名 A 和打包的文件夹名 B 不同，重命名文件夹为 A 即可。一开始创建的环境名就是最终要使用的环境名。
以上打包方式在后来发现的问题类似于 warning libmamba Extracted package cache '/opt/miniforge3/pkgs/libzlib-1.2.13-h4ab18f5_6' has invalid url 的警告。可能需要用 mamba clean -i 清理一下旧的 cache。 上面打包方式包含了 opt/miniforge3/envs/ 这个前缀，其实最好是进入 envs 之后只对 torch241_build 打包，避免把 opt、miniforges3、env 这些目录也放进去。 opencv 报错：ImportError: libGL.so.1: cannot open shared object file: No such file or directory。尝试 pip install opencv-python-headless 没解决，尝试 mamba -c menpo opencv 也没解决。最后是把它们都卸载了，安装 numpy==2.0.2 然后安装 opencv-python-headless 才解决的。挺奇怪的。 导出到一个绝对路径不同的环境会出现问题，环境中有些配置文件硬编码了路径。我之前是两台服务器间转移数据，使用的环境是基于同一个镜像创建的容器，所以没有问题。 Jupyter Notebook 报错： ImportError: /opt/miniforge3/envs/torch241_build/lib/python3.12/lib-dynload/_sqlite3.cpython-312-x86_64-linux-gnu.so: undefined symbol: sqlite3_deserialize. View Jupyter &lt;a href=&#39;command:jupyter.viewOutput&#39;&gt;log&lt;/a&gt; for further details.&#34;   ]]></content></entry><entry><title>用特定的 CUDA 版本构建 PyTorch</title><url>/posts/programming/python/%E7%94%A8%E7%89%B9%E5%AE%9A%E7%9A%84-CUDA-%E7%89%88%E6%9C%AC%E6%9E%84%E5%BB%BA-PyTorch-%E5%B9%B6%E6%89%93%E5%8C%85-Conda-%E7%8E%AF%E5%A2%83/</url><categories/><tags><tag>torch</tag><tag>cuda</tag><tag>cpp</tag><tag>conda</tag></tags><content type="html">  说明文章是按照我解决问题的过程来写的，不是一个一步式的教程，所以显得有点凌乱。如果要操作请务必先看完全文，以免跟着中间过程走了同样的弯路。如果不想看前面的内容可以直接跳到 conda 打包这一节。
编译和安装 PyTorch（egg 格式）PyTorch 官方只为每个 PyTorch 版本准备了几个可选的 CUDA 版本，如果需要对 PyTorch 使用不同的 CUDA 就需要自己从源码中编译。我们想要用 PyTorch 2.4.1 源码构建支持 CUDA 11.7 的包。
参考官方的说明 https://github.com/pytorch/pytorch#from-source ，过程非常简单，如果下载顺畅，在 32 核服务器上需要近一个小时编译完成。我下载的版本是 v2.4.1。总体流程是先准备好一个 conda 环境，只安装好 python 即可。然后根据说明安装各种东西，最后用 python setup.py install 或者 python setup.py develop 来安装 PyTorch。
Note
如何选择 install 和 develop？
根据 https://stackoverflow.com/a/26588871/ ，develop 会在 site-packages 中创建一个 .egg-link 文件，将包的路径指向工作区，这样就可以通过在工作区修改代码来影响系统中安装的 Python 包。 根据 setuptools/command/install.py，install 会调用命令 bdist_egg，会生成一个 egg 格式的发布包并安装，在 site-packages 对应的 egg 文件夹中确实有源码的一份副本。 注意 .egg 和 .egg-link 有区别！
然后 conda 环境中就会出现 PyTorch，而且用的 CUDA 版本也是系统里面的版本（如果用的镜像基于 NVIDIA 的 CUDA 镜像就肯定没问题），可以用 python -c &amp;amp;quot;import torch; print(torch.version.cuda)&amp;amp;quot; 来验证一下。不过，这时如果下载其他的 pip 包，pip 就会认为 torch 没有被安装，并且帮你去下载一个新的，下载完成之后 CUDA 的版本就变了！
一些想法：
在 …  </content></entry><entry><title>fma 指令</title><url>/posts/programming/cuda/fma-%E6%8C%87%E4%BB%A4/</url><categories/><tags/><content type="html">  今天写 atan 反向传播的 CUDA kernel 发现和 torch 算出来的不一样。核心代码如下：
__global__ void elementwise_atan_backward(float* in, float* din, float* dout, int N) { for (int i = blockIdx.x * blockDim.x + threadIdx.x; i &amp;lt; (N); i += blockDim.x * gridDim.x) { // din[i] = dout[i] / (in[i] * in[i] + 1.f); // // pytorch/tools/autograd/derivatives.yaml // - name: atan(Tensor self) -&amp;gt; Tensor // self: grad / (self * self + 1).conj() // result: auto_element_wise // float square = in[i] * in[i] + 0.f; // disable fma so we can align with torch din[i] = dout[i] / (square + 1.f); } } PyTorch 是用规则文件生成自动梯度求导的，torch.atan 的求导规则为 grad / (self * self + 1).conj()，其中 grad 和 self 都是张量，conj() 在实数张量的场景下是可以不管的。我按照同样的方法写 kernel，发现和 torch 算出来的结果有极小的差异。
上面的代码 我也放在 Compiler Explorer 了，从汇编来看，in[i] * in[i] + 1.f 被优化成了一条指令，这样不仅更快，而且精度更高（从网上的资料来看，nvcc 默认会进行不少优化，fma 就是其中一种）。PyTorch 生成梯度求导规则的方法将乘法和加法放在了两个不同的 kernel 里面，导致编译器无法使用 fma 优化。
我尝试把乘法和加法拆开，但是编译器太聪明了，还是使用了 fma 优化：
float square = in[i] * in[i]; din[i] = dout[i] / (square + 1.f); 最后想到的一种方法是先让编译器用常数 0 完成 fma，防止乘法结果和 1.f 融合。
现代 CPU 和 GPU 基本都支持 fma。其实 fma 函数在 C++ 中也是有的，可以参考 https://en.cppreference.com/w/cpp/numeric/math/fma 。还有一篇看上去比较好的文章 https://momentsingraphics.de/FMA.html 。
  </content></entry><entry><title>添加用户到 docker 组</title><url>/posts/cli/docker/%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7%E5%88%B0-docker-%E7%BB%84/</url><categories/><tags><tag>linux</tag><tag>docker</tag></tags><content type="html">  通过 sudo usermod -aG docker xx 把 xx 加到 docker 组之后，需要先退出当前登录才能生效。
  </content></entry><entry><title>安装 cv2 Python 包</title><url>/posts/programming/python/%E5%AE%89%E8%A3%85-cv2-Python-%E5%8C%85/</url><categories/><tags><tag>python</tag></tags><content type="html">  通过 mamba/conda 安装mamba install -c mempo opencv 通过 pip 安装pip install opencv-python opencv-python-headless 可能需要安装 opencv-contrib-python-headless，但是我这里不安装也成功了。
注意两种安装方式不能混合使用。尤其是在通过 pip 安装 opencv-python 之后，发现不生效，是不能通过 conda 安装 opencv 来补救的。只能继续安装 opencv-python-headless。
  </content></entry><entry><title>在 C++ 项目中使用 Pybind11</title><url>/posts/programming/cpp/%E5%9C%A8-C++-%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%BD%BF%E7%94%A8-Pybind11/</url><categories/><tags><tag>cpp</tag><tag>pybind11</tag><tag>python</tag></tags><content type="html">  安装 pybind11：
pip install &amp;#39;pybind11[global]&amp;#39; # add your executable set(PYTHON_EXECUTABLE /opt/miniforge3/bin/python) find_package(pybind11 REQUIRED) target_link_libraries(your_executable PRIVATE pybind11::pybind11 pybind11::embed) 设置 PYTHON_EXECUTABLE 可以确保 pybind11 使用正确的 python 版本，这样才能在里面找到你安装好的其他的包。
  </content></entry><entry><title>Windows 释放 NAT 服务占用的端口</title><url>/posts/systems/Windows/Windows-%E9%87%8A%E6%94%BE-NAT-%E6%9C%8D%E5%8A%A1%E5%8D%A0%E7%94%A8%E7%9A%84%E7%AB%AF%E5%8F%A3/</url><categories/><tags><tag>windows</tag></tags><content type="html">  释放 NAT 服务占用的端口查看被占用的 TCP 端口，检查自己所用的服务端口是否被包含在结果中：
netsh interface ipv4 show excludedportrange protocol=tcp 重启 winnat 服务来释放大多数端口（需要管理员权限），验证 TCP 端口是否被释放：
net stop winnnat &amp;amp;&amp;amp; net start winnat 设置动态端口号范围看看应用程序的动态端口范围：
netsh int ipv4 show dynamicport tcp 我这里的结果是：
协议 tcp 动态端口范围 --------------------------------- 启动端口 : 1024 端口数 : 13977 接下来按照网上的建议修改 TCP 动态端口范围（需要管理员权限）：
netsh int ipv4 set dynamic tcp start=49152 num=16384 最后再重启一下 winnat。根据 https://github.com/docker/for-win/issues/3171#issuecomment-1895729704 的说法，修改端口号范围之后，Hyper-V 就不会把其他端口预留了。
最后以上只对 ipv4 进行了操作，如果要操作 ipv6 方法是一样的。
参考链接：
https://superuser.com/questions/1579346/many-excludedportranges-how-to-delete-hyper-v-is-disabled https://github.com/docker/for-win/issues/3171#issuecomment-739740248   </content></entry><entry><title>超线程</title><url>/posts/systems/%E8%B6%85%E7%BA%BF%E7%A8%8B/</url><categories/><tags><tag>hardware</tag></tags><content type="html"><![CDATA[  分类我们平时说的超线程可能指同时多线程（SMT），也可能指 Intel 的超线程（HT）。
flowchart TD SMT(&#34;Simultaneous multithreading (SMT)&#34;) HT(&#34;Hyper-threading (HT)&#34;) TMT(&#34;Temporal multithreading, or super-threading&#34;) SMT --&gt;|Intel&#39;s implementation| HT TMT &lt;--&gt;|SMT 同一条流水线能执行来自多个线程的指令，另外一个不能| SMT HT -.-&gt; HT_note(&#34;两个逻辑线程共享包括 TLB 和 cache 等资源，但 CR3 等资源独立&#34;)也存在一个物理核心对应超过 2 个逻辑线程的 SMT 实现，比如 IBM Power8: 12 cores, 8T each, (32 FX + 32 FP) registers per thread，FX 是定点数，FP 是浮点数。
更完整的分类：
We can consider that Super-Threading the same as Temporal multithreading (coarse-grain). I.e. types of multithreading is vary as follows - from shared anything to shared nothing in CPU-core between threads: None (fully software multithreading), TM (fine-grained) in barrel processors, TM (coarse-grained) - Super Threading, SMT - Hyper Threading, CMT (Chip Multithreading) - multicore with shared expensive resource (single FPU on some cores), CMP (Chip Multiprocessors) - multicore with shared Last Level Cache &amp; interconnect.
这段文字来自 https://stackoverflow.com/a/33702200 ，是对 https://ece757.ece.wisc.edu/lect03-cores-multithread.pdf#page=9 这一页幻灯片的提炼。
我的理解：Temporal multithreading（super-threading）也是硬件实现，肯定是比软件实现的单核多线程要快，但是不能像 SMT 那样充分利用 CPU 的资源。CMT 和 CMP 都是指芯片级别的多线程，指的是核心间的合作方式，而其他几个指的是单核的多线程方式。现在的 CPU 用 SMT + CMP 比较常见，未来有去除超线程的趋势。
Hyper-threading逻辑线程不共享的资源：
CR3 register，这是顶级页表寄存器。 通用寄存器，比如 x86 中的 AX, BX, CX, DX。 控制寄存器。 指令标志寄存器，比如 x86 的 EFLAGS。 中断掩码寄存器。 内存管理单元（MMU）寄存器。 状态寄存器 / 标志寄存器 / 条件码寄存器，都是一个意思，比如 x86 的 FLAGS。 是否并非所有寄存器都需要多一份？为何没有文章有“所有寄存器”这个说法？
But essentially, a hyper-threaded core duplicates the minimal amount of state required to make it seem as if there&rsquo;s another full core present (basically the registers). &ndash; https://stackoverflow.com/a/39076156
Hyper-threading works by duplicating certain sections of the processor—those that store the architectural state—but not duplicating the main execution resources. &ndash; https://en.wikipedia.org/wiki/Hyper-threading
参考资料https://en.wikipedia.org/wiki/Simultaneous_multithreading https://en.wikipedia.org/wiki/Temporal_multithreading https://stackoverflow.com/questions/39075942/hyper-threads-sipi-and-registers https://exfly.github.io/experiment-to-understand-how-hyperthreading-works/ 这个博客里面有一个做 nop 和 pause 绑定同一个物理核、不同逻辑核的实验，符合我的“超线程共享同一物理核心上的 IPC 上限”的预期。   ]]></content></entry><entry><title>Hugo 文章摘要</title><url>/posts/unsorted/Hugo-%E6%96%87%E7%AB%A0%E6%91%98%E8%A6%81/</url><categories/><tags><tag>hugo</tag></tags><content type="html"><![CDATA[  说明在我写这个文章摘要代码片段的时候，Hugo 还没有支持按照元素截取，因此 summary 是纯文本、没有格式。
现在 Hugo 已经实现了带格式的截取。目前内置实现和我实现的区别是：内置实现是按照词数截取的，直到词数满足要求就停止添加新的元素，我的实现是按照顶级元素数量截取的（以前用 Hexo 插件有这个功能，因此我实现的也是这个）。
由于 Hugo 没有开放给 html 模板足够的功能，很多数据结构有点大材小用，Hugo 内置实现远远快于用 html 模板的实现。在我电脑上测试是快了好几倍，也就是说这个文章摘要功能拖累了渲染速度。
实现在 themes/hugo-theme-next/layouts/partials/post/body.html 的基础上修改。原本内容类似于：
{{- with .ctx -}} {{- if or (not $.IsHome) .Params.Expand -}} {{ .Content }} {{- else -}} {{ .Summary }} {{ end }} 现在一个字符一个字符地遍历文章，然后找到前 summaryElementCount 个非标题元素截断。配置为：
params: summaryByElement: true summaryByElementStrideMode: true summaryElementCount: 3 summaryDontCountHeadings: true summaryByElement 是这个功能的总开关，summaryElementCount 是要截取元素的数量，summaryDontCountHeadings 表示排除对标题的计数，因为只有标题没有内容不太好看（尤其是在有连续几个大小标题的时候）。
summaryByElementStrideMode 表示是否严格启用按照顶级元素截取，如果不启用的话直接搜索第三个 &amp;lt;/p&amp;gt; 截取即可。但是：
&amp;lt;p&amp;gt; 不一定是顶级元素。 顶级元素不一定是 &amp;lt;p&amp;gt;。 因此截取效果可能会有偏差，导致有些文章很长，有些文章很短。但是这种处理方式非常快，不会感受到渲染变慢。在 Hugo 还没有实现带格式摘要时可以使用这种方式过渡。
Partial 代码为：
{{- with .ctx -}} {{- …  ]]></content></entry><entry><title>4. Synchronizing concurrent operations</title><url>/cpp-concurrency-in-action/4.-Synchronizing-concurrent-operations/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag></tags><content type="html"><![CDATA[  这一章主要讲线程之间的同步和信息传递，包括条件变量（condition variable）、futures、latches/barries。
条件变量头文件是 &amp;lt;condition_variable&amp;gt;。包含 std::condition_variable 和 std::condition_variable_any。前者只能在 std::mutex 上使用，后者可以在所有满足 BasicLockable（lock() + unlock()，不需要 try_lock()）的类型上使用。如果只需要使用 std::mutex，那么就用前者，开销可能会比后者小一点。
Tip
接口只有一处区别：std::condition_variable 可以获取 native handle，而 std::condition_variable_any 不能。
条件变量可以用来协调生产者和消费者之间的关系。
典型操作流程：
先用 std::unique_lock 获得锁。 然后用条件变量来等待锁。这个过程需要一个 pred（用来检查条件是否满足），如果条件已经满足则会直接返回；否则释放锁并陷入休眠，直到自发唤醒（spurious wake）或者被通知（notify）。 使用方法可以参考 https://en.cppreference.com/w/cpp/thread/condition_variable 。
之所以不用 std::lock_guard 是因为条件变量的等待对象必须是可解锁的。而 std::unique_lock 又比直接对 std::mutex 操作安全。
案例：线程安全的队列和第 3 章中线程安全栈一样，书上还是提供了两种重载，一种用传出参数来返回结果，一种返回共享指针。同时，由于队列常常用来协调消费者和生产者之间的关系，因此又有阻塞等待和轮询两个版本。
bool try_pop(T &amp;amp;value); std::shared_ptr&amp;lt;T&amp;gt; try_pop(); // 如果失败就返回空指针 void wait_and_pop(T &amp;amp;value); std::shared_ptr&amp;lt;T&amp;gt; wait_and_pop(); 如果生产者完成了生产，那么可以用 notify_one 来通知一个消费者。如果是一个线程完成初始化操作，其他 …  ]]></content></entry><entry><title>3. Sharing data between threads</title><url>/cpp-concurrency-in-action/3.-Sharing-data-between-threads/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag></tags><content type="html"><![CDATA[  三种避免竞争情况的办法上锁。 无锁编程。通常通过修改数据结构和 invariants（数据结构要保持的约束）来完成。 事务（software transactional memory, STM）。 使用互斥量保护临界区std::lock_guard（可以用 CTAD）和 std::mutex API。C++11 除了 std::mutex 之外还有 std::timed_mutex、std::recursive_mutex、std::recursive_timed_mutex。
不要把受保护数据的引用传出锁的保护范围外，尤其是要注意不要把它的引用传入到来历不明的其他函数中。
案例：实现线程安全的栈（top() 和 pop() 的原子化）接口设计上的问题：栈的 API 中 empty() 和其他方法各自原子是不够的，因为 empty() 的结果在下一个方法运行时不一定还能成立。
我们也可能想把 pop() 和 top() 两个函数结合，将它们合并成一个原子化的功能，但又会遇到异常安全的问题（元素的构造函数抛出异常时，被 pop 的数据会丢失）。
解决方案 1：用输出参数返回结果pop() 不返回值，而是将值存在引用中。这要求用户提前分配好空间，而且在成功将值赋值出去之前，栈可以不用舍弃数据。这保证了失败时栈中的数据不丢失。
std::vector&amp;lt;int&amp;gt; result; some_stack.pop(result); 缺点：用户要提前分配空间、元素类型要支持赋值操作符（很多类可能没有实现）、元素类型要支持默认构造或者能提前知道用来构造元素的参数。
解决方案 2：返回指针返回指针，因为指针的复制是不会导致异常的。Java 就能采用这种方案。
智能指针在行为上和指针非常相似，其中的共享指针在拷贝时也不会抛出异常，所以书上给了一个共享指针的例子。（用 std::unique_ptr&amp;lt;&amp;gt; 不也可以吗？）
std::shared_ptr&amp;lt;T&amp;gt; pop() { std::lock_guard&amp;lt;std::mutex&amp;gt; lock(m); if(data.empty()) throw empty_stack(); std::shared_ptr&amp;lt;T&amp;gt; const …  ]]></content></entry><entry><title>VS Code 终端多重 conda 环境</title><url>/posts/developer/vscode/VS-Code-%E7%BB%88%E7%AB%AF%E5%A4%9A%E9%87%8D-conda-%E7%8E%AF%E5%A2%83/</url><categories/><tags><tag>vscode</tag></tags><content type="html">  准确的说是 conda 环境的提示重复了两次，实际上是同一个环境 env1，但显示出来是 (env1) (env1)。
解决方案：
关闭 python.terminal.activateEnvironment，然后重载工作区，防止自动加载。 或者关闭 conda 的自动激活：conda config --set auto_activate_base false。 我觉得 2 更方便一点，因为 vscode 调试 python 程序还是需要自动激活的。
  </content></entry><entry><title>Docker 升级之后 docker-compose 无法正常启动使用 GPU 的容器</title><url>/posts/cli/docker/Docker-%E5%8D%87%E7%BA%A7%E4%B9%8B%E5%90%8E-docker-compose-%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E5%90%AF%E5%8A%A8%E4%BD%BF%E7%94%A8-GPU-%E7%9A%84%E5%AE%B9%E5%99%A8/</url><categories/><tags><tag>docker</tag></tags><content type="html"><![CDATA[  解决 docker-compose 启动的容器无法使用 GPU最近有人升级了服务器的 docker，我们创建容器有点问题。症状是这样：在命令行用 --gpus all 参数启动的都能正常使用 GPU（可以通过运行 nvidia-smi 命令测试），但是在 docker-compose.yml 文件中指定要使用 GPU 就不行。
之前的 docker-compose.yml 文件是这样：
version: &#34;3.9&#34; services: my-dev: container_name: ${CONTAINER_NAME} image: ${IMAGE} ## -D 表示非 daemon 模式，-e 表示将日志输出到 stderr ## 如果有错误信息，可以用 docker compose logs 看到 command: /usr/sbin/sshd -D -e restart: always volumes: - ./workspace:/workspace - ./data:/data ports: - &#34;${PORT}:22&#34; working_dir: /workspace shm_size: &#39;8gb&#39; pid: &#34;host&#34; security_opt: - seccomp:unconfined cap_add: - SYS_PTRACE deploy: resources: reservations: devices: - capabilities: [gpu] 出错原因是 devices 一栏写的不全面，要加上 count 属性才行。可能以前的 count 默认值是 all，但是现在实测不写就不行。
附上系统环境：
Docker Compose version v2.29.7
Docker:
Client: Docker Engine - Community Version: 27.3.1 API version: 1.47 Go version: go1.22.7 Git commit: ce12230 Built: Fri Sep 20 11:40:59 2024 OS/Arch: linux/amd64 Context: default Server: Docker Engine - Community Engine: Version: 27.3.1 API version: 1.47 (minimum version 1.24) Go version: go1.22.7 Git commit: 41ca978 Built: Fri Sep 20 11:40:59 2024 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.7.22 GitCommit: 7f7fdf5fed64eb6a7caf99b3e12efcf9d60e311c runc: Version: 1.1.14 GitCommit: v1.1.14-0-g2c9f560 docker-init: Version: 0.19.0 GitCommit: de40ad0 系统 Ubuntu 24.04.1 LTS
解决容器时不时丢失 GPU，需要重启容器https://github.com/NVIDIA/nvidia-container-toolkit/issues/48
问题描述：
runc 要求被注入容器的字符设备出现在 /dev/char/ 下，但是 NVIDIA GPU 不会自动这样做。 当且仅当使用 runc，同时用 systemd 来管理 cgroup 时会出现这个 BUG（Docker 守护进程的参数 &quot;exec-opts&quot;: [&quot;native.cgroupdriver=systemd&quot;]）。 类似地，k8s 也受此影响。 在 Docker 中复现：
先重启容器，用 nvidia-smi 看确认 GPU 还在。 然后在宿主机运行 sudo systemctl daemon-reload。 确认容器中的 GPU 已经丢失，nvidia-smi 输出 Failed to initialize NVML: Unknown Error。 （按照链接中给出的这个步骤我成功复现了问题。）
这里提供了三种解决思路：
创建一些符号链接。这个评论 也提到了相同的内容。 在宿主机和容器中都操作过了，但是没有效果，不知道如何才能成功。 需要使用 nvidia-ctk（见 安装文档）。 禁用 cgroups 并重启 docker daemon。 在 /etc/docker/daemon.json 中修改 &quot;exec-opts&quot;: [&quot;native.cgroupdriver=cgroupfs&quot;]。 重启 docker，经测试可以成功。 降级 docker。 2024 年 10 月 26 日：现在其他同学反映使用 native.cgroupdriver=cgroupfs 之后无法启动新的容器？
2024 年 10 月 31 日：恢复了原来的 cgroup driver，并尽可能保证服务器不用 systemctl daemon-reload。知会了所有同学，但是还是隔段时间又有 systemd 重载配置的情况发生。通过 journalctl 发现是 snapd.service 请求了重载，就将 snapd 禁用了。
  ]]></content></entry><entry><title>C++ 结构化绑定过程</title><url>/posts/programming/cpp/C++-%E7%BB%93%E6%9E%84%E5%8C%96%E7%BB%91%E5%AE%9A%E8%BF%87%E7%A8%8B/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  起因同学给出如下代码，指出 std::forward_as_tuple() 的返回值不能被 auto 结构化绑定：
#include &amp;lt;tuple&amp;gt; int main() { auto t1 = std::tuple{0}; auto [a0] = t1; // ok auto t2 = std::forward_as_tuple(0); auto [a1] = t2; // error } 修改代码尝试了几次发现，t2 只是不能被 auto 结构化绑定，可以被 auto &amp;amp; 和 auto &amp;amp;&amp;amp;（万能引用）结构化绑定。查阅资料得知 std::forward_as_tuple() 返回的 std::tuple 的参数类型都是完美转发后的类型，t2 的类型是 std::tuple&amp;lt;int &amp;amp;&amp;amp;&amp;gt; 而不是 std::tuple&amp;lt;int&amp;gt;。
将代码修改如下，果然 t1 也无法被结构化绑定了。
#include &amp;lt;tuple&amp;gt; int main() { - auto t1 = std::tuple{0}; - auto [a0] = t1; // ok + auto t1 = std::tuple&amp;lt;int &amp;amp;&amp;amp;&amp;gt;{0}; // don&amp;#39;t use CTAD + auto [a0] = t1; // error auto t2 = std::forward_as_tuple(0); auto [a1] = t2; // error } 所以说，std::forward_as_tuple() 不应该背这个锅。
std::tuple&amp;lt;T&amp;amp;&amp;amp;&amp;gt; 的复制构造函数被删除了从上面代码编译时的错误来看，结构化绑定在尝试调用 std::tuple 的复制构造函数，但是当有一个模板参数为右值引用类型时，std::tuple 的复制构造函数就会被删除，导致编译失败。
做以下测试：
struct A { int &amp;amp;&amp;amp;x; }; struct B { int &amp;amp;x; }; static_assert(std::is_move_constructible_v&amp;lt;A&amp;gt;); …  ]]></content></entry><entry><title>简易的计时函数</title><url>/posts/programming/cpp/%E7%AE%80%E6%98%93%E7%9A%84%E8%AE%A1%E6%97%B6%E5%87%BD%E6%95%B0/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  template &lt;typename F&gt; void timed_execute(std::string_view tag, F &amp;&amp;f) { auto start = std::chrono::steady_clock::now(); f(); auto end = std::chrono::steady_clock::now(); auto ns = std::chrono::duration_cast&lt;std::chrono::nanoseconds&gt;(end - start).count(); std::printf(&#34;%-20s: &#34;, tag.data()); if (ns &gt;= 1e6) { std::printf(&#34;%.1fms\n&#34;, ns / 1e6); } else if (ns &gt;= 1e3) { std::printf(&#34;%.1fus\n&#34;, ns / 1e3); } else { std::printf(&#34;%zdns\n&#34;, ns); } } 用法：
timed_execute(&#34;reduce&#34;, [&amp;] { auto result = reduce(v.begin(), v.end(), 0); }); 2024 年 10 月 2 日：其实 duration 的 count() 不一定非得是整数。参考 https://en.cppreference.com/w/cpp/chrono/duration ，可以自己定义数据类型为浮点数的 ratio（通用单位，在 std::chrono 中自然就表示时间单位，比如 std::milli 表示 1e-3 这个比例，而 std::chrono::milliseconds 真正表示毫秒这个时间段）。例子：
#include &lt;chrono&gt; #include &lt;iostream&gt; using namespace std::chrono_literals; int main() { using Minute = std::chrono::duration&lt;double, std::ratio&lt;60, 1&gt;&gt;; std::cout &lt;&lt; std::chrono::duration_cast&lt;Minute&gt;(1s).count() &lt;&lt; &#34; minutes\n&#34;; } // 0.0166667 minutes   ]]></content></entry><entry><title>2024-09-16 教程和工具</title><url>/daily/2024-09-16-%E6%95%99%E7%A8%8B%E5%92%8C%E5%B7%A5%E5%85%B7/</url><categories><category>daily</category></categories><tags/><content type="html">  教程https://www.bilibili.com/video/BV1jwHhebE8o/ 【系统设计需要知道的延迟等级】
https://github.com/rasbt/LLMs-from-scratch LLM 原理讲解，虽然印刷和电子书籍是要付费的，但是 ipynb 版本都是免费的
http://www.uinio.com/Linux/Vim/ Vim 速查，作者是嵌入式大牛，博客也很有意思
工具https://github.com/chen08209/FlClash 又一个基于 Clash Core 的 GUI 代理软件
  </content></entry><entry><title>WSL2 中 nvim 的复制粘贴和 Windows 不共享剪贴板</title><url>/posts/systems/Windows/WSL2-%E4%B8%AD-nvim-%E7%9A%84%E5%A4%8D%E5%88%B6%E7%B2%98%E8%B4%B4%E5%92%8C-Windows-%E4%B8%8D%E5%85%B1%E4%BA%AB%E5%89%AA%E8%B4%B4%E6%9D%BF/</url><categories/><tags><tag>wsl</tag><tag>windows</tag></tags><content type="html"><![CDATA[  三个剪贴板Windows 一个，X selection 一个，Wayland 一个。
安装 wl-clipboard 包可以获得 wl-copy 和 wl-paste 工具，它们操作 Wayland 剪贴板。
安装 xclip 可以获得 xclip 工具，xclip 或 xclip -i 类似 wl-copy，完成复制功能，xclip -o 完成粘贴功能。它操作的是 X selection。
现象描述在 Windows 上复制文本，可以写入 Wayland 剪贴板和 Windows 剪贴板，不能写入 X selection。
在 nvim 中选中文本，用 &quot;+y 复制到 &quot;+ 寄存器，可以写入 Wayland 剪贴板，不能写入 Windows 剪贴板和 X selection。
Tip
查看能不能写入 X selection 或者 Wayland 剪贴板可以分别用 xclip -o 和 wl-paste 看看输出。
难道是因为我安装了 wslg，所以 WSL 上默认的剪贴板变成了 Wayland 剪贴板？
解决方案参考 https://stackoverflow.com/a/67229362/ ，先在 Windows 上安装 win32yank.exe（scoop 和 choco 都能安装），然后在 neovim 配置中新增：
let g:clipboard = { \ &#39;name&#39;: &#39;win32yank-wsl&#39;, \ &#39;copy&#39;: { \ &#39;+&#39;: &#39;/path-file/win32yank.exe -i --crlf&#39;, \ &#39;*&#39;: &#39;/path-file/win32yank.exe -i --crlf&#39;, \ }, \ &#39;paste&#39;: { \ &#39;+&#39;: &#39;/path-file/win32yank.exe -o --lf&#39;, \ &#39;*&#39;: &#39;/path-file/win32yank.exe -o --lf&#39;, \ }, \ &#39;cache_enabled&#39;: 0, \ }   ]]></content></entry><entry><title>2. Managing threads</title><url>/cpp-concurrency-in-action/2.-Managing-threads/</url><categories><category>cpp-concurrency-in-action</category></categories><tags><tag>cpp</tag><tag>cpp-concurrency-in-action</tag></tags><content type="html"><![CDATA[  2.2 向线程传递参数向线程传递参数时最好是都复制一份，而且转换成线程启动函数期望的类型。举例：
void foo(std::string) { // ... } std::thread launch_thread() { char buf[1024]; return std::thread{ foo, buf }; } 这里 foo 的参数是 std::string 类型，而 std::thread 在构造时复制的是 char * 类型的参数。等线程创建好，真正开始执行的时候，复制过来的 buf 就可能已经是悬挂引用了。
其他：想要引用可以用 std::ref，想要使用一个对象的成员函数还需要额外传递对象的地址（this 指针）。
案例：并行 accumulate 的实现下面 parallel_accumulate 这个方法使用的是书上的朴素实现，其他测试都是调用标准库。用 Release 模式编译测试，测试在我的笔记本上进行，结果仅供参考。
#include &amp;lt;benchmark/benchmark.h&amp;gt; #include &amp;lt;algorithm&amp;gt; #include &amp;lt;chrono&amp;gt; #include &amp;lt;execution&amp;gt; #include &amp;lt;iterator&amp;gt; #include &amp;lt;numeric&amp;gt; #include &amp;lt;print&amp;gt; #include &amp;lt;random&amp;gt; #include &amp;lt;ranges&amp;gt; #include &amp;lt;thread&amp;gt; #include &amp;lt;vector&amp;gt; template &amp;lt;typename Iterator, typename T&amp;gt; struct accumulate_block { void operator()(Iterator first, Iterator last, T &amp;amp;result) { result = std::accumulate(first, last, result); } }; template &amp;lt;typename Iterator, typename T&amp;gt; T parallel_accumulate(Iterator first, Iterator …  ]]></content></entry><entry><title>同学 Zoom 黑屏掉线</title><url>/posts/systems/Windows/%E5%90%8C%E5%AD%A6-Zoom-%E9%BB%91%E5%B1%8F%E6%8E%89%E7%BA%BF/</url><categories/><tags><tag>proxy</tag><tag>windows</tag></tags><content type="html">  起因同学说 Zoom 卡，影响了他在线考试。我们收集了一些资料后发现 Zoom 有中国服务器，但是只有商业用户可以连接，而免费账户只能连接到美国的服务器。我怀疑是中国到 Zoom 的美国服务器网络线路不好。
我们尝试了下发现挂代理也没用——尽管 Zoom 已经检测到了代理（在统计信息页面）。我同学说他那边丢包，我这边感觉还好，但有时候也有丢包。我担心是 UDP 请求不能被正常代理。
补充：几种代理方式的能力范围HTTP 代理支持 IPv4 和 IPv6，仅能代理 TCP。
从 https://superuser.com/a/302955/ 来看，虽然其主要是代理 HTTP（当然也能代理 HTTPS），但许多 HTTP 代理服务器能够处理 CONNECT 请求（因此实际上支持了裸 TCP 连接），所以 HTTP 代理也能用来代理其他 TCP 协议。
SOCKS4 代理支持 IPv4 的 TCP 请求。
SOCKS5 代理支持 IPv4 和 IPv6，支持 TCP 和 UDP，算是比较全能了。
在 v2rayN 上的设置为了能用代理 UDP 连接，首先修改以下的选项：
代理方式设置为白名单，而且还要点击主界面的检查更新 &amp;amp;gt; Geo files，完成 Geosite 和 Geoip 的更新（这样做是避免没有 Geo files 数据，导致软件不能判断每个请求是否要代理）1。 打开设置中的 UDP 代理。 v2rayN 的默认代理为 http，要选择 socks://{ip}:{socks_port} 才能使用 socks 代理。 在 NatTypeTester 中测试到服务器 stun.syncthing.net 的连接情况，手动填写 socks 代理之后确实能代理 UDP（即看到的公网 IP 是代理服务器的，而不是本地的，可以通过查询公网 IP 的归属地来分辨）。但是不填写就不行，用不了系统代理 2。
查阅资料得知 Windows 上系统代理的 SOCKS 协议是 SOCKS4，不能代理 UDP 3。实际上，使用 SOCKS 代理之后，在 Windows 系统代理服务器设置页面的 ip 位置会显示 http://socks=127.0.0.1 而不是 127.0.0.1，好像也暗示了实际上是 HTTP 代理。不过至少从 NatTypeTester 测试 …  </content></entry><entry><title>Python 临时目录在退出时没有被清理</title><url>/posts/programming/python/Python-%E4%B8%B4%E6%97%B6%E7%9B%AE%E5%BD%95%E5%9C%A8%E9%80%80%E5%87%BA%E6%97%B6%E6%B2%A1%E6%9C%89%E8%A2%AB%E6%B8%85%E7%90%86/</url><categories/><tags><tag>python</tag></tags><content type="html">  我的主要代码是这样：
def main(): with tempfile.TemporaryDirectory() as d: write_tmp_files(d) 即便是程序在终端被 ^C 终止，临时文件夹也会被正常清理，但是我发现 SIGHUP 到来时，临时文件夹就不会被正常清理了。可以注册一个信号处理器函数：
import signal import sys signal.signal(signal.SIGHUP, lambda signum, frame: sys.exit(0)) # 其实应该改成信号值 + 128 这样在 SIGHUP 到来时，临时目录也会被正常清理。
经过更多尝试，我发现 Python 只处理了 SIGINT 这一种情况，对于 SIGQUIT 等信号处理器也都没有处理。在收到 SIGINT 信号时能正常清理资源我猜测是 Python 对 SIGINT 有特殊处理（转换成 KeyboardInterrupt）。
为了在收到信号而终止时正常退出，最好是为每个会杀死程序的信号（除了 SIGKILL）注册信号处理器函数。最常见的信号可能是：
SIGINT：在终端终止程序。 SIGKILL 和 SIGTERM：由用户使用 kill(1) 产生。 SIGHUP：用户关闭了终端。 除了 SIGKILL 实在没办法处理，其他几个处理了也就够了。保险点可以把以上之外的信号处理也注册了。
  </content></entry><entry><title>Docker 的 seccomp 选项</title><url>/posts/cli/docker/Docker-%E7%9A%84-seccomp-%E9%80%89%E9%A1%B9/</url><categories/><tags><tag>docker</tag></tags><content type="html">  https://docs.docker.com/engine/security/seccomp/
seccomp 选项可以控制容器内可以执行的系统调用。可以用 --security-opt seccomp=/path/to/seccomp/profile.json，也可以用 --security-opt seccomp=unconfined 表示不受限。
This feature is available only if Docker has been built with seccomp and the kernel is configured with CONFIG_SECCOMP enabled.
之所以用这个选项，是前段时间有个要跑的服务启动失败了，和其他同类服务比较发现没有加 seccomp 选项。
  </content></entry><entry><title>在 Python 中对文件名按照数值排序</title><url>/posts/programming/python/%E5%9C%A8-Python-%E4%B8%AD%E5%AF%B9%E6%96%87%E4%BB%B6%E5%90%8D%E6%8C%89%E7%85%A7%E6%95%B0%E5%80%BC%E6%8E%92%E5%BA%8F/</url><categories/><tags><tag>python</tag></tags><content type="html"><![CDATA[  对数据集的文件名正确排序有些训练或评估程序要求数据集输入文件的顺序严格有序 1，但是文件名长度又不同，不能简单按照字典序来排序。比如，数据集的标签文件名可能是 0.txt、1.txt……10.txt 等，能想到的一个方法是在前面填充字符 '0'。
lst = os.listdir(directory) lst = sorted(lst, key=lambda s : s.zfill(50)) 如果先去掉后缀名，然后再把前面的字符串转数字，则可能会遇到很多复杂的情况（比如多重后缀名），比不上在前面填充字符简单。
用 zfill 填充好之后，文件名都是这样的：
00000...001.txt 00000...002.txt ... 00000...100.txt 这样直接按照字典序排序就可以了。
其他和填充相关的格式化方法Python 中用来填充的方法还是挺多的，比如 rjust()、ljust()、center() 方法分别是向右对齐、向左对齐、居中对齐，还能自己选择用来对齐的字符（默认是空格）。因此，rjust() 实际上是 zfill() 功能的超集。
Tip
Python 中没有字符类型，只有字符串，所以字符其实是长度为 1 的字符串。
除了这三个函数之外，使用 f-string 也能完成字符串的对齐，比如：
&gt;&gt;&gt; f&#39;{&#34;A&#34;:&lt;16}&#39; &#39;A &#39; &gt;&gt;&gt; f&#39;{&#34;A&#34;:-&lt;16}&#39; &#39;A---------------&#39; &gt;&gt;&gt; f&#39;{&#34;A&#34;:-^16}&#39; &#39;-------A--------&#39; &gt;&gt;&gt; f&#39;{&#34;A&#34;:-&gt;16}&#39; &#39;---------------A 最好避免这一做法。但是很多时候时间仓促，又或者接手的代码就是这样，只能临时修补一下。&#160;&#x21a9;&#xfe0e;
  ]]></content></entry><entry><title>上手 cv2 遇到的一些问题</title><url>/posts/programming/python/%E4%B8%8A%E6%89%8B-cv2-%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98/</url><categories/><tags><tag>python</tag></tags><content type="html">  cv2 的参数输入格式cv2 全部改成了用 numpy.ndarray 作为图像处理格式。只是操作图像的时候：
数据类型必须是 uint8。 形状必须是 (H, W, C) 或者 (H, W)，后者为灰度图。 必须是连续的，必要时得用 np.ascontiguousarray() 转换一下（不然报错会很晦涩）。 如果使用训练模型用的张量转 numpy，一定要记得把批量维度去掉，并且转 channels-last 格式。否则 cv2 不能正常识别图像，并可能报错（报错信息晦涩难懂）。
此外，pillow 库的 Image 默认格式为 RGB，而 cv2 中图像的默认格式为 BGR，需要按需转换。
cv.imwrite()cv2.imwrite() 是将 numpy 数组表示的图像写入到磁盘。
cv2.imencode()cv2.imencode() 函数将 numpy 数组表示的图像编码成字节，尽管形式上还是 numpy 数组，但是应该使用 numpy 的 tobytes() 函数转换成字节，然后以二进制模式打开文件并写入。如果用 cv2.imwrite() 尝试写入这样的图像将报错。
  </content></entry><entry><title>读英伟达博客：CUDA Wrap 级原语</title><url>/posts/programming/cuda/%E8%AF%BB%E8%8B%B1%E4%BC%9F%E8%BE%BE%E5%8D%9A%E5%AE%A2CUDA-Wrap-%E7%BA%A7%E5%8E%9F%E8%AF%AD/</url><categories/><tags><tag>cuda</tag></tags><content type="html"><![CDATA[  原文https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/
笔记Warp 内规约#define FULL_MASK 0xffffffff for (int offset = 16; offset &gt; 0; offset /= 2) val += __shfl_down_sync(FULL_MASK, val, offset); 先在 warp 内用原语规约，比在 block 级别用共享内存规约快很多。（虽然也有 __reduce_add_sync() 函数，但是截至 2024 年 9 月 5 日只支持 unsigned 和 int 类型，给浮点数做规约就要用 __shfl_xx_sync() 系列。）
CUDA 9 的相关 API直接从原博客摘录：
Synchronized data exchange: exchange data between threads in warp. 形式为 __xx_sync(mask, val)。 __all_sync, __any_sync, __uni_sync, __ballot_sync __shfl_sync, __shfl_up_sync, __shfl_down_sync, __shfl_xor_sync __match_any_sync, __match_all_sync Active mask query: returns a 32-bit mask indicating which threads in a warp are active with the current executing thread. __activemask Thread synchronization: synchronize threads in a warp and provide a memory fence. __syncwarp 说明：
__syncwarp() 只保证在运行此函数的时候在 warp 内达成同步，但不保证同步后的下一条语句依然由 warp 内所有的线程参与执行。应该只能用来同步到共享内存的写入和读取？ __xx_sync(mask, val) 不等于 __xx(val) 和 __syncwarp() 的组合。 __balloc_sync(mask, pred) 是从 mask 中找出 pred 非零的、还未退出的线程的集合，返回方式为 32 位掩码。 __match_any_sync(mask, val) 是把 val 相同的分区到一起，返回当前区的 mask。 __match_all_sync(mask, val, pred) 要么返回 mask（mask 里的所有线程都分区到一起），要么返回 0。传出参数 pred 根据是否成功设置成 true 或者 false。 Warp 内同步void __syncwarp(unsigned mask=FULL_MASK); 考虑不使用 __shfl_down_sync()，而是用类似共享内存内累加的方式完成 warp 内的累加。
❌ 错误的 warp 内累加：
unsigned tid = threadIdx.x; // Incorrect use of __syncwarp() shmem[tid] += shmem[tid+16]; __syncwarp(); shmem[tid] += shmem[tid+8]; __syncwarp(); shmem[tid] += shmem[tid+4]; __syncwarp(); shmem[tid] += shmem[tid+2]; __syncwarp(); shmem[tid] += shmem[tid+1]; __syncwarp(); ✔ 正确的 warp 内累加：
unsigned tid = threadIdx.x; int v = 0; v += shmem[tid+16]; __syncwarp(); shmem[tid] = v; __syncwarp(); v += shmem[tid+8]; __syncwarp(); shmem[tid] = v; __syncwarp(); v += shmem[tid+4]; __syncwarp(); shmem[tid] = v; __syncwarp(); v += shmem[tid+2]; __syncwarp(); shmem[tid] = v; __syncwarp(); v += shmem[tid+1]; __syncwarp(); shmem[tid] = v; 2025/3/25 我试了一下用 if (tid &lt; stride) shmem[tid] += shmem[tid+stride]; __syncwarp(); 也是能工作的。这个和 blockreduce 的模式一样，用 if 条件可以保证正在被读的对象不会被写。
机会主义的 warp 级编程原文给了一个把 per-thread 原子加改写成 per-warp 原子加的代码：
// increment the value at ptr by 1 and return the old value __device__ int atomicAggInc(int *ptr) { // group threads by ptr value int mask = __match_any_sync(__activemask(), (unsigned long long)ptr); int leader = __ffs(mask) – 1; // select a leader int res; if(lane_id() == leader) // leader does the update res = atomicAdd(ptr, __popc(mask)); res = __shfl_sync(mask, res, leader); // get leader’s old value // let every thread THINK that they did the atomic op separately return res + __popc(mask &amp; ((1 &lt;&lt; lane_id()) – 1)); //compute old value } 这段代码写的比 读英伟达博客：Warp 聚合原子操作 —— 以过滤为例 考虑得还要周到一点。代码解释可以参考刚刚给出的另外一篇博客。
其他建议文章后面的内容大概意思是建议全部换用新的 __xx_sync() API，不要再用旧的。文章也讲了一下原来的写法中存在的风险。主要原因还是原来的 __xx() API 不接受掩码参数，不会（对指定的线程）显式同步，因此依赖于运行时逐语句的同步执行。但是新的 GPU 上的 warp 调度优化越来越多，按同一个步调执行每条语句这个条件不一定还能满足。
  ]]></content></entry><entry><title>读英伟达博客：Warp 聚合原子操作 —— 以过滤为例</title><url>/posts/programming/cuda/%E8%AF%BB%E8%8B%B1%E4%BC%9F%E8%BE%BE%E5%8D%9A%E5%AE%A2Warp-%E8%81%9A%E5%90%88%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C-%E4%BB%A5%E8%BF%87%E6%BB%A4%E4%B8%BA%E4%BE%8B/</url><categories/><tags><tag>cuda</tag></tags><content type="html"><![CDATA[  原文链接https://developer.nvidia.com/blog/cuda-pro-tip-optimized-filtering-warp-aggregated-atomics/
场景将 src 中大于 0 的数字移动到 dst 中去，并返回新数组的元素数量。和 C++ 的 std::copy_if 相似。
int filter(int *dst, const int *src, int n) { int nres = 0; for (int i = 0; i &amp;lt; n; i++) if (src[i] &amp;gt; 0) dst[nres++] = src[i]; // return the number of elements copied return nres; } 如果用全局内存实现：
__global__ void filter_k(int *dst, int *nres, const int *src, int n) { int i = threadIdx.x + blockIdx.x * blockDim.x; if(i &amp;lt; n &amp;amp;&amp;amp; src[i] &amp;gt; 0) dst[atomicAdd(nres, 1)] = src[i]; } 每个参与的进程用 atomicAdd() 占位得到自己的坐标（atomicAdd() 返回原子操作之前的旧值），然后将结果写进去。缺点是全局内存上原子操作开销大，尤其是在竞争激烈的时候。
用共享内存实现略。在原文写了一块代码，代码不仅复杂，效果也仅仅比全局内存好了一点点（都很差）。
Warp-aggregated Atomics主要流程如下，和全局内存上的实现很像，只是 atomicAdd() 改成了 atomicAggInc()：
__global__ void filter_k(int *dst, const int *src, int n) { int i = threadIdx.x + blockIdx.x * blockDim.x; if(i &amp;gt;= n) return; if(src[i] &amp;gt; 0) dst[atomicAggInc(nres)] = src[i]; } 重点是怎么把 atomicAggInc() 写的快一点：
__activemask()  …  ]]></content></entry><entry><title>Linux Mint 22 虚拟机安装 CUDA Toolkit</title><url>/posts/programming/cuda/Linux-Mint-22-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AE%89%E8%A3%85-CUDA-Toolkit/</url><categories/><tags><tag>linux</tag></tags><content type="html"><![CDATA[  本机没有 NVIDIA GPU，只是无聊想要试试能不能在没有 GPU 的机器（宿主机没 GPU）上做编译工作。
按照 官网链接，选择 Ubuntu 即可。cuda-repo-ubuntu2404-12-6-local_12.6.1-560.35.03-1_amd64.deb 这个文件占了 3.2G，安装之后就更大了。
安装完成之后，可以在 /usr/local/cuda-12.6/bin/ 中找到 nvcc。加到 PATH 之后，编译都能正常进行，但是因为没有 GPU，运行时 CUDA 相关的 API 都会报错，仅此而已。
#include &lt;iostream&gt; // https://leimao.github.io/blog/Proper-CUDA-Error-Checking/ #define CHECK_CUDA_ERROR(val) check((val), #val, __FILE__, __LINE__) void check(cudaError_t err, const char* const func, const char* const file, const int line) { if (err != cudaSuccess) { std::cerr &lt;&lt; &#34;CUDA Runtime Error at: &#34; &lt;&lt; file &lt;&lt; &#34;:&#34; &lt;&lt; line &lt;&lt; std::endl; std::cerr &lt;&lt; cudaGetErrorString(err) &lt;&lt; &#34; &#34; &lt;&lt; func &lt;&lt; std::endl; // We don&#39;t exit when we encounter CUDA errors in this example. // std::exit(EXIT_FAILURE); } } #define CHECK_LAST_CUDA_ERROR() checkLast(__FILE__, __LINE__) void checkLast(const char* const file, const int line) { cudaError_t const err{cudaGetLastError()}; if (err != cudaSuccess) { std::cerr &lt;&lt; &#34;CUDA Runtime Error at: &#34; &lt;&lt; file &lt;&lt; &#34;:&#34; &lt;&lt; line &lt;&lt; std::endl; std::cerr &lt;&lt; cudaGetErrorString(err) &lt;&lt; std::endl; // We don&#39;t exit when we encounter CUDA errors in this example. // std::exit(EXIT_FAILURE); } } __global__ void calc(int n, float *x, float *y) { for (int i = 0; i &lt; n; ++i) { *x += *y; } } int main() { constexpr int n = 10; float *x, *y; CHECK_CUDA_ERROR(cudaMalloc(&amp;x, n * sizeof(float))); CHECK_CUDA_ERROR(cudaMalloc(&amp;y, n * sizeof(float))); // 懒得初始化了 calc&lt;&lt;&lt;1, 1&gt;&gt;&gt;(n, x, y); CHECK_LAST_CUDA_ERROR(); CHECK_CUDA_ERROR(cudaFree(x)); CHECK_CUDA_ERROR(cudaFree(y)); } 输出：
CUDA Runtime Error at: main.cu:42 CUDA driver version is insufficient for CUDA runtime version cudaMalloc(&amp;x, n * sizeof(float)) CUDA Runtime Error at: main.cu:43 CUDA driver version is insufficient for CUDA runtime version cudaMalloc(&amp;y, n * sizeof(float)) CUDA Runtime Error at: main.cu:45 CUDA driver version is insufficient for CUDA runtime version CUDA Runtime Error at: main.cu:46 CUDA driver version is insufficient for CUDA runtime version cudaFree(x) CUDA Runtime Error at: main.cu:47 CUDA driver version is insufficient for CUDA runtime version cudaFree(y)   ]]></content></entry><entry><title>64 伪终端</title><url>/the-linux-programming-interface/64-%E4%BC%AA%E7%BB%88%E7%AB%AF/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  基本认识伪终端解决这样的问题：远程登录等场合，用户并不能和真正的终端进行交互，而且信息也不能简单通过 socket 转发，因为很多（面向终端的）应用程序是假设了有控制终端的。应用了伪终端的程序包括：script(1)（能录制本次交互程序的全部用户输入和用户能看到的输出）、screen(1)、expect(1)（在 一个可以用来测试某交互程序的是否如期运行的工具，在 Debian 上需要额外安装）、xterm 等终端模拟器。
伪终端很像一个双向管道。主设备写入、从设备可以读；从设备写入、主设备可以读。在从设备侧，伪终端表现得就和真实终端一样：所有在终端上能使用的系统调用在伪终端上都不会报错，对伪终端无意义的设置也会被忽略。因此，驱动程序（接收用户输入）面向主设备，应用程序面向从设备（它们对自己使用的是真实终端还是伪终端可能并不知情）。
System V (UNIX 98) 伪终端posix_openpt() 函数可以打开一个未使用的伪终端主设备，返回其 fd。 grantpt() 可用于修改对应的从设备的属组和权限。 unlockpt() 用于解锁从设备，这样从设备就能被打开了（这是为了应对竟态条件）。 ptsname() 函数返回主设备对应的从设备名称。 posix_openpt() 的 O_NOCTTY 标志可以使得伪终端主设备不成为当前进程的控制终端，在 Linux 上是默认启用的；O_RDWR 标志以读写方式打开，一般开发者都会指定此标志。最初 System V 终端实现中，获取主设备是通过打开伪终端主克隆设备 /dev/ptmx 实现的。也就是说，posix_openpt() 完全可以被实现为：
int posix_openpt(int flags) { return open(&amp;amp;#34;/dev/ptmx&amp;amp;#34;, flags); } 对伪终端数量在 /proc/sys/kernel/pty/max 中可查（我系统里面是 4096），还有一个文件 /proc/sys/kernel/pty/nr 用来记录当前有多少伪终端设备被打开。每次打开一个新的伪终端，在 /dev/pts/ 文件夹下就会多一个以数字命名的伪终端从设备，而 /proc/sys/kernel/pty/nr 的计数会 +1。
grantpt() …  </content></entry><entry><title>bash 等待特定进程结束</title><url>/posts/cli/bash/bash-%E7%AD%89%E5%BE%85%E7%89%B9%E5%AE%9A%E8%BF%9B%E7%A8%8B%E7%BB%93%E6%9D%9F/</url><categories/><tags><tag>bash</tag></tags><content type="html">  这是我写的某个测试的脚本：
B 需要等待 A 程序先运行起来之后才能启动。 A 退出之后，应该中止 B。 代码能保证 B 不会在 A 之前中止。 #!/bin/bash ./build/test/A -n 5000 &amp;amp; PROC_A=$! sleep 3 python test/B.py &amp;amp; PROC_B=$! tail --pid=$PROC_A -f /dev/null kill $PROC_B tail --pid=$PROC_A -f /dev/null 这一句是等待特定进程结束的关键。参考 https://stackoverflow.com/questions/1058047/wait-for-a-process-to-finish 。
（不过，这个脚本还有一个问题，当脚本收到 ^C 中止时，如果 shell 还在，那么两个进程会因为是后台进程而无法收到中止信号。这下大家都知道我写的测试很垃圾了＞﹏＜。）
  </content></entry><entry><title>保存被终端转义后的文本</title><url>/posts/systems/Linux/Linux-%E4%BF%9D%E5%AD%98%E8%A2%AB%E7%BB%88%E7%AB%AF%E8%BD%AC%E4%B9%89%E5%90%8E%E7%9A%84%E6%96%87%E6%9C%AC/</url><categories/><tags><tag>linux</tag><tag>bash</tag></tags><content type="html">  问题起因我的某个程序会自己打印 \r 和 \b 字符以在终端上起到提示效果，但是如果将内容重定向到文件，那么显示出来效果就不好。在很多阅读器中特殊字符不能被正确显示，在 VS Code 中 \r 会换行，而 \b 也不会真正起到删除的作用。
方法 1：cat 或者 less -r假设现在文件 A.log 中包含了大量 \r 和 \b，想要阅读它可以直接将其 cat 到终端，或者使用 less -r A.log 来阅读。用 less -r 是比较推荐的，因为还能用 / 查找、用 &amp;amp; 过滤。
方法 2：col如果想要真正保存一份和我们在终端看上去一样的文件，可以使用：
col -b &amp;lt; A.log &amp;gt; A1.log 这样 A1.log 中保存的文本就和我们在终端看上去的一样。不过，col 输出的结果看起来和终端里面还是有一点差异，比如 backspace 后面接一个 space 就没有把该覆盖的东西覆盖，只会把光标向前移动一格！
失败的尝试：
尝试先把空格都替换成 col 手册中没有的特殊字符，然后用 col 处理完成之后再替换回来：特殊字符可能被舍弃或者没有正常处理，在 col 处理完成之后还原不了。 尝试把空格替换成文中没有出现过的字符串：每一行末尾的可能会残留字符串，因为 col 在解释 \b 的时候只后退一个字节，并不知道某个字符串是原先的空格。 其他：
col 默认缓冲 128 行，用 stdbuf 来调整是没用的，要用 -l 选项。 ANSI 颜色转义还得再处理。   </content></entry><entry><title>63.1 验证单个进程能使用的最大文件描述符个数</title><url>/the-linux-programming-interface/63.1-%E9%AA%8C%E8%AF%81%E5%8D%95%E4%B8%AA%E8%BF%9B%E7%A8%8B%E8%83%BD%E4%BD%BF%E7%94%A8%E7%9A%84%E6%9C%80%E5%A4%A7%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6%E4%B8%AA%E6%95%B0/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  实验设计以下实验都是在 wsl 中进行的。
$ cat /proc/sys/fs/file-max # 整个系统中能使用的最大文件描述数量 9223372036854775807 $ cat /proc/sys/fs/nr_open # 单个进程中能使用的最大文件描述符个数 1048576 编译运行以下测试代码（不要用 Release 模式、不要增加 -DNDEBUG；这份代码还假设了 0、1、2 号文件描述符已经被打开）：
#include &amp;lt;cassert&amp;gt; #include &amp;lt;cerrno&amp;gt; #include &amp;lt;cstdio&amp;gt; #include &amp;lt;cstdlib&amp;gt; #include &amp;lt;fcntl.h&amp;gt; #include &amp;lt;sys/resource.h&amp;gt; #include &amp;lt;unordered_set&amp;gt; #include &amp;lt;vector&amp;gt; int main() { // check rlimit int ret; struct rlimit rlimit_res; if ((ret = getrlimit(RLIMIT_NOFILE, &amp;amp;rlimit_res)) == -1) { perror(&amp;#34;getrlimit&amp;#34;); exit(EXIT_FAILURE); } printf(&amp;#34;soft limit of fd count: %lu\n&amp;#34;, (unsigned long)rlimit_res.rlim_cur); printf(&amp;#34;hard limit of fd count: %lu\n&amp;#34;, (unsigned long)rlimit_res.rlim_max); // try to open as many files as we can std::vector&amp;lt;int&amp;gt; opened_files{0, 1, 2}; while (true) { int fd = open(&amp;#34;/dev/zero&amp;#34;, O_RDONLY); if (fd == -1) { if (errno == EMFILE) { break; } else { perror(&amp;#34;open&amp;#34;); …  ]]></content></entry><entry><title>bash 搜索内置命令的帮助信息</title><url>/posts/cli/bash/bash-%E6%90%9C%E7%B4%A2%E5%86%85%E7%BD%AE%E5%91%BD%E4%BB%A4%E7%9A%84%E5%B8%AE%E5%8A%A9%E4%BF%A1%E6%81%AF/</url><categories/><tags><tag>bash</tag></tags><content type="html">  想要搜索 bash 内置命令的帮助信息，但是发现找不到，比如 man ulimit 没有对应的页面，怎么办呢？
其实和 bash 内置命令相关的帮助信息就在 bash 的 man 手册当中，可以用 man bash 来查看。然后在弹出的 less 阅读器中，搜索 SHELL BUILTIN COMMANDS 就能找到这一栏了（用小写就能搜索）。
  </content></entry><entry><title>62 终端</title><url>/the-linux-programming-interface/62-%E7%BB%88%E7%AB%AF/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  整体概览终端可以分成两种工作模式：1. 规范模式（输入按照行来处理）；2. 非规范模式，比如 vim、less 等程序中。
终端驱动程序的作用是：操作两个队列，一个用于从终端设备把输入字符传送到读取进程上，另外一个用于将输出字符从进程传输到终端上。如果开启了终端回显功能，那么终端输入队列上面的新字符也会自动被追加到输出队列的尾部。终端驱动程序还能识别终端输入中的特殊字符，并根据字符含义做出相应的行为（比如 ctrl + d 和 ctrl + c）。
如果进程想要知道终端上面有多少没有读取的内容（假设终端的是其标准输入），在 Linux 上面可以使用 ioctl(fd, FIONREAD, &amp;amp;amp;cnt)。这个特性在 SUS 中没有规定。
获取和修改终端属性可以用 tcgetattr(2) 和 tcsetattr(2) 操作终端属性。这只能由前台进程调用，如果是后台进程，会因为没有控制终端而收到终端驱动程序发来的 SIGTTOU 信号。
stty 命令stty 命令能够在命令行上查看和修改终端属性，相当于是提供了 tcgetattr(2) 和 tcsetattr(2) 的功能。
Tip
还有一个 tty 命令，它能够打印和标准输入流相连接的终端的名称。比如
$ tty /dev/pts/6 查看终端属性使用 stty -a 可以查看终端当前的属性。
stty 只能读取标准输入的终端信息。如果想要查看其他终端的信息，可以使用 stty -a &amp;amp;lt; /dev/tty3。在 Linux 上面有个扩展，可以使用 -F（fetch）选项来读取其他终端的信息，比如 stty -a -F /dev/tty3。
修改终端特殊字符映射可以使用 stty intr ^L 将中止操作按键从 ^C 改成 ^L。指定字符可以使用以下方法之一：
^X 这样的 ^ 加上一个字符。 用 8 进制或者 16 进制数字表示。 直接输入字符本身。在这种方式下要先输入 literal next 字符（一般是 ctrl + v），然后输入对应的字符（比如 ctrl + l）。 还可以将非控制字符修改成终端的特殊字符，比如一个字母按键。但是这样的操作不常见。
修改终端标志stty tostop # 添加 TOSTOP 标志 stty -tostop # 去除 TOSTOP …  </content></entry><entry><title>63 其他 I/O 模型</title><url>/the-linux-programming-interface/63-%E5%85%B6%E4%BB%96-IO-%E6%A8%A1%E5%9E%8B/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  概览I/O 多路复用，select() 和 poll()，检查大量文件描述符时性能不好 信号驱动 I/O Linux 特有的 epoll() POSIX 异步 I/O（AIO），在本书不讲（应该也不是一种通知模型） Tip
Libevent 库为包括 select()、poll()、epoll()、信号驱动 I/O、Solaris 专有的 /dev/poll 和 BSD 专有的 kqueue 接口在内的很多 I/O 方式提供了抽象层。
通知文件描述符就绪的两种方式是水平触发和边缘触发。
水平触发：文件描述符上可以非阻塞执行 I/O 调用，则认为已经就绪。select() / poll() 和 epoll() 可以支持水平触发模型。 边缘触发：文件描述符自上次检查以来有了新的 I/O 活动，则认为需要通知。信号驱动 I/O 和 epoll() 可以支持水平触发模型。 书上还提到边缘触发时一般需要尽可能读取完所有字节，以免很长时间没有接收到下一次通知。比如：在循环中每次检查是否有数据可以读，如果有，则最多读取 1024 个字节，然后进入下一个循环，这样的操作就只能在水平触发模型上正常工作。这是因为只要状态没有改变，边缘触发模式下的通知系统就不会再次发送通知，如果只最多读取 1024 个字节，后面即便有数据没有读取完成，也不会有新的通知了。
本章讲的 I/O 通知模型都要和非阻塞的 I/O 结合使用。
I/O 多路复用select()select() 最早出现于 BSD 中，历史上的应用更加广泛。（poll 出现在 System V 中。）
SYNOPSIS #include &amp;amp;lt;sys/select.h&amp;amp;gt; typedef /* ... */ fd_set; int select(int nfds, fd_set *_Nullable restrict readfds, fd_set *_Nullable restrict writefds, fd_set *_Nullable restrict exceptfds, struct timeval *_Nullable restrict timeout); 参数其中 exceptfds 是指要监控哪些 fd 的异常状态。这里的异常状态指：
连接到处于信包模式下的伪终端主设备上的从设备状态发生了改变。 流式 …  </content></entry><entry><title>连续运行程序观察 pid 的变化</title><url>/posts/systems/Linux/%E8%BF%9E%E7%BB%AD%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F%E8%A7%82%E5%AF%9F-pid-%E7%9A%84%E5%8F%98%E5%8C%96/</url><categories/><tags><tag>linux</tag></tags><content type="html"><![CDATA[  我的测试环境是 wsl，系统是空载的。理想的情况是两次程序的 pid 连续：
$ grep -i &#39;^pid:&#39; /proc/self/status Pid: 3355 $ grep -i &#39;^pid:&#39; /proc/self/status Pid: 3356 但实际上我发现我每次回车（不运行 grep）都会导致 Pid +7，运行 grep 时会 +8（合理，毕竟 grep 本身也是一个进程）。
我以前以为是 bash 在创建子进程的时候会多运行一些东西，所以每次创建的子进程 Pid 不连续。现在发现回车都会导致 Pid 增长，才发现是 PS1 变量的问题。我的 PS1 变量包含了一些代码，用来让 prompt 更加美观。
用以下方式修改 PS1：
PS1=&#39;$ &#39; 现在果然 pid 就是连续了。
  ]]></content></entry><entry><title>61 Socket：高级主题</title><url>/the-linux-programming-interface/61-Socket%E9%AB%98%E7%BA%A7%E4%B8%BB%E9%A2%98/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  部分读和部分写套接字上面可能发生部分读和部分写，书中提供了 writen() 和 readn() 函数来保证读写完数据，接口和 write() / read() 一样，可以借鉴一下这种思路。
shutdown() 函数可以指定关闭 socket 的读 / 写 / 读写。如果不用 shutdown()，打开的 socket（文件描述）只会在所有指向它的文件描述符都关闭了之后才会被关闭。
SHUT_RD：关闭读端。在 UNIX 域流套接字上面执行了这个操作之后，对端应用程序写入会受到 SIGPIPE 信号（或者 EPIPE 错误，如果屏蔽或处理了这个信号）。对于 TCP 套接字，关闭读端没有意义。 SHUT_WR：关闭写端。读端能继续读，读完之后能看到 EOF，写端不能再写（SIGPIPE 和 EPIPE）。 SHUT_RDWR：相当于先执行 SHUT_RD 再执行 SHUT_WR。 recv() 和 send()接口相比 read() 和 write() 多了一个 flags 参数，能在 socket 操作上面对本次读写实现更多的功能控制。
sendfile()sendfile() 能将文件（fd）的指定范围（offset 和 count）的数据直接发送到套接字中。与先读数据后写入相比，这样的操作不需要经过用户缓冲区，能直接在内核缓冲区完成传输。
#include &amp;amp;lt;sys/sendfile.h&amp;amp;gt; ssize_t sendfile(int out_fd, int in_fd, off_t *_Nullable offset, size_t count); 写入的文件描述符 out_fd 必须是套接字，读取的文件 in_fd 必须是可以用 mmap() 操作的（一般是普通文件）。
在 Linux 2.6.33 之后，out_fd 不再必须是一个 socket，可以是任何文件。在 Linux 5.1.2 之后，如果 out_fd 是一个 pipe，那么 sendfile() 就等同 splice(2)，受到它的规则限制。
Tip
在 2.6.16 版本之后，Linux 提供了 splice()、vmsplice()、tee() 系统调用。这些函数的功能比 sendfile() 要多。
Linux 4.5 …  </content></entry><entry><title>yt-dlp 下载 YouTube 视频</title><url>/posts/cli/yt-dlp-%E4%B8%8B%E8%BD%BD-YouTube-%E8%A7%86%E9%A2%91/</url><categories/><tags/><content type="html">  下载前使用 -F 选项来查看视频格式：
yt-dlp -F https://www.youtube.com/watch?v=lNPZV9Iqo3U 下载选定格式的视频（yt-dlp 给 YouTube 视频选的默认格式通常很模糊，但是因为同时包含音频和视频，所以就成了默认）：
yt-dlp -N 4 -f 137+139 https://www.youtube.com/watch?v=lNPZV9Iqo3U -N 4 表示分成 4 块下载，默认是 1 块。-f 表示格式，如果安装了 ffmpeg，可以选择多个格式，这些格式会被合并到一个视频中（audio only 和 video only 的格式的合并）。
  </content></entry><entry><title>libstdc++ 中 std::shared_ptr 的内存开销</title><url>/posts/programming/cpp/libstdc++-%E4%B8%AD-shared_ptr-%E7%9A%84%E5%86%85%E5%AD%98%E5%BC%80%E9%94%80/</url><categories/><tags><tag>cpp</tag><tag>libstdcxx</tag></tags><content type="html"><![CDATA[  std::shared_ptr&lt;T&gt; 的内存开销std::shared_ptr&lt;T&gt; element_type* _M_ptr; // Contained pointer. sizeof(intptr_t) 字节 __shared_count&lt;_Lp&gt; _M_refcount; // Reference counter. sizeof(intptr_t) 字节 _Sp_counted_base&lt;_Lp&gt;* _M_pi; std::_Sp_counted_base&lt;__default_lock_policy&gt; // vtable pointer // sizeof(intptr_t) 字节 _Atomic_word _M_use_count; // #shared 4 字节，实际上是 int 类型 _Atomic_word _M_weak_count; // #weak + (#shared != 0) 4 字节 其中，记录 use count 是为了判断什么时候可以释放共享指针指向的对象；记录 weak count 是为了判断什么时候可以安全释放控制块本身。即便是共享指针指向对象已经被释放（use count 归零），也可能有弱指针会尝试转换成共享指针，因此应该保证这些弱指针能安全查询控制块。还有一点，如果用 std::make_shared 创建共享指针，use count 归零而 weak count 不归零时，共享对象只是被析构，其内存会等到 weak count 归零时一起被释放。可以参考 https://stackoverflow.com/a/49585948/ 。
在 64 位环境下，一个 std::shared_ptr&lt;T&gt; 是 16 字节（8 + 8），其中控制块的真实大小是 16 字节（4 + 4 + 8）。（在 std::shared_ptr&lt;T&gt; 中存储的是指向控制块的指针、而不是控制块本身，这样才能保证使用相同的控制块。）
std::_Sp_counted_base&lt;_Lp&gt; 的大小不过，std::_Sp_counted_base 还支持其他的上锁策略，从 /usr/include/c++/12/bits/shared_ptr_base.h 的以下代码可以看出一共有 4 种可选的上锁类型。
using __gnu_cxx::_Lock_policy; using __gnu_cxx::__default_lock_policy; using __gnu_cxx::_S_single; using __gnu_cxx::_S_mutex; using __gnu_cxx::_S_atomic; 其中 __gnu_cxx::_S_mutex 会导致 std::_Sp_counted_base&lt;_Lp&gt; 继承的基类 _Mutex_base&lt;_Lp&gt; 从 0 字节（空基类优化）变成 40 字节（在 64 位环境下），此时 std::_Sp_counted_base&lt;__gnu_cxx::_S_mutex&gt; 为 56 字节。这种类型会在两个用来计数的变量（_M_use_count 和 _M_weak_count）不能使用原子操作时被启用：此时这两个计数变量就只负责计数，同步用 mutex 来保证。在 x86 上 int 类型是可以支持原子操作的，所以默认模式不是 __gnu_cxx::_S_mutex。
// Empty helper class except when the template argument is _S_mutex. template&lt;_Lock_policy _Lp&gt; class _Mutex_base { protected: // The atomic policy uses fully-fenced builtins, single doesn&#39;t care. enum { _S_need_barriers = 0 }; }; template&lt;&gt; class _Mutex_base&lt;_S_mutex&gt; : public __gnu_cxx::__mutex { protected: // This policy is used when atomic builtins are not available. // The replacement atomic operations might not have the necessary // memory barriers. enum { _S_need_barriers = 1 }; }; 在支持整数原子操作的平台，标题中的类型的大小为 4 + 4 + sizeof(intptr_t) /* vptr */；在不支持整数原子操作的平台，此大小为 4 + 4 + sizeof(intptr_t) + sizeof(std::mutex)。
  ]]></content></entry><entry><title>查找 malloc 和 free 是否配对</title><url>/posts/cli/bash/bash-%E6%9F%A5%E6%89%BE-malloc-%E5%92%8C-free-%E6%98%AF%E5%90%A6%E9%85%8D%E5%AF%B9/</url><categories/><tags><tag>awk</tag><tag>cpp</tag><tag>bash</tag></tags><content type="html"><![CDATA[  说明因为项目有老代码所以才需要这样处理，一般建议用 RAII 等技术避免裸露资源。
find_malloc.sh要点：
用 gcc 去除代码注释。 用 awk 对正则表达式计数。 check() { gcc -fpreprocessed -dD -E -P &#34;$1&#34; 2&gt;/dev/null | awk -v file=&#34;$1&#34; &#39; BEGIN { malloc=0; free=0; queueCreate=0; queueDestroy=0; notifierCreate=0; notifierDestroy=0; handleCreate=0; handleDestroy=0; } /cnrtMalloc\(/ { malloc++; } /cnrtFree\(/ { free++; } /cnrtQueueCreate\(/ { queueCreate++; } /cnrtCreateQueue\(/ { queueCreate++; } /cnrtDestroyQueue\(/ { queueDestroy++; } /cnrtQueueDestroy\(/ { queueDestroy++; } /cnrtCreateNotifier\(/ { notifierCreate++; } /cnrtDestroyNotifier\(/ { notifierDestroy++; } /cnnlCreate\(/ { handleCreate++; } /cnnlDestroy\(/ { handleDestroy++; } END { if (malloc != free) { print &#34;file: &#34; file &#34;, malloc: &#34; malloc &#34;, free: &#34; free } if (queueCreate != queueDestroy) { print &#34;file: &#34; file &#34;, queueCreate: &#34; queueCreate &#34;, queueDestroy: &#34; queueDestroy } if (notifierCreate != notifierDestroy) { print &#34;file: &#34; file &#34;, notifierCreate: &#34; notifierCreate &#34;, notifierDestroy: &#34; notifierDestroy } if (handleCreate != handleDestroy) { print &#34;file: &#34; file &#34;, handleCreate: &#34; handleCreate &#34;, handleDestroy: &#34; handleDestroy } }&#39; } check $1 find_malloc_all.sh要点：使用 find 匹配时应该选择正则表达式类型，同时和 Python 的 re 模块一样要全字符串匹配（不能匹配只部分字符，因此想只匹配中间部分的时候，就要在两边加上 .*）。
find src/ include/ -regextype egrep -regex &#39;.*\.(h|hpp|cc|cpp)&#39; -exec bash find_malloc.sh {} \;   ]]></content></entry><entry><title>60 Socket 服务器设计</title><url>/the-linux-programming-interface/60-Socket-%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%BE%E8%AE%A1/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  迭代型服务器和并发型服务器迭代型服务器每次只处理一个客户端，在处理客户端请求时无法响应其他客户端；并发型服务器每次接受新的请求后，就会创建新的线程或者进程去专门处理这个请求。
inetd（Internet 超级服务器）守护进程/etc/services 下列举着大量服务，但是每个服务器只是偶尔运行。inetd 进程通过监听一组 socket 端口并按需启动对应的服务来节省系统开销。因此 inetd 又被叫做 Internet 超级服务器。守护进程 inetd 的行为由配置文件 /etc/inetd.conf 控制（在我的 WSL（Debian）上面没有安装 inetutils-inetd，所以没有这个配置文件）。修改配置文件之后，向 inetd 发送 SIGHUP 可以要求其重载配置。
许多发行版有更加先进的 xinetd(8)。
几列数据分别是服务的名称（可以根据 /etc/services 查到服务对应的端口，理论上有些服务在不同协议下有可能使用不同端口，但是我看 /etc/services 中的服务都是 udp 和 tcp 用相同的端口号）、socket 的类型、协议、标记（要么是 wait，要么是 nowait；wait 表示在子进程运行时暂时将对应 socket 从监听列表中移除，等子进程退出后再次加入监听）、登录名（控制子进程的用户名和组名，由于 inetd 是 root 运行的，所以不控制子进程的凭据会有很大的风险）、程序位置、参数列表（图中只提供了 aegv[0]）。
还可以看到 ftp/telnet/login 这几个服务都使用了 tcpd 程序，但是参数不同。
Tip
一般来说 TCP 服务的标志用的是 nowait，因为 TCP 服务接收连接后，一个进程很可能就只处理一个客户端。而 UDP 服务用的是 wait。
在启动新的服务前，inet 会先 fork()，然后设置好标准输入 / 输出 / 错误描述符，将其和 UDP/TCP 套接字描述符关联起来，再关闭其他的文件描述符，这样就能调用 exec() 了。这样做可以简化服务程序的逻辑，因为服务程序现在可以直接和标准输入 / 输出流交互。
  </content></entry><entry><title>换新笔记本之后 OneDrive 没有把桌面同步过来</title><url>/posts/systems/Windows/%E6%8D%A2%E6%96%B0%E7%AC%94%E8%AE%B0%E6%9C%AC%E4%B9%8B%E5%90%8E-OneDrive-%E6%B2%A1%E6%9C%89%E6%8A%8A%E6%A1%8C%E9%9D%A2%E5%90%8C%E6%AD%A5%E8%BF%87%E6%9D%A5/</url><categories/><tags><tag>windows</tag></tags><content type="html">  OneDrive 可以同步桌面，我以前的桌面是 C:\Users\xxx\OneDrive\Desktop，现在我的新电脑的桌面是 C:\Users\xxx\Desktop，虽然 OneDrive 仍然保存了之前的文件夹，但是没有对桌面进行同步。
解决方案是从文件资源管理器进入用户目录，然后右键桌面，选择位置 &amp;gt; 移动。点击移动之后桌面上面的文件就会被移动到新的路径（新路径的旧文件不会被删除，遇到同名文件会询问是否覆盖），随后新的路径会被设置为桌面。
  </content></entry><entry><title>58 TCP/IP 网络基础</title><url>/the-linux-programming-interface/58-TCP-IP-%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  多宿主机（Multihomed host）指拥有多个网络接口的主机（可以是个人计算机，也可以是路由器）。
在网络层中，IPv4 为 IP 头提供了校验和，这样就能检测出头中的错误，但是 IPv4 并没有为包的内容提供校验。IPv6 则没有为 IP 头提供校验和。在传输层中，UDP 校验和在 IPv4 上可选、在 IPv6 上强制；TCP 校验和总是强制的。
常量 INADDR_ANY 就是所谓的 IPv4 通配地址，大多数实现将其定义成了 0.0.0.0。使用通配地址，多宿主机可以接收任意一个主机 IP 地址的数据。
IPv6 的环回地址为 ::1，通配地址为 0::0 或者 ::（同一个值的两种写法而已）。IPv6 还提供了“IPv4 映射的 IPv6 地址”，这样的 IPv6 地址是在 IPv4 地址前面加上 ffff（两个字节的全 1），然后再加上一堆 0 形成的。与 204.152.189.116 等 价 的 IPv4 映 射 的 IPv6 地 址 是 ::FFFF:204.152.189.116。
端口号：0-1023 被保留。1024-41951 是注册端口，需要向 IANA 注册（但不是已经全都注册满了）。IANA 将位于 41952 到 65535 之间的端口称为动态或私有端口（书上写的不是 41952，怀疑写错了），这表示这些端口可供本地应用程序使用或作为临时端口分配，但不同实现的分配范围可能不同，比如 Linux 通过 /proc/sys/net/ipv4/ip_local_port_range 表示端口分配范围，在我本地看是 32768 和 60999 两个数字。
UDP 的功能很少，只是在 IP 的基础上加了端口号和整个包的校验和。
  </content></entry><entry><title>56 Socket</title><url>/the-linux-programming-interface/56-Socket/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  Socket 基础Socket 分为 UNIX Domain Socket 和 Internet Domain Socket，两者都有数据报和字节流两种工作模式。前者（UNIX Domain Socket）是同一台主机不同进程之间通信的方式，是可靠的通信（包括数据报通信方式）。
SUS 规定 socket 至少可选以下的 domain，具体实现可以提供更多选择：（AF 表示地址族，PF 表示协议族，早期设计人员认为一个协议族可以支持多个地址族，但实际上协议族和地址族基本上是一一对应的关系，而且所有 PF_ 开头的常量都被定义成对应的 AF_ 开头的常量。）
SUS 规定 socket 至少可选流（SOCK_STREAM）和数据报（SOCK_DGRAM），具体实现可以提供更多选择，比如 SOCK_RAW 表示直接使用 IP 而不是传输层协议，但这可能需要特权。在流类型的 socket 中，连接的另外一方被称为 peer socket（对等 socket）。
流 socket系统调用的过程使用 socket() 系统调用创建一个 socket。 （服务器）使用 bind() 系统调用把 socket 绑定到一个周知的地址上。Internet domain 上的 socket 可以不用 bind() 直接调用 listen()。 （服务器）使用 listen() 系统调用允许一个流 socket 来接收其他 socket 的接入连接。 （服务器）使用 accept() 系统调用等待对等程序的连接，连接成功时返回一个指向新 socket 的文件描述符。接下来可以通过这个文件描述符指定的 socket 和对等 socket 交换信息。 （客户端）使用 connect() 系统调用发送连接请求。 创建 socketSYNOPSIS #include &amp;amp;lt;sys/socket.h&amp;amp;gt; int socket(int domain, int type, int protocol); TLPI 这本书中不需要用到特殊的 protocol，总是把 protocol 填 0。类型字段还能或上 SOCK_NONBLOCK 或者 SOCK_CLOEXEC，相当于一步完成了对 socket 文件描述符的 fcntl()。
刚创建出来的 socket 都是主动 socket，一个主 …  </content></entry><entry><title>57 UNIX domain socket</title><url>/the-linux-programming-interface/57-UNIX-domain-socket/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  UNIX 域套接字 bind() 时会在文件系统上面创建文件UNIX domain socket 在 bind 的时候会在文件系统上面创建一个 socket 文件。
如果文件系统上面已经有该路径，则会绑定失败。往往是服务器在 bind() 之前调用 remove() 来尝试删除旧文件（remove() 既可以删除文件夹又可以删除普通文件），在不再需要 socket 时也会立即调用 unlink() 来删除 socket，等所有使用该 socket 的进程退出之后文件就会被文件系统自动清理。
Linux 特有的抽象 socket 名字空间在 bind() 的时候把 struct sockaddr_un 的 sun_path 字段的第一个字节指定为 '\0'，后面仍然填 socket 名字，则可以为 socket 创建一个抽象名字，这样 socket 就不会出现在文件系统上面，也不会和文件系统上面的条目冲突。
UNIX domain 数据报 socket 能传输的最大大小通过 SO_SNDBUF 选项和 /proc 文件系统下面的限制表示。可以参考 socket(7)。我本地看是 212992。
为 UNIX domain socket 创建 socket 对socketpair() 系统调用有一点像 pipe() 系统调用，前者会创建匿名的 socket 对，可以跨过 fork() 共享给子进程。这个系统调用为我们省去了 socket()、bind()、listen()、connect()、accept() 等环节，而且创建的 socket 对外是不可见的。
socketpair() 只能用在 AF_UNIX 这种 domain 上面。和 pipe() 相比的好处是：除了可以指定流类型之外，还能指定数据报类型，这样我们就不用自己去划分数据的边界。
  </content></entry><entry><title>PyTorch 的 CPU 计算为什么使用 double 作为 32 位浮点数的累加类型？</title><url>/posts/programming/python/PyTorch-%E7%9A%84-CPU-%E8%AE%A1%E7%AE%97%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8-double-%E4%BD%9C%E4%B8%BA-32-%E4%BD%8D%E6%B5%AE%E7%82%B9%E6%95%B0%E7%9A%84%E7%B4%AF%E5%8A%A0%E7%B1%BB%E5%9E%8B/</url><categories/><tags><tag>torch</tag></tags><content type="html">  Tip
本文没有得到最终结论，只是一些个人猜想。
CUDA Kernel 常用 float 类型这件事 这篇笔记提到一个 issue 里面说 ATen 使用 double 作为 32 位浮点数的累加类型是因为用 float 会挂掉一个 batchnorm 的测试。这在我看来不可思议，因为 GPU 上面测试都没有挂，为什么 CPU 上面反而会挂呢？本文记录笔者看 batchnorm 的实现、试图找到原因的过程。
PyTorch 的 batchnorm 要对每一轮的输入计算均值和标准差，其中计算均值就需要将输入都加起来（再除以元素总数），这中间就可能产生累加误差。标准差的计算也类似，会有累加产生的误差。
从 aten/src/ATen/native/native_functions.yaml 中可以找到 native_batch_norm() 函数是在哪里实现的：
- func: native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -&amp;gt; (Tensor, Tensor, Tensor) dispatch: CPU: batch_norm_cpu CUDA: batch_norm_cuda MPS: batch_norm_mps MkldnnCPU: mkldnn_batch_norm CUDA 中的累加函数是 batch_norm_collect_statistics_kernel()。计算方差时用了 Welford 算法，看不懂。Welford 算法是一种只进行一次遍历的在线计算方差的方法，能够有效降低舍入误差。可以参考 https://shuai.guru/welford-variance/ 和 https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance 。
CPU 中的累加函数是 batch_norm_cpu_collect_stats_kernel()。该函数又分情况调用了很多函数，可以先参考 batch_norm_cpu_collect_stats_contiguous_impl()（代码如下），可以看出并行是在多通道层面上的，每个通道上是把每个像素的值一个一个加起来的。按照 https://en.wikipedia.org/wiki/Pairwise_summation 的说法，这样的 naive 累加误差会比 pairwise 的算法误差大。而算方差的时候，这段代码又进行了第二次遍历，没有使用一次遍历算法，误差应该是会比 Welford 更小一点？
// batch_norm_cpu_collect_stats_contiguous_impl() 函数中的代码 at::parallel_for(0, n_channel, 1, [&amp;amp;](int64_t begin, int64_t end) { for (const auto c : c10::irange(begin, end)) { // compute mean per input accscalar_t sum = 0; for (const auto n : c10::irange(n_batch)) { for (const auto i : c10::irange(image_size)) { auto offset = n * n_channel * image_size + c * image_size + i; sum += input_data[offset]; } } scalar_t mean = sum / N; mean_data[c] = mean; // compute variance per input accscalar_t _var_sum = 0; for (const auto n : c10::irange(n_batch)) { for (const auto i : c10::irange(image_size)) { auto offset = n * n_channel * image_size + c * image_size + i; auto x = input_data[offset]; _var_sum += (x - mean) * (x - mean); } } var_sum_data[c] = _var_sum; } }); https://github.com/pytorch/pytorch/issues/113414#issuecomment-1809470317 中说 CPU 上 batchnorm 在单精度计算时使用 float 类型而不是 double 类型作为累加类型，会导致一个单元测试失败，是不是因为 CPU 在计算均值和方差的求和过程中没有用 pairwise 或者 kahan 算法？（2024 年 8 月 27 日：可能是相比于 pairwise，按顺序加对 cache 更友好；kahan 会慢。）
  </content></entry><entry><title>CUDA Kernel 常用 float 类型这件事</title><url>/posts/programming/cuda/CUDA-Kernel-%E5%B8%B8%E7%94%A8-float-%E7%B1%BB%E5%9E%8B%E8%BF%99%E4%BB%B6%E4%BA%8B/</url><categories/><tags><tag>cuda</tag></tags><content type="html">  本文分别讨论双精度、单精度、半精度的浮点数计算，最后提及混合精度。在 CPU 方面，仅考虑 x86-64 CPU 和 GNU/Linux 上的 GCC 编译器；GPU 方面仅考虑 NVIDIA GPU。
GPU 上双精度计算慢在哪里？https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#arithmetic-instructions 以上链接说明：GPU 双精度浮点数运算比单精度浮点数慢，在有些架构（很多 $x.y~(y \ne 0)$ 运算能力的 GPU 都是游戏卡）上甚至慢得多。除了指令慢之外，double 类型也不利于 cache 和全局内存带宽。
https://forums.developer.nvidia.com/t/use-float-rather-than-double-in-a-kernel/107363 A 64 bit double variable takes 2 registers. A 32 bit float can be stored in 1 register. 双精度浮点数的使用会增加单个 CUDA 线程对寄存器数量的需求，从而减少实际上同时可以运行的线程数。
怎么正确使用单精度类型？——谨防隐式转换成双精度CUDA 和 C/C++ 都不会先将 float 转 double 再计算，除非……
https://godbolt.org/z/Me66bEeaa 我在本地尝试构造浮点数精度损失，但是无法构造出来，去 compiler explorer 一看发现实际上单精度浮点数被转换成了双精度浮点数计算。为什么呢？
https://godbolt.org/z/jM6sGn5je 罪魁祸首其实是表达式中的那些常量，他们都是 double 类型的，会导致其他 float 参数被转换成 double。
https://godbolt.org/z/4hevdr7Mo 写模板函数时如果需要使用浮点数字面量，最好是先写成 double 类型（比如 3.14 而不是 3.14f）然后在前面做类型强制转换，字面量的类型转换可以由编译器完成，而无需运行时使用类型转换指令。
template &amp;amp;lt;typename T&amp;amp;gt; __device__ __host__ T …  </content></entry><entry><title>要小心 C++ 静态初始化顺序</title><url>/posts/programming/cpp/%E8%A6%81%E5%B0%8F%E5%BF%83-C++-%E9%9D%99%E6%80%81%E5%88%9D%E5%A7%8B%E5%8C%96%E9%A1%BA%E5%BA%8F/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  https://godbolt.org/z/n5bjMGcx3
编译器并不会自动根据代码的依赖关系去编排静态初始化顺序，示例代码中 vec 在被推入两个元素之后又被初始化了一次（在 compiler explorer 中看汇编也能看出来）。
#include &lt;iostream&gt; #include &lt;vector&gt; extern std::vector&lt;int&gt; vec; void report_size() { printf(&#34;vec.size(): %zd\n&#34;, vec.size()); } auto _1 = []() { vec.push_back(0); printf(&#34;first &#34;); report_size(); return 0; }(); auto _2 = []() { vec.push_back(0); printf(&#34;second &#34;); report_size(); return 0; }(); std::vector&lt;int&gt; vec; int main() { printf(&#34;main &#34;); report_size(); } 输出：
first vec.size(): 1 second vec.size(): 2 main vec.size(): 0 在这个测试中，各个变量看起来是按照定义顺序初始化的。遇到多个目标文件链接的情况，初始化顺序就不太好控制了。必要时使用 41 共享库基础 - 个人回忆 中描述的懒初始化方法。
  ]]></content></entry><entry><title>53 POSIX 信号量</title><url>/the-linux-programming-interface/53-POSIX-%E4%BF%A1%E5%8F%B7%E9%87%8F/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  大概特点POSIX 信号量有两种：命名信号量和匿名信号量，前者和 System V 信号量比较相似（System V 的 IPC 都用 key 来标识，因此相当于是命名的）。
POSIX 信号量使用了 futex(2) 来实现，在没有争抢的情况下，不会发生系统调用，因此效率比 System V 实现更高。在争抢频繁的情况下，两者性能差不多。
和 POSIX 消息队列类似，Linux 上的 POSIX 信号量被挂载在 /dev/shm 目录这个 tmpfs 文件系统下。该文件系统具有内和持久性。
（二元）信号量和 pthreads mutex 相比：
前者是异步信号安全的，后者不是。但是处理信号还是建议用 sigwaitinfo()。 前者可以由任何线程释放资源（sem_post()），后者只能由锁的持有者释放，否则是未定义行为。 命名信号量可以用 sem_open() 来打开或创建命名信号量。这个过程和打开文件很像，如果需要创建命名信号量，则需要额外提供 mode 和 value 参数。这保证了命名信号量创建和初始化过程的原子化，这是 System V 没有的保证。
sem_open() 的返回值是 sem_t *，这意味着我们要固定地址来使用信号量，不能复制它的值。如果打开 / 创建命名信号量失败，则会返回 SEM_FAILED。
关闭信号量用 sem_close()，进程结束时也会自动关闭。删除信号量用 sem_unlink()，命名信号量和文件一样有引用计数：尽管已经调用 sem_unlink()，只有所有进程都关闭命名信号量后，该信号量才会真正被删除。
信号量操作As with a System V semaphore, a POSIX semaphore is an integer that the system never allows to go below 0.
信号量的值永远不会小于 0。不要以为可以先扣到负数再增加！
POSIX 信号量的 sem_wait() 和 sem_post() 操作每次只能操作一个信号量，而且只能将该信号量值的绝对值改变 1（如果操作成功）。这是和 SysV 不同的。
sem_wait() 如果被中断会失败并设置 EINTR 错误（英文书上说的是 fails with the error EINTR，翻译的是“ …  </content></entry><entry><title>54 POSIX 共享内存</title><url>/the-linux-programming-interface/54-POSIX-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  POSIX 共享内存对应虚拟文件系统 /dev/shm，这是一个 tmpfs 文件系统，具有内核持久性。如果不满意默认的大小（书上说默认大小是 256M，但是我测试默认大小是内存的一半——在服务器、虚拟机、wsl 上都是这样；docker 容器共享内存的默认大小则是 64M），可以使用 mount -o remount,size=&lt;num_bytes&gt; ... 重新挂载。
回忆：PyTorch 的 dataloader 经常需要共享内存，因此创建的跑 PyTorch 程序的容器需要设置更大一点的共享内存限制。
POSIX 共享内存的使用方式很像一个文件，可以用 shm_open() 打开或者创建，用 shm_unlink() 来删除。
SYNOPSIS #include &lt;sys/mman.h&gt; #include &lt;sys/stat.h&gt; /* For mode constants */ #include &lt;fcntl.h&gt; /* For O_* constants */ int shm_open(const char *name, int oflag, mode_t mode); int shm_unlink(const char *name); POSIX 共享内存对象要和 mmap() 一起用：先打开一个共享内存对象，然后将其文件描述符映射到内存的某处。这个时候 shm_open() 和 mmap() 的关系很像 shmget() 和 shmat() 的关系。
联想记忆：有些系统上没有提供匿名映射，因此创建匿名映射需要打开文件 /dev/zero 然后创建文件映射。
另外注意到共享内存对象刚创建时大小是 0，因此我们有必要在创建共享内存对象之后用 ftruncate() 修改它的大小，新增的部分将被填充为 0。
联想记忆：如果是普通文件，用 ftruncate() 增大文件大小时，多出来的部分会被 0 填充，新增的页面会形成空洞，并不会真正占用磁盘空间。
SUSv3 规定 O_TRUNC + O_RDONLY 打开共享内存对象是未定义的。在 Linux 中这样做依然会将文件截断。
shm_open() 返回的文件描述符有 close-on-exec 标记，不能跨越 exec()。这个标志虽然可以后期更改，但是 exec() 载入的新的进程映像很难知道到底哪些继承的文件描述符和共享内存段关联。通过环境变量或者命令行指定 fd 参数都需要修改被载入程序的源码，这大概也是为什么默认有 FD_CLOEXEC 标记。参考： https://stackoverflow.com/a/48191050/ 。
既然 shm_open() 要和 mmap() 一起用，为什么不直接用 mmap()？单靠 mmap() 无法解决不写入文件的命名共享内存问题。要不写入文件，就得匿名，但是这样无关进程就不能共享内存了。而 shm_open() 通过虚拟文件系统解决了这个问题。
另外一方面，基于文件的共享内存在重启仍保留已经同步到磁盘的内容，而其他共享内存手段的信息在重启后会丢失。所以两者各有长处。
  ]]></content></entry><entry><title>55 文件锁：flock() 和 fcntl() 加锁</title><url>/the-linux-programming-interface/55-%E6%96%87%E4%BB%B6%E9%94%81flock-%E5%92%8C-fcntl-%E5%8A%A0%E9%94%81/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  要点Linux 提供了两种文件加锁系统调用：从 BSD 衍生出来的 flock() 和从 System V 衍生出来的 fcntl()。尽管这两组系统调用在大多数 UNIX 实现上都是可用的，但只有 fcntl() 加锁在 SUSv3 中进行了标准化。
要理解 flock() 和 fcntl() 的锁分别和什么东西有关联，才能理解什么行为会导致锁的意外释放。“锁和什么有关联”意思就是以什么来标识锁的主人。而锁的对象则分别是整个文件（flock()）和指定区域（fcntl()）。锁是要放在锁的对象上的，所以锁链表在打开文件上记录。
flock() 对整个文件加锁从 BSD 衍生而来。加的是劝告锁（advisory locking）。
flock(2)：
SYNOPSIS #include &amp;amp;lt;sys/file.h&amp;amp;gt; int flock(int fd, int operation); 操作有三种：LOCK_SH、LOCK_EX、LOCK_UN。还可以或上标志 LOCK_NB 表示非阻塞。从语义来看是标准的读写锁，但是却没有明确提到“读写”这个概念。
flock() 锁转换不是原子的如果已经持有了文件的锁，现在指定了另外一种类型的锁，则会先解除锁定，再重新请求锁。这个过程称为锁转换，这个过程不是原子的！有可能在释放锁之后另外一个进程获得了锁，导致阻塞，或者（在非阻塞情况下）丢失了锁而失败返回。
flock() 锁的释放和继承flock() 锁和打开的文件项（是 file description 而不是 descriptor）相关，如果打开文件项从系统打开文件表中撤下（引用计数归 0），则对应的文件项的锁会被释放。
另外一方面，显式释放锁会导致系统打开文件表上的这个文件项中记录的锁的释放！
dup() 来的 fd 会指向同一个打开文件项，关闭其一会使得文件被关闭，锁也会被释放。如果想要一个 fd 一把锁，那就不要 dup()，而是打开同一个文件多次。 flock() 锁可以跨越 fork()，但是子进程和父进程共享同样的打开文件项，因此共享同样的锁，操作不当（比如子进程关闭文件）将会导致父进程的锁一起丢失（实际上，锁并不以进程标识）。 flock() 锁能跨越 exec()，除非文件项设置了 close-on-exec，这样锁会随着文件的关闭而解 …  </content></entry><entry><title>torch 自动求导的代码在哪里？</title><url>/posts/programming/python/torch-%E8%87%AA%E5%8A%A8%E6%B1%82%E5%AF%BC%E5%92%8C%E6%B4%BE%E5%8F%91%E7%9A%84%E4%BB%A3%E7%A0%81%E5%9C%A8%E5%93%AA%E9%87%8C/</url><categories/><tags><tag>python</tag><tag>torch</tag></tags><content type="html"><![CDATA[  2024 年 8 月 5 日：当前 torch 发布的版本是 2.4。PyTorch 的源码中还有几个 YAML 文件，这些文件都挺重要的，可以关注一下。
tools/autograd/derivatives.yaml 中有一些求导代码片段：
- name: prod.dim_int(Tensor self, int dim, bool keepdim=False, *, ScalarType? dtype=None) -&gt; Tensor self: prod_backward(grad, self.to(grad.scalar_type()), result, dim, keepdim) result: (prod_backward(at::ones({}, result.options()).expand_as(result), self_p.to(result.scalar_type()), result, dim, keepdim) * self_t.conj()).sum(dim, keepdim).conj() - name: put(Tensor self, Tensor index, Tensor source, bool accumulate=False) -&gt; Tensor self: &#34;accumulate ? grad : grad.put(index, zeros_like(source), false)&#34; index: non_differentiable source: grad.take(index).reshape_as(source) result: self_t.put(index, source_t, accumulate) - name: linalg_qr(Tensor A, str mode=&#39;reduced&#39;) -&gt; (Tensor Q, Tensor R) A: linalg_qr_backward(grad_Q, grad_R, Q, R, mode) Q, R: linalg_qr_jvp(A_t, Q, R, mode) - name: rad2deg(Tensor self) -&gt; Tensor self: rad2deg_backward(grad) result: auto_element_wise - name: random_.from(Tensor(a!) self, int from, int? to, *, Generator? generator=None) -&gt; Tensor(a!) self: zeros_like(grad) result: self_t.zero_() - name: random_.to(Tensor(a!) self, int to, *, Generator? generator=None) -&gt; Tensor(a!) self: zeros_like(grad) result: self_t.zero_() 看起来 name 是近似于 python 的伪代码，其他的都是 C++ 代码？
aten/src/ATen/native/native_functions.yaml 这个文件中有 native 函数在不同平台上的派发，比如：
- func: native_batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps) -&gt; (Tensor, Tensor, Tensor) dispatch: CPU: batch_norm_cpu CUDA: batch_norm_cuda MPS: batch_norm_mps MkldnnCPU: mkldnn_batch_norm   ]]></content></entry><entry><title>50 虚拟内存操作</title><url>/the-linux-programming-interface/50-%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E6%93%8D%E4%BD%9C/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  本章介绍在进程的虚拟地址空间上执行操作的各个系统调用。
mprotect() 系统调用修改一块虚拟内存区域上的保护信息。 mlock() 和 mlockall() 系统调用将一块虚拟内存区域锁进物理内存，从而防止它被交换出去。 mincore() 系统调用让一个进程能够确定一块虚拟内存区域中的分页是否驻留在物理内存中。 madvise() 系统调用让一个进程能够将其对虚拟内存区域的使用模式报告给内核。 mprotect()同 mmap() 的 prot 参数。
mlock()可能是为了速度，也可能是为了防止敏感信息写入磁盘（这样恶意程序没办法从磁盘中读取内容）。
一些电脑的休眠模式会在磁盘上存储当前系统运行状态的副本，不管页面有没有被锁定。
SYNOPSIS #include &amp;amp;lt;sys/mman.h&amp;amp;gt; int mlock(const void addr[.len], size_t len); int mlock2(const void addr[.len], size_t len, unsigned int flags); int munlock(const void addr[.len], size_t len); int mlockall(int flags); int munlockall(void); 如果传给 mlock() 的 addr 不是对齐到页的，那么系统会将其向下舍入到页面的整数倍。addr + len 则是向上舍入。例如，在一个分页大小为 4096 字节的系统上，mlock(2000, 4000) 调用会将 0 到 8191 之间的字节锁住（2000 + 4000 向上舍入到 8192）。
通过查看 Linux 特有的 /proc/PID/status 文件中的 VmLck 条目能够找出一个进程当前已经锁住的内存数量。
RLIMIT_MEMLOCK 资源限制非特权进程能够锁定的页面数量是有限的。RLIMIT_MEMLOCK 资源限制描述了能够锁定的字节数，实际检查时会将其向下舍入到页面的整数倍。其默认值 32768 对应 8 个页面。
对于 mmap()、mlock()、mlockall()，RLIMIT_MEMLOCK 限制了一个非特权进程可以锁定的字节数（向下舍入到页），它们共享这个限制。 对于 shmctl() …  </content></entry><entry><title>51 POSIX IPC 介绍</title><url>/the-linux-programming-interface/51-POSIX-IPC-%E4%BB%8B%E7%BB%8D/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  总体来说，POSIX IPC 的接口比 System V IPC 更简单，而且使用方式也更贴近文件。
POSIX IPC 对象名字需要是类似于 /myobject 的、以斜线开头后面跟非斜线字符的字符串。字符串长度受到 NAME_MAX 限制（255 个字符）。信号量的名字还要少 4 个，因为会增加前缀 sem.。如果不以 / 开头，则是实现定义。IPC 对象名字很像一个根目录下的文件的绝对路径，在有些实现上，IPC 对象真的被放在文件系统上。 创建和打开 IPC 对象很像创建或打开文件。 POSIX IPC 对象有引用计数，进程退出或者关闭 IPC 对象后引用计数就会减少。进程调用 exec() 后 POSIX IPC 对象也会被关闭（很像文件有 close-on-exec 标记）。{mq,sem,shm}_unlink() 可以用来删除 POSIX IPC 对象，已经打开了 IPC 对象的进程仍能继续使用它们。而 System V 的删除（除了共享内存）是立即生效的，进程的后续访问会出错。 持久性：和 System V IPC 一样，POSIX IPC 对象也有内核持久性（如果不显式删除，将会持续到系统关机）。 IPC 对象管理：System V IPC 可以用 ipcs 来列出 IPC 对象，用 ipcrm 来删除 IPC 对象。POSIX IPC 没有这样标准化的命令。Linux 上的 POSIX IPC 对象被挂载在虚拟文件系统上，其所在目录有粘滞位，可以用 ls(1) 和 rm(1) 这样的标准命令来操作 Linux 的 POSIX IPC 对象。 System V IPC 更古老，可移植性更强。 System V IPC 用 key 来访问，本质都是命名的；POSIX 信号量可以匿名也可以命名；POSIX 用 shm_open 创建共享内存是命名的，但用 mmap 也可以创建匿名共享内存（mmap 也是 POSIX 标准）；POSIX 消息队列是命名的。   </content></entry><entry><title>52 POSIX 消息队列</title><url>/the-linux-programming-interface/52-POSIX-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  和 System V 不同点：
消息按照优先级排序消息按照优先级排序（数值越小越靠前）。每次接收都只能拿到开头的消息，不像 SysV 消息队列那样不按照优先级排序、且可以选择性获取中间的消息。
注册消息通知POSIX 消息队列还有一个功能就是能够注册消息通知，以得到有消息来临的消息：
任何时候只能有一个进程可以注册特定队列的消息通知（第二个进程注册时会失败得到 EBUSY 错误）。进程也可以主动解除通知。 消息通知是一次性的，通知完成之后就会自动解除。 只有消息队列从空变成非空时，才可能有通知。在非空的状态下来消息是不会产生通知的，只能先清空再来消息才可以产生通知。 消息队列从空变成非空时，如果有其他因为调用 mq_receive() 而阻塞的进程，那么消息由其中的一个进程获取，而不会产生通知！！ API：
SYNOPSIS #include &lt;mqueue.h&gt; #include &lt;signal.h&gt; /* Definition of SIGEV_* constants */ int mq_notify(mqd_t mqdes, const struct sigevent *sevp); sigevent 类型可以通过 system_data_types(7) 和 sigevent(7) 查到，它允许我们选择用一个自选信号通知，或者选择创建一个新线程处理通知（这个新线程要运行的函数由我们来指定）。
和 POSIX 消息队列相关的 Linux 特性mqueue 虚拟文件系统可以用 mount -t mqueue none /dev/mqueue 挂载 mqueue 虚拟文件系统。在我的系统上，这个文件系统已经存在于 /dev/mqueue 了，不需要手动挂载，通过 cat /proc/mounts 就能看到。
Tip
除了能够看到 /dev/mqueue 是 mqueue 文件系统之外，还能看到 /dev/shm 是 tmpfs 文件系统。
多路复用消息队列描述符实际上是文件描述符，可以用 I/O 多路复用的 API（select/poll/epoll）来监听。
资源限制MQ_PRIO_MAX：消息的最大优先级。 MQ_OPEN_MAX：进程最多能打开的消息队列数量。Linux 没有这个限制，但是因为消息队列描述符被实现为文件描述符，所以受到进程可以打开的文件描述符数量限制。 msg_max：新创建消息队列可以选择的优先级上限（默认值 10）。 msgsize_max：新创建消息队列可以选择的消息大小上限（默认值 8192，最小值 128，最大值 1048576，但可能随着内核版本会变化）。 queues_max：系统上能创建消息队列的最大数量，默认为 256。   ]]></content></entry><entry><title>49 内存映射 mmap()</title><url>/the-linux-programming-interface/49-%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84-mmap/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  内存映射分类内存映射可以通过 mmap() 函数来完成。
内存映射从可见性来讲可以分成私有（MAP_PRIVATE）和共享（MAP_SHARED）。 私有内存映射有写时复制语义。 共享映射页面上的内容变化对所有共享者都可见。共享文件映射的页面变化还会同步回文件。 内存映射从映射类型上可以分成文件映射和匿名映射。 文件映射页面被初始化为文件对应位置的内容。 匿名映射页面被初始化为 0。 因此，它们可以有以下 4 种组合方式：
私有文件映射：映射的内容会被初始化为相同的内容。多个映射同一个文件的进程一开始会共享内存的物理分页，但是在修改时会触发写时复制。在私有文件映射上面的变更不会同步回文件。 私有匿名映射：malloc() 申请大块内存时就会使用 mmap() 的私有匿名映射。这样的映射虽然会在 fork() 后由子进程继承，但是在写入页面的时候会触发写时复制。 共享文件映射：主要功能有两个，即文件映射 I/O 和无关进程的 IPC。 共享匿名映射：可以通过 fork() 由相关进程共享。 Note
进程的文本段就是私有文件映射。尽管文本段保护位一般是 PROT_EXEC | PROT_READ，而且程序本身也一般不会尝试去修改代码本身，但是调试器等可能会修改程序代码。我们不希望这样的修改操作同步回可执行文件，所以使用 MAP_PRIVATE 而不是 MAP_SHARED 来映射文本段。
进程的初始化数据段也是私有文件映射。（书上没说，但是未初始化数据段大概是私有匿名映射吧？）
共享内存不能跨越 exec()（会替换整个地址空间），但是能够跨越 fork()，可以参考 Stack Overflow 的 这个回答。内存映射也不像 System V 共享内存段一样是一种需要手动释放的资源，在进程终止的时候就会解除。
创建内存映射#include &amp;amp;lt;sys/mman.h&amp;amp;gt; void *mmap(void addr[.length], size_t length, int prot, int flags, int fd, off_t offset); int munmap(void addr[.length], size_t length); 其中 addr 填写 NULL 就好（固定地址我感觉很少用）。如果固定地址，则内核一般会将其对齐到页大小的整数倍。 …  </content></entry><entry><title>48 System V 共享内存</title><url>/the-linux-programming-interface/48-System-V-%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  共享内存是 IPC 机制中最快的一种，因为共享内存段会成为进程用户空间内存的一部分，因此在申请完成之后无需内核介入便可通信。作为对比，管道数据生产者需要将数据从用户缓冲区（如果使用 stdio）写入到内核缓冲区，管道数据的消费者也需要从内核缓冲区读取信息。
使用方式：
用 shmget() 创建或取得共享内存段的标识符。 用 shmat() 来附上共享内存段。 用 shmdt() 来分离共享内存段，此操作完成之后共享内存段将无法访问。在进程终止时，未分离的共享内存段会自动分离。 用 shmctl() 来删除共享内存段。只有所有附加到共享内存段的进程都与其分离后，内存段才会被销毁。 创建 System V 共享内存段#include &amp;lt;sys/shm.h&amp;gt; int shmget(key_t key, size_t size, int shmflg); 标志 IPC_CREAT 表示如果不存在和 key 对应的段，就创建一个新的；IPC_EXCL 表示共享内存段必须由当前进程创建，否则返回错误并设置 errno 为 EEXIST，使用时要同时指定 IPC_CREAT（man 手册中没讲不同时指定会怎么样）。其他标志略。
如果 size 不是页的整数倍，则会向上取整。如果用 shmget() 获得既有段的标识符，则 size 无意义，但不能大于创建时指定的大小。
附加 System V 共享内存段#include &amp;lt;sys/shm.h&amp;gt; void *shmat(int shmid, const void *_Nullable shmaddr, int shmflg); int shmdt(const void *shmaddr); shmaddr 可以为 NULL，此时会自动选择一个地址。shmaddr 不为 NULL 时，如果该地址已经不能使用，则会返回错误，关于 shmaddr 不为 NULL 的使用含义这里略去（一般用 NULL 也就够了）。
shmflg：
SHM_RDONLY 只读（默认是读写） SHM_REMAP 替换已有映射 SHM_RND 将 shmaddr 向上舍入到 SHMLBA（shared memory low boundary address）的整数倍 SHMLBA 与提升 CPU 快速缓冲性能有关，在 x86 …  ]]></content></entry><entry><title>47 System V 信号量</title><url>/the-linux-programming-interface/47-System-V-%E4%BF%A1%E5%8F%B7%E9%87%8F/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  SysV 信号量是以信号量集的形式出现的。
创建 SysV 信号量后需要显式初始化在 Linux 中，创建的 SysV 信号量的 semval 会被初始化为 0，但是这个行为是不可以移植的。在其他系统中，需要手动创建，再跟着初始化，这两部分可能会出现同步错误。
使用 semctl 前需要自己提供 semun 定义参考 man semctl，应用程序必须自己提供 semun 的定义（如果想要给 semctl 传递第 4 个参数）。这个定义并不在头文件里！
union semun { int val; /* Value for SETVAL */ struct semid_ds *buf; /* Buffer for IPC_STAT, IPC_SET */ unsigned short *array; /* Array for GETALL, SETALL */ struct seminfo *__buf; /* Buffer for IPC_INFO (Linux-specific) */ }; semop() 和操作系统课程所学有什么差异？共性：永不为负，P 和 V 都是原子操作。关于“永不为负”这一点我还去求证了一下，发现确实是自己本科学的东西记错了。
semop() 执行操作系统课程中学习的信号量操作，有一点差异。
权限检查：当 semop() 指定的信号量增量不为 0 的时候，进程就需要对信号量集有写权限；否则需要有读权限。semop() 指定信号量增量为 0 表示测试一下当前的资源量是否为负，如果为负会阻塞进程。
Wait-for-zero/increase：Man 手册上面同时有 semzcnt 和 semncnt 两个计数。semop() 指定的信号量增量为 0 时，如果阻塞，则执行的是 wait-for-zero 操作（会增加 semzcnt 计数）。semop() 指定的信号量增量为负时，如果阻塞，则会增加 semncnt 计数，等待资源增加（不需要等待资源非负，只要申请方需要的资源可以得到满足即可）。
Each semaphore in a System V semaphore set has the following associated values: unsigned short semval; /* semaphore value …  </content></entry><entry><title>45 System V IPC</title><url>/the-linux-programming-interface/45-System-V-IPC/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  System V IPC 对象 xxx_get 来打开（含创建）、xxx_ctl 来控制（含删除）。
操作 System V IPC 对象需要 key，key 可以用 IPC_PRIVATE 来让系统创建一个独一无二的，也可以从 ftok() 按照文件的 inode 号生成。System V IPC 其实都是命名的，IPC_PRIVATE 并不能真正实现匿名，只是生成一个不重复的名字罢了。
System V IPC 对象具有内核持久性，消息队列和信号量是无连接的（删除立即生效）、共享内存段有引用计数（比较像文件）。
一些命令：
ipcs：查看当前 System V IPC 对象的使用情况。 ipcs -l：列出 System V IPC 对象的资源上限。 ipcrm -[M|Q|S] key / ipcrm -[m|q|s] id：删除 System V IPC 对象。   </content></entry><entry><title>44 管道和 FIFO</title><url>/the-linux-programming-interface/44-%E7%AE%A1%E9%81%93%E5%92%8C-FIFO/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  管道管道：一般指的是匿名管道。
创建方式：
可以用 pipe() 创建，通过 fork() 或者 UNIX 域套接字共享给其他进程。 也可以通过 popen() 创建子进程。 popen() 和 system() 有一些差异：
system() 会为调用进程忽略 SIGINT 和 SIGTERM，但是 popen() 不会忽略这些信号，因为调用进程没有阻塞等待子进程。 popen() 不会阻塞 SIGCHLD。如果阻塞了，那么在对应的 pclose() 之前就不能正常接受子进程退出的消息了。但这也有个问题：wait() 可能会接收到 popen() 创建的子进程的消息，这样调用 pclose() 的时候就会返回 -1 并设置 errno 为 ECHLD。 popen() 和 pclose() 配套。除了关闭文件描述符之外，pclose() 还会回收子进程，所以不能用 fclose() 代替 pclose()。 管道的一些性质这些性质都是匿名 / 命名管道都有的。
1. 块缓冲管道是块设备，因此 stdio 库的输出时会使用块缓冲（想要及时刷新缓冲区可以：1. 手动刷新；2. 用 setbuf() 修改缓冲模式；3. 分配伪终端使写入按照字符设备的方式刷新）。
2. 单向传输管道的传输方向是单向的，如果想要双向数据传输，可以用 UNIX domain stream socket pairs（socketpair() 系统调用）。
3. 容量有限管道的本质是缓冲区，所以容量是有上限的。Linux 2.6.11 起，管道的存储能力是 64KB（更早的内核固定使用一页作为缓冲区）。可以通过 fcntl(fd, F_SETPIPE_SZ, size) 来修改这个限制，非特权进程可以将这个值修改到 /proc/sys/fs/pipe-max-size 的数值以内的一个数。
/proc/sys/fs/pipe-max-size 的默认大小是 1M，只有特权进程（CAP_SYS_RESOURCE）才能修改：
eric@debian:~$ cat /proc/sys/fs/pipe-max-size 1048576 4. 数据少时保证原子写入一次性写入不超过 PIPE_BUF 字节就是原子写入，如果写成功可以保证内容不会和其他写者交叉。这在有多个写者的情况下很有 …  </content></entry><entry><title>私有化构造函数</title><url>/posts/programming/cpp/%E7%A7%81%E6%9C%89%E5%8C%96%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  有的时候我们希望私有化构造函数，然后要求用户只通过工厂方法访问我们的类型，在 std::enable_shared_from_this 的例子 中就有使用。这个例子是从 cppreference 上面抄来的。但是今天我发现去年 11 月有人修改了网页上的例子，修订记录为 https://en.cppreference.com/mwiki/index.php?title=cpp%2Fmemory%2Fenable_shared_from_this&diff=162885&oldid=153414 。
后来这个例子又有了新的修订，现在这个例子是：
class Best : public std::enable_shared_from_this&lt;Best&gt; { struct Private{ explicit Private() = default; }; // 这个 explicit 构造函数非常重要 public: // Constructor is only usable by this class Best(Private) {} // Everyone else has to use this factory function // Hence all Best objects will be contained in shared_ptr static std::shared_ptr&lt;Best&gt; create() { return std::make_shared&lt;Best&gt;(Private()); } std::shared_ptr&lt;Best&gt; getptr() { return shared_from_this(); } }; 构造函数不再私有，调用者能明确看到需要一个私有的标记类，从而对 API 的使用方式会更加清楚。
尤其是 Private 类中的 explicit Private() = default; 非常重要，如果没有这个，使用者可以通过避免明确书写 Private 类型而构造出 Private 类型的对象！这是非常危险的。
int main() { Best best({}); }   ]]></content></entry><entry><title>42.1 几个搜索顺序</title><url>/the-linux-programming-interface/42.1-%E5%87%A0%E4%B8%AA%E6%90%9C%E7%B4%A2%E9%A1%BA%E5%BA%8F/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  要区分找依赖 / 共享库和找符号。
找共享库：动态链接器在 ELF 文件中见到一个依赖名，查找此依赖的搜索顺序。
在共享库中找符号：
在全局符号对象中符号的搜索顺序 解析共享对象中的符号时的搜索顺序。（加载时没 RTLD_LAZY 立即解析，有则延后函数解析、立即变量解析。）   </content></entry><entry><title>42 共享库高级特性</title><url>/the-linux-programming-interface/42-%E5%85%B1%E4%BA%AB%E5%BA%93%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  动态加载库：dlopen API#include &amp;amp;lt;dlfcn.h&amp;amp;gt; void *dlopen(const char *filename, int flags); int dlclose(void *handle); 使用 dlopen API 要给 gcc 传递 -ldl 参数使其链接到 libdl.so。
dlopen()每个被加载的库会有一个引用计数，一个库被加载时，它依赖的其他库（被称为依赖树）会被自动加载，它们的引用计数增加；卸载时引用计数又会减少，归零时才真正意义上卸载共享库。
filename 参数如果 filename 包含 /，那么按照文件路径查找；否则在标准的路径中按照 41 章描述的顺序查找。 如果 filename 为 NULL，那么返回主程序的句柄，也就是“全局符号对象”（global symbol object）。 在全局符号对象中符号的搜索顺序如果用全局符号对象的句柄作为参数调用 dlsym()，那么会：
先在主程序中搜索符号 然后在程序启动时加载的共享库中按顺序搜索 最后在所有使用了 RTLD_GLOBAL 标志加载的共享库中按顺序搜索。 解析共享对象中的符号时的搜索顺序加载时没 RTLD_LAZY 立即解析，有则延后函数解析、立即变量解析。
Symbol references in the shared object are resolved using (in order):（这一段话来自 man 手册）
symbols in the link map of objects loaded for the main program（不包括主程序本身！） and its dependencies; symbols in shared objects (and their dependencies) that were previously opened with dlopen() using the RTLD_GLOBAL flag; and definitions in the shared object itself (and any dependencies that were loaded for that object). 有了这样的解析顺序，想要在不重新链接程序的情况下替换 malloc …  </content></entry><entry><title>40 登录记账</title><url>/the-linux-programming-interface/40-%E7%99%BB%E5%BD%95%E8%AE%B0%E8%B4%A6/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  两个标准文件utmp（/var/run/utmp）、wtmp（/var/log/wtmp）。utmp 维护当前登录进系统的用户的状态（登出后信息就被删除），后者维护每条和登录相关的信息，也就是说 who(1) 可以用前者实现，last(1) 可以用后者实现。
用户不需要知道文件的路径，使用时也应该通过 glibc 提供的宏 _PATH_UTMP 和 _PATH_WTMP 来表示这两个文件的路径。 utmp 和 wtmp 在维护用户登录之外还维护有别的信息，登录信息只是它的一部分功能而已。 Tip
lastb 命令和 last 相似，但是展示的是 /var/log/btmp 文件的内容，这里记录了那些失败的登录尝试。
getlogin() 也可以用 utmp 实现：它会从 utmp 文件中搜索当前进程的控制终端的 id（可以用 ttyname() 找到），如果找到了则返回对应记录中的登录名。
对比：getpwuid(getuid()) 是从密码文件中找到第一项 id 符合的记录，尽管用户可能使用的不是该记录关联的登录名（一个 id 可以对应多个登录名）。
同一组 API默认操作位置是 utmp 的文件路径，但是也可以通过 utmpxname() 来把路径修改到 wtmp 的路径。
使用老的 utmp API 用 utmp.h 头文件，使用新的 utmpx API 则用 utmpx.h。在 Linux 上，查找 utmpx API 的手册也会跳转到 utmp API 中。
utmp 和 wtmp 文件很早就出现了，但是不同的实现之间有区别，尤其是 BSD 和 System V。System V Release 4 对 API 进行了大量的扩展，创建了全新的并行的 utmpx 结构和相关的 utmpx/wtmpx 文件。Linux 的 utmpx API 是 BSD 和 System V 实现的混合体。Linux 上的 utmpx API 和它提供的传统的 utmp API 效果几乎等同，也没有专门使用 utmpx/wtmpx 文件，继续沿用了 utmp/wtmp 文件。
书上讲的是 utmpx API，但是和 utmp 差的不会很多。下面的写的时候会混着写，区别只有字母 x。
在 Linux 的 man 手册中对 utmp.h API 的罗列：
struct …  </content></entry><entry><title>41 共享库基础</title><url>/the-linux-programming-interface/41-%E5%85%B1%E4%BA%AB%E5%BA%93%E5%9F%BA%E7%A1%80/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  操作静态库静态库可以使用 ar 命令创建和管理（尽管一般不需要我们自己调用 ar 命令）。
创建归档：
ar r libdemo.a mod1.o mod2.o mod3.o 列出归档：
$ ar tv libdemo.a rw-r--r-- 1000/100 1001016 Nov 15 12:26 2009 mod1.o rw-r--r-- 1000/100 406668 Nov 15 12:21 2009 mod2.o rw-r--r-- 1000/100 46672 Nov 15 12:21 2009 mod3.o 从归档中删除内容：
ar d libdemo.a mod3.o 共享库基本介绍虽然共享库的代码是由多个进程共享的，但其中的变量却不是。每个使用库的进程会拥有自己的在库中定义的全局和静态变量的副本。 共享库通常需要使用额外的寄存器来支持位置独立编码（PIC），在运行时也需要符号解析（重定位）。 DSO 指 dynamic shared object。
创建共享库在 gcc 中使用 -fPIC 来生成位置无关编码的程序，用 -shared 来生成共享库而不是可执行文件。
位置独立编码（PIC）生成位置独立编码会让程序每次对全局数据（包括变量和函数地址）的访问都相对于一个偏移进行（这个偏移其实就是 GOT 表的起始位置）。在一些平台上要生成共享库必须使用 PIC。
Linux/x86-32 环境中不用 PIC 也能生成共享库，只是这样创建出来的共享库代码不能被多个进程复用内存，而是在每个进程中都有一份修改后的副本。（外存共享、内存不共享。）
确定文件是否使用了 -fPIC 选项编译1. 检查目标文件的符号表如果目标文件（*.o）在编译时使用了 -fPIC 选项，则 nm 或 objdump 命令会有输出：
# 1 nm mod1.o | grep _GLOBAL_OFFSET_TABLE_ # 如果 nm 的输入是静态库，则会对静态库中的每个目标文件都进行搜索 # 2 readelf -s mod1.o | grep _GLOBAL_OFFSET_TABLE_ 以上两个命令都是读取目标文件的符号表。
2. 检查共享库的符号表如果以下任何命令产生了输出，说明共享库中至少有一个目标文件在编译时没有使用 -fPIC 选项。举例：
# …  </content></entry><entry><title>37 Daemon</title><url>/the-linux-programming-interface/37-Daemon/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  在概述小节的疑惑书上说：在 Linux 上，特定的 daemon 会作为内核线程运行，比如 pdflush，用 ps(1) 列出线程时，这些 daemon 的名字会用花括号括起来。但可能因为书太老了，很多内容已经变化了。我在服务器上查出来的情况是（用我的 wsl 查不出来什么，可能内核修改太多了）：
$ ps -p 1 -p 2 -o user,pgid,ppid,pid,tid,cmd USER PGID PPID PID TID CMD root 1 0 1 1 /sbin/init splash root 0 0 2 2 [kthreadd] 我的理解：[kthreadd] 和 /sbin/init 的父进程 ID 都是 0，可能表示都是被内核创建出来的？PID 和 TID 相等表示它们都是进程而不是线程。[kthreadd] 的 PGID 为 0，可能表示内核进程组，而 init 则是在一个单独的进程组中。
查找和“flush”匹配的进程：
$ ps axf -o user,pgid,ppid,pid,tid,cmd | grep flush root 0 2 5 5 \_ [slub_flushwq] root 0 2 549 549 \_ [kdmflush] root 0 2 553 553 \_ [kdmflush] root 0 2 557 557 \_ [kdmflush] root 0 2 3639641 3639641 \_ [kworker/u65:2-flush-259:0] amax 3642118 3618263 3642119 3642119 \_ grep --color=auto flush 下面的一堆 [*flush] 都是 [kthreadd] 的子进程。再看看 ps axf -o user,pgid,ppid,pid,tid,cmd|less 的结果（太长了，这里省略）：
[kthreadd] 会创建一堆子进程，它们的名字都有中括号，而且它们的 PGID 都为 0。这些进程的用户都是 root。 1 号 PID 的进程也是属于 root 用户的，随后它会创建很多用户进程，有的用户进程可能使用不同的用户。 37.2~37.3 创建 daemon书上在此处列举了创建 daemon 的原理和一些要点。
逃脱进程组： …  </content></entry><entry><title>38 编写安全的特权程序</title><url>/the-linux-programming-interface/38-%E7%BC%96%E5%86%99%E5%AE%89%E5%85%A8%E7%9A%84%E7%89%B9%E6%9D%83%E7%A8%8B%E5%BA%8F/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  本文讲的很多东西是适用于 set-user/group-ID 的。
避免使用 set-user-ID 和 set-group-ID 程序如题。
使用尽可能少的权限这里的权限指的是用户的身份，即 user ID。组 ID 可以类比过来，操作方式相似。
只在需要权限的时候暂时改变权限一个 set-user-ID 的进程启动时保存其有效用户 ID。 用 seteuid(getuid()) 更换有效用户 ID 为真实用户 ID 以执行其他程序。 在需要权限的时候暂时设置有效用户 ID，之后切换回来。 永久放弃权限为了保证进程以后不再能获取权限，出了恢复有效用户 ID 之外，也应该恢复保存的用户 ID。但是只有进程有特权时，setuid() 才能设置真实用户 ID 和保存的用户 ID。因此，如果一个 root 用户的 set-user-ID 程序想要永久放弃权限，需要：
用 seteuid() 恢复自己的身份为 root（如果之前暂时降低了自己的权限）。 然后再用 setuid(getuid()) 永久放弃权限（注意这里的 setuid 和前面的 seteuid 不同）。 对于非 root 用户，就没办法这么做了。
Linux 提供了非标准的 setreuid() 系统调用可以解决普通用户无法设置真实用户 ID 和保存的用户 ID 的问题，也更推荐使用。
其他建议很多，不好总结。
  </content></entry><entry><title>39 Capabilities</title><url>/the-linux-programming-interface/39-Capabilities/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  简介和进程凭证相似，Linux 的能力也有区分进程和文件的，它们都有许可集、有效集和继承集（内核 2.6.24 才实现了文件能力，老内核只有进程能力）。
进程能力集合：
许可集（CapPrm）: TODO 有效集（CapEff）: TODO 继承集（CapInh, inheritable）: TODO 可执行文件能力集合：
许可集: TODO 有效集: TODO 继承集: TODO 此外，进程还有边界集 CapBnd 和 CapAmb（ambient），在 /proc/PID/status 中可以看到。CapAmb 约束了非特权程序调用 exec() 之后能继续保持的能力，在 Linux 4.3 引入，因此书上没有提及。
进程的能力集合实际上是线程的属性，而不是进程的。通过 cat /proc/PID/status | grep -i ^cap 中查看到的能力集是进程主线程的能力集，而通过 cat /proc/PID/task/TID/status | grep -i ^cap 看到的是具体线程的能力集。
例子：ping 命令缺少权限ping 命令在安装后第一次使用时，可能会提示缺少权限，并提示：
ping: socktype: SOCK_RAW ping: socket: Operation not permitted ping: =&amp;gt; missing cap_net_raw+p capability or setuid? 可以根据提示使用 setcap 命令给 ping 增加 cap_net_raw 到许可集中：
sudo setcap cap_net_raw+p /bin/ping 有些教程写的是使用 =pe 而不是 =p（这里 = 和 + 是一样的，因为初始状态下 ping 没有任何权限），是指同样开启有效集标志，这样进程在从可执行文件启动的时候就会将许可集拷贝到有效集，不需要进程自己去检查。但是 ping 是处理了 capabilities 的，所以不需要打开 e 位。
也可以给 ping 命令增加 set-user-ID 标志位，Debian 系统中 /usr/bin/ 下的可执行文件都是属于 root 的，但是刚安装的时候可能没有 set-user-ID 标志。
  </content></entry><entry><title>35 进程优先级与实时调度</title><url>/the-linux-programming-interface/35-%E8%BF%9B%E7%A8%8B%E4%BC%98%E5%85%88%E7%BA%A7%E4%B8%8E%E5%AE%9E%E6%97%B6%E8%B0%83%E5%BA%A6/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  Nice 值范围是 +19~-20，越低优先级越高，默认值为 0。它会影响时间片轮转算法下进程分到的时间长度。
资源限制参数、系统调用的返回值等场景可能会对 nice 值做一些简单的变换，而不是直接使用 +19~-20 这个范围。 Nice 值可以通过系统调用设置、也有相关的命令。 实时优先级调度策略如下：
SCHED_OTHER SCHED_RR SCHED_FIFO SCHED_BATCH（Linux 2.6 增加，非标准） SCHED_IDLE（Linux 2.6 增加，非标准） 第 1 种是默认的时间片轮转策略，2、3 是实时调度策略，优先级都大于 SCHED_OTHER。SCHED_BATCH 和 SCHED_IDLE 也不是实时调度策略，调度方式和 SCHED_OTHER 类似：SCHED_BATCH 会导致频繁唤醒的任务调度次数减少，SCHED_IDLE 等价于一个非常低的 nice 值（比 +19 的优先级还要低）。
Linux 上实时优先级从 1 到 99 供 99 种，越高越优先（其他 UNIX 实现中的实时优先级取值范围可能不同，而且也不要求 SCHED_RR 和 SCHED_FIFO 使用相同的范围，但 Linux 等多数 UNIX 实现用的是同一个范围）。不管进程的调度策略是 SCHED_RR 还是 SCHED_FIFO，只要实时优先级相同，那它们就有相同的调度优先级。系统总是会优先调度高实时优先级的策略（可能有饥饿现象，而且存在抢占式调度），并为每个优先级都维护了专门的队列。
在多核操作系统中，不同的 CPU 核上有不同的调度队列，因而在 CPU 0 上调度的程序即便是比 CPU 1 上调度的程序更加优先，也必须在 CPU 0 上继续等待前面的程序。
SCHED_RR 调度策略还是用的时间片轮转，区别是有高实时优先级。区别：如果都使用 SCHED_OTHER 调度策略，那么优先级较低的进程也总能有机会获取到 CPU。
使用 SCHED_RR 调度策略的进程会失去 CPU 的情况：
时间片用完 自愿放弃 CPU（可能是由于执行了一个阻塞式系统调用或调用了 sched_yield() 系统调用） 终止 被优先级更高的进程抢占 在前两种情况下，进程会回到同一个优先级的调度队列的队尾。在被高优先级进程抢占的时候，进程会保留其位置，等高优先级 …  </content></entry><entry><title>34 进程组、会话和作业控制</title><url>/the-linux-programming-interface/34-%E8%BF%9B%E7%A8%8B%E7%BB%84%E4%BC%9A%E8%AF%9D%E5%92%8C%E4%BD%9C%E4%B8%9A%E6%8E%A7%E5%88%B6/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  进程组进程组和会话的作用进程组和会话的主要作用是 shell 的作业控制。一个以 ;（或者什么都没有）结尾的命令会启用一个前台进程组，一个以 &amp;amp;amp; 结尾的命令会启用一个后台进程组。在终端（窗口环境中的控制终端实际上是一个伪终端）中键入特殊字符发送信号时，信号会发给前台进程组的中的所有进程。
通常 shell 和 login(1) 会通过系统调用设置进程组和会话号。
进程组获取 / 设置的 API可以通过 pid_t getpgrp(void) 获得当前进程的进程组 ID，通过 setpgid(pid, pgid) 来设置给定进程的进程组 ID。这两个函数的后缀不同，是因为历史原因。
对于 setpgid，如果两个参数指定了同一个进程，那么就会创建一个新的线程组；否则，指定的进程会被移动到给定的线程组中。pid 参数只能用来指定调用进程和其中一个子进程，而 pgid 参数必须是会话中的进程。另外，一个进程在子进程执行 exec() 之后就不能对其设置进程组 ID 了。
在作业控制 shell 中设置进程组一个任务（即一个命令或一组以管道符连接的命令）中的所有进程必须被放置在一个进程组中。实际上 shell 进程需要将其他任务的进程组号设置为第一个任务的进程号。
同时，由于我们不清楚 fork() 之后父子进程的调度顺序，所以我们在 fork() 后的父进程和子进程后都要对子进程设置进程组号，并在父进程中忽略 EACCES 错误（因为子进程可能已经执行了 exec()）。在父进程中也要设置子进程的进程组号，可能是因为父进程后面的逻辑还会依赖进程组的使用。
会话获取会话 ID会话是进程组的集合。通过系统调用 getsid(pid) 可以获得进程号为 pid 的进程的会话号。少数系统上只有当前进程和给定的进程处于同一个会话当中时，才能获取给定进程的会话 ID，在 Linux 上没有这个限制。
创建新的会话使用无参的 setsid() 函数可以创建一个新的会话。这个函数在命名上有点奇怪，尽管它的名字中带有 set，但并不代表会用参数去设置会话 ID，反而是创建了新的会话。
用 setsid() 创建新会话后，调用进程会成为会话和进程组中的首个进程。正因此，如果调用进程已经是进程组的首个进程，那么 setsid() 系统调用就会报错（设想进程组的组长都跑了， …  </content></entry><entry><title>GNU 扩展语法：带有返回值的多语句表达式</title><url>/posts/programming/cpp/GNU-%E6%89%A9%E5%B1%95%E8%AF%AD%E6%B3%95%E5%B8%A6%E6%9C%89%E8%BF%94%E5%9B%9E%E5%80%BC%E7%9A%84%E5%A4%9A%E8%AF%AD%E5%8F%A5%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url><categories/><tags><tag>gcc</tag></tags><content type="html">  https://godbolt.org/z/vo195MYGj
int main() { return ({ 1; }); } 以上代码返回 1。在花括号中写多条语句都没关系。
  </content></entry><entry><title>29.3 用 `kill` 发送信号给特定线程的尝试</title><url>/the-linux-programming-interface/29.3-%E7%94%A8-kill-%E5%8F%91%E9%80%81%E4%BF%A1%E5%8F%B7%E7%BB%99%E7%89%B9%E5%AE%9A%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%B0%9D%E8%AF%95/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  线程号在整个系统是唯一的，而 kill 命令也疑似可以精准发送信号给目标线程（见下方代码的测试 1；测试时只保留测试 1 和 2 其中一个，注释掉另外一个）。特殊情况：
当目标线程已经是僵尸的时候，则会将信号发给同组的其他线程。见测试 2。 如果线程正常退出，也被系统正常回收了资源（不是僵尸），那么 kill 就会报错（因为没有这个线程了，也不可能找到它的线程组），如 bash: kill: (23196) - No such process。在很极端的情况下，这个 PID 被其他进程使用了，kill 会将信号发给不相关的进程。但是由于 Linux 以循环递增的方式重用 PID，这需要相当长的时间，一般不会遇到这种情况。 #define _GNU_SOURCE #include &lt;pthread.h&gt; #include &lt;signal.h&gt; #include &lt;stdio.h&gt; #include &lt;unistd.h&gt; // Not portable since gettid is only on Linux. unsigned long get_thread_id(void) { return (unsigned long)gettid(); } void *f(void *arg) { fprintf(stderr, &#34;Thread %lu starts\n&#34;, get_thread_id()); for (;;) { pause(); fprintf(stderr, &#34;Thread %lu is awoken\n&#34;, get_thread_id()); pthread_exit(NULL); } fprintf(stderr, &#34;Thread %lu but shouldn&#39;t reached here\n&#34;, get_thread_id()); return NULL; } void chld_handler(int sig) { // (f)printf is not async-signal-safe, but I use it for testing. fprintf(stderr, &#34;Handler thread is %lu\n&#34;, get_thread_id()); } int main() { fprintf(stderr, &#34;Main thread is %lu\n&#34;, get_thread_id()); // 因为 SIGCHLD 的默认行为是忽略，所以不设置信号处理器函数，SIGCHLD 就不会让 thread1 从 pause() 返回。 struct sigaction action; action.sa_handler = chld_handler; sigset_t signals_blocked; sigfillset(&amp;signals_blocked); action.sa_mask = signals_blocked; action.sa_flags = 0; if (sigaction(SIGCHLD, &amp;action, NULL) != 0) { perror(&#34;sigaction&#34;); return 1; } pthread_t thread1; pthread_create(&amp;thread1, NULL, f, NULL); // 测试 1：让主线程去等待 thread1，通过 htop 可以发现两个线程都活着。以两个线程之一的 PID 为参数发送 SIGCHLD // 信号，会使得对应的线程处理这个信号。 pthread_join(thread1, NULL); // 测试 2：让主线程先退出，只有 thread1 活着，这个时候无论是根据两个线程中的哪一个发送信号，都是由活着的 thread1 // 处理。但为什么主线程退出后会成为僵尸？ // pthread_detach(thread1); // pthread_exit(NULL); // 主线程结束后不会再处理信号 } 主线程为什么退出后成为僵尸？为什么我不能成功对主线程 join 或者 detach 以在其终止后回收资源（不再是僵尸）？
在 https://stackoverflow.com/questions/11130828/after-main-thread-call-pthread-exit-it-turn-into-zombie-something-wrong 中，有人解释：
From my understanding on how the pthreads library works, I believe that the reason for the zombie thread is that joining normally with the main thread would throw away its resources and since the main thread returns a status (through the return of the main function) that could and in some cases is expected to be consumed by the parent process (i.e., through the use of wait), this thread cannot be completely destroyed until the thread group has exited entirely (i.e., that the whole process has exited). If it was somehow allowed to return the value of the pthread_exit call to the parent process then the parent would think that the child had exited which wouldn&rsquo;t be true, since the PrintHello function would be still running.
因为主线程和进程同 PID，而其资源要留着等其父进程回收，所以在主线程退出、但其他线程没有退出时，保持主线程为僵尸的状态，在其结束前使用 pthread_detach() 或结束后使用 pthread_join() 都不会回收它的资源。
相关链接：
https://www.bo-yang.net/2014/11/20/pthread_exit-in-main https://linux.kernel.narkive.com/i5fs92OF/main-thread-pthread-exit-sys-exit-bug   ]]></content></entry><entry><title>32 线程取消</title><url>/the-linux-programming-interface/32-%E7%BA%BF%E7%A8%8B%E5%8F%96%E6%B6%88/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  API#include &amp;lt;pthread.h&amp;gt; int pthread_cancel(pthread_t thread); 线程取消状态和线程取消类型它们分别可以用 pthread_setcancelstate 和 pthread_setcanceltype 来设置。
#include &amp;lt;pthread.h&amp;gt; int pthread_setcancelstate(int state, int *oldstate); int pthread_setcanceltype(int type, int *oldtype); 调用 fork() 或者 exec() 时线程的行为某线程调用 fork() 时，子进程会继承当前线程的取消类型和状态。某线程调用 exec() 时，新程序主线程的取消类型和取消状态都会被重置。解释：
多线程程序调用 fork() 之后，新进程中只会留下一个线程，大概这个新线程的有些属性会从 fork() 的调用者线程继承。根据 man 手册：
The child process is created with a single thread—the one that called fork(). The entire virtual address space of the parent is replicated in the child, including the states of mutexes, condition variables, and other pthreads objects; the use of pthread_atfork(3) may be helpful for dealing with problems that this can cause.
这个表现应该和“Linux 中线程被实现为一种特殊的进程”有关系。
而调用 exec() 会重新加载进程映像，从而会终止所有已存在的线程。
线程取消状态线程取消状态有两种，一种是可以取消（默认状态，PTHREAD_CANCEL_ENABLE），一种是不可以取消（PTHREAD_CANCEL_DISABLE）。如果线程不可以取消，那么尝试取消一个线程的另外一个线程就会被挂起，直到线程的取消状态被其他线程设置为可以取消。
线程取消类型如果线程是 …  ]]></content></entry><entry><title>33 线程的更多细节</title><url>/the-linux-programming-interface/33-%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%9B%B4%E5%A4%9A%E7%BB%86%E8%8A%82/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  主要内容线程和传统 UNIX API 之间的交互（信号、进程控制原语） Linux 上的两个线程实现 线程栈的大小在 x86_64-linux-gnu 上，除了主线程，其他线程的缺省大小都是 2MB。
Tip
2025/3/8 省流：
缺省：主线程一般 8MB（ulimit -s 看，单位是 KB 不是 B），非主线程缺省 2MB。 最小：16KB。 参考：Go 中协程最小栈大小是 2KB。
// https://go.dev/src/runtime/stack.go#L74 // The minimum size of stack used by Go code stackMin = 2048 设置线程栈的大小为了设置线程栈的大小，需要在创建线程前构建一个线程属性（pthread_attr_t），然后将其作为 pthread_create 的参数。
可以使用 pthread_attr_setstacksize() 设置线程栈的大小。 也可以用 pthread_attr_setstack() 同时设置线程栈的大小和地址，但是这样做会损害可移植性。 获取线程栈大小的限制其实我们常常希望线程的栈更小一点，因为我们需要创建更多的线程！假设有 3GB 的虚拟地址空间，2MB 的线程栈大小意味着我们最多只能创建 1500 个线程。
我们可以用 sysconf(_SC_THREAD_STACK_MIN) 来获取线程最小的栈大小，在 Linux/x86-32 上的 NPTL，这个值测出来是 16384，也就是 16K。
我自己测试发现，虽然头文件中有定义 _SC_THREAD_STACK_MIN 这个最小值参数，但是没有定义最大值参数，也就是说不能用 sysconf() 查到线程栈大小的最大限制。另外，sysconf(_SC_THREAD_THREADS_MAX) 的结果是 -1，同时 errno 没有被置为非 0 值，说明进程的线程数不明确设限。
限制子进程的线程栈大小可以在 shell 中使用 ulimit -s 来设置线程栈的字节数（我本地试了一下返回的是 8192）。在 main() 函数中使用 setrlimit() 来设置线程栈的资源限制可能行不通，因为线程在进入 main() 函数之前就已经创建了。
为什么这个 8192 …  </content></entry><entry><title>33.1 能不能用 kill(1) 给特定线程发送信号呢？</title><url>/the-linux-programming-interface/33.1-%E8%83%BD%E4%B8%8D%E8%83%BD%E7%94%A8-kill1-%E7%BB%99%E7%89%B9%E5%AE%9A%E7%BA%BF%E7%A8%8B%E5%8F%91%E9%80%81%E4%BF%A1%E5%8F%B7%E5%91%A2/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  用 kill 发送信号给特定线程的尝试 这篇文章提到了用 kill(1) 给特定的线程发送信号，但是标准上没有说这样是可行的。因此这篇文章探讨一下为什么 kill(1) 会具有这样的行为。以下阅读的代码都是在 2024 年 7 月 12 日 的主分支上的最新代码。
kill(1) 的实现这里 是 kill 命令实现的关键部分，其中只调用了 kill() 系统调用。所以可以排除是 kill(1) 自己处理了发送信号给特定线程的过程。
kill(2) 在 glibc 中没有实现kill 系统调用是需要链接 libc 的，其声明的头文件也是在 signal.h 中，因此我们需要先看 glibc 的源码。
在 glibc 源码中没有找到 kill() 对 Linux 系统调用的包装。只有一个 __kill() 的空实现（总会设置 errno 为 ENOSYS 并返回 -1）并将其声明为 kill 的弱别名（使用 weak_alias 宏）。（对于某些架构，比如 hurd，会提供 kill() 的实现，可能是这些系统上没有 kill 系统调用）。因此，kill 系统调用是直接在 Linux 内核中实现的。
Linux kernel 中对 kill(2) 的实现tkill() 和 tgkill()首先看下 tkill() 和 tgkill() 的实现，方便和 kill() 做下对比。在 Linux 源码中，kernel/signal.c 中有 tkill() 和 tgkill() 的定义，它们都调用了 do_tkill()。
static int do_tkill(pid_t tgid, pid_t pid, int sig) { struct kernel_siginfo info; prepare_kill_siginfo(sig, &amp;amp;amp;info, PIDTYPE_PID); return do_send_specific(tgid, pid, sig, &amp;amp;amp;info); } 这些函数中的 pid 是作为线程 id 用的，pid 的枚举定义为：
enum pid_type { PIDTYPE_PID, PIDTYPE_TGID, PIDTYPE_PGID, PIDTYPE_SID, PIDTYPE_MAX, }; 然 …  </content></entry><entry><title>31 线程特有数据（TSD）和线程局部存储（TLS）</title><url>/the-linux-programming-interface/31-%E7%BA%BF%E7%A8%8B%E7%89%B9%E6%9C%89%E6%95%B0%E6%8D%AETSD%E5%92%8C%E7%BA%BF%E7%A8%8B%E5%B1%80%E9%83%A8%E5%AD%98%E5%82%A8TLS/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  TSD 和 TLS 都属于每线程存储（Per-Thread Storage）。
仅初始化一次#include &lt;pthread.h&gt; pthread_once_t once_control = PTHREAD_ONCE_INIT; int pthread_once(pthread_once_t *once_control, void (*init_routine) (void)); 线程特有数据（Thread-Specific Data）在 C11 之前，thread_local 变量是不受到语言支持的，因此为了创建线程特有数据就只能用相关的 API。
Pthreads 系列的特有数据 API 看起来很难用：
#include &lt;pthread.h&gt; int pthread_key_create(pthread_key_t *key, void (*destr_function) (void *)); int pthread_key_delete(pthread_key_t key); int pthread_setspecific(pthread_key_t key, const void *pointer); void * pthread_getspecific(pthread_key_t key); Pthreads API 为每个线程维护了一张数据表。每个数据项是一个数据指针和一个析构函数指针。表的长度也是有限的，可用 _SC_THREAD_KEYS_MAX 查到。我这里查出来是 1024（Linux 上是这个值）：
#include &lt;errno.h&gt; #include &lt;stdio.h&gt; #include &lt;unistd.h&gt; int main() { errno = 0; long ret = sysconf(_SC_THREAD_KEYS_MAX); int err = errno; if (ret == -1 &amp;&amp; err != 0) { perror(&#34;sysconf&#34;); } else if (ret == -1) { printf(&#34;no limit\n&#34;); } else { printf(&#34;limit is %ld\n&#34;, ret); // 1024 } } 用 pthread_key_create() 创建的每个键实际上是对应了一个下标，用来在每个线程各自的表中去索引数据。之所以要设计成键而不是直接用下标，可能和要存储析构函数有关？在线程结束的时候，相应的析构函数会被调用，以保证数据的正确释放。如果数据项是 NULL（这也是所有数据项的初始值），则不会调用析构函数。
有点奇怪的是，pthread_key_delete() 会将对应的 key 清除，却不管对所有线程的数据的析构。
在创建线程之前就使用 pthread_key_create() 来创建键是一件比较麻烦的事情。所以 pthread_key_create() 经常会使用 pthread_once()。而 pthread_once_t 类型的标志则一般是一个全局的、函数里面可以访问到的标志。书中有个例子是使用 pthreads API 来实现一个线程安全的 strerror() 函数（非线程安全的 strerror() 函数是将结果放在一个全局数组中返回，每次调用都会修改全局数组）。
线程局部存储（Thread-Local Storage）用起来比 TSD 更简单，只需要在全局或静态变量的定义处加上 __thread 说明符。
线程局部存储需要内核（由 Linux 2.6 提供）、Pthreads 实现（由 NPTL 提供）以及 C 编译器（在 x86-32 平台上由 gcc 3.3 或后续版本提供）的支持。
C 语言标准的支持在 C11 之前，语言级别并没有支持线程局部存储，__thread 是 GNU 的扩展功能。
在 C11 中有了 TLS 的支持，thread_local 成为一个宏，被定义为 _Thread_local（关键字），C23 的时候 thread_local 成为关键字（也可能同时是一个预定义宏）。
效率https://stackoverflow.com/a/32246896/
不会被翻译成对 TSD 的调用，且比 TSD 要快。
TLS is implemented both on i386 and amd64 Linux with a segment register (%fs for i386, %gs for amd64). The speed difference is negligible. &ndash;fuz
如上文，这很像 C++ 虚函数依靠变化的虚表指针和不变的表内下标来实现多态。
  ]]></content></entry><entry><title>30 线程同步</title><url>/the-linux-programming-interface/30-%E7%BA%BF%E7%A8%8B%E5%90%8C%E6%AD%A5/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  互斥量互斥量 API为了在 man 手册中看到这些内容，Debian 系统应该安装 glibc-doc 包。
#include &amp;amp;lt;pthread.h&amp;amp;gt; pthread_mutex_t fastmutex = PTHREAD_MUTEX_INITIALIZER; pthread_mutex_t recmutex = PTHREAD_RECURSIVE_MUTEX_INITIALIZER_NP; pthread_mutex_t errchkmutex = PTHREAD_ERRORCHECK_MUTEX_INITIALIZER_NP; int pthread_mutex_init(pthread_mutex_t *mutex, const pthread_mutexattr_t *mutexattr); int pthread_mutex_lock(pthread_mutex_t *mutex); int pthread_mutex_trylock(pthread_mutex_t *mutex); int pthread_mutex_unlock(pthread_mutex_t *mutex); int pthread_mutex_destroy(pthread_mutex_t *mutex); 应该使用 PTHREAD_MUTEX_INITIALIZER、PTHREAD_RECURSIVE_MUTEX_INITIALIZER_NP、PTHREAD_ERRORCHECK_MUTEX_INITIALIZER_NP 之一，或者 pthread_mutex_init() 来初始化一个互斥量。只有 PTHREAD_MUTEX_INITIALIZER 是标准的，另外两个都是 Linux 提供的非标准的宏。
虽然书上说前者是用来初始化静态分配的互斥量的，但是没有实现禁止用其初始化在堆上分配的互斥量，也无法确定“静态分配”指的是有稳定地址还是一定要分配在静态数据存储区。另外，前面几个宏只能使用默认的属性，想要对属性进行更加精细的控制，则需要使用 pthread_mutex_init()。
初始化一个已经初始化过的互斥量是 UB。
当互斥量不再被需要时，应该使用 pthread_mutex_destroy 将其销毁。书上说只有互斥量属于未锁定状态时销毁它才是安全的。
互 …  </content></entry><entry><title>29.1 线程共享了什么、私有数据是什么？</title><url>/the-linux-programming-interface/29.1-%E7%BA%BF%E7%A8%8B%E5%85%B1%E4%BA%AB%E4%BA%86%E4%BB%80%E4%B9%88%E7%A7%81%E6%9C%89%E6%95%B0%E6%8D%AE%E6%98%AF%E4%BB%80%E4%B9%88/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  线程共享了什么？实际上就是 clone() 用于支持线程的标志 中的那些标志提到的内容。以下抄书：
除了全局内存之外，线程还共享了一些其他属性（这些属性对于进程而言是全局性的， 而并非针对某个特定线程），包括以下内容。
进程 ID（process ID）和父进程 ID。 进程组 ID 与会话 ID（session ID）。 控制终端。 进程凭证（process credential）（用户 ID 和组 ID ）。 打开的文件描述符。 由 fcntl() 创建的记录锁（record lock）。 信号（signal）处置。 文件系统的相关信息：文件权限掩码（umask）、当前工作目录和根目录。 间隔定时器（setitimer()）和 POSIX 定时器（timer_create()）。 系统 V（system V）信号量撤销（undo，semadj）值（47.8 节）。 资源限制（resource limit）。 CPU 时间消耗（由 times() 返回）。 资源消耗（由 getrusage() 返回）。 nice 值（由 setpriority() 和 nice() 设置）。 2025/3/8 总结一下，希望好记一点：
内存：共享虚拟地址空间。 一组标识：pid/ppid/pgid/sid、进程凭证（uid 和 gid）。 文件：文件描述符、文件记录锁、cwd、umask 进程交互：sysv 信号量、控制终端（算是进程交互吧？因为有控制终端代表着有其他进程来控制） 信号和时间：信号处理方式、定时器 资源分配和调度：资源限制 rlimit、CPU 时间 / 资源消耗的统计信息、nice 值 从另外一个角度考虑，线程共享了什么可以看 clone() 用于支持线程的标志。
线程的私有数据是什么？书中列举了一部分：
线程 ID（thread ID，29.5 节）。 信号掩码（signal mask）。 线程特有数据（31.3 节）。 （thread local?） 备选信号栈（sigaltstack()）。 errno 变量。 浮点型（floating-point）环境（见 fenv(3)）。 实时调度策略（real-time scheduling policy）和优先级（35.2 节和 35.3 节）。 CPU 亲和力（affinity，Linux 所特有，35.4 节将加以描述）。 能力（capability，Linux 所特有，第 39 章将加以描述）。 栈，本地变量和函数的调用链接（linkage）信息（calling convention 的一些东西）。   </content></entry><entry><title>29.2 线程创建</title><url>/the-linux-programming-interface/29.2-%E7%BA%BF%E7%A8%8B%E5%88%9B%E5%BB%BA/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  pthread_t 类型在 Linux 中是个整数（unsigned long），NPTL 将其强制转换成指针。将其解释为整数或指针是不可移植的，在其他平台上，此类型可能是某个结构体。
Pthreads 线程的终止如何影响进程的终止？在 Linux 中，要让一个进程终止，需要让它的所有（包括 detach 的）线程都终止。怎么理解包括 detach 的线程也要终止呢？如果一个线程被 detach，但是它还在运行过程中，使用了进程的资源，因此进程就不能终止。这和 C++ 的 std::thread API 的 detach 含义有点不同，后文会解释。
使用 exit() 退出程序就会终止所有的线程（从 main() 返回则 C 语言运行时会调用 exit()）。这其实给进程保持运行增加了一个隐含的条件：主线程不能从 main() 函数中返回。Pthreads API 的确有绕开这一条件的方法，用 pthread_exit(NULL) 来退出主线程，则进程不会直接退出，而是会等待其他线程都结束、或任意线程调用 exit()。
Note
注意返回和退出的区别。
Pthreads API 提供了 pthread_detach() 和 pthread_join() 两个函数。前者使得一个线程被标识为 detached，其信息不会被保留、不可 join，而且在终止后会自动被系统回收（有点像设置 SIGCHLD 的处理方式为 SIG_IGN）。后者则是等待一个线程结束并获取其信息（有点像用于进程等待的 waitpid() 系统调用）。两者都只能在 joinable pthreads 上调用，调用一次之后 pthreads 就不再 joinable，再次调用以上两个函数之一是未定义行为，比如同样的线程标识符可能被其他线程重用，导致操作的线程变了。
Caution
固然可以在线程调用 pthread_exit() 前通过 pthread_detach(pthread_self()) 将自己设置为 detached 来保证资源的正常回收，但是这样会使得等待这个线程的行为变得未定义。所以最好不要用这种模棱两可的做法，在创建线程的时候就要确定好这个线程的用途，以及它是要 detach 还是要被 join。
验证已经 detach 的线程还在运行时，也会阻止主进程退出#include …  </content></entry><entry><title>torch 分布式程序产生僵尸进程</title><url>/posts/programming/python/torch-%E5%88%86%E5%B8%83%E5%BC%8F%E7%A8%8B%E5%BA%8F%E4%BA%A7%E7%94%9F%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B/</url><categories/><tags><tag>torch</tag><tag>python</tag></tags><content type="html">  聊天记录：
A torch 的分布式程序在一些异常结束的情况下会留下一些僵尸进程 我之前经常是这样 你 kill 掉主进程子进程不会被回收
B 为什么没有会回收？因为父进程没死且没有被回收，难道父进程不是 torch 的主进程，而是整个容器里面的一个活跃进程？ 不在容器里使用是否不会出现这种情况？ 如果父进程死了，应该由 init 回收 是否是因为容器的起始进程不是 init
A 不知道
B 是在容器中吗
A 不是
关联：
NVIDIA 显卡显存占用高但是 nvidia-smi 查不到 验证父进程被杀死后僵尸会被 init 进程收养 Python 多进程脚本的常见问题 26 监控子进程 wait() 论坛帖子 PyTorch doesn&amp;rsquo;t free GPU&amp;rsquo;s memory of it gets aborted due to out-of-memory error - PyTorch Forums 有 PyTorch 开发者回答是 Python 的 multiprocessing 模块有 bug，可能会导致僵尸进程。
@rabst so, I remember this issue. When investigating, we found that there’s actually a bug in python multiprocessing that might keep the child process hanging around, as zombie processes. It is not even visible to nvidia-smi.
The solution is killall python, or to ps -elf | grep python and find them and kill -9 [pid] to them.
根据网上的说法：Python 是使用子进程而不是线程来实现 multiprocessing 模块的，因为 CPython 有 GIL 的限制，这使得不同的线程不能同时解释 Python 字节码。
multiprocessing 和 subprocess 模块的比较：前者还是使用 Python 解释器来执行 Python 代码，进程通信的过程是透明化的；后者则是启动其他命令或程序。
  </content></entry><entry><title>28 进程的创建和执行过程</title><url>/the-linux-programming-interface/28-%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%88%9B%E5%BB%BA%E5%92%8C%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  记账记账功能打开后，系统会在每个进程结束后记录一条账单信息。标准工具 sa(8) 对账单文件进行汇总，lastcomm(1) 则就先前执行的命令列出相关信息。
Tip
Linux 系统的进程记账功能属于可选内核组件，可以通过 CONFIG_BSD_PROCESS_ACCT 选项进行配置。 在 Debian 上，需要使用 apt install acct 来安装（否则 man 8 sa 和 which lastcomm 都找不到）。
特权进程可以使用 acct 系统调用来打开或关闭记账功能，应用程序则很少使用到这种调用。
系统调用 clone()clone() 的地位和 fork()、vfork() 一样，它们在内核中都是用 do_fork() 来实现的，但是它能支持比后两个函数更加精细的控制，因此也被用作线程实现的方式。我们一般使用的 clone() 是 glibc 的包装函数，它和内核提供的 SYS_clone 系统调用有一点差异。
/* Prototype for the glibc wrapper function */ #define _GNU_SOURCE #include &amp;amp;lt;sched.h&amp;amp;gt; int clone(int (*fn)(void *_Nullable), void *stack, int flags, void *_Nullable arg, ... /* pid_t *_Nullable parent_tid, void *_Nullable tls, pid_t *_Nullable child_tid */ ); clone() 的 stack 参数用来指定子进程要使用的栈空间。其实现假设了栈是向下生长的。在 Linux 中，仅有很少见的硬件的栈是向上生长。
clone() 的 flags 参数有两个用途：
flags 的低字节存放了子进程的终止信号，表示子进程终止之后要向父进程发送什么样的信号，在 fork() 和 vfork() 中无法指定子进程终止信号，相当于这个信号只能是 SIGCHLD。 其他字节可以用来存放控制进程创建行为的标志。有不少标志都是内核内部使用的，不是开放给用户程序用的。还有些标志是为了支持线程提供的，有些则是为了支持容器（轻量级虚拟化的一种形式）提供的。 NTPL 线程实现占用了 2 个实时信 …  </content></entry><entry><title>对 CMake 构建类型 CMAKE_BUILD_TYPE 的考量</title><url>/posts/cli/cmake/%E5%AF%B9-CMake-%E6%9E%84%E5%BB%BA%E7%B1%BB%E5%9E%8B-CMAKE_BUILD_TYPE-%E7%9A%84%E8%80%83%E9%87%8F/</url><categories/><tags/><content type="html">  参考https://stackoverflow.com/a/59314670/
https://cmake.org/cmake/help/latest/variable/CMAKE_BUILD_TYPE.html 的解释：
Specifies the build type on single-configuration generators (e.g. Makefile Generators or Ninja). Typical values include Debug, Release, RelWithDebInfo and MinSizeRel, but custom build types can also be defined.
Stack Overflow 回答里提到的 BetaTest 等其他构建类型应该就是上面所说的 custom build types.
在尽可能复现错误的情况下调试使用 RelWithDebInfo？考虑编译器 gcc 或者 clang：
RelWithDebInfo：-O2 -g -DNDEBUG Release: -O3 -DNDEBUG 这样来看这两个选项的优化等级还是有区别的。
我觉得是因为 -O3 使用了大量空间换时间的优化方式，对应到源码上不好调试，所以 RelWithDebInfo 才没有用 -O3。虽然优化等级不一样，但是（如果相信编译器绝对不会有 bug）后者出现的错误在前者大概率也能复现？
在 MSVC 上，优化等级还是 /O2，但是内联等特殊的优化选项会降级。
使用自定义构建类型比如 -O3 -g 来代替 -O3 -DNDEBUG。
  </content></entry><entry><title>对键盘的碎碎念</title><url>/posts/life/%E5%AF%B9%E9%94%AE%E7%9B%98%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5/</url><categories/><tags><tag>键盘</tag><tag>日常</tag></tags><content type="html">  说明这里放的是我觉得没有必要专门写一篇文章的内容。
2024-07-06V75K 不同的键有点高低不一致了，怀疑是定位板被我弄的不平了。数字 5、6、7、8 这几个位置不仅突起，而且手感还偏硬，估计是下面有电池（这同时意味着这个地方不应该再使劲按下去了，可能不安全）；回车的位置下陷了，我觉得是装键帽使劲按回车导致的。
2024-07-07鲸海轴一定要对准孔位小心插入。和其他轴体清脆一声按下去就是插好了不同，鲸海轴听到清脆一声按下去了可能是方向不正，有可能针脚都跪了。我已经跪两颗了。 卫星轴是调不好的，只有放弃强迫症安心用键盘。 2024-07-10鲸海轴还是太重了，换回阿尼亚轴了。昨天晚上把键盘里面也拆了，定位板是有一点变形，怪不得键帽高高低低的。调是调不好了。又在可乐蛙的店铺买了特氟龙和空格卫星轴，其他店铺一般都是多个 2U 和一个 6.25U 捆绑销售的，这个店铺可以单买。
2024-07-13还是觉得因为定位板变形导致键帽高低不平看着难受，下次换钢板定位板算了。 最好选准轴体不要自己换了。 避开短行程轴体的键盘。厂家可能为了更好的效果使用短行程的卫星轴，自己换长行程的轴体时大键按下去就会有异样的感觉。我的 V75K 大概率用的就是短行程卫星轴。我试了一下用 3.5±0.4mm 的鲸海轴和 3.5mm 的卫星轴（单独买的，不知道 V75K 标配卫星轴多长键程）也会有卡涩的感觉，说明轴体应该明显小于卫星轴键程。 2024-07-14不只是我的 V75K，就连我的 IKBC 也变形了。看来键盘都挺容易变形的，装进书包的时候要小心。然后现在觉得靠近红轴的参数可能比较舒服一点，尤其是始发压力选个 30gf 左右的。
2025-01-13量产键盘买回来千万不要换轴换键帽！卫星轴太容易出问题了。 今天发现 V75K 的蓝牙连接超快，显著快于 Nuphy Air75 V2，因为蓝牙连接本来就只要几秒，所以之前还没有注意到过。 2025-01-17发现 Nuphy Air75 V2 蓝牙连接其实也不是特别慢，其实已经连上了，只是指示灯延迟了一两秒才变。可能是固件设定了要用灯条显示足够长时间的信息。这点还是有点烦的。
  </content></entry><entry><title>利用 ssh-agent 在两个服务器之间传输文件</title><url>/posts/cli/ssh/%E5%88%A9%E7%94%A8-ssh-agent-%E5%9C%A8%E4%B8%A4%E4%B8%AA%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B9%8B%E9%97%B4%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6/</url><categories/><tags><tag>ssh</tag></tags><content type="html">  eval $(ssh-agent -s) ssh-add ~/.ssh/id_ed25519 # 根据实际情况操作 ssh -A server1 scp server2:/data /data 由于 sever1 可能没有把 server2 作为主机存储，在 scp 的时候需要输入一长串的用户名、主机、端口。
  </content></entry><entry><title>27 进程的执行 exec()</title><url>/the-linux-programming-interface/27-%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%89%A7%E8%A1%8C-exec/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  exec() 函数SYNOPSIS #include &amp;amp;lt;unistd.h&amp;amp;gt; extern char **environ; int execl(const char *pathname, const char *arg, ... /*, (char *) NULL */); int execlp(const char *file, const char *arg, ... /*, (char *) NULL */); int execle(const char *pathname, const char *arg, ... /*, (char *) NULL, char *const envp[] */); int execv(const char *pathname, char *const argv[]); int execvp(const char *file, char *const argv[]); int execvpe(const char *file, char *const argv[], char *const envp[]); /* GNU 扩展 */ /* 不知道为什么单独出来一个手册页，和上面没有放在一起？ */ int execve(const char *pathname, char *const _Nullable argv[], char *const _Nullable envp[]); 函数命名规则：
其中 exec 前缀是一定有的。 然后用 l（va_list 形式）或者 v（数组形式）表示命令行参数，这也是一定有的。 （可选）如果允许在 PATH 中搜索（可执行）文件，而不是用绝对或相对路径搜索文件，则有 p 后缀。 （可选）如果允许（以字符串数组的形式）设置环境变量，则有 e 后缀。 如果在设置环境变量的 exec() 系列系统调用中没有提及 PATH 环境变量，则使用默认 PATH。根据系统不同，默认的 PATH 可能不同，常见的 PATH 是 .:/usr/bin:/bin。处于安全考虑，特权用户的 PATH 中常常没有 .（当前工作目录）。
If this variable isn&amp;amp;rsquo;t defined, the path list defaults to a list that …  </content></entry><entry><title>less 大小写不敏感搜索、过滤</title><url>/posts/cli/common/less-%E5%A4%A7%E5%B0%8F%E5%86%99%E4%B8%8D%E6%95%8F%E6%84%9F%E6%90%9C%E7%B4%A2%E8%BF%87%E6%BB%A4/</url><categories/><tags><tag>linux</tag><tag>vim</tag><tag>less</tag></tags><content type="html">  启用标记（例子：大小写不敏感搜索）- 加上其他字符。比如 -i 表示开关大小写敏感搜索（ignore case in searches）。但是，这只对全小写的输入有用，如果查询的词中包含大写字母、又想要大小写不敏感搜索，则需要使用 -I（ignore case in searches and in patterns）。
这些标记不仅可以从命令行选项中设置，还能从 LESS 环境变量中读取，当然也能像上一段所说的那样在 less 已经打开后设置。Man 手册打开的 less 分页器似乎就是带有 -i 标志的。
Tip
在我的电脑上 vim 的 / 默认是大小写敏感，而 less 是默认带有 -i 标志。有些老的电脑上面 less 可能需要自己加标志。
如果想要在 vim 中使用大小写不敏感搜索，需要在搜索条目中加上 \c 转义，这个标志可以加在搜索条目的任何位置，参考 https://stackoverflow.com/a/2287449/ 。还有一种方式使用命令 :set ic 开启大小写不敏感搜索。
过滤行先按 &amp;amp;（而不是 /）可以将输出过滤，只显示匹配的行。
  </content></entry><entry><title>25 进程的终止 exit()、_exit()</title><url>/the-linux-programming-interface/25-%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%BB%88%E6%AD%A2-exit_exit/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  _exit() 系统调用虽然参数是 int 类型，但是只有低 8 位可用。而且由于终端中用信号值 + 128 表示进程因信号退出的状态码（$?），所以最好也不要使用超过 127 的退出值。
exit() 函数会做这几件事：
执行退出处理程序，这些程序是用 atexit() 和 on_exit() 注册的。 刷新 stdio 流缓冲区。 调用 _exit()。 由于在执行退出处理程序时，main() 函数已经退出，所以退出处理函数不能使用 main() 函数中定义的变量。
如果用户程序没有调用 _exit() 和 exit()，并正常从 main() 函数中返回，则使用 main() 函数的返回值作为对 exit() 调用时传入的参数，这个过程是由运行时函数处理的。如果 main() 函数没有显式提供返回值，则在 C89 中属于未定义行为，在 C99/C++ 中会隐式返回 0。
退出处理程序退出处理程序注册函数有两种，一个是 atexit()，一个是 on_exit()。后者是 glibc 提供的、非标准的，但是参数的信息更多。
退出处理程序的特点：
如果用户显式调用了系统调用 _exit()，那么就没有调用退出处理程序的过程。 进程能够注册多个退出处理程序，其调用顺序和注册顺序相反。SUSv3 规定一个进程应该至少能注册 32 个退出处理程序，允许的最大值也能通过 sysconf() 查到，在 glibc 中是近乎无限制的。 如果退出处理程序调用 exit()，则结果未定义。 通过 fork() 创建出的子进程会继承退出处理程序。但是 exec() 会将退出处理程序连同其他的代码段（即所有的代码段）替换掉，因此退出处理程序是不能跨越 exec() 的。
Tip
一个能够跨越 exec() 的例子是文件描述符。
fork() 和 stdio 的交互没有交互。
由于 fork() 是系统调用，而 stdio 是用户代码，所以 fork() 肯定不会主动刷新用户缓冲区的。在 fork() 的时候，stdio 的用户缓冲区（比如 stdout）会被拷贝一份，这样可能会导致重复输出。解决办法有 2 种：
在 fork() 之前将所有的 stdio 的流都用 fflush 刷新好。（我觉得这种做法更好一点。） 或者让一个进程（一般是父进程）用 exit() 退出，而其他进程用 _exit() 退出，从而不对缓冲区刷新。（但是如果缓冲区在程序运行中途还是刷新了，那就无法解决重复输出的问题。）   </content></entry><entry><title>26 监控子进程 wait()</title><url>/the-linux-programming-interface/26-%E7%9B%91%E6%8E%A7%E5%AD%90%E8%BF%9B%E7%A8%8B-wait/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  子进程的状态1. 状态的分类调用 _exit() 正常退出（无论是手动调用还是运行时在 main() 函数退出后自动调用）。 收到信号而终止。 收到信号而暂停执行。 收到信号而恢复执行。 2. 如何在父进程中区分子进程状态为了区分这 4 种状态，等待函数中 int 类型的输出参数实际上会有低 2 个字节被使用（虽然实际上返回状态只需要用 1 个字节表示）：
可以分别通过 WIFEXITED (status)、WIFSIGNALED (status)、WIFSTOPPED (status)、WIFCONTINUED (status) 来判断是否属于这几种情况。这几种情况是互斥的。在进程被信号所杀时，内核转储标志可能会被设置，这时如果宏 WCOREDUMP 被定义，可以用 WCOREDUMP 来检查内核转换标志是否被设置。
3. 在信号处理函数中终止子进程如果需要对某个信号做出一定的处理再终止子进程，则不能调用 _exit() 函数，否则子进程会被视为正常终止。如果想要让子进程终止时可以反应真实的终止原因，需要在信号处理器函数中做出善后处理之后，再将该信号的处置方式设置成默认，然后用 raise() 系统调用发送相同的信号。
用来等待子进程的 APIpid_t wait(int *_Nullable wstatus); pid_t waitpid(pid_t pid, int *_Nullable wstatus, int options); -------+ int waitid(idtype_t idtype, id_t id, siginfo_t *infop, int options); | /* This is the glibc and POSIX interface; see | NOTES for information on the raw system call. */ | | +------------------------------------------+ | V pid_t wait3(int *_Nullable wstatus, int options, struct rusage *_Nullable rusage); pid_t wait4(pid_t pid, int *_Nullable wstatus, int …  </content></entry><entry><title>24 进程的创建 fork()</title><url>/the-linux-programming-interface/24-%E8%BF%9B%E7%A8%8B%E7%9A%84%E5%88%9B%E5%BB%BA-fork/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  几个系统调用 / 库函数的介绍fork()：创建子进程。 exit(status)：库函数，退出当前进程，是 _exit 的包装。 wait(&amp;amp;status)：挂起当前进程并等待一个子进程。 execve(pathname, argv, envp)：加载一个新的程序。 Tip
SUSv3 还规定了 posix_spawn() 函数，相当于 fork + exec，在有些实现中速度会快一些，有的实现中则不是。网上对此的讨论也很多。
fork 和文件共享fork 后父子进程是可以共享打开的文件描述符的，而且这些文件描述符都指向内核打开文件表的同一个项目，共享文件属性和偏移量。不过可以在打开文件时设置 O_CLOEXEC 选项，使得子进程将来调用 exec 时关闭文件。
vfork 和写时复制早前 fork 函数没有 copy-on-write 功能，因而在子进程要调用 exec 时，显得不划算。vfork 让父子进程共享内存，只是复制极小部分用来管理进程的数据，并且将父进程挂起，直到子进程调用 exec 或者 _wait 才恢复。如果子进程在此期间做出了别的行为，则行为未定义。
这里的别的行为指：1. 修改了除了 vfork 返回值以外的任何数据；2. 从调用 vfork 的函数中返回；3. 在调用 exec / _wait 之前调用了任何函数。
由于现在已经有了 COW 功能，vfork 显得不是很重要了，现在已经不推荐使用。
fork 后父子进程的调度顺序不要依赖于父子进程在 fork 后的调度顺序，应该加上适当的同步操作。
Linux 曾经（作者是在 2.2.19 版本进行测试）是父进程在 fork 之后继续执行，而子进程需要等待调度；在 2.6 版本的时候又出现过 fork 后子进程优先得到调度的情况，理由是子进程很可能会调用 exec 替换掉内存，从而避免了父进程首先修改页面导致页面复制开销；在 2.6.32 版本的时候，又改回了 fork 后父进程先得到调度，理由是父进程正在运行过程中，TLB（translation look-aside buffer，用于缓存虚拟地址转换结果）已经存储了大量父进程的信息，先运行父进程性能会更好。
如果想要修改父子进程调度的顺序，可以修改 /proc/sys/kernel/sched_child_runs_first 的值为 0（默认值）/ 非 0。
进程间同步举例书中有一个 fork 出子进程，并和父进程之间同步的例子。首先是用 sigprocmask 阻塞住 SIGUSR1 信号，然后 fork 出子进程。子进程完成工作之后给父进程发 SIGUSR1 信号。父进程则是（可能先做其他的工作，然后再）用 sigsuspend 来等待 SIGUSR1 信号。如果子进程早就发送了信号，则 SIGUSR1 信号是 pending 的，父进程不会进入休眠状态而直接从 sigsuspend 调用中返回。
这种发信号来表示同步是否比较 tricky？如果有别的进程也给父进程发这个信号（即乱发信号）怎么办？
  </content></entry><entry><title>ctrl + f5 可以强制 chrome 拉取最新的网页资源</title><url>/posts/programming/www/ctrl-+-f5-%E5%8F%AF%E4%BB%A5%E5%BC%BA%E5%88%B6-chrome-%E6%8B%89%E5%8F%96%E6%9C%80%E6%96%B0%E7%9A%84%E7%BD%91%E9%A1%B5%E8%B5%84%E6%BA%90/</url><categories/><tags/><content type="html">  如题。
  </content></entry><entry><title>23 定时器与休眠</title><url>/the-linux-programming-interface/23-%E5%AE%9A%E6%97%B6%E5%99%A8%E4%B8%8E%E4%BC%91%E7%9C%A0/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  定时器 API1. setitimer 和 getitimer（不建议）SYNOPSIS #include &amp;lt;sys/time.h&amp;gt; int getitimer(int which, struct itimerval *curr_value); int setitimer(int which, const struct itimerval *restrict new_value, struct itimerval *_Nullable restrict old_value); which 参数指定创建的定时器的类型可以是真实时间，到期的信号是 SIGALARM。 可以是用户 CPU 时间（进程虚拟时间），到期的信号为 SIGVTALRM。 可以是内核 + 用户 CPU 时间（profiling 定时器），到期的信号是 SIGPROF。 以上三种信号默认行为是终止进程，所以定时器要结合信号处理函数使用。
struct itimerval 参数解释struct itimerval { struct timeval it_interval; /* Interval for periodic timer */ struct timeval it_value; /* Time until next expiration */ }; 其中 timeval 是带有秒和微秒的结构体，可以参考 10.01 时间类型 tm time_t timeval timespec。
it_interval 指的是定时器的发生周期，如果是 0 μs，则表示这是一次性定时器。it_value 是定时器的首次触发时间，可以和 it_interval 不同，如果为 0 μs 则表示清除（已有的）定时器而不是设置定时器。
定时器的数量限制以上三种定时器每个进程都只能最多各一个。
其他使用 setitimer 和 alarm 创建的定时器可以不会被 exec 清理，但是不会被 fork 继承到子进程。
SUSv4 废止了 getitimer() 和 setitimer()，同时推荐使用 POSIX 定时器 API。
2. alarm（不建议）SYNOPSIS #include &amp;lt;unistd.h&amp;gt; unsigned int alarm(unsigned int …  ]]></content></entry><entry><title>为什么用 tar.gz 安装的共享库 gcc 找不到？</title><url>/posts/systems/Linux/%E4%B8%BA%E4%BB%80%E4%B9%88%E7%94%A8-tar.gz-%E5%AE%89%E8%A3%85%E7%9A%84%E5%85%B1%E4%BA%AB%E5%BA%93-gcc-%E6%89%BE%E4%B8%8D%E5%88%B0/</url><categories/><tags><tag>c</tag><tag>cpp</tag><tag>gcc</tag><tag>linux</tag></tags><content type="html"><![CDATA[  情况项目是由 CMake 构建的动态库，用 CPack 我们打包得到了一个 deb 包版本和一个 tar.gz 的压缩包版本。前者安装之后 demo 能够正常编译运行，但是在换用压缩包安装共享库后编译 demo 则出现了找不到库的错误（这里讨论的是非标准路径的情况，即安装路径不在 /、/usr 和 /usr/local 下）。
测试 demo 是用 Makefile 写的，设置了 INCLUDE 环境变量为要包含的头文件路径，并且新增了 /etc/ld.so.conf.d/xxx.conf 和重做了 ldconfig 的 cache。但是 gcc 还是无法识别这个库。
Tip
这是因为 ldconfig 只是管理一个库在运行时可以去哪些路径搜索，静态链接的时候链接器不会去看这个配置。INCLUDE 环境变量可能是我记错了，我现在没有找到什么工具是认识这个环境变量的。CMake 认识的环境变量可以参考链接 https://cmake.org/cmake/help/latest/manual/cmake-env-variables.7.html 。Make 也认识一些环境变量，但是 INCLUDE 不在其列。
我想要真正把共享库安装在系统里面，所以不想在 Makefile 中手动去加头文件包含路径和库路径（那样的话需要修改每个 Makefile）。
解决 gcc 找不到头文件的问题设置 INCLUDE 环境变量，但是 gcc 不认。如果认的话理应输出 ignoring nonexistent directory &quot;/aaaa&quot;。
$ env INCLUDE=/aaaa gcc -E -Wp,-v - &lt;/dev/null ignoring nonexistent directory &#34;/usr/local/include/x86_64-linux-gnu&#34; ignoring nonexistent directory &#34;/usr/lib/gcc/x86_64-linux-gnu/12/include-fixed&#34; ignoring nonexistent directory &#34;/usr/lib/gcc/x86_64-linux-gnu/12/../../../../x86_64-linux-gnu/include&#34; #include &#34;...&#34; search starts here: #include &lt;...&gt; search starts here: /usr/lib/gcc/x86_64-linux-gnu/12/include /usr/local/include /usr/include/x86_64-linux-gnu /usr/include End of search list. # 0 &#34;&lt;stdin&gt;&#34; # 0 &#34;&lt;built-in&gt;&#34; # 0 &#34;&lt;command-line&gt;&#34; # 1 &#34;/usr/include/stdc-predef.h&#34; 1 3 4 # 0 &#34;&lt;command-line&gt;&#34; 2 # 1 &#34;&lt;stdin&gt;&#34; https://stackoverflow.com/a/2497388/ 回答指出以下环境变量被 gcc 识别第一个是不分语言的，后面几个是分语言的。还是用上面的方式测试，包含路径能被正常识别。
CPATH C_INCLUDE_PATH CPLUS_INCLUDE_PATH OBJC_INCLUDE_PATH ✔ 已成功。
解决 gcc 找不到共享库的问题试过 ldconfig -p 能找到，但是 gcc 依然找不到。
同样考虑使用环境变量的方式，我在 https://gcc.gnu.org/onlinedocs/gcc/Environment-Variables.html 找到了类似的说明，可以使用 LIBRARY_PATH 来指定 gcc 在链接阶段去检查的路径。
✔ 已成功。
Note
gcc 在链接阶段（调用 ld）并不直接使用 LD_LIBRARY_PATH，而是使用 LIBRARY_PATH。前者是在可执行程序运行时，系统的链接器搜索动态链接库的路径。
其他能不能不通过环境变量的方式处理问题，而是将配置写进系统呢？
  ]]></content></entry><entry><title>Debian 本地软件包的安装和卸载</title><url>/posts/systems/Linux/Debian-%E6%9C%AC%E5%9C%B0%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E5%8D%B8%E8%BD%BD/</url><categories/><tags><tag>linux</tag><tag>debian</tag></tags><content type="html">  操作起来感觉 apt 和 dpkg 在安装和卸载软件上是可以混用的，其一安装的包可以由另外一者去卸载。
安装软件（-i | --install）dpkg -i localpackage.deb 经过测试，不必像 apt 一样需要加上 ./ 前缀以安装本地的软件包。
卸载软件（-r | --remove）dpkg -r packagename 必须要使用包名才能卸载，使用 dpkg -r localpackage.deb 这样的文件路径是无效的。查看报名的方式是：
dpkg --get-selections | grep -i yourpackagename Note
不知道为什么用 apt remove ./localpackage.deb 反而会起到安装软件、而不是卸载软件的效果？但是 apt remove packagename 就能正常完成卸载。
删除软件并删除其配置文件（-P | --purge）dpkg -P packagename   </content></entry><entry><title>鲸海轴体验</title><url>/posts/life/2024%E5%B9%B46%E6%9C%8825%E6%97%A5-%E9%B2%B8%E6%B5%B7%E8%BD%B4%E4%BD%93%E9%AA%8C/</url><categories/><tags><tag>键盘</tag><tag>日常</tag></tags><content type="html">  狼蛛 M75 在 618 首发会送 80 颗鲸海轴，把鲸海轴的价格打下来了，全新在咸鱼上是 75~80 元。而且是刚好 80 颗！和我的 V75K 的按键数一样，所以头脑一热就入了。我前几天也把极光冰淇淋轴和静音轴都出了：静音轴体用着还是有点憋屈，而冰淇淋轴对于我来说始发压力（30 gf）太轻了，在滑键的时候会发出声音，我不喜欢。
🤔 是不是对我来说选择始发压力 35 gf 以上的轴体会比较合适呢？
外观：轴体本身是蓝色的，没有导光柱，和极光冰淇淋其实蛮像的，也就懒得拍了。
手感：按压力度上鲸海轴比较适中，参数和红轴很相近，但是它有一种液压感，快速重复按压会觉得压力很大（比如连续按 backspace），但是慢慢打字又觉得压力比较合适。和我之前使用的阿尼亚轴比起来肯定是要费力一些。因为有防尘壁，轴体实装后按键的稳定性相当不错。
声音：很不错，比极光冰淇淋好很多。声音也是比较闷的，音量上比阿尼亚小一点。
其他 1：感觉鲸海轴特别难插入，和难拔的极光冰淇淋截然相反。可能是我的定位板有问题？2024 年 7 月 1 日：插入的时候不要用力插，能放上就行了，也是可以正常使用的，没必要死死卡进去。
其他 2：以前以为 V75K 的大写锁定按键灯是粉色的，现在看是蓝色的。大概是白光，轴什么颜色照出来就什么颜色。
2024 年 6 月 27 日：前段时间学长说现在的肌无力轴不好使，不如红轴，也是我突发奇想买鲸海轴的一个原因吧（之前用的都是轻压力轴）。我这几天体验下来是真觉得鲸海轴比红轴要重了，现在来看红轴除了声音难听还有弹簧音还是挺舒服的（算是我这段时间挑轴体的 baseline 吧）。
  </content></entry><entry><title>CUDA 中 SFINAE 的坑</title><url>/posts/programming/cuda/CUDA-%E4%B8%AD-SFINAE-%E7%9A%84%E5%9D%91/</url><categories/><tags><tag>cpp</tag><tag>template</tag></tags><content type="html"><![CDATA[  TL;DR如果想要写一些 traits，而且涉及到了函数和变量（而不是类型），则需要同时加上 __device__ 和 __host__ 以确保它在 device 侧和 host 侧都可见。否则会因为 SFINAE 不报错（实际上可能是在 device 侧找不到函数或变量），而且不知道为什么结果不对。
描述项目用的语言标准是 C++17，atomicAdd 是 CUDA 中的一族函数，能对支持类型进行原子操作，其参数为一个地址和一个值，我想要判断 atomicAdd 是否有某个基本数据类型对应的重载版本。
template &lt;typename T, typename U = std::decay_t&lt;T&gt;&gt; __device__ __host__ auto atomicAddTest(T&amp;&amp;) -&gt; std::void_t&lt;decltype(atomicAdd((U*)(nullptr), std::declval&lt;U&gt;()))&gt;; __device__ __host__ auto atomicAddTest(...) -&gt; int; template &lt;typename T&gt; __device__ __host__ static inline constexpr auto atomicAddable = std::is_same_v&lt;decltype(atomicAddTest(std::declval&lt;T&gt;())), void&gt;; static_assert(atomicAddable&lt;float&gt;); static_assert(atomicAddable&lt;unsigned&gt;); 看起来很正常对不对？但是如果想要同时在 host 侧和 device 侧来使用 atomicAddable 变量，但是又忘记给这些函数加 __device__ __host__，就会有 calling device function from host 的错误，然后因为 SFINAE 不报错，下面的程序实际使用时总是走了不一样的分支，半天不知道原因在哪里！后来加了 static_assert，同时暂时性地将 SFINAE 保护的部分放到函数体里面去，才通过 LSP 了解到具体的出错原因。
接下来编译又出现一个问题：
a __device__ variable &#34;atomicAddable [with T=DType]&#34; cannot be directly read in a host function 所以还是把变量改成 Trait 类算了：
template &lt;typename T, typename U = std::decay_t&lt;T&gt;&gt; __device__ __host__ auto atomicAddTest(T&amp;&amp;) -&gt; std::void_t&lt;decltype(atomicAdd((U*)(nullptr), std::declval&lt;U&gt;()))&gt;; __device__ __host__ auto atomicAddTest(...) -&gt; int; template &lt;typename T, typename U = void&gt; struct AtomicAddable : std::false_type {}; template &lt;typename T&gt; struct AtomicAddable&lt; T, std::enable_if_t&lt;std::is_same_v&lt;decltype(atomicAddTest(std::declval&lt;T&gt;())), void&gt;&gt;&gt; : std::true_type {}; static_assert(AtomicAddable&lt;float&gt;::value); static_assert(AtomicAddable&lt;int&gt;::value); static_assert(AtomicAddable&lt;unsigned&gt;::value); 在 C++20 有了 concept 之后，这种情况可能会好很多，因为 concept 的结果是右值，而且不用写好几个函数迂回地描述一件事情，也就不会存在这种到底是 host 侧还是 device 侧的问题。
  ]]></content></entry><entry><title>极光冰淇淋轴体验</title><url>/posts/life/2024%E5%B9%B46%E6%9C%8819%E6%97%A5-%E6%9E%81%E5%85%89%E5%86%B0%E6%B7%87%E6%B7%8B%E8%BD%B4%E4%BD%93%E9%AA%8C/</url><categories/><tags><tag>键盘</tag><tag>日常</tag></tags><content type="html">  极光冰淇淋轴是我从咸鱼上买的，本来买完有点后悔，因为我看到了有人出我更想要的蓝莓冰淇淋，而且价格相当好，但是这倒也没什么。比较难受的是：卖家说自己是到手拆，但是我拿到的轴针脚歪歪扭扭的，特别是有一个轴的金色针脚都快从中间一分二了。如果平时都没怎么用过，我都不敢想装货的时候有多暴力。而且这个卖家卖了特别多键设，原来大家的容忍度都这么高吗？
我个人觉得有棉花塞棉花，没有棉花塞卫生纸，不要在罐子中留下空隙，不然即使没有外力压迫，罐子在运输过程中不断摇晃也是可能损伤到针脚的。
吐槽完交易来说体验，我觉得极光冰淇淋有点对不起它拆机 1.4、1.5 元的价格。先看外观图，粉色的是阿尼亚，紫色的是极光冰淇淋，极光冰淇淋的颜值还是很高的，我很喜欢这种圆形防尘壁的设计：
外观是好看的，没什么说的。但是声音不好听。按键感觉也不够顺滑，有的好按有的不好按，和更便宜的阿尼亚轴完全没法比（2024 年 6 月 29 日：听说极光冰淇淋需要自润）。虽然平均压力是 40 gf，但是比 42 gf 为平均压力的阿尼亚轴体感要费力很多，是因为公差比较大吗？
视频：极光冰淇淋和阿尼亚轴实装比较 视频：极光冰淇淋和阿尼亚轴裸轴轻压声音测试（2 倍音量） 解释视频：首先是连续按压，极光冰淇淋的声音偏脆，而阿尼亚轴的声音偏闷。在按压力度不大的时候，极光冰淇淋声音比阿尼亚轴更大，按压力度上来之后两者声音差不多大。在轻轻按压时，极光冰淇淋下沉更多，阿尼亚轴弹簧更有力一点。个人感觉阿尼亚轴弹簧弹性大可以减少误按压（不是误触发），从而减少手指在键盘上方移动造成的杂音。感觉是和参数上的始发压力有关系。
另外，极光冰淇淋拔轴异常困难，要么是和键帽卡在一起，拔键帽直接把轴也拔出来了，然后需要用很大力气分离；要么就是轴不好拔。我在 上一篇日志 中提到过我买了新的拔轴拔键器，当时还对拔键器的效果很失望，没想到这个拔轴器反倒是有用。以前看 b 站视频带货拔轴器我不以为然，我拔过好几种其他的轴体都非常轻松，而且上次确实也觉得用新的拔轴器反而费力（相对地），现在没想到真香了。2024 年 6 月 29 日：我现在怀疑就是这种拔轴器导致我的定位板变形的。
其他资料：草莓冰淇淋pro真有那么好吗？越用越顺还是越卡涩？随便聊聊这颗被吹上天的冰淇淋
  </content></entry><entry><title>模除运算</title><url>/posts/programming/cpp/%E6%A8%A1%E9%99%A4%E8%BF%90%E7%AE%97/</url><categories/><tags><tag>c</tag><tag>cpp</tag></tags><content type="html">  C++ 中两数相除（假设被除数和除数都不是 0），同号则结果为正，异号则结果为负。模除运算则定义为：
If $a~/~b$ is representable in the result type, $(a~/~b)*b + a~\%~b == a$.（来自 https://en.cppreference.com/w/cpp/language/operator_arithmetic ）
实践起来则是：在被除数不是 0 的情况下，模除运算的结果总是和除数同正负。
  </content></entry><entry><title>记一次代码合并后发生错误的定位过程</title><url>/posts/cli/git/%E8%AE%B0%E4%B8%80%E6%AC%A1%E4%BB%A3%E7%A0%81%E5%90%88%E5%B9%B6%E5%90%8E%E5%8F%91%E7%94%9F%E9%94%99%E8%AF%AF%E7%9A%84%E5%AE%9A%E4%BD%8D%E8%BF%87%E7%A8%8B/</url><categories/><tags><tag>git</tag></tags><content type="html">  昨天晚上合并完新的代码准备提交上去但是 CI 跑不了，有一个单元测试报错。然后照着官方的 git-bisect 文档找问题。这个工具比想象中要好用很多，大部分时间都花在了构建项目上面（每次修改 HEAD 之后都要重新构建才能测试）。半个小时后锁定了问题在一个具体的提交上。
接下来我需要将我的代码和这部分有问题的代码分离。我的分支是 main，远程的分支是 origin/develop，有错误的分支是 origin2/develop。因为 main 合并了一部分 origin2/develop 的代码才导致了错误。分支的结构是这样的：
* --(若干次提交)-- origin/develop --(若干次提交)-- main \ / (若干次提交，非线性，想要舍弃掉) --- origin2/develop ------------------------- 因为我要保证 origin/develop 这个我们的仓库总是 fast-forward 合并，所以我先以这个分支为基准创建新的本地分支。然后将在 main 中（有我的新代码）、不在 next 中（因为我本来就在 next 的位置上）、不在 origin2/develop 中（有错误）的提交重播。
git checkout -b next origin/develop git cherry-pick main ^next ^origin2/develop 因为没有加 -m 参数，所以遇到 merge 结点的时候会出错，我直接忽略掉这些 merge 结点一路 git cherry-pick --continue 了。因为这些 merge 结点全都是因为合并 origin2/develop 才产生的。（而且加 -m 参数的话，好几个 merge 结点的 parents 不同，是不是要分段一个一个重播呢？我这里不需要任何 merge 结点，所以就没这样操作。）
  </content></entry><entry><title>以 zstd 压缩方式导出镜像</title><url>/posts/cli/docker/%E4%BB%A5-zstd-%E5%8E%8B%E7%BC%A9%E6%96%B9%E5%BC%8F%E5%AF%BC%E5%87%BA%E9%95%9C%E5%83%8F/</url><categories/><tags><tag>docker</tag><tag>linux</tag></tags><content type="html">  步骤docker save image:tag | zstd -o image.tar.zst docker save 是将镜像输出到标准输出流，docker save -o 是将输出写入到文件。 zstd -o 是将压缩数据写入文件，而 zstd -c 是将压缩的数据输出到标准输出流。 为什么用 zstd 而不是 gzip 来压缩zstd 在 ubuntu/debian 中有现成的包可以下载，安装非常轻松。 压缩速度非常快，压缩比可以接受。 我的使用场景是在服务器之间传输文件，带宽很高，所以不想花太多时间在压缩和解压上。   </content></entry><entry><title>22 信号高级特性</title><url>/the-linux-programming-interface/22-%E4%BF%A1%E5%8F%B7%E9%AB%98%E7%BA%A7%E7%89%B9%E6%80%A7/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  核心转储核心转储的产生有非常多的原因会导致核心转储不发生，最容易出现的是没有用 ulimit 对进程设置核心转储大小上限（默认是 0）。此外，对核心转储路径没有写权限、set-group-ID 或 set-user-ID 程序由非属组 / 主执行、对可执行文件没有读权限等原因都会导致核心转储不发生。
在 Linux 2.4 之后，prctl 函数的 PR_SET_DUMPABLE 操作可以为进程设置 dumpable 标志，如果有这个标志，set-group-ID 或 set-user-ID 程序在非属组 / 主执行时也能核心转储。Linux 2.6.13 之后，/proc/sys/fs/suid_dumpable 为此标志提供系统级的控制，默认值是 0。
Linux 2.6.23 之后，/proc/PID/coredump_filter 能控制对应进程核心转储中可以包含的内存类型。文件的值是 4 位掩码，表示私有匿名映射、私有文件映射、共享匿名映射以及共享文件映射是否受允许，默认值是仅允许匿名映射、不允许文件映射。如今，我的 WSL 内核版本是 5.15.153.1-microsoft-standard-WSL2，该文件中存储的是 00000033。
核心转储的路径可以用 /proc/sys/kernel/core_pattern 查看核心转储文件的存储路径。
系统对一些特殊信号的处理SIGKILL 和 SIGSTOP 的行为无法被改变，调用 signal 或 sigaction 以图改变其行为总是会返回错误。
SIGCONT 总是会让处于停止状态的进程恢复运行，即使该进程已经阻塞了 SIGCONT 信号。阻塞 SIGCONT 只是会让 SIGCONT 的处理器函数暂时无法执行而已。另外，如果进程收到了 SIGCONT，那么处于等待状态的停止信号（SIGSTOP、SIGTSTP、SIGTTIN、SIGTTOU 等）会被丢弃，这是为了防止进程刚被唤醒就再次停止。
如果程序发现终端相关的信号处理方式被设置为 SIG_IGN，则一般不应该去更改其设置。这不是硬性规定，是建议遵守的协定。
不可中断的睡眠睡眠的状态分为以下几种：
TASK_INTERRUPTIBLE：对应 ps(1) 中 STAT 字段的字母 S。例子：正在等待终端输入，等待数据写入当前的空管道， …  </content></entry><entry><title>水蜜桃、青柠 V3 + 新的拔轴器体验</title><url>/posts/life/2024%E5%B9%B46%E6%9C%8810%E6%97%A5-%E6%B0%B4%E8%9C%9C%E6%A1%83%E9%9D%92%E6%9F%A0-V3-%E4%BD%93%E9%AA%8C%E6%96%B0%E7%9A%84%E6%8B%94%E8%BD%B4%E5%99%A8%E5%88%B0%E8%B4%A7/</url><categories/><tags><tag>键盘</tag><tag>日常</tag></tags><content type="html">  新的拔键器到货（😓不好用）之前的文章说键盘附送的拔键器会伤到键帽，所以买了个新的拔键器：
拔轴要把整个拔轴器按下去，退轴的时候要拨弹簧卡扣，也不是不好用吧，但是我觉得比原来的拔轴器麻烦。拔键要向下压弹簧才能把拔键器卡进键位，实际感受是比较累的，既不如送的拔键器小巧，又不如它好用。而且拔键的一端卡不到某些键位里面去，以下两张图中都是因为碰到了键盘边框所以无法卡进去：
~~不过，在拔键器能够卡进去的位置，我还是优先使用这个拔键器，这样不会损坏键帽的边缘。（心疼！）~~已经完全放弃了，还是原来的小型拔轴器好用，出坑了就用手指甲刮一下。
水蜜桃 V3 和青柠轴 V3一元一颗，一样买了 10 颗，还包邮，夸夸高特👍。
青柠轴的感觉，嗯……的确是能体会到段落感，但是因为我其他轴都是线性的，配上段落的会比较奇怪。因为我没有全部换上青柠轴，我也不知道整体上手是什么感觉。声音上感觉比水蜜桃稍微大一些，和我的笔记本键盘敲击声差不多大。
水蜜桃感觉比静音灰雪轴要顺滑一点。（我有几颗静音灰雪轴不顺滑是因为我反复拆吗？）我的静音灰雪轴在大键上（但不包括空格）有粘滞的感觉，估计是和键程有关系，这也是为什么我去买了低键程的水蜜桃。我曾经就是因为粘滞的问题才把左 shift、backspace、enter 键都换成了阿尼亚轴，现在换成了水蜜桃轴，感觉回弹正常了。唯一的不足是我其他的轴体键程比较长，在这几个键上能体会到手指下沉的长度不同，但是这也比之前的粘滞感要好一点。在其他的键上，我还是喜欢静音灰雪轴，我觉得更长的行程能更好地给手指卸力，会让人感觉按起来更加轻松。除了键程之外，水蜜桃和静音灰雪轴好像没有什么区别，就连沙沙的声音我也听不出来区别。
实际上声音是复合的，沙沙声只是很小的一部分，键帽也会发出声音。单听轴体沙沙声才明显，有点像左脚 EVA 拖鞋顶着柜子的同时搭在右脚上，右脚抖腿导致拖鞋摩擦柜子发出的声音。
轴换多了还是能感觉到公差的存在，应该是在所有轴体上都无法避免。我会一颗一颗比较，把我觉得还不错的装上去。毕竟我的键盘是 80 键，很多轴的套装都是 35、90 键，会多出来一部分。这次我又只换三个大键，可以慢慢选。青柠轴和水蜜桃轴都试了一下，最后还是决定用水蜜桃。
  </content></entry><entry><title>20.9 信号集和信号的处理</title><url>/the-linux-programming-interface/20.9-%E4%BF%A1%E5%8F%B7%E9%9B%86%E5%92%8C%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%A4%84%E7%90%86/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  说明20 信号 讲了信号的基本概念、列举了一部分信号，并且说明了发送信号的方式。这一节主要是讲和信号处理相关的 API。
信号集信号集对应类型 sigset_t，操作它的函数都是以其指针为参数的。相关的函数有：
#include &amp;lt;signal.h&amp;gt; int sigemptyset(sigset_t *set); int sigfillset(sigset_t *set); int sigaddset(sigset_t *set, int signum); int sigdelset(sigset_t *set, int signum); int sigismember(const sigset_t *set, int signum); 必须用 sigemptyset 或者 sigfillset 对 sigset_t 类型的数据完成初始化，直接对其赋值 0 会有可移植性的问题。
GNU C 库还实现了三个函数：sigandset / sigorset / sigisemptyset。
不过，这些函数都没有提供遍历信号的方法。我们可以用 for 循环来遍历元素，这需要用到 NSIG，它表示信号的最大编号 + 1。可能需要定义 BSD_SOURCE、_SVID_SOURCE 或者 _GNU_SOURCE 之一来获取它的定义。
sigprocmask：用信号掩码阻塞信号的传递信号掩码能够将对应的信号暂时屏蔽掉，等掩码位移除之后再生效。这里说的阻塞并不是阻塞线程，而是阻塞信号。实际上，信号掩码属于线程属性，每个线程都可以有自己的信号掩码。
#include &amp;lt;signal.h&amp;gt; /* Prototype for the glibc wrapper function */ int sigprocmask(int how, const sigset_t *_Nullable restrict set, sigset_t *_Nullable restrict oldset); sigprocmask 系统调用就能设置当前线程的掩码，并将旧的掩码保存到 oldset 中（如果它非空）。其中 how 参数可以设置为以下值：
SIG_BLOCK 表示将给定的信号阻塞，也就是和当前的线程掩码取并集（union）。 SIG_UNBLOCK 表示不阻塞给定的信 …  ]]></content></entry><entry><title>21 如何正确处理信号？</title><url>/the-linux-programming-interface/21-%E5%A6%82%E4%BD%95%E6%AD%A3%E7%A1%AE%E5%A4%84%E7%90%86%E4%BF%A1%E5%8F%B7/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  设计处理器函数处理器函数应该尽可能简单，尤其是不要调用 stdio 库函数（因为它们一般不是异步信号安全的）。以下是几种处理方式：
修改全局数据结构。程序周期性检查这些结构。 清理资源并终止程序，或者使用非本地跳转返回到主程序中的预定位置。 两个概念可重入（Reentrant）函数SUSv3 对可重入函数的定义是：函数由两条或多条线程调用时，即便是交叉执行，其效果也与各线程以未定义顺序依次调用时一致。
有点不好理解的是：malloc 族函数是线程安全的，但是不是可重入的，因为它管理的是全局的数据结构，这个数据结构不能在多个线程上同时修改。Glibc 2.x 的 malloc 是首先选择一个 arena，然后试图获取它的锁，然后从其中分配内存；如果不同线程获取的 arenas 不同，那么可以同时得到锁（不是同一个锁），也自然不会冲突。printf、scanf 这些 stdio 的函数也是不可重入的，在执行的时候会加锁，因为它们要管理全局的缓冲区。还有一些通过静态分配的数据结构返回信息的函数，它们也是不可重入的，比如 crypt()、getpwnam()、gethostbyname() 以及 getservbyname()。
举个例子：如果在调用了 malloc，获取到锁之后，被信号打断，转入信号处理器中，在信号处理器中又调用 malloc，而且是尝试获取同一个锁，就会因为无法获得锁而一直卡在信号处理器中无法退出！所以可重入是比线程安全更加严格的概念。
可以理解为靠锁来保证线程安全破坏了交叉执行的要求吧？
异步信号安全（Async-signal-safe）函数从信号处理函数调用时，可以保证其实现安全的函数就是异步信号安全函数。如果一个函数可重入，或者信号处理器函数无法将其中断，函数就是异步信号安全的。因此，异步信号安全函数是一个比可重入函数更广的概念。
为了编写异步信号安全的函数，我们有以下的思路：
保证函数是可重入的，而且只调用 SUS 规定的异步信号安全的系统调用。 在主程序中要修改信号处理器中也可能访问的数据结构时，将信号暂时阻塞掉。（实践起来比较困难。） 由于在一些条件下（比如 handle 了多个信号，或者使用 SA_NODEFER 允许同一信号的递归处理），信号处理器可能会发生递归，所以即便主程序不访问信号处理器使用的数据结构，（不）可重用性依然不会 …  </content></entry><entry><title>20 信号</title><url>/the-linux-programming-interface/20-%E4%BF%A1%E5%8F%B7/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  信号信号是对进程的通知机制，也被称为软中断，分成标准信号（传统信号，编号范围是 1~31）和实时信号。
部分信号：
SIGINT：ctrl + c。 SIGQUIT：ctrl + &amp;lt;/kbd&amp;gt;，和 SIGINT 比多了核心转储。 SIGTERM：kill 命令默认发送的信号，程序可以注册处理这个信号，因此可以实现优雅退出。 SIGKILL：必杀信号。 SIGSTOP：必停信号。 SIGPIPE：写管道有错，可能是读的进程把管道关了。 SIGFPE：名字是浮点数错误，实际上泛指除 0 错误。而且 x86-64 上浮点数除 0 默认不出错，需要用 feenableexcept() 启用异常。 SIGALRM：实时计时器过期。 SIGVTALRM:：虚拟计时器过期。 SIGHUP：会话结束（终端断开）时发送给程序的信号，默认行为为杀死程序。在一些守护程序上还有重载配置的作用。 SIGTSTP：ctrl + z。 SIGUSR1 和 SIGUSR2：留给程序员自己用的，系统绝对不会发送的信号。 SIGWINCH：终端环境的窗口尺寸发生变化。 一个信号默认的处理行为是三者之一：1. 忽略；2. 终止；3. 内核转储。
处理信号使用 signal 或者 sigaction 注册信号处理函数，一般条件下 sigaction 是更好的选择。处理信号时一般不要调用 printf 等来自 stdio.h 的函数。
发送信号kill 系统调用可以向指定进程发送给定的信号：
进程号 &amp;gt; 0：指定进程。 进程号 = 0：同组所有进程，包括自己。 进程号 &amp;lt; -1：取绝对值，然后向指定的进程组中所有进程。 进程号 = -1：系统范围内除了 init 和进程自己以外的、所有的当前进程有权限可以发送信号的目标进程。 信号值 = 0：不发送信号，但是检查是否能够成功向目标进程发送信号。可能的 errno 值有：EPERM 表示进程存在但是没有权限；ESRCH 表示进程不存在。 其他发送信号的规则：
特权级（CAP_KILL）进程可以向任何进程发送信号。 init（1 号）进程是一个特例，只有它注册了某个信号的处理函数，才能向它发送这个信号。（原文是：It can be sent only signals for which it has a handler …  ]]></content></entry><entry><title>20.1 使用 SIGTERM 和核心转储</title><url>/the-linux-programming-interface/20.1-%E4%BD%BF%E7%94%A8-SIGTERM-%E5%92%8C%E6%A0%B8%E5%BF%83%E8%BD%AC%E5%82%A8/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  核心转储介绍GDB 可以加载核心转储以复现程序终止时的内存，也可以为给定的进程创建核心转储。
核心转储是可以通过发送信号实现的。调用 abort() 时，会向进程自身发送 SIGABRT 信号，该信号的默认行为是终止进程并为其生成核心转储。在终端中，SIGQUIT（ctrl + /）和 SIGINT（ctrl + c）相比，也多出来了生成核心转储的行为。可以从以下尝试中体会出两个信号的差异：
(py310) xxx /data/apue $ ulimit -c unlimited (py310) xxx /data/apue $ ./build/main ^C # 返回码 130 (py310) xxx /data/apue $ ./build/main ^\Quit (core dumped) # 返回码 131 可以检查核心转储文件的路径。既可以通过 /proc 文件系统查看路径，也可以通过 sysctl 命令查看路径。在 WSL 中打印出来的结果见下方：
(py310) xxx $ cat /proc/sys/kernel/core_pattern /mnt/wslg/dumps/core.%e (py310) xxx $ sysctl kernel.core_pattern kernel.core_pattern = /mnt/wslg/dumps/core.%e 尝试使用核心转储用 gcc -g 编译以下 C 语言程序：
#include &lt;stdlib.h&gt; int main() { int a = 5; abort(); } 然后在 WSL 中运行：
(py310) xxx /data/tlpi $ /data/tlpi/build/main Aborted (py310) [134] xxx /data/tlpi $ ls /mnt/wslg/dumps/ (py310) xxx /data/tlpi $ ulimit -c unlimited (py310) xxx /data/tlpi $ /data/tlpi/build/main Aborted (core dumped) (py310) [134] xxx /data/tlpi $ ls /mnt/wslg/dumps/ core.main ulimit -c unlimited 设置了核心转储文件的大小为无限制，如果不加这个就没有核心转储生成（因为这个限制的默认大小是 0）。这条命令只在当前的终端中生效。
接下来用 gdb 加载核心转储，能用 bt 看到栈信息：
(py310) xxx /data/tlpi $ gdb /data/tlpi/build/main /mnt/wslg/dumps/core.main GNU gdb (Debian 13.1-3) 13.1 Copyright (C) 2023 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type &#34;show copying&#34; and &#34;show warranty&#34; for details. This GDB was configured as &#34;x86_64-linux-gnu&#34;. Type &#34;show configuration&#34; for configuration details. For bug reporting instructions, please see: &lt;https://www.gnu.org/software/gdb/bugs/&gt;. Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;. For help, type &#34;help&#34;. Type &#34;apropos word&#34; to search for commands related to &#34;word&#34;... Reading symbols from /data/tlpi/build/main... [New LWP 286206] [Thread debugging using libthread_db enabled] Using host libthread_db library &#34;/lib/x86_64-linux-gnu/libthread_db.so.1&#34;. Core was generated by `/data/tlpi/build/main&#39;. Program terminated with signal SIGABRT, Aborted. #0 __pthread_kill_implementation (threadid=&lt;optimized out&gt;, signo=signo@entry=6, no_tid=no_tid@entry=0) at ./nptl/pthread_kill.c:44 44 ./nptl/pthread_kill.c: No such file or directory. (gdb) bt #0 __pthread_kill_implementation (threadid=&lt;optimized out&gt;, signo=signo@entry=6, no_tid=no_tid@entry=0) at ./nptl/pthread_kill.c:44 #1 0x00007f4eab33fe8f in __pthread_kill_internal (signo=6, threadid=&lt;optimized out&gt;) at ./nptl/pthread_kill.c:78 #2 0x00007f4eab2f0fb2 in __GI_raise (sig=sig@entry=6) at ../sysdeps/posix/raise.c:26 #3 0x00007f4eab2db472 in __GI_abort () at ./stdlib/abort.c:79 #4 0x000055a332a0214d in main () at /data/tlpi/main.c:12 (gdb) 也能使用 coredumpctl list 来发现所有的核心转储，但这需要首先安装 systemd-coredump 这个 Debian 包。安装这个包之后，核心转储的存储位置就发生变化了，和 WSL 的默认位置不一样：
(py310) xxx /data/tlpi $ cat /proc/sys/kernel/core_pattern |/lib/systemd/systemd-coredump %P %u %g %s %t 9223372036854775808 %h 但是安装这个包之后我找不到生成的核心转储，用 coredumpctl list 也显示没有转储。回答 https://unix.stackexchange.com/a/65111/ 提到 systemd 会将转储记录在 journal 中，所以我先用 journalctl -f 来追踪日志，然后再在另外一个 shell 中运行以上程序，发现了新日志：
Jun 05 23:36:03 xxx systemd-coredump[3854]: Failed to connect to coredump service: No such file or directory 始终解决不了这个问题……可能是 WSL 的实现问题，还是卸载 systemd-coredump 算了。卸载完成之后，cat /proc/sys/kernel/core_pattern 的结果又变成了 core……！（重启 WSL 之后会恢复成原来的那个。）
  ]]></content></entry><entry><title>19 inotify 监控文件事件</title><url>/the-linux-programming-interface/19-inotify-%E7%9B%91%E6%8E%A7%E6%96%87%E4%BB%B6%E4%BA%8B%E4%BB%B6/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  基本流程使用 inotify_init 创建一个 inotify 实例，返回值是文件描述符，用来读取 inotify 监控项信息。 使用 inotify_add_watch 对 inotify 实例创建或者修改监控项目。参数 fd 指代 inotify 实例，参数 pathname 表示要监控的文件或者目录，用户必须有其读取权限（只检查一次，创建监控项目成功之后即便权限发生变化监控也不会被移除）。函数的返回值是一个监控描述符（watch descriptor，wd）。 不断使用 read 系统调用去读取 fd 关联文件的信息，然后将字节流中的地址转换成 struct inotify_event * 类型，然后判断其信息。给 read 提供的缓冲区需要足够大，至少需要容纳 sizeof(struct inotify_event) + NAME_MAX + 1 个字节，不过 read 缓冲区越大读取的效率越高。 struct inotify_event { int wd; /* Watch descriptor */ uint32_t mask; /* Mask describing event */ uint32_t cookie; /* Unique cookie associating related events (for rename(2)) */ uint32_t len; /* Size of name field */ char name[]; /* Optional null-terminated name */ }; 使用 inotify_rm_watch 移除监控事件。 使用 close 关闭 inotify_init 创建的 fd。 inotify_init1Linux 还有一个系统调用 inotify_init1，它比 inotify_init 多出来一个 flags 参数，可以用来指定 IN_CLOEXEC 或者 IN_NONBLOCK。这避免了稍后用 fcntl 设置 flags 的繁琐操作。
读取监控事件受监控目录有文件发生事件时，name 字段是一个零字符结尾字符串；受监控目录本身发生事件时，len 为 0，name 没有有效内容。可以监控的事件类型相当多，具体可以参考手册。特殊事件包括：IN_IGNORED（监控项被内核或应用移除）、IN_Q_OVERFLOW（事件队列溢出）、IN_UNMOUNT（包含监控对象的文件系统被卸载）等。
如果连续发生两个相同的事件，内核会将其合并，也就是说 inotify 接口中同一事件发生多次（中间没有其他事件）被视作只发生一次。
inotify 事件还可以用 select、poll、epoll 等函数来监听。
inotify 的资源限制/proc 文件系统中有其限制：
(py310) xxx $ cat /proc/sys/fs/inotify/max_user_instances 128 (py310) xxx $ cat /proc/sys/fs/inotify/max_user_watches 524288 (py310) xxx $ cat /proc/sys/fs/inotify/max_queued_events 16384 每个真实用户 ID 下的 inotify 实例和总的监听数是有限的。单个监听实例队列大小也有限制，队列容量不足时，系统会丢弃数据，并将 IN_Q_OVERFLOW 作为事件写到队列中。
旧的监控方式 dnotifydnotify 顾名思义只能监听目录，而 inotify 可以监听所有文件（inode）。此外，dnotify 的机制是发送信号，写起来可能不如 inotify 方便。而且 dnotify 会打开监听的目录，这不仅消耗文件描述符，还会使得包含目录的文件系统在进程运行期间无法卸载。dnotify 还有一些缺点，总之现在已经被 inotify 代替。
  </content></entry><entry><title>18.1-2 i-node 和链接</title><url>/the-linux-programming-interface/18-%E7%9B%AE%E5%BD%95%E5%92%8C%E9%93%BE%E6%8E%A5/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  i-nodei 节点一般写作 i-node，中间有个短横线。i-node 表的编号开始于 1，因为 0 用来表示未使用的条目，然后 i-node 1 用来记录文件系统的坏块，i-node 2 用来记录根目录，即 /。由于可能有多个路径不同、名称不同的文件（通过硬链接）指向同一个 i-node，因此 i-node 中并不记录本文件的名称。
符号链接符号链接的所有权和权限在大多数情况下会被忽略。仅在符号链接所在目录具有粘着位，又要删除或者重命名符号链接时，才会考虑符号链接本身的所有权。
符号链接解引用的次数是有限的，SUSv3 规定对路径中的每个符号链接部件至少 _POSIX_SYMLOOP_MAX 即 8 次。内核 2.6.18 之前，Linux 最多支持 5 次，2.6.18 时支持了 8 次。Linux 还规定一个完整路径中符号链接引用解除次数最多 40 次。
符号链接使用 symlink 创建，使用 readlink 读取。
link 和 unlink（不会解除符号链接引用）link 创建（硬）链接，unlink 解除链接（也就是删除文件）。SUSv3 规定 link 要解符号链接引用，但是 Linux 并没有这样实现。现在 SUSv4 规定 link 调用是否解除链接由实现定义。
unlink 不会对符号链接解引用（SUSv3 在 Linux 上也没有歧义？）。
rename（不会解除符号链接引用）这个系统调用可以重命名文件或者目录，其实际效果是移动文件，但是又和 mv 命令有些不同。第一，rename 两个参数要么都是目录名，要么都不是目录名，不像 mv 默认行为那样当第二个参数为已存在的目录名时，会将第一个参数移动到第二个目录中去。mv 其实也有 -T 参数，这样就和 rename 的语义一样：如果 oldpath 是文件夹，newpath 也是文件夹，假设 oldpath 存在，只有当 newpath 存在、为空、进程有权限将其删除，或者 newpath 不存在当进程有权限创建时才能重命名文件夹。第二，oldpath 和 newpath 必须存在于同一个文件系统内，mv 命令则做了包装，在遇到跨文件系统拷贝时实际上是先复制再删除旧文件。
rename() 系统调用对其两个参数中的符号链接均不进行解引用。
mkdir 和 rmdir（不会解除符号链 …  </content></entry><entry><title>17 ACL setfacl getfacl</title><url>/the-linux-programming-interface/17-ACL-setfacl-getfacl/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  ACL 介绍ACL 在 Linux 内核 2.6 被支持，是用文件的 扩展属性 实现的，扩展属性名为 system.posix_acl_access。
要想在 ext2、ext3、ext4 或 reiserfs 文件系统上创建 ACL，装配相应的文件系统时需要带 mount –o acl 选项。
ACL 的功能是传统访问权限的超集，优先于传统访问权限生效。每个 ACL 项目（Access Control Entry，即 ACE）指定一个 rwx（3 个二进制位）的权限。其中：
ACL_USER_OBJ、ACL_GROUP_OBJ 和 ACL_OTHER（在没有指定其他项目时）相当于传统权限，这个时候 ACL 被称为最小 ACL。 支持对特定用户（ACL_USER）或者特定组（ACL_GRUOP）指定权限。 支持掩码。ACL_MASK 记录了可由 ACL_USER、ACL_GROUP_OBJ 以及 ACL_GROUP 型 ACE 所能授予的最高权限。但如果 ACL 含有标记类型为 ACL_USER 或 ACL_GROUP 的记录，那么就必须包含一条 ACL_MASK 型的 ACE。如果包含了掩码项目，ACL 就成为扩展 ACL。 ACL_USER_OBJ、ACL_GROUP_OBJ、ACL_OTHER 和 ACL_MASK 都只能出现一次。 ACL 权限匹配算法ACL 的权限检查同样是具有短路特性的。
如果是特权进程，则放行。（实际实现的时候可能会把这一步放在最后作为 fallback，因为系统审计程序只应该记录进程真正需要使用到特权的情况。） 按照用户检查，如果进程有效用户 ID 和 ACL_USER_OBJ 匹配，则按照这一项检查权限。 否则，如果进程有效用户 ID 和某个 ACL_USER 匹配，则将它和 ACL_MASK 求与作为权限结果。 否则，如果进程的有效组 ID 或者辅助组 ID 之一满足全部权限检查，则放行。 如果组 ID 匹配 ACL_GROUP_OBJ，则将其和 ACL_MASK 求与（如果没有 ACL_MASK 则跳过这一步）。 如果组 ID 匹配 ACL_GRUOP，则将其和 ACL_MASK 求与（此时 ACL_MASK 必定存在）。 否则，按照 ACL_OTHER 检查权限（ACL_MASK 不会影响这一项）。 第 4 点的全部权限检 …  </content></entry><entry><title>小白入坑挑键盘经历</title><url>/posts/life/2024%E5%B9%B45%E6%9C%8829%E6%97%A5-%E5%B0%8F%E7%99%BD%E5%85%A5%E5%9D%91%E6%8C%91%E9%94%AE%E7%9B%98%E7%BB%8F%E5%8E%86/</url><categories/><tags><tag>键盘</tag><tag>日常</tag></tags><content type="html">  更新2024 年 6 月 26 日：解决在桌面上移动键盘时脚撑发出刺耳摩擦声的办法：在脚撑上面贴上透明胶布。 2024 年 6 月 29 日：现在键盘因为多次拔键拔轴已经是战损状态了，尤其是卫星轴和定位板之间卡不紧、有松动，问题相当大。很扎心：以后选键盘还是选个一开始就能接受轴体的，不要再换轴了吧 (*^_^*) 。总觉得 V75K 的卫星轴专门顺着阿尼亚轴的短行程调过（或者是挑选过），换阿尼亚轴匹配度更高一点。我现在没有别的轴体了（卖了），就试了鲸海轴，空格左侧是有 空键程 的，换成阿尼亚轴就好一点。 买键盘的历史本人小白，以前都是用薄膜键盘，这两个月买过以下键盘：
京东京造 K3，佳达隆矮茶轴，对于长时间用笔记本薄膜键盘的我来说非常容易上手。但是 84 按键（无论从手感还是视觉上都）非常紧凑，有时候找不到方向键，按 ctrl 和 shift 按键也经常按错。大写锁定灯在按键下方，不容易看到。另外对于 340 元这个价位来说，这样一把塑料机身的键盘显得有点廉价。因为是矮轴（2024 年 6 月 1 日：我现在才知道并不是所有矮轴都是无边框）因为是 keychron 的无边框设计，难买适配的防尘罩。也担心放到书包里面被电脑压弯，不过主要退货原因还是经常按错按键。 宁芝有线 35g 87 键。刚到手在桌面上就放不平，在 NGA 上也搜到了相同问题，对宁芝的品控非常担心，秒退。 Keychron K1 Pro，87 键佳达隆矮茶轴。因为上次 84 键太紧凑不太好找方向键，所以这次买了 87 键的。好处是现在能够更容易看到 CapsLock 指示灯。到手的时候备用键帽有质量问题换不上去，请客服补发了一次。不知道为什么，感觉按键敲下去就是没有 K3 好用。而且可能是因为矮轴机身薄 + 填充足，想要给料但是机身又塞不下，所以是鼓起的！已退。关于我觉得没有 K3 好用，可能和这个截图中的评论有关：IKBC 红轴有线，选了个好看的配色，还送了键帽。键盘左侧区域有钢丝音，尤其是 tab 按键，OEM 键帽用起来也挺顺手。拉出大脚撑，在桌面上移动键盘，就会发出粉笔垂直划黑板的声音 1 ，其他键盘的脚撑就不会有刺耳的声音。没有明显质量问题（钢丝音是普遍现象我觉得也还能忍），而且刚到手的那段时间我确实觉得还不错（不过买了 V75K 就不喜欢 IKBC 了），所以留了。 ATK …  </content></entry><entry><title>16.01 文件扩展属性 EA getfattr setfattr</title><url>/the-linux-programming-interface/16.01-%E6%96%87%E4%BB%B6%E6%89%A9%E5%B1%95%E5%B1%9E%E6%80%A7-EA-getfattr-setfattr/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  什么是扩展属性扩展属性（Extended Attributes）可以将任何字符串键和任何数据值的信息和文件 inode 关联起来，值可以不是零结尾的字符串。其键的命名方式是 namespace.name，其中 namespace 只能是以下四种之一：
user：权限管理方式和读写文件的内容是一样的。 trusted：和 user 类似，但是需要管理员权限，即 CAP_SYS_ADMIN。 system：键的第二分量只能是内核认可的字符串。 security：用来支持操作系统的安全模块。 在 ext2、ext3、ext4 或 Reiserfs 文件系统上，如欲将 user EA 与一文件关联，在装配底层文件系统时需带有 user_xattr 选项。 比如：
mount -o user_xattr &lt;device&gt; &lt;directory&gt; Note
书上没有说扩展属性在 Linux 中是怎么实现的。
扩展属性和 inode 中其他信息的比较主要是和 inode 模式位（st_mode）、inode 标志（flags）来对比：
inode 模式中的访问权限是 UNIX 规定的访问权限；inode 标志是某些 UNIX 在某些文件系统支持的功能，也是按位的形式存储的。 EA 允许存储任意类型的数据，而不只是 bool 类型。 EA 是用户可扩展的，不是系统调用手册里定死的，任何程序可以给文件附加元信息并为其提供含义。 inode 模式位是存储在 struct stat 中的，inode 标志和 EA 是在部分文件系统才支持、而且要用其他系统调用获取的。另外操作 inode 标志的命令（lsattr / chattr）和操作 inode 扩展属性的命令（setfacl / getfacl）在 Debian 上都是需要额外安装的。 如何操作扩展属性在 shell 中，可执行 setfattr(1) 和 getfattr(1) 命令来设置和查看文件的 EA（扩展属性）。
Tip
setfattr 和 getfattr 命令可能需要额外安装。我的 Debian 系统里面就没有，要用 sudo apt install attr 来安装。
一些限制user 命名空间的 EA 只能施加于普通文件或者目录，不能施加于（块或字符）设备、socket、符号链接、fifo。 如果目录有 sticky 位，那么非特权且非 owner 的进程是不能给目录增加 user EA 的。 EA 的名称长度、内容长度都有对应的限制。 对应的系统调用在头文件 sys/xattr.h 中，支持 setxattr / getxattr / removexattr / listxattr 四种操作，每个操作都有普通版本、l 前缀版本、f 前缀版本。
由于存储的属性值可以是任何类型，不是靠末尾零来对字符串长度计数的，所以在设置 xattr 时，需要显式传递缓冲区的长度。在获取时，为了防止缓冲区溢出，也要给出缓冲区的长度。
出于安全考虑，list 中返回的 EA 名称可能不包含调用进程无权访问的属性名。
有的文件系统会返回进程无权访问的属性名，这个时候操作这个属性就会失败。
  ]]></content></entry><entry><title>15.01-02 文件时间戳</title><url>/the-linux-programming-interface/15.01-02-utime-%E6%9B%B4%E6%96%B0%E6%96%87%E4%BB%B6%E6%97%B6%E9%97%B4%E6%88%B3/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  stat可以用 stat 族系统调用来获取文件的属性。
utime 秒级时间戳更新用 utime 族系统调用来设置文件的时间信息。修改时需要有相应的权限，以 utime 为例，其签名为：
int utime(const char *filename, const struct utimbuf *_Nullable times); 如果 times 参数为 NULL，则会将文件的 atime 和 mtime 修改为当前的时间。这需要进程的文件系统用户 ID 和文件匹配，且有写权限，或者是带有 CAP_FOWNER 或者 CAP_DAC_OVERRIDE 的特权级程序。
如果 times 参数非空，那么会用给定结构体的信息去更新 atime 和 mtime（ctime 信息是不能用系统调用任意修改的）。这需要进程的文件系统用户 ID 和文件匹配并有写权限，或者是带有 CAP_FOWNER 的特权级程序。
utimes 微秒级时间戳更新utimes / futimes / lutimes 也都能更新文件时间，加了 s 表示其参数是 timeval 的数组，也就支持了微秒级别的精度。
utimensat 纳秒级时间戳更新int utimensat(int dirfd, const char *pathname, const struct timespec times[_Nullable 2], int flags); int futimens(int fd, const struct timespec times[_Nullable 2]); timespec 中的 tv_nsec 字段设置为 UTIME_NOW 可以将时间戳更新为当前时间，设置为 UTIME_OMIT 可以将时间戳保持不变。除了纳秒级时间之外，utimensat 和 futimens 可以独立更新某一个时间（atime 或者 mtime）也是一种改进。
  </content></entry><entry><title>15.03 新建文件的属主是谁？</title><url>/the-linux-programming-interface/15.03-%E6%96%B0%E5%BB%BA%E6%96%87%E4%BB%B6%E7%9A%84%E5%B1%9E%E4%B8%BB%E6%98%AF%E8%B0%81/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  新建文件对应用户 ID 是进程（文件系统）有效用户 ID。
新建文件对应组 ID 在父目录 set-group-ID 未设置的情况下，是进程（文件系统）有效组 ID，否则是父目录的组 ID。除了显式设置父目录 set-group-ID 之外，使用 –o grpid 或者 –o bsdgroups 挂载也会将父目录的这一位置位。（挂载的默认行为是 –o nogrpid / –o sysvgroups，也就是 System V 行为。）
  </content></entry><entry><title>15.04 st_mode 组成和每一位的解释</title><url>/the-linux-programming-interface/15.04-st_mode-%E7%BB%84%E6%88%90%E5%92%8C%E6%AF%8F%E4%B8%80%E4%BD%8D%E7%9A%84%E8%A7%A3%E9%87%8A/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  st_mode 的组成st_mode 在 inode(7) 手册中的说明是 file type and mode，其组成是：文件类型 4 位 + 特殊 3 位 + 权限 9 位。
高 4 位是用来表示文件类型的（以下内容出自 man 7 inode），目前是有 7 种类型：
// 8 进制 S_IFMT 0170000 bit mask for the file type bit field S_IFSOCK 0140000 socket S_IFLNK 0120000 symbolic link S_IFREG 0100000 regular file S_IFBLK 0060000 block device S_IFDIR 0040000 directory S_IFCHR 0020000 character device S_IFIFO 0010000 FIFO stat 结构中 st_mode 字段的低 12 位定义了文件权限。其中的前 3 位为专用位，分别是 set-user-ID 位、set-group-ID 位和 sticky 位（粘着位）。后面的 9 位分别是用户、组、其他的 rwx 权限。
Set-user-ID 位如果可执行文件具有此位，则在执行时将进程的有效用户 ID 设置为可执行文件对应的用户 ID。
Set-group-ID 位如果可执行文件具有此位，则在执行时将进程的有效组 ID 设置为可执行文件对应的组 ID。 如果目录具有此位，那么目录及它的各级子目录下新创建的文件属组都是父目录的组，因为 set-group-id 位是会被子目录继承的。 如果屏蔽了属组的可执行权限位，那么 set-group-ID 权限位可以用来表示强制文件锁定。 Sticky 位对应宏 S_ISVTX。
早期用来指示可执行文件在第一次运行结束后，将代码留在交换区中，而不是直接清除掉，以加快可执行文件的下次载入，现在已经抛弃了这种用法。
对于目录而言，sticky 位作用是限制删除。特权进程除外，想要删除或者重命名文件，必须拥有文件或者拥有文件的父目录、且对目录有写权限。
  </content></entry><entry><title>15.04 目录读权限和执行权限</title><url>/the-linux-programming-interface/15.04-%E7%9B%AE%E5%BD%95%E8%AF%BB%E6%9D%83%E9%99%90%E5%92%8C%E6%89%A7%E8%A1%8C%E6%9D%83%E9%99%90/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  访问文件时，需要拥有对路径名所列所有目录的执行权限。例如，想读取文件 /home/mtk/x，则需拥有对目录 /、/home 以及 /home/mtk 的执行权限（还要有对文件 x 自身的读权限）。若当前的工作目录为 /home/mtk/sub1 ，访问相对路径名 ../sub2/x 时，需握有 /home/mtk 和 /home/mtk/sub2 这两个目录的可执行权限（不必有对 / 或 /home 的执行权限）。
拥有对目录的读权限，用户只是能查看目录中的文件列表。要想访问目录内文件的内容或是这些文件的 i 节点信息，还需握有对目录的执行权限。
  </content></entry><entry><title>15.04 其他文件系统函数</title><url>/the-linux-programming-interface/15.04-%E5%85%B6%E4%BB%96%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%87%BD%E6%95%B0/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  umask用来限制当前进程（和它将来的子进程）创建文件的访问权限。大多数 shell 的初始化文件会将 umask 默认置为八进制值 022 (&amp;mdash;-w&amp;ndash;w-)，也就是说即便给了组和其他的写权限，实际创建出来的文件也是没有这两项权限的。
access检查实际用户 / 组是否有文件的访问权限，但是不做实际访问。也能仅仅检查文件是否存在。
变种 faccessat 有更多功能，比如有选项支持对有效用户 / 组进行权限检查。
但是，因为检查文件和实际访问文件之间有滞后性（不是原子的），所以尽量避免“先使用 access 检查文件再访问”。
chmod当非特权级（不具备 CAP_FSETID 能力的）进程调用 chmod 时，若文件的组 ID 不等于进程的有效组 ID 或是任一辅助组 ID，内核则总是清除文件的 set-group-ID 权限，这也是出于安全考虑。书中的例子：
chown略。
  </content></entry><entry><title>15.05 inode 标志：命令 lsattr chattr + 系统调用 ioctl</title><url>/the-linux-programming-interface/15.05-inode-%E6%A0%87%E5%BF%97%E5%91%BD%E4%BB%A4-lsattr-chattr-+-%E7%B3%BB%E7%BB%9F%E8%B0%83%E7%94%A8-ioctl/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  简要介绍这是一种 Linux 相对于 UNIX 上扩展的非标准功能，只在部分文件系统上支持。不过现代 BSD 上也有 chflags 命令和系统调用，功能有类似之处。
在程序中可利用 ioctl() 系统调用来获取并修改 i 节点标志；在终端则可以使用 lsattr 和 chattr 命令操作文件属性。
用 ioctl 更新标志的例子：
inode 标记的功能其中 FS_IMMUTABLE_FL 将文件设置为不可更改，既不能更新文件数据（write() 和 truncate()），也不能改变文件元数据（即 chmod()、chown()、unlink()、link()、rename()、rmdir()、utime()、setxattr() 和 removexattr()）只有特权级进程（具备 CAP_LINUX_IMMUTABLE 能力的进程）可为文件设置这一标志。该标志一旦设定，即便是特权级进程也无法改变文件的内容或元数据。 这也意味着文件不能被删除，2023 年底我校流行的一种挖矿病毒1上有使用到这个标志。
一般而言，如果针对某一目录设置了 i 节点标志，那么新建于其下的文件和子目录会自动将其继承。不过也有例外，比如 FS_DIRSYNC_FL（chattr +D）只能应用于目录，所以只有子目录会继承；当将 FS_IMMUTABLE_FL (chattr +i) 标志应用于目录时，不会有创建于该目录下的文件或子目录继承此标志，因为该标志会阻止在此目录中添加任何新的条目。
更详细一点的标志列表可以用 man chattr 查看，书可能因为出版时间问题标志少了一些。
参考 yayaya Miner 木马病毒分析。其他相关信息：攻击者使用了开源程序 Diamorphine，以内核模块的方式隐藏进程。top 和 ps 看不到进程，但是 sysdig 能看到。WSL 现在还缺一些东西，无法正常运行 sysdig。&amp;#160;&amp;#x21a9;&amp;#xfe0e;
  </content></entry><entry><title>14.01 系统编程概念</title><url>/the-linux-programming-interface/14.01-%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B%E6%A6%82%E5%BF%B5/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  设备设备分为两种：字符设备和块设备。每个设备都有主 ID 和辅 ID。主 ID 表示设备的一般等级，辅 ID 在主 ID 相同的设备中标识自己。每个设备驱动程序都是按照自己和主设备号的关联关系向内核注册的。
在 Linux 的早期版本中，/dev 包含了系统中所有可能设备的条目，即使某些设备实际并未与系统连接。这意味着 /dev 会包含数以千计的未用设备项，从而导致了两个缺点：其一，对于需要扫描该目录内容的应用而言，降低了程序的执行速度；其二，根据该目录下的内容无法发现系统中实际存在哪些设备。Linux 2.6 运用 udev 程序解决了上述问题。该程序所依赖的 sysfs 文件系统，是装载于 /sys 下的伪文件系统，将设备和其他内核对象的相关信息导出至用户空间。
一些命令创建文件系统组分的系统调用/命令基本上都是用 mk 开头。比如：
mknod 可以创建 inode 结点，具体来说包括 socket、fifo、普通文件、字符设备、块设备。除了创建设备之外，一般都使用专门的系统调用不是直接用 mknod。有些 UNIX 实现用 mknod 来创建目录，但是 Linux 不这样做。 mkdir 表示创建目录。 mkfifo。 mkswap。这是用户空间命令，而不是一个系统调用。 文件系统文件系统分配空间的基本单位是逻辑块，这个块大小可能和物理块不同。文件系统由引导块（第 1 块，不管这个磁盘是不是用来引导操作系统的）、超级块（第 2 块，包含和文件系统相关的诸多参数，比如 i 节点表的容量、文件系统逻辑块大小和文件系统大小）、i 节点表、数据块组成。
Linux 的 i 节点中记录了三种时间：上次访问时间（atime）、内容最后修改时间（mtime）、文件状态（也就是 inode）的最后改变时间（ctime），但是不包括文件的创建时间！（Windows 的 NTFS 文件系统会记录创建时间。）
如果文件有空洞（通过 lseek 改变偏移量写入得到），则在 i 节点的数据块指针中将对应的指针设置为 0 即可，不必真的分配数据块。
  </content></entry><entry><title>14.10 文件系统挂载</title><url>/the-linux-programming-interface/14.10-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%8C%82%E8%BD%BD/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  挂载基础挂载首先是需要管理员权限的，而且必须是目标已经存在才能挂载并覆盖它。然后 mount 命令是挂载，umount 是解除挂载。
Linux 中有三个文件包含了挂载信息：
/proc/mounts 包含了文件系统的挂载信息。因为 Linux 现在支持了每个进程有不同于系统的文件系统，所以 /proc/mounts 被实现为指向 /proc/self/mounts 的一个符号链接。 /etc/mtab 文件由 mount(8) 和 umount(8) 来维护。 /etc/fstab 由系统管理员来维护，其中指定的挂载项目会在 systemd 启动其他服务前执行。 创建 tmpfs 文件系统tmpfs 并不只是把数据写到内存那么简单，它也是一个虚拟文件系统，因而在内存不足时，依然可以将文件写到交换中。tmpfs 除了用来把内存作为硬盘加速计算之外，也被用于 System V 共享内存和共享匿名内存映射、POSIX 共享内存和 POSIX 信号量。
以下代码是创建 tmpfs 文件系统并挂载到 /tmp。这里的 mytmpfs 是挂载源，但是因为是 tmpfs，所以这里只充当名称的作用，并不是从这个路径挂载。
sudo mount -t tmpfs -o size=1G mytmpfs /tmp 默认的 tmpfs 占用内存的一半，在我的 8G 内存的 wsl 上，不加参数 size= 得到的文件系统大小为 3.9G，这可以通过 df -h 来看到。
可以用 sudo umount /tmp 来解除挂载。
挂载选项略。
高级挂载特性内核版本 2.4 之后，允许在多个挂载点挂载同一个文件系统。
内核版本 2.4 之后，允许在同一个挂载点挂载多次，就像函数调用一样，后来的挂载会覆盖之前的挂载，卸载后又能看到之前的挂载内容。此时 Linux 还支持每次挂载都指定不同的挂载标志，而不是一个挂载点只能有一个挂载标志。
内核版本 2.4 之后，Linux 支持了创建绑定挂载，这是指在文件系统目录层级的另一处挂载目录或文件，因而目录或文件在多处可见，绑定挂载有点类似于硬链接，但是它可以（a）对目录挂载，而硬链接不能链接目录；（b）跨越文件系统完成挂载。
2.4.11 版本之后，Linux 支持递归绑定挂载，即在绑定挂载时将源目录下的子挂载也复制到目标目录中。默认情况下只会将源目录下的真实文件树挂载到目标目录中。
获取文件系统信息statvfs() 和 fstatvfs() 库函数能够获得与已挂载文件系统有关的信息。
  </content></entry><entry><title>10.01 时间类型 tm time_t timeval timespec</title><url>/the-linux-programming-interface/10.01-%E6%97%B6%E9%97%B4%E7%B1%BB%E5%9E%8B-tm-time_t-timeval-timespec/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  总览和时间相关的很多函数都是不可重入的。它们修改同一块静态分配的内存区域并返回，因此不是线程安全的。在新版本已经有 *_r 这样的可重入函数来替代它们。
timeval 精确时间，微秒级struct timeval 是带有秒和微秒的结构体，可以用 gettimeofday 获取，gettimeofday 的第二个参数 struct timezone_t * 建议填 NULL。
#include &lt;sys/time.h&gt; struct timeval { time_t tv_sec; /* Seconds */ suseconds_t tv_usec; /* Microseconds */ }; time_t 日历时间，秒级C 标准库 time 函数获得的秒就是 timeval 结构体的一个分量。尽管 timeval 信息更全面，在分解和格式化时间的时候都只支持了秒级别（time_t）。
tm 分解时间，秒级分解时间（broken-down） tm 包含了各个组分，有了这个结构体我们也能写出自己的格式化函数。
struct tm { int tm_sec; /* Seconds [0, 60] */ int tm_min; /* Minutes [0, 59] */ int tm_hour; /* Hour [0, 23] */ int tm_mday; /* Day of the month [1, 31] */ int tm_mon; /* Month [0, 11] (January = 0) */ int tm_year; /* Year minus 1900 */ int tm_wday; /* Day of the week [0, 6] (Sunday = 0) */ int tm_yday; /* Day of the year [0, 365] (Jan/01 = 0) */ int tm_isdst; /* Daylight savings flag */ #ifdef _BSD_SOURCE long tm_gmtoff; /* Seconds East of UTC */ const char *tm_zone; /* Timezone abbreviation */ #endif }; 为什么 tm_sec 的最大值是 60？这是因为闰秒，最近一次闰秒在 北京时间 2017 年 1 月 1 日 7 时 59 分 59 秒（时钟显示 07:59:60）出现。但有消息说 2035 年将取消闰秒。
使用 time_t mktime(struct tm *tm) 函数可以将分解时间修改之后转换成日历时间。这里修改的含义是：超过存储范围的数值会被正确进位 / 退位，并将数值修改反映在其他部分。
timespec 纳秒级时间类型struct timespec { time_t tv_sec; /* Seconds */ /* ... */ tv_nsec; /* Nanoseconds [0, 999&#39;999&#39;999] */ }; 在使用 futimens / utimensat 等系统调用时，时间参数类型是纳秒级别的 timespec。
  ]]></content></entry><entry><title>10.05 更新时钟</title><url>/the-linux-programming-interface/10.05-%E6%9B%B4%E6%96%B0%E6%97%B6%E9%92%9F/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  首先，更新系统时间要求程序具有相应的权限，即 CAP_SYS_TIME。
settimeofday 允许我们以 timeval 结构体表示的时间设置系统时间，不过，虽然它的精度很高，但是我们的计时器不一定能够达到这么高的精度，因此在微秒级设定的时间也可能是不准确的。
stime 类似，但是只能设置秒级时间。
adjtime 函数则是可以减慢或者加快始终速度，从而温和地完成时间调整。不过 adjtime 在执行的时间里可能无法完成所有的时间调整，这个时候剩余未修改的时间将保存在第二个参数中。（settimeofday 可能会突然改变系统时间，从而使得依赖绝对时间戳工作的程序不能正常运行，比如数据库或者 make。）
  </content></entry><entry><title>10.06 系统软件时钟</title><url>/the-linux-programming-interface/10.06-%E7%B3%BB%E7%BB%9F%E8%BD%AF%E4%BB%B6%E6%97%B6%E9%92%9F/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  系统软件时钟的单位是 jiffies，这是时间片轮转的单位。经过多年的发展，现在时钟频率可以设置到 100 / 250（默认）/ 300 / 1000 Hz。
(2025.2.13) Linux 6.13 在 250Hz 与 1000Hz 计时器频率之间的性能对比 近日，社区有讨论将默认始终频率从 250Hz 调整到 1000Hz。
  </content></entry><entry><title>10.07 进程时间 tms</title><url>/the-linux-programming-interface/10.07-%E8%BF%9B%E7%A8%8B%E6%97%B6%E9%97%B4-tms/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  什么是进程时间进程时间包含：
CPU 在用户模式下消耗的时间。 CPU 在内核模式下消耗的时间（比如 I/O、页错误处理）。 times 系统调用#include &lt;sys/times.h&gt; clock_t times(struct tms *buf); 其中 tms 结构体包含了当前进程和等待的子进程的时间信息。“等待的子进程”含义是：只有调用 wait 或者 waitpid 回收了一个子进程，子进程的时间才会累加到当前进程的 tms_cutime 和 tms_cstime 上。
struct tms { clock_t tms_utime; /* user time */ clock_t tms_stime; /* system time */ clock_t tms_cutime; /* user time of children */ clock_t tms_cstime; /* system time of children */ }; 返回值表示从一个任意时开始的时钟滴答数，因此只有两次返回值的差是有意义的。任意时和系统实现有关系，而且也有溢出的可能性，所以 man page 中推荐使用 clock_gettime(2) 来衡量时间。
times 函数所使用的 clock_t 频率由 sysconf(_SC_CLK_TCK) 决定，其数值除以这个值就得到了秒数。
在大多数 Linux 的硬件架构，sysconf(_SC_CLK_TCK)返回 100。与此对应的内核常量是 USER_HZ。然而 USER_HZ 在其他几个架构下可以被定义超过 100，如 Alpha 和 IA - 64。
标准库函数 clock#include &lt;time.h&gt; clock_t clock(void); clock 函数返回进程在用户和内核模式下运行的粗略总时间。
在 POSIX.1，CLOCKS_PER_SEC 是常量 10000，但是不知道其类型（因此打印时最好先转换成更大的类型）。在我的计算机上，这个宏被定义为 ((__clock_t) 1000000)。 clock 返回值除以这个值就得到了秒数。
Note
虽然 times 函数和 clock 函数返回类型都是 clock_t，但是因为 POSIX 标准和 C 语言标准的不同，两者单位不同。
  ]]></content></entry><entry><title>11.01-03 系统限制</title><url>/the-linux-programming-interface/11.01-03-%E7%B3%BB%E7%BB%9F%E9%99%90%E5%88%B6/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  可以从哪些地方获取系统限制信息？limits.h 头文件中定义的限制。 sysconf 获取的限制，这些限制在进程运行期间保持恒定。获取限制一般使用 _SC 开头的宏作为参数。 pathconf 和 fpathconf 获取的限制，这些限制在进程运行期间是可以改变的。获取限制一般使用 _PC 开头的宏作为参数。 pid_t 类型的表示上限在我的 wsl 中来看，pid_t 这个数据类型占用 4 个字节，是一个有符号整数（实际上是 int），我这里 /proc/sys/kernel/pid_max 显示可用的最大 pid 号为 4194304，即 $2^{22}$。这其实和 PID_MAX_LIMIT 相等，不可能将 pid_max 调整得更大，但是可以小于这个值。在 32 位机器上，这个系统限制最大是 32768，即 $2^{15}$。最大可用的 pid 值比文件中的值小 1，见后文。
参考 https://unix.stackexchange.com/a/162105/ 。
$ sudo sysctl -w kernel.pid_max=4194303 # 改小可以 kernel.pid_max = 4194303 $ sudo sysctl -w kernel.pid_max=4194305 # 改大不行 sysctl: setting key &amp;#34;kernel.pid_max&amp;#34;: Invalid argument $ sudo sysctl -w kernel.pid_max=4194304 # 改回默认值 kernel.pid_max = 4194304 直接向 /proc/sys/kernel/pid_max 里面 echo 也是可以的，只是 sudo 给命令的提权并不会作用于当前 shell 的重定向符号（重定向使用的权限是当前的 shell 的）。这种情况下可以用 ... | sudo tee，也可以用 sudo bash -c '...' 把 echo 和重定向包在内部。
🆕2025.2.9 最大可用的 pid 值比文件 /proc/sys/kernel/pid_max 中的小 1。可见 此处。man 5 proc 中有提到：
/proc/sys/kernel/pid_max
This file (new in Linux 2.5) specifies the value at which PIDs wrap around (i.e., the value in this file is one greater than the maximum PID). The default value for this file, 32768, results in the same range of PIDs as on earlier kernels. On 32-bit platforms, 32768 is the maximum value for pid_max. On 64-bit systems, pid_max can be set to any value up to $2^{22}$ (PID_MAX_LIMIT, approximately 4 million).
  </content></entry><entry><title>11.03 将目录重定向到标准输入</title><url>/the-linux-programming-interface/11.03-%E5%B0%86%E7%9B%AE%E5%BD%95%E9%87%8D%E5%AE%9A%E5%90%91%E5%88%B0%E6%A0%87%E5%87%86%E8%BE%93%E5%85%A5/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  在 Linux/UNIX 系统编程手册中看到这样的一段代码：
(py310) xxx /data/apue $ file /proc/self/fd/0 /proc/self/fd/0: symbolic link to /dev/pts/2 (py310) xxx /data/apue $ file /proc/self/fd/0 &amp;lt; . /proc/self/fd/0: symbolic link to /data/apue 这说明目录也是能够被重定向并使用 0 号 fd 打开的，只要程序支持标准输入流不是普通文件就行。
  </content></entry><entry><title>12.01 /proc 文件系统</title><url>/the-linux-programming-interface/12.01-proc-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  /proc 下的进程信息这些信息都是以 /proc/PID 开头的，其中 PID 为进程自己的进程号。用 /proc/self 可以表示进程本身。
在内核 2.4 之后，Linux 增加了线程组概念，正式支持了 POSIX 线程模型。/proc/PID/task/TID 是进程号为 PID 的进程中线程号为 TID 的线程的信息文件夹。
由于 $$ 表示当前 shell 的进程号，而一个进程中的主线程号和进程号相同，我们可以用以下方式来访问当前 shell 主线程的文件夹：
(py310) xxx /data/apue $ ls /proc/$$/task/$$ arch_status cgroup cmdline cwd fd io maps mounts oom_adj pagemap root sessionid smaps_rollup statm uid_map attr children comm environ fdinfo limits mem net oom_score personality sched setgroups stack status wchan auxv clear_refs cpuset exe gid_map loginuid mountinfo ns oom_score_adj projid_map schedstat smaps stat syscall 信息总量会比进程信息少一些，还有一些信息是和进程信息重复的。但是线程也有自己独特的信息，比如 /proc/PID/task/TID/status 中可能会有不一样的信息。
直接访问 /proc/TID/ 也是能够获取到信息的：涉及到和进程相关的信息，就访问的是所在进程的；涉及到和线程相关的信息，就相当于访问的是自己的。比如：如果 MainThread 是所在进程的主线程，Thread1 是另外一个线程，那么访问 /proc/Thread1/task/ 相当于访问 /proc/MainThread/task/。
/proc 下的系统信息这些信息有些是只读的，有些允许读写。有些是只能其所属用户或者 root 才能读取。
  </content></entry><entry><title>12.02 用 uname 获取系统标识信息</title><url>/the-linux-programming-interface/12.02-%E7%94%A8-uname-%E8%8E%B7%E5%8F%96%E7%B3%BB%E7%BB%9F%E6%A0%87%E8%AF%86%E4%BF%A1%E6%81%AF/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  uname 是个系统调用，同时也对应于命令 /usr/bin/uname。
  </content></entry><entry><title>13 文件 I/O 缓冲</title><url>/the-linux-programming-interface/13-%E6%96%87%E4%BB%B6%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E7%BC%93%E5%86%B2/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  C 语言标准库的缓冲C 语言输入输出函数会将数据缓冲到用户区域，从而减少了系统调用次数。
可以用函数 setvbuf 来改变一个 FILE * 的缓冲方式：
int setvbuf(FILE *restrict stream, char buf[restrict .size], int mode, size_t size); 其中 mode 有三种：
_IONBF: unbuffered _IOLBF: line buffered _IOFBF: fully buffered buf 可以是 NULL，这时 stdio 库会给 buf 自动分配一块缓冲区；buf 也可以是一块持久分配的内存。经过测试，以下代码会出现内存泄漏：
#include &amp;lt;fcntl.h&amp;gt; #include &amp;lt;stdio.h&amp;gt; #include &amp;lt;stdlib.h&amp;gt; #include &amp;lt;unistd.h&amp;gt; int main() { for (int i = 0; i &amp;lt; 895463893; ++i) { setvbuf(stdout, (char *)malloc(4096), _IOFBF, 4096); } printf(&amp;#34;setvbuf has been called so many times!\n&amp;#34;); } 而把 (char *)malloc(4096) 换成 NULL 就不会。我猜 buf 为 NULL 时，可能指向的是一块 threadlocal 的内存？
刷新 stdio 的缓冲使用 fflush 可以刷新 stdio 的写缓冲。这个操作会将用户缓冲区的数据复制到内核缓冲区，但还不是刷新到磁盘。对于一般应用程序来说，这个操作已经足够了，因为当程序退出的时候内核缓冲区的数据还是会被内核写到磁盘上的；对于数据库等程序来说，这个操作还不够。
如果 fflush 的参数为 NULL，那么将刷新所有的缓冲区（这个和 cudaStreamSynchronize 有点相似）。
Note
在包括 glibc 库在内的许多 C 函数库实现中，若 stdin 和 stdout 指向一终端，那么无论何时从 stdin 中读取输入时，都将隐含调用一次 fflush(stdout) 函数。这个特性在 SUSv3 和 C99 中都 …  ]]></content></entry><entry><title>09.01 Linux 进程凭证（Credentials）</title><url>/the-linux-programming-interface/09.01-Linux-%E8%BF%9B%E7%A8%8B%E5%87%AD%E8%AF%81Credentials/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  Linux 进程凭证进程凭证包括以下内容：
实际用户 ID（real user ID）和实际组 ID（real group ID）。 有效用户 ID（effective user ID）和有效组 ID（effective group ID）。 保存的 set-user-ID（saved set-user-ID）和保存的 set-group-ID（saved set-group-ID）。 文件系统用户 ID（file-system user ID）和文件系统组 ID（file-system group ID）（Linux 专有）。 辅助组 ID。 保存的设置用户/组 ID文件系统中每个非目录文件有设置用户/组 ID 位，启动这样的文件会使得有效用户/组 ID 按照文件的所有者来设置。出于安全考虑，在 Linux 中可执行文件的设置用户/组 ID 权限对于 shell 脚本无效。
设计保存的设置用户 ID（保存的设置组 ID 同，为了表述方便略去）是为了让程序的有效用户 ID 能够在实际用户 ID 和保存的设置用户 ID 之间切换。这样程序在不需要使用其他用户（尤其是 root）的权限时可以将有效用户 ID 转回实际用户 ID，需要权限时再转回来。程序启动时，保存的设置用户 ID 从有效用户 ID 复制过来。
文件系统用户/组 ID文件系统用户/组 ID 管辖和文件系统操作相关的权限问题，是由 Linux 专有的。一般情况下它们和有效用户/组 ID 相同，除非调用了 setfsuid / setfsgid。
文件系统 ID 始见于 Linux 1.2 版本。在该版本的内核中，如果进程某甲的有效用户 ID 等同于进程某乙的实际用户 ID 或者有效用户 ID，那么发送者（某甲）就可以向目标进程（某乙）发送信号。这在当时影响到了不少程序，比如 Linux NFS（网络文件系统）服务器程序，在访问文件时就好像拥有着相应客户进程的有效 ID。然而，如果 NFS 服务器真的修改了自身的有效用户 ID，面对非特权用户进程的信号攻击，又将不堪一击。为了防范这一风险，文件系统用户 ID 和组 ID 应运而生。NFS 服务器将有效 ID 保持不变，而是通过修改文件系统 ID 伪装成另一用户，这样既达到了访问文件的目的，又避免了遭受信号攻击。
自内核 2.0 起，Linux 开始在信号 …  </content></entry><entry><title>05.12 用 tmpfile 创建临时文件</title><url>/the-linux-programming-interface/05.12-%E7%94%A8-tmpfile-%E5%88%9B%E5%BB%BA%E4%B8%B4%E6%97%B6%E6%96%87%E4%BB%B6/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  在 Linux 上推荐使用的创建临时文件的方法只有 mkstemp 和 tmpfile。前者是系统调用，用起来更复杂一点，后者是 C 标准库函数。其他的函数多多少少有自己的问题。
tmpfile 不再需要我们提供字符数组来存储文件名，返回的是 FILE* 而不是 fd。此外还在刚创建文件之后就使用了 unlink 来删除文件，这样就只有当前进程可以访问到这个文件了（除非 fork）。
#include &lt;assert.h&gt; #include &lt;fcntl.h&gt; #include &lt;stdio.h&gt; #include &lt;unistd.h&gt; int main() { // 创建文件，记得关闭。 FILE *fp; assert((fp = tmpfile()) != NULL); // 查询文件路径并打印。 char path[128]; char link_path[128]; int fd = fileno(fp); assert(fd != -1); sprintf(link_path, &#34;/proc/self/fd/%d&#34;, fd); assert(readlink(link_path, path, sizeof(path)) != -1); printf(&#34;tmpfile: %s\n&#34;, path); fprintf(fp, &#34;write something\n&#34;); fflush(fp); // 在这里停顿。由于已经 unlink 了这个文件，文件系统上看不到它。 getchar(); fclose(fp); } 运行结果：
(py310) xxx /data/apue $ /data/apue/build/apue tmpfile: /tmp/#943520 (deleted) 多出来的一行是因为 getchar() 有停顿，需要键入换行符。在停顿的时候去看 /tmp 目录，根本找不到临时文件。
  ]]></content></entry><entry><title>06.06 用 /proc/self/cmdline 获取命令行参数</title><url>/the-linux-programming-interface/06.06-%E7%94%A8-proc-%E6%96%87%E4%BB%B6%E5%A4%B9%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  /proc/self/cmdline 是一个以 \0 结尾的文件，我尝试过用 fgets 读取，但是失败了；转而使用 fgetc 逐字符读文件。
#include &lt;fcntl.h&gt; #include &lt;stdio.h&gt; #include &lt;unistd.h&gt; int main() { FILE *f = fopen(&#34;/proc/self/cmdline&#34;, &#34;r&#34;); if (!f) { perror(&#34;fopen&#34;); return 1; } int i = 0, j = 0; int ch; char buf[128]; while ((ch = fgetc(f)) != EOF) { if (ch == &#39;\0&#39;) { buf[j] = &#39;\0&#39;; printf(&#34;argv[%d]: %s\n&#34;, i++, buf); j = 0; } else { buf[j++] = ch; } } fclose(f); } 例子：
(py310) xxx /data/apue $ /data/apue/build/apue 5 265 argv[0]: /data/apue/build/apue argv[1]: 5 argv[2]: 265   ]]></content></entry><entry><title>05.07 readv 和 writev</title><url>/the-linux-programming-interface/05.07-readv-%E5%92%8C-writev/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  这被称为 Scatter-Gather I/O。
其中，struct iovec 的定义如下：
struct iovec { void *iov_base; /* Start address of the buffer */ size_t iov_len; /* Number of bytes to transfer to/from buffer */ }; 这样 readv 和 writev 就能一次完成多个缓冲区的读取/写入。最重要的特征是：和多次调用 read/write 相比， readv/writev 操作具有原子性！
类似地，还有 preadv 和 pwritev，连 lseek 的过程都一起加进来变得原子化了。
  </content></entry><entry><title>00 说明</title><url>/the-linux-programming-interface/00-%E8%AF%B4%E6%98%8E/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  对书的介绍Linux/UNIX 系统编程手册原名 The Linux Programming Interface，副标题是 A Linux and UNIX System Programming Handbook，这也是其翻译名的由来。
这本书经常被简称为 TLPI。
笔记的编号方式有些笔记的编号是在章内简单排序（在书上没有对应或者不能直接对应），有些笔记的编号是和书的章节对应的。这点确实做的不好，看书的时间太长了，写笔记的方式也发生了变化。
我的测试环境有一部分是在本机的 wsl 测试的，有一部分是在服务器上测试的（会明确说明）。
2024 年 7 月 20 日：开始考虑使用虚拟机安装系统测试，对应内容是 41 共享库基础 的中间部分（及以后）。
wsl 环境wsl 系统版本：
$ lsb_release -a No LSB modules are available. Distributor ID: Debian Description: Debian GNU/Linux 12 (bookworm) Release: 12 Codename: bookworm $ cat /proc/version Linux version 5.15.153.1-microsoft-standard-WSL2 (root@941d701f84f1) (gcc (GCC) 11.2.0, GNU ld (GNU Binutils) 2.37) #1 SMP Fri Mar 29 23:14:13 UTC 2024 wsl 版本：
C:\Users\xxx&amp;gt;wsl --version WSL 版本： 2.2.4.0 内核版本： 5.15.153.1-2 WSLg 版本： 1.0.61 MSRDC 版本： 1.2.5326 Direct3D 版本： 1.611.1-81528511 DXCore 版本： 10.0.26091.1-240325-1447.ge-release Windows 版本： 10.0.22631.3737 服务器环境服务器：
$ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.6 LTS Release: 20.04 Codename: focal 虚拟机环境eric@debian:~$ cat /proc/version Linux version 6.1.0-23-amd64 (debian-kernel@lists.debian.org) (gcc-12 (Debian 12.2.0-14) 12.2.0, GNU ld (GNU Binutils for Debian) 2.40) #1 SMP PREEMPT_DYNAMIC Debian 6.1.99-1 (2024-07-15)   </content></entry><entry><title>05.04 Shell 启动的程序的三大标准文件是同一个文件</title><url>/the-linux-programming-interface/05.04-Shell-%E5%90%AF%E5%8A%A8%E7%9A%84%E7%A8%8B%E5%BA%8F%E7%9A%84%E4%B8%89%E5%A4%A7%E6%A0%87%E5%87%86%E6%96%87%E4%BB%B6%E6%98%AF%E5%90%8C%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  #include &lt;errno.h&gt; #include &lt;fcntl.h&gt; #include &lt;linux/kcmp.h&gt; #include &lt;stdio.h&gt; #include &lt;sys/syscall.h&gt; #include &lt;unistd.h&gt; int main() { pid_t pid = getpid(); /* always successful */ int ret = syscall(SYS_kcmp, pid, pid, KCMP_FILE, 0, 1); int ec = errno; if (ec) { perror(&#34;kcmp&#34;); return 1; } printf(&#34;kcmp returns %d\n&#34;, ret); } 其中，kcmp 系统调用可以用来比较两个进程的资源大小（0 等于，1 小于，2 等于，3 不相等但无法确定大小）。输出：
kcmp returns 0 这说明此文件在终端中运行时，标准输入流和输出流使用的是相同的打开文件项（事实上就连标准错误流都是用的同一个文件项）。一个程序的标准输入输出使用不会产生冲突吗？查看一下当前 shell 的信息：
(py310) xxx ~ $ ls -lh /proc/self/fd/0 lrwx------ 1 xxx xxx 64 May 16 16:49 /proc/self/fd/0 -&gt; /dev/pts/0 (py310) xxx ~ $ ls -lh /proc/$$/fd/0 lrwx------ 1 xxx xxx 64 May 16 16:43 /proc/387/fd/0 -&gt; /dev/pts/0 (py310) xxx ~ $ cat /proc/$$/fdinfo/0 pos: 0 flags: 0100002 mnt_id: 115 ino: 3 (py310) xxx ~ $ cat /proc/$$/fdinfo/1 pos: 0 flags: 0100002 mnt_id: 115 ino: 3 (py310) xxx ~ $ file /proc/$$/fd/0 /proc/387/fd/0: symbolic link to /dev/pts/0 (py310) xxx ~ $ file $(readlink -f /proc/$$/fd/0) /dev/pts/0: character special (136/0) 从两次 ls 可以看出 shell 把和自己关联的文件分给了子进程。 从两次 file 看出这个关联文件是一种字符设备。 从两次 cat 可以看出字符设备的 pos 总是 0，因此文件偏移量不会干扰读写。 学完 62 章终端和 64 章伪终端就明白为什么了。
  ]]></content></entry><entry><title>05.05 dup 文件描述符为什么要共享文件打开项？</title><url>/the-linux-programming-interface/05.05-dup-%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E6%89%93%E5%BC%80%E9%A1%B9/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html">  书上的例子是：
# 在 bash 中 ./myscript &amp;gt; results.log 2&amp;gt;&amp;amp;1 这样能够将标准输出流和错误流都重定向到日志文件中去。我们希望标准输出流和标准错误流能共享文件偏移量等信息，否则两者写入同一个文件中时就会相互覆盖。
注意，这里将输出流和错误流都重定向到了一个普通文件，因而 1 和 2 号文件描述符并不是像终端那样对应着字符设备，此时文件偏移量是非常重要的信息。
  </content></entry><entry><title>05.06 pwrite 不会改变文件的偏移量</title><url>/the-linux-programming-interface/05.06-pwrite-%E4%B8%8D%E4%BC%9A%E6%94%B9%E5%8F%98%E6%96%87%E4%BB%B6%E7%9A%84%E5%81%8F%E7%A7%BB%E9%87%8F/</url><categories><category>the-linux-programming-interface</category></categories><tags><tag>the-linux-programming-interface</tag></tags><content type="html"><![CDATA[  #include &lt;assert.h&gt; #include &lt;fcntl.h&gt; #include &lt;unistd.h&gt; #include &lt;stdio.h&gt; int main() { int fd; assert((fd = open(&#34;A.txt&#34;, O_WRONLY | O_TRUNC | O_CREAT, S_IRUSR | S_IWUSR | S_IRGRP | S_IROTH)) != -1); assert(pwrite(fd, &#34;pwrite&#34;, 6, 0) == 6); assert(write(fd, &#34;WRITE&#34;, 5) == 5); } 最后 A.txt 的文件内容为：
WRITEe 这说明第一次用 pwrite 读写完成之后，文件偏移量并没有被更新，还是在 0 的位置。
  ]]></content></entry><entry><title>UNIX 中 printf 指定参数绑定顺序</title><url>/posts/programming/cpp/UNIX-%E4%B8%AD-printf-%E6%8C%87%E5%AE%9A%E5%8F%82%E6%95%B0%E7%BB%91%E5%AE%9A%E9%A1%BA%E5%BA%8F/</url><categories/><tags><tag>c</tag><tag>linux</tag><tag>java</tag></tags><content type="html"><![CDATA[  UNIX 中的 printfSingle UNIX Specification 中允许 printf 使用 %m$ 和 *m$ 的形式来绑定第 m 个参数，其中 m 从 1 开始计数。如果使用了这种表达方式，则所有参数都要指定序号，而且不能遗漏参数。这样做的好处是：可以多次使用同一个参数。
请注意，参数是 %m$ 和 *m$ 这两个结构索取的。这意味着以下两行的含义相同：
printf(&#34;%*d&#34;, width, num); printf(&#34;%2$*1$d&#34;, width, num); 首先 %2$ 索要了参数 num 用来表示输出的数字，然后 *m$ 索要了参数 width 来表示输出的宽度。这和我们看到的 %*d 的参数顺序有差异：%*d 中就好像输出数字这个参数是 d 索取的一样。相关链接：StackOverflow 的提问。
C99 中没有规定这种指定序号绑定参数的方式。
对比：Java 中的 printf在 Java 中，printf 由 Formatter 类支持。这种多次使用一个参数的用法可以极大地方便日期的输出。比如：
Date date = new Date(); System.out.printf(&#34;%1$tH:%1$tM:%1$tS %1$tp %1$tL %1$tN %1$tz %n&#34;, date); 测试打印结果：
00:43:08 上午 280 280000000 +0800 不过，像 UNIX 那样用下标指定打印数和宽度没有成功。后来发现 Java 的格式化器不支持 *。不只是 *m$，是 variable width / precision 这一整个功能都不支持！
public class Main { public static void main(String args[]) { int width = 4; int num = 7; System.out.printf(&#34;%2$*1$d&#34;, width, num); } } // Exception in thread &#34;main&#34; java.util.UnknownFormatConversionException: Conversion = &#39;2&#39; Java 的 printf 还有一些其他扩展，比如说可以用 ^ 居中。
  ]]></content></entry><entry><title>我们实验室的服务器曾如何处理 Docker 数据转移的问题？</title><url>/posts/systems/Linux/%E6%88%91%E4%BB%AC%E5%AE%9E%E9%AA%8C%E5%AE%A4%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9B%BE%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86-Docker-%E6%95%B0%E6%8D%AE%E8%BD%AC%E7%A7%BB%E7%9A%84%E9%97%AE%E9%A2%98/</url><categories/><tags><tag>docker</tag><tag>linux</tag></tags><content type="html"><![CDATA[  修改配置文件网上一般推荐的做法是这种： https://linuxiac.com/how-to-change-docker-data-directory/
修改 /etc/docker/daemon.json，向其中加入：
{ &#34;data-root&#34;: &#34;/new/docker/root&#34; } 或者在 systemd 的服务启动程序中指定数据的路径。
不修改配置文件，只转移数据但是我们实验室的服务器没有采用以上方案，却通过其他方式完成了从标准位置 /var/lib/docker 向其他位置的数据转移，而且两个文件夹中的数据是一样的。可以想到的方法有三种：软链接、硬链接、挂载。一个一个分析。
有个同学说我们服务器是从 /var/lib/docker 到 /data/docker 有软链接。但是用 sudo ls -dlh /var/lib/docker /data/docker 看两个目录都不是软链接。
是硬链接吗？/var/lib 的挂载点是 /，文件系统是 /dev/nvme0n1p3，/data 的挂载点是 /data，文件系统是 /dev/sda1。文件系统不一样，肯定不是硬链接。另外，如果真的是硬链接，不能将数据转移到另外一个分区，我们（准确地说是实验室前辈）原本的目标就是把数据从空间少的固态硬盘转移到空间多的机械硬盘，这和目标相悖。还可以继续验证：进目录里面去数子文件夹数量，加上 . 和结点本身需要的一个引用得到 13，docker 文件夹的链接数也刚好是 13，说明没有其他文件夹链接到这里。
再看 df 的结果，发现 /var/lib/docker 的挂载点是 /var/lib/docker，不是 /。用 findmnt 看一下：
findmnt -T /var/lib/docker TARGET SOURCE FSTYPE OPTIONS /var/lib/docker /dev/sda1[/docker] ext4 rw,relatime 可见服务器曾是用挂载的方式处理 docker 数据转移问题的。再看 /etc/fstab，果然有这么一条记录，而文件从 2 年以前就是这么写的了：
(base) xxx@yyy:~$ cat /etc/fstab # /etc/fstab: static file system information. # # Use &#39;blkid&#39; to print the universally unique identifier for a # device; this may be used with UUID= as a more robust way to name devices # that works even if disks are added and removed. See fstab(5). # # &lt;file system&gt; &lt;mount point&gt; &lt;type&gt; &lt;options&gt; &lt;dump&gt; &lt;pass&gt; # / was on /dev/sda3 during installation UUID=c0ad5ae9-640d-478f-852c-85650bb068d4 / ext4 errors=remount-ro 0 1 # /boot was on /dev/sda1 during installation UUID=78c5af6f-b90c-4d1c-a309-d0a515c96147 /boot ext4 defaults 0 2 # swap was on /dev/sda2 during installation #UUID=0c47825f-1e06-4e6c-84e3-b9445a4e57b1 none swap sw 0 0 UUID=7d7fe0a2-14df-4102-a91b-393fcf30063f /data ext4 defaults 0 0 /data/docker /var/lib/docker none bind 0 0 (base) xxx@yyy:~$ ls -lh /etc/fstab -rw-rw-r-- 1 root root 875 6月 7 2022 /etc/fstab 这里的使用了 none 来作为 type，意义为绑定挂载（MS_BIND）或者移动（MS_MOVE），详细一点的解释可以参考 https://askubuntu.com/a/743812/1666727 。简单来说，none 是用来表示文件系统已经被 mount，现在只是为文件系统中的某个路径添加一个新的访问点。
根据 TLPI 第 18 章第 1 节：
使用绑定挂载（bind mount）可以获得与为目录创建硬链接相似的效果。
  ]]></content></entry><entry><title>04.14 文件系统</title><url>/apue/04.14-15-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html"><![CDATA[  软链接（符号链接）软链接本质上存储了目标文件名，但因为是特殊的文件，我们不能直接用 openat 打开软链接文件并用 read 读取其内容。想要跟踪符号链接，可以向 readlink 系统调用传入软链接文件路径。
用 openat 尝试读取软链接目标有什么错误？openat 默认会 follow 符号链接，这不是我们期望的；如果把 flags 设置成 O_RDONLY | O_NOFOLLOW，则会（在遇到软链接文件时）直接打开失败。
Important
不像 openat，lstat 和带有 AT_SYMLINK_NOFOLLOW 标志的 fstatat 就能够读取符号链接本身的信息。
Note
AT_SYMLINK_NOFOLLOW 和 AT_SYMLINK_FOLLOW 两个宏都是有定义的，而且它们处在不同的位！
似乎没有通过软链接本身的 fd 获得软链接目标的系统调用？给 openat 传入 O_PATH | O_NOFOLLOW 的确可以得到一个不会跟踪的、没有打开文件的、只能标识文件位置的 fd，但是获取这样的 fd 就需要文件路径作为参数，所以可能没有必要设计这样的一个系统调用？
Note
在我的 WSL 上，O_PATH 没有被定义，需要使用 __O_PATH。
硬链接（链接）文件系统中的链接说的是硬链接，使用 stat 结构的 st_nlink 成员记录。硬链接不能跨文件系统。
任何一个叶目录的链接数都是 2。多出来的这一个链接是由于它的目录项中的 .，即本目录目录项。
/data/apue $ mkdir d /data/apue $ cd d /data/apue/d $ ls -al total 8 drwxr-xr-x 2 &lt;USER&gt; &lt;USER&gt; 4096 May 14 14:50 . drwxr-xr-x 6 &lt;USER&gt; &lt;USER&gt; 4096 May 14 14:50 .. /data/apue/d $ mkdir b /data/apue/d $ ls -al total 12 drwxr-xr-x 3 &lt;USER&gt; &lt;USER&gt; 4096 May 14 14:50 . drwxr-xr-x 6 &lt;USER&gt; &lt;USER&gt; 4096 May 14 14:50 .. drwxr-xr-x 2 &lt;USER&gt; &lt;USER&gt; 4096 May 14 14:50 b 还可以看到 .. 这个上一级目录的目录项也是真实存在的，因为创建新的子文件夹之后，d 文件夹的链接计数增加了 1。
大多数系统不支持创建目录的硬链接（. 和 .. 比较特殊），因为这样可能会造成文件系统循环。
link 和 linkat#include &lt;unistd.h&gt; int link(const char *oldpath, const char *newpath); #include &lt;fcntl.h&gt; /* Definition of AT_* constants */ #include &lt;unistd.h&gt; int linkat(int olddirfd, const char *oldpath, int newdirfd, const char *newpath, int flags); linkat 默认不会跟踪符号链接，因此如果 oldpath 对应符号链接文件，就会创建符号链接文件本身的链接。使用 AT_SYMLINK_FOLLOW 这个标志时，linkat 会先跟踪符号链接再创建链接。
unlink 和 unlinkat这两个函数用来删除文件。从名字可以看出，删除文件的本质是删除目录项，即链接数量减少 1。如果文件处在具有粘着位的目录中，则还受到粘着位规则规定的删除文件需要的权限限制。
当链接计数为 0，同时没有进程正在使用文件时，文件可以被删除。
如果 unlink 的参数是符号链接文件的路径，则会删除符号链接文件本身，而不是其所指的文件。
Important
除了 unlink 之外，remove 函数也能删除文件。对于普通文件，remove 的作用和 unlink 相同；对于目录，remove 的作用和 rmdir 相同。对于目录而言，rmdir 和简单的 unlink 是有差异的，毕竟很多系统都不允许 link 目录。
  ]]></content></entry><entry><title>04.10 Linux 中只有超级用户可以修改文件 owner</title><url>/apue/04.10-Linux-%E4%B8%AD%E5%8F%AA%E6%9C%89%E8%B6%85%E7%BA%A7%E7%94%A8%E6%88%B7%E5%8F%AF%E4%BB%A5%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6-owner/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html">  用 chown 修改 ownerLinux 和 BSD 下只有 root 才可以。有些系统允许用户修改自己文件的所有者完成文件转让。
用 chown 修改 group超级用户肯定是可以的。
或者，进程拥有此文件（看有效用户 ID），参数 owner 等于 -1 或者文件所有者的 ID，参数 group 等于进程的有效组 ID 或者附属组 ID 中的一个。
这意味着非超级用户只能更改自己拥有文件的组 ID，而且只能改到自己所属的组（即完成文件的组内转让）。
  </content></entry><entry><title>04.11 文件截断和空洞</title><url>/apue/04.11-%E6%96%87%E4%BB%B6%E6%88%AA%E6%96%AD%E5%92%8C%E7%A9%BA%E6%B4%9E/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html">  int truncate(const char *path, off_t length); int ftruncate(int fd, off_t length); 这两个函数能够设置文件长度，如果新的长度比原来更短，则旧的内容被截断。如果新的长度比原来更长，则中间的部分会形成空洞。形成空洞的部分在被其他程序读取的时候，得到的是 0；全 0 的块可以不实际分配给文件，因此不会增加文件体积。
  </content></entry><entry><title>04.08 umask 设置屏蔽字</title><url>/apue/04.08-umask-%E8%AE%BE%E7%BD%AE%E5%B1%8F%E8%94%BD%E5%AD%97/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html">  umask 系统调用这样理解屏蔽字：当某一位被设置为 1，这一位就不起作用。umask 把当前进程的文件创建屏蔽字设置为 mask &amp;amp; 0777，也就是只有文件权限位是受到屏蔽的。umask 能影响 open 和 mkdir 等系统调用，这相当于每次传入它们的 mode_t 参数都用 umask 屏蔽了给定的位。
Tip
文件打开标志中（int flags），读、写、读写三个状态被设置成了互斥的，读和写不能简单叠加得到读写。它们的宏以 O_ 开头（可能表示 open），分别是 O_RDONLY / O_WRONLY / O_RDWR，访问前要先用 O_ACCMODE 掩码对 flags 做好处理。 文件访问权限模式（mode_t mode）读、写、执行可以叠加。它们的宏以 S_I 开头（可能表示 stat、inode），然后跟 R/W/X 中的一个，再跟 USR/GRP/OTH 中的一个。 Tip
掩码和屏蔽字好像都是 mask。前者的用法是 x &amp;amp; mask，后者的用法是 x &amp;amp; ~mask。
默认的 umask 值是 S_IWGRP | S_IWOTH，也就是 022，这表示如果无其他修改，我们无法简单地创建 group 和 others 可以写入的文件。
当文件父目录被设置了 ACL 时，umask 被忽略。
umask 命令Single UNIX Specification 规定 shell 有 umask 命令。umask 可以用来显示或设置当前的 shell 的 umask。
umask 默认显示模式是数字，这和我们传入 mode 很像。但是 umask 的符号模式（-S）显示的内容形如 u=rwx,g=rx,o=rx，看上去是和我们设置的屏蔽字反着的，意义变成了掩码。
  </content></entry><entry><title>04.09 chmod</title><url>/apue/04.09-chmod/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html">  区别于 umask 的操作只作用于文件的读写执行相关的 9 位，chmod 是字如其名的操作 struct stat 类型 st_mode 字段的系统调用。
chmod 系统调用只会改变文件 inode 结点的上次修改时间，不会改变文件内容的上次修改时间。因此，用 ls 列出 chmod 修改过权限的文件属性时，我们不会看到文件的上次修改时间有变化。
$ ls -lh A.txt -rw-r----- 1 root root 20 May 8 23:35 A.txt $ chmod 644 A.txt $ ls -lh A.txt -rw-r--r-- 1 root root 20 May 8 23:35 A.txt chmod 在一些条件下会清除粘着位、设置用户 ID 位和设置组 ID 位。略。
粘着（sticky）位对应 S_ISVTX（saved-text bit，又叫保存正文位），在尚未使用请求分页的早期 UNIX 版本中，带有粘着位的可执行文件在第一次执行结束之后其代码副本会被保存到交换区，这样下一次就可以被更快被加入到内存中。常用的文本编辑器或者编译器都适合使用粘着位。
现在 Single UNIX Specification 扩展了粘着位的含义：如果一个目录具有粘着位，对该目录具有写权限且满足 a) 拥有此文件 b) 拥有此目录 c) 是超级用户 三个条件中的至少一个才能删除或者重命名目录下的文件。目录 /tmp 和 /var/tmp 就适合设置粘着位，它们都是公用目录，允许所有用户在里面创建文件，但是不希望其他用户删除或者重命名。我的理解是删除和重命名是在修改文件的元信息，而不是修改文件的内容，所以有专门的控制选项。
  </content></entry><entry><title>04.09.2 验证文件粘着位的作用</title><url>/apue/04.09.2-%E9%AA%8C%E8%AF%81%E6%96%87%E4%BB%B6%E7%B2%98%E7%9D%80%E4%BD%8D%E7%9A%84%E4%BD%9C%E7%94%A8/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html"><![CDATA[  #include &lt;errno.h&gt; #include &lt;fcntl.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; void perror_and_exit (const char *msg) { int err = errno; fflush (stdout); fprintf (stderr, &#34;%s: %s\n&#34;, msg, strerror (err)); exit (errno); } int main (int argc, char **argv) { if (argc != 2) { fprintf (stderr, &#34;Usage: %s &lt;path&gt;\n&#34;, argv[0]); exit (1); } struct stat buf; if (stat (argv[1], &amp;buf) == -1) perror_and_exit (&#34;stat&#34;); if (buf.st_mode &amp; S_ISVTX) printf (&#34;S_ISVTX is set\n&#34;); else printf (&#34;The bit is not set\n&#34;); } 编译运行：
⇨ /data/apue $ /data/apue/build/apue build/ The bit is not set ⇨ /data/apue $ /data/apue/build/apue /tmp/ S_ISVTX is set ⇨ /data/apue $ /data/apue/build/apue /var/ The bit is not set ⇨ /data/apue $ /data/apue/build/apue /var/tmp/ S_ISVTX is set 验证一下没有粘着位的影响：
⇨ /data/apue $ sudo touch build/rootfile.txt [sudo] password for &lt;USER&gt;: ⇨ /data/apue $ ls -lAh build/rootfile.txt -rw-r--r-- 1 root root 0 May 12 22:18 build/rootfile.txt ⇨ /data/apue $ mv build/rootfile.txt build/userfile.txt ⇨ /data/apue $ build/rootfile.txt 文件之前不存在，现在是 root 创建的，但是普通用户居然也能将文件改名！我们在设置了粘着位的 /tmp 目录看看这个情况：
⇨ /data/apue $ sudo touch /tmp/rootfile.txt [sudo] password for &lt;USER&gt;: ⇨ /data/apue $ ls -lAh /tmp/rootfile.txt -rw-r--r-- 1 root root 0 May 12 22:25 /tmp/rootfile.txt ⇨ /data/apue $ mv /tmp/rootfile.txt /tmp/userfile.txt mv: cannot move &#39;/tmp/rootfile.txt&#39; to &#39;/tmp/userfile.txt&#39;: Operation not permitted 这就比较符合预期了。之前很多次遇到权限不够的情况，我还以为不能删除其他用户的文件是通过文件读写执行的权限检查的，现在看来还是粘着位的作用。
  ]]></content></entry><entry><title>cudaLaunchKernel 非常耗时？</title><url>/posts/programming/cuda/cudaLaunchKernel-%E9%9D%9E%E5%B8%B8%E8%80%97%E6%97%B6/</url><categories/><tags><tag>cuda</tag></tags><content type="html">  事情起因在第一次使用 nsys 的时候发现 cudaLaunchKernel 非常耗时。网友觉得 cudaLaunchKernel 超过了 50ms 就觉得很大了，但我在服务器上测是 400~500ms！
我想到的可能原因：
服务器的 CPU 和 GPU 负载太高。用环境变量 CUDA_VISIBLE_DEVICES 换到同一台服务器上相对比较空闲的卡，发现 kernel 启动时间从平均 440 ms 减少到了 372 ms，因此可以排除 GPU 负载高的影响。 启动 kernel 时申请的资源太多。我们自己写的 kernel 每个 block 都是固定 512 线程数，GPU 为 3090，每个 SM 上最大能容纳 1024 个线程；对 cudnn 的调用（比如卷积核）看了一下是用满了 1024 线程数。 GPU 在 warmup 阶段。 真正原因GPU 在 warmup 阶段。
我之前都是参考 Avg，没有参考 Min。幸好我的测试程序恰好调用了两次 kernel，这才让我看到第二次调用（也就是 Min）实际上只花了 30 us（微秒）。而第一次花费了 917 ms。
另外网上也说 nsys 不适合高精度的程序观察（比如极短的内核），记录的 cudaLaunchKernel 的时间中可能包含了上下文切换，因而比实际花费的时间略长。
  </content></entry><entry><title>04.04-07 设置用户 id 和设置组 id</title><url>/apue/04.04-07-%E8%AE%BE%E7%BD%AE%E7%94%A8%E6%88%B7-id-%E5%92%8C%E8%AE%BE%E7%BD%AE%E7%BB%84-id/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html">  进程有哪些用户或组 id？和一个进程关联的 id 有 6 个或者更多：
实际用户 id 和实际组 id 有效用户 id、有效组 id 和附属组 id 保存的设置用户 id 和保存的设置组 id（由 exec 函数保存） 有效用户（组）决定实际访问权限什么是有效用户 id？一个进程在启动时可以以别人的身份启动，从而拥有别人的权限，这个时候真正生效的是有效用户 id。有效组 id 也是类似的。
什么时候需要用别人的身份启动？passwd 程序就是不需要 root 权限的，但是能够修改 root 才能写入的文件，这是因为 passwd 程序就使用了 root 作为有效用户。其他例子包括：mount、unmount、su 和 wall，前三个是设置用户 ID，最后一个是设置组 ID，其作用是向 tty 下辖的所有终端写入一条信息。
如何按文件设置有效用户 id？可以在文件的模式字（st_mode）中设置特殊标志，用来表示执行此文件时，将进程的有效用户 id 设置为文件所有者的用户 id，这个特殊标志就是设置用户 id 位。同样，还有设置组 id 位。
access 和 faccessat 函数可以测试用户访问权限access 函数可以测试实际用户的访问权限。faccess 函数的功能更多，还能设置相对目录的 fd 或者测试有效用户的访问权限。
既然决定进程是否真正具有访问权限的是有效用户 id，我们为什么还需要判断实际用户的访问权限？比如，有些程序是用 root 的身份进行的，但是我们在程序执行过程中想要判断进程所属的用户是否真正拥有访问权限。
  </content></entry><entry><title>04.05 判断文件访问权限</title><url>/apue/04.05-%E5%88%A4%E6%96%AD%E6%96%87%E4%BB%B6%E8%AE%BF%E9%97%AE%E6%9D%83%E9%99%90/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html"><![CDATA[  #include &lt;errno.h&gt; #include &lt;fcntl.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;sys/stat.h&gt; #include &lt;unistd.h&gt; void perror_and_exit (const char *msg) { int err = errno; fflush (stdout); fprintf (stderr, &#34;%s: %s\n&#34;, msg, strerror (err)); exit (errno); } int main (int argc, char **argv) { struct stat buf; const char *ptr; for (int i = 1; i &lt; argc; ++i) { printf (&#34;%s &#34;, argv[i]); if (lstat (argv[i], &amp;buf) &lt; 0) perror_and_exit (&#34;lstat&#34;); if (S_ISREG (buf.st_mode)) ptr = &#34;regular&#34;; else if (S_ISDIR (buf.st_mode)) ptr = &#34;directory&#34;; else if (S_ISCHR (buf.st_mode)) ptr = &#34;character special&#34;; else if (S_ISBLK (buf.st_mode)) ptr = &#34;block&#34;; else if (S_ISFIFO (buf.st_mode)) ptr = &#34;fifo&#34;; else if (S_ISLNK (buf.st_mode)) ptr = &#34;symbolic link&#34;; else if (S_ISSOCK (buf.st_mode)) ptr = &#34;socket&#34;; else ptr = &#34;** unknown mode **&#34;; printf (&#34;%s\n&#34;, ptr); } } 例子：
$ /data/apue/build/apue /home /dev/fd/0 / /home directory /dev/fd/0 symbolic link / directory   ]]></content></entry><entry><title>在 Ubuntu 上安装和使用 nsys</title><url>/posts/programming/cuda/%E5%9C%A8-Ubuntu-%E4%B8%8A%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8-nsys/</url><categories/><tags><tag>cuda</tag><tag>linux</tag></tags><content type="html">  安装nsys 来自包 cuda-nsight-systems-11-7（和自己的 CUDA 版本对应一下）。
在网上一直都没有搜到安装方式，官网也说的不明不白。尝试过两个错误的包：
nsight-systems：这个是 Qt 写的图形界面程序，提供的二进制可执行程序是 nsight-sys。 nvidia-nsight：这个是 Java 写的图形界面程序，提供的二进制可执行程序是 nsight。 使用用 nsys profile --stat=true xxx 运行完程序后得到 report1.nsys-rep，report 后面的编号是自动增长的，而 --stat=true 表示用文本形式在命令行输出信息。如果有条件可以把 report1.nsys-rep 下载下来然后用本地的图形化程序加载分析。
但是这样导出的程序看不到 CUDA 内存占用。为了看到 CUDA 内存占用情况，考虑：
nsys profile --cuda-um-cpu-page-faults=true \ --cuda-um-gpu-page-faults=true \ --cudabacktrace=all \ --cuda-memory-usage=true \ --gpu-metrics-device=0 &amp;lt;program&amp;gt; 但还是没有成功：
从结果来看程序占用了 32 MiB 显存，但是 nvidia-smi 这类工具认为程序占用了 800 MiB 显存。难道是显存分配但未读写的部分不会被计入 nsys？ 受到 paranoid 等级的限制，CPU 无法采样，CUDA backtrace 和 CUDA memory usage 无法开启。 又用 echo 2 | sudo tee /proc/sys/kernel/perf_event_paranoid 改了宿主机（不是容器）的 paranoid 等级（我的容器启动参数有 --pid=host，没有 --privileged），可以采样 CPU 了。
现在 nsys-ui 的诊断信息中还有一个错误（之前是两个），看上去是权限不够，得在创建容器的时候给 --cap-add=SYS_ADMIN 。
Caution
不清楚 paranoid 等级具体有什么用，我测试完已经改回去了。
接下来可以考虑的方法：参考 https://stackoverflow.com/questions/38758627 把容器停止，修改参数，然后重启 docker 服务。但是重启整个 docker 服务对我来说不太现实。Commit 现有容器再创建新容器也有点麻烦，就没兴趣继续看下去了。
  </content></entry><entry><title>03.12 dup 等效于 fcntl 的 F_DUPFD 选项</title><url>/apue/03.12-dup-%E7%AD%89%E6%95%88%E4%BA%8E-fcntl-%E7%9A%84-F_DUPFD-%E9%80%89%E9%A1%B9/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html">  fcntl(fd, F_DUPFD, 0) 相当于 dup(fd) 在两次调用间没有其他线程、信号量处理等可能再次打开 fd2 的情况下： close(fd2) fcntl(fd, F_DUPFD, fd2) 相当于 dup2(fd, fd2) 但是没有原子性，而且 errno 有差异。   </content></entry><entry><title>03.14 用 fcntl 检查文件属性</title><url>/apue/03.14-%E7%94%A8-fcntl-%E6%A3%80%E6%9F%A5%E6%96%87%E4%BB%B6%E5%B1%9E%E6%80%A7/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html"><![CDATA[  抄的书上的代码。
#include &lt;errno.h&gt; #include &lt;fcntl.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;sys/param.h&gt; #include &lt;sys/syscall.h&gt; #include &lt;sys/times.h&gt; #include &lt;unistd.h&gt; extern int errno; void perror_and_exit (const char *msg) { perror (msg); exit (errno); } int main (int argc, char **argv) { int val; if (argc != 2) { fputs (&#34;usage: a.out &lt;descriptor#&gt;\n&#34;, stderr); exit (1); } if ((val = fcntl (atoi (argv[1]), F_GETFL, 0)) &lt; 0) { int ec = errno; fprintf (stderr, &#34;fcntl error for fd %d: %s&#34;, atoi (argv[1]), strerror (ec)); exit (ec); } switch (val &amp; O_ACCMODE) { case O_RDONLY: printf (&#34;read only&#34;); break; case O_WRONLY: printf (&#34;write only&#34;); break; case O_RDWR: printf (&#34;read write&#34;); break; default: perror_and_exit (&#34;unknown access mode&#34;); } if (val &amp; O_APPEND) printf (&#34;, append&#34;); if (val &amp; O_NONBLOCK) printf (&#34;, nonblocking&#34;); if (val &amp; O_SYNC) printf (&#34;, synchronous writes&#34;); #if !defined(_POSIX_C_SOURCE) &amp;&amp; defined(O_FSYNC) &amp;&amp; (O_FSYNC != O_SYNC) if (val &amp; O_FSYNC) printf (&#34;, synchronous writes&#34;); #endif putchar (&#39;\n&#39;); exit (0); } 非常惊讶的是，Linux 上 Bash 给应用程序分配的标准输入、输出、错误流都是可读可写的。似乎 Bash 是把当前的打字机设备（tty）打开并分配给了应用程序的三个标准流，因为 /proc/&lt;pid&gt;/fd/0 （和其他两个）都是链接到了 /dev/pts/5 上，而这个设备是我当前的终端。
$ /data/apue/build/apue 0 read write $ /data/apue/build/apue 1 read write $ /data/apue/build/apue 2 read write $ /data/apue/build/apue 0 &lt;A.txt read only $ /data/apue/build/apue 0 &lt;&gt;A.txt read write $ /data/apue/build/apue 5 5&lt;&gt;B.txt read write 注意 Bash 中 /data/apue/build/apue 5 5&lt;&gt;B.txt 这种重定向，它把 5 号文件描述符分配给了 B.txt 文件，而且是用可写的方式打开。因为这里有写方式打开，所以 B.txt 不存在时会自动创建，如果是只读方式打开，那么 B.txt 不存在就会报错。
  ]]></content></entry><entry><title>03.xx write 有 O_APPEND 标志也会修改文件偏移量</title><url>/apue/03.xx-write-%E6%9C%89-O_APPEND-%E6%A0%87%E5%BF%97%E4%B9%9F%E4%BC%9A%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E5%81%8F%E7%A7%BB%E9%87%8F/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html"><![CDATA[  首先保证 A.txt 文件是空的。然后编译运行：
#include &lt;errno.h&gt; #include &lt;fcntl.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;unistd.h&gt; void perror_and_exit (const char *msg) { perror (msg); exit (errno); } int main (int argc, char **argv) { int fd; char buf[64]; /* 完成截断 */ if ((fd = open (&#34;A.txt&#34;, O_CREAT | O_WRONLY | O_TRUNC)) == -1) perror_and_exit (&#34;open for truncation&#34;); if (close (fd) == -1) perror_and_exit (&#34;close for truncation&#34;); if ((fd = open (&#34;A.txt&#34;, O_APPEND | O_RDWR)) == -1) perror_and_exit (&#34;open&#34;); /* 第一次写入 */ if (write (fd, &#34;nodoubtnodoubt&#34;, 14) == -1) perror_and_exit (&#34;write nodoubtnodoubt&#34;); /* 第二次写入只能写入到末尾，是因为 O_APPEND 存在 */ if (lseek (fd, 0, SEEK_SET) == -1) perror_and_exit (&#34;lseek 64&#34;); if (write (fd, &#34;lalala&#34;, 6) == -1) perror_and_exit (&#34;write lalala&#34;); /* * 尽管之前调用过 lseek，但还是无法读出字符，说明 O_APPEND 模式下的 write * 也会更新文件偏移量 */ if (read (fd, buf, 16) == -1) perror_and_exit (&#34;read&#34;); printf (&#34;read: %s\n&#34;, buf); /* 再次 lseek 就能读出开头的字符 */ if (lseek (fd, 0, SEEK_SET) == -1) perror_and_exit (&#34;lseek 0&#34;); if (read (fd, buf, 16) == -1) perror_and_exit (&#34;read&#34;); printf (&#34;read: %s\n&#34;, buf); } 最后 A.txt 文件的内容：
nodoubtnodoubtlalala 输出的内容：
read: read: nodoubtnodoubtla   ]]></content></entry><entry><title>3.12 dup 不共享文件描述符属性</title><url>/apue/03.12-dup-%E4%B8%8D%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6%E5%B1%9E%E6%80%A7/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html"><![CDATA[  #include &lt;errno.h&gt; #include &lt;fcntl.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;sys/param.h&gt; #include &lt;sys/syscall.h&gt; #include &lt;sys/times.h&gt; #include &lt;unistd.h&gt; extern int errno; void err_sys (const char *msg) { perror (msg); exit (errno); } int main (int argc, char **argv) { int fd = open (&#34;A.txt&#34;, O_WRONLY | O_CREAT | O_TRUNC, S_IRUSR | S_IWUSR | S_IRGRP | S_IWGRP | S_IROTH); if (fd == -1) err_sys (&#34;open&#34;); int ret, fd2; if ((ret = fcntl (fd, F_SETFD, FD_CLOEXEC)) == -1) err_sys (&#34;fcntl set fd failed&#34;); fd2 = dup (fd); if (fd2 == -1) err_sys (&#34;dup&#34;); if ((ret = fcntl (fd, F_GETFD, FD_CLOEXEC)) == -1) err_sys (&#34;fcntl get fd failed&#34;); printf (&#34;ret=%d\n&#34;, ret); if ((ret = fcntl (fd2, F_GETFD, FD_CLOEXEC)) == -1) err_sys (&#34;fcntl get fd2 failed&#34;); printf (&#34;ret=%d\n&#34;, ret); } 结果：
ret=1 ret=0 FD_CLOEXEC 被清理掉了。
  ]]></content></entry><entry><title>3.12 dup 会共享文件属性</title><url>/apue/03.12-dup-%E4%BC%9A%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%B1%9E%E6%80%A7/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html"><![CDATA[  #include &lt;errno.h&gt; #include &lt;stdio.h&gt; #include &lt;stdlib.h&gt; #include &lt;sys/syscall.h&gt; #include &lt;sys/times.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/param.h&gt; #include &lt;fcntl.h&gt; #include &lt;string.h&gt; extern int errno; void err_sys(const char *msg) { perror(msg); exit(errno); } int main (int argc, char **argv) { int fd = open(&#34;A.txt&#34;, O_WRONLY | O_CREAT | O_TRUNC, S_IRUSR | S_IWUSR | S_IRGRP | S_IWGRP | S_IROTH); if (fd == -1) { err_sys(&#34;open&#34;); } int fd2 = dup(fd); if (fd2 == -1) { err_sys(&#34;dup&#34;); } const char *msg; size_t n; msg = &#34;first message&#34;; n = strlen(msg); if (write(fd, msg, n) != n) { err_sys(&#34;write fd&#34;); } msg = &#34;second message&#34;; n = strlen(msg); if (write(fd2, msg, n) != n) { err_sys(&#34;write fd2&#34;); } } 结果：两条消息按顺序写入了文件，后者并没有覆盖前者。
  ]]></content></entry><entry><title>3.13 sync 族函数的区别</title><url>/apue/03.13-sync-%E6%97%8F%E5%87%BD%E6%95%B0%E7%9A%84%E5%8C%BA%E5%88%AB/</url><categories><category>advanced-programming-in-the-unix-environment</category></categories><tags><tag>apue</tag></tags><content type="html">  Caution
应当参考 13 文件输入输出缓冲，当前文件中有些内容可能是有错误的。
syncfs(int fd) 是 Linux 特有。sync / fsync / fdatasync 是 POSIX 标准。
函数功能返回时是否完成写入？POSIXBSDLinuxfsync(int fd)写入磁盘。不保证含糊不清保证fdatasync(int fd)写入数据到磁盘，不保证属性被写入。不保证含糊不清保证sync(void)发起写入磁盘请求。不保证不保证保证？syncfs(int fd)发起写入磁盘请求。\\不保证fsync 和 fdatasync 的保证性比 sync 更强。受接口限制，在想要保证写入时只能选择它们。
按照 Hacker News 帖子 的说法，BSD 上不少厂商是没有做到 fsync 返回时数据已写入的保证的，比如 macOS。
关于 sync：书上说名为 update 的内核进程一般每 30s 调用一次 sync 来进行数据同步，但是我没找到 update 进程。FreeBSD 上是有 syncer 内核进程来做这件事。~~Linux 上的没找到对应的概念，可能有更加精细的控制方式。~~Linux 使用的是内核线程（而不是进程）实现的，2.4 版本中这个内核线程叫做 kupdated，2.6 版本中这个内核线程叫做 pdflush。
  </content></entry><entry><title>std::lower_bound 是一种分区查找算法</title><url>/posts/programming/cpp/std__lower_bound-%E6%98%AF%E4%B8%80%E7%A7%8D%E5%88%86%E5%8C%BA%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/</url><categories/><tags><tag>cpp</tag><tag>algorithm</tag></tags><content type="html"><![CDATA[  起因：每日一题官解看不明白今天（2024 年 5 月 4 日）做 Leetcode 每日一题又没有做出来，最后抄了答案。题目是这样的：1235. 规划兼职工作。
思路是先按照 endTime 排序，然后再 dp，然后 dp 中用二分查找求满足“自己的 endTime 小于等于当前元素 startTime ” 的元素数量。但是官方解答的 std::upper_bound 传参实在是看迷糊了。
二分查找：AoS 和 SoA 的比较一般数组（Array of Structures 或 AoS）排序好之后，直接用 std::lower_bound / std::upper_bound 做就好了。但如果数组里面存的不是可以直接用 operator&amp;lt; 或者自定义 comp 比较的值，写 comp 就比较伤脑筋。比如这道题里面为了减少数据拷贝（或者内存使用量），只对下标排序：
注：comp 指的是自定义的比较器。
int jobScheduling(vector&amp;lt;int&amp;gt; &amp;amp;startTime, vector&amp;lt;int&amp;gt; &amp;amp;endTime, vector&amp;lt;int&amp;gt; &amp;amp;profit) { vector&amp;lt;int&amp;gt; idx(n); iota(idx.begin(), idx.end(), 0); sort(idx.begin(), idx.end(), [&amp;amp;](int i, int j) -&amp;gt; bool { return endTime[i] &amp;lt; endTime[j]; }); // ... } 现在有下标，但是需要拿着下标去访问不同的数组，布局方式是 Structure of Arrays，即 SoA。这个时候解题一般需要手写二分查找。能不能继续利用标准库的二分呢 ？
看了一下 cppreference 上面 std::lower_bound 和 std::upper_bound 的 possible implementation，发现两者只有 comp 的使用方式有变化。拿默认比较方式 operator&amp;lt; 来理解：
std::lower_bound 函数形式是 comp(cur, pivot)。满足条件就 lo = mid + 1，否则 hi = mid。结果是把满足条件的划分 …  ]]></content></entry><entry><title>为什么我不推荐用 enum class 作为强类型的整数？</title><url>/posts/programming/cpp/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E4%B8%8D%E6%8E%A8%E8%8D%90%E7%94%A8-enum-class-%E4%BD%9C%E4%B8%BA%E5%BC%BA%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%95%B4%E6%95%B0/</url><categories><category>cpp-language</category></categories><tags><tag>cpp</tag><tag>cppreference</tag></tags><content type="html">  C++11 之后 enum 的新增功能enum class 是 C++11 提供的功能，为了更好理解后文的内容，我们先看看 C++11 之后 enum 有什么变化。参考资料见 https://en.cppreference.com/w/cpp/language/enum 。
有作用域枚举有作用域枚举（Scoped enumerations）使用 enum class|struct ClassName 声明，以区别于原来的无作用域枚举。无作用域枚举的枚举量可以直接在外围名字空间中访问，当枚举类有名字且 C++ 版本至少为 C++11 时，可以通过 枚举名::枚举量 访问；有作用域枚举只能通过 枚举名::枚举量 访问。
有作用域枚举的默认底层类型是 int。
例子：
void example() { enum class Color { red, green = 20, blue }; Color r = Color::blue; } 显式指定底层类型C++11 可以显式指定枚举类的底层类型（underlying type），提高了代码可移植性。此前枚举底层类型是实现定义。
例子：
enum : int { APPLE, }; 笼统枚举声明笼统枚举声明（Opaque enum declaration）就是不写枚举项，但是声明一个枚举类型，同时枚举类的底层类型也在声明的位置上确定下来。因此，笼统枚举声明只能用来声明有作用域枚举，或者用来声明有显式底层类型的无作用域枚举。
例子：
enum byte : unsigned char; 从整数类型到固定底层类型枚举类的显式转换（C++17）在 C++17 之后，一个枚举类有了固定底层类型（不再是实现定义底层类型，包括有作用域枚举和显式声明了底层类型的枚举类型这两种情况），就能从整数类型显式构造，不过要保证这个构造不会使得整数表示范围变窄。
Cppreference 的网页说了很多要求，但是从形式上来看就像枚举类对每个 non-narrowing 的整数类型有了 explicit 的构造函数（枚举类不是类，本身没有构造函数）：
enum byte : unsigned char {}; // byte is a new integer type; see also std::byte (C++17) byte …  </content></entry><entry><title>cudaDeviceSynchronize 和 cudaStreamSynchronize</title><url>/posts/programming/cuda/cudaDeviceSynchronize-%E5%92%8C-cudaStreamSynchronize/</url><categories/><tags><tag>cuda</tag></tags><content type="html">  我的理解CUDA 的 API 都是和 device 相关的，调用前要先确保已经调用过 cudaSetDevice 将 context 关联到相关的设备上（据 Stackoverflow 的老提问，这个 context 会占用 150 MB 显存；从我这边来看，这个显存占用量还更大一些，有 200300 MB）。创建流是不需要提供设备号的，所以它肯定使用的是 thread_local 的 device。
也就是说，每个流是和设备关联起来的，用 cudaDeviceSynchronize 实际上是同步了这个设备上所有的流，而 cudaStreamSynchronize 是同步了单个流。前者的同步范围更大。
根据 Stackoverflow 的这个回答，cudaStreamSynchronize 的默认参数是 nullptr，也就是默认流，同步它相当于同步当前设备上的所有阻塞流。由于可以创建非阻塞流，所以就算不给 cudaStreamSynchronize 传参或者传 nullptr，效果也和 cudaDeviceSynchronize() 可能是不一样的。
cudaStreamCreateWithFlags( stream_0, cudaStreamNonBlocking ); cudaStreamCreate( stream_1 ); // ... cudaStreamSynchronize( nullptr ); // sync with stream_1 and legacy stream cudaDeviceSynchronize(); // sync with stream_0, stream_1 and legacy 其他cudaThreadSynchronize 方法和 cudaDeviceSynchronize 很相似，前者是过时方法，建议使用后者。
  </content></entry><entry><title>inline 函数不对外链接？gnu89 和 c99 恐怖的语义对换！</title><url>/posts/programming/cpp/inline-%E5%87%BD%E6%95%B0%E4%B8%8D%E5%AF%B9%E5%A4%96%E9%93%BE%E6%8E%A5gnu89-%E5%92%8C-c99-%E6%81%90%E6%80%96%E7%9A%84%E8%AF%AD%E4%B9%89%E5%AF%B9%E6%8D%A2/</url><categories/><tags><tag>c</tag><tag>cpp</tag></tags><content type="html"><![CDATA[  经过遇到过一个坑：为共享库写函数，但是又需要从头文件隐藏实现时，不要将函数声明为内联。否则编译器会认为它未被使用并忽略它，链接的时候就找不到这个函数。
项目使用的语言是 C++。
TL;DR其实只是不会主动生成函数定义罢了，不是不能对外链接。除非调用处看到的声明带有 inline 关键字，从而尝试在其所在的翻译单元中寻找。
尝试解释：C++ 中内联函数按需生成https://zh.cppreference.com/w/cpp/language/inline 中有一句：
内联函数或变量 (C++17 起) 的定义必须在访问它的翻译单元中可达（不一定要在访问点前）。
C++ 外部链接的内联函数 / 变量是什么意思？文档中有这句话：
Inline const variables at namespace scope have external linkage by default (unlike the non-inline non-volatile const-qualified variables).
证实后半句：
// main.cc #include &amp;lt;iostream&amp;gt; const int a = 3; void f(); int main() { f(); printf(&amp;#34;lalala\n&amp;#34;); } // linkme.cc #include &amp;lt;cstdio&amp;gt; extern int a; void f() { printf(&amp;#34;a=%d\n&amp;#34;, a); } 以上代码 linkme.cc 是无法成功链接 a 的。但是把 const 去掉了就可以。
这很怪：
全局变量可以对外链接。 全局常量（非 inline、非 volatile）不能对外链接。 全局 inline 常量可以对外链接。 还有这一句话：
An inline function or variable (since C++17) with external linkage (e.g. not declared static)&amp;hellip;
C++ 是允许不同翻译单元中出现同一 inline 函数或者变量的，但是它们的地址在每个翻译单元中都相同、声明在每个翻译单元中都必须标记 inline（在 gcc 12.2 上做测试， …  ]]></content></entry><entry><title>gitlab-jh 和 gitlab-ce 的区别以及博客内容声明</title><url>/posts/systems/Linux/gitlab/gitlab-jh-%E5%92%8C-gitlab-ce-%E7%9A%84%E5%8C%BA%E5%88%AB%E4%BB%A5%E5%8F%8A%E5%8D%9A%E5%AE%A2%E5%86%85%E5%AE%B9%E5%A3%B0%E6%98%8E/</url><categories/><tags><tag>gitlab-jh</tag></tags><content type="html">  Gitlab 极狐版本是极狐购买了经营权的版本，内部也分会员版。从免费版的功能来看，两者几乎没有区别。但是为了更严谨一些，本博客中所有内容都可能是在 gitlab-jh 或者 gitlab-ce 上试过（或者混用），不保证仅在 gitlab-ce 上操作（尽管它们的操作方式应该一致）。
  </content></entry><entry><title>VS Code 无法使用 cuda-gdb 调试</title><url>/posts/developer/vscode/VS-Code-%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8-cuda-gdb-%E8%B0%83%E8%AF%95/</url><categories/><tags><tag>cuda</tag><tag>vscode</tag></tags><content type="html">  创建 launch.json 的时候找不到 cuda-gdb 这个 type：需要安装 Nsight Visual Studio Code Edition：
  </content></entry><entry><title>在 Gitlab 实例之间创建仓库镜像</title><url>/posts/systems/Linux/gitlab/%E5%9C%A8-Gitlab-%E5%AE%9E%E4%BE%8B%E4%B9%8B%E9%97%B4%E5%88%9B%E5%BB%BA%E4%BB%93%E5%BA%93%E9%95%9C%E5%83%8F/</url><categories/><tags><tag>gitlab-jh</tag></tags><content type="html">  Important
gitlab-jh 和 gitlab-ce 的区别以及博客内容声明
问题简述主机 A 有自己的内网服务，用的是 Gitlab Premium。主机 B 也有自己的内网服务，用的是 Gitlab 极狐（而且是免费版）。目前仓库是在 B 上的，需要在 A 上创建镜像仓库。
分析由于主机 A 是付费服务支持功能更多，所以我选择由主机 A 主动拉取（Pull） B 的仓库。
过程首先在 A 上面创建空仓库，然后点进去选择 Settings &amp;gt; Repository &amp;gt; Mirroring repositories，在下面填入仓库的 URL。我们的主机 B 只把 http 端口映射出来了，也没有映射出来 ssh 端口，所以不能使用公钥验证，而只能选择密码验证，URL 的协议也只能是 http（我们仓库没做 https）。
注意以下几点（这三个坑我都踩过）：
这里的 URL 要加上用户名，这样才知道用什么样的身份登录。就像 Gitlab 提示板块里面写的 https://username@gitlab.company.com/group/project.git 这种样式。 用户名后面不要加 :password 这样的密码形式，这样会出现 HTTP 状态码 301。 密码必须得是真正的登录密码，不能是在 Gitlab 仓库中申请的 access token。 然后根据具体需求选择是否只同步保护分支、是否触发 CI 等等即可。
  </content></entry><entry><title>GCC optimize-sibling-calls 的反向优化</title><url>/compiler-explorer-experiments/2024-04-20-GCC-optimize-sibling-calls-%E7%9A%84%E5%8F%8D%E5%90%91%E4%BC%98%E5%8C%96/</url><categories><category>compiler-explorer-experiments</category></categories><tags><tag>cpp</tag><tag>gcc</tag><tag>c</tag></tags><content type="html"><![CDATA[  #include &lt;benchmark/benchmark.h&gt; static inline constexpr int FIBONACCI_N = 10; int fib(int n) { return n &lt; 2 ? n : fib(n - 1) + fib(n - 2); } static void BM_fib(benchmark::State &amp;state) { for (auto _ : state) { int res = fib(FIBONACCI_N); benchmark::DoNotOptimize(res); } } BENCHMARK(BM_fib); int x; // Magic line. // clang does not use DP anymore: much slower. // gcc chooses a different optimizing approach: much faster. int fib_x(int n) { return n &lt; 2 ? n : fib_x(n - 1) + fib_x(n - 2) + x; } static void BM_fib_x(benchmark::State &amp;state) { for (auto _ : state) { int res = fib_x(FIBONACCI_N); benchmark::DoNotOptimize(res); } } BENCHMARK(BM_fib_x); BENCHMARK_MAIN(); 编译条件：GCC 13.2 -O2 -std=c++17
结果：因为 x 改变了 fib_x 的优化流程，fib_x 虽然看起来更复杂或者和 fib 同样复杂，但实际上比 fib 快。在编译时打开 -fno-optimize-sibling-calls 禁用这项优化，结果就正常了。
Open in Quick C++ BenchmarkOpen in Compiler Explorer
随后我又补充了对单个函数关闭 sibling 优化的补充实验，结果是 sibling 优化使得 fib 严重减速，fib_x 速度变化不大（有时候略微提速）。从 Compiler Explorer 的结果来看，这个行为是从 GCC 10.1 开始产生的。在之前 sibling 优化结果则符合预期，fib 和 fib_x 两个函数都得到了不同程度的加速，其中 fib 因为更简单所以获得的加速比更大。
WHY?
Note
Compiler Explorer 上每次运行分配到的机器配置不同、负载不同，因此只有时间的相对变化有意义，不同次运行结果之间的时间比较没有意义。
Tip
clang 的表现比较正常，而且 -O2 下斐波那契递归求解被改造成了动态规划。带有 x 的版本阻碍了优化，因而速度较慢一些。
  ]]></content></entry><entry><title>Docker 更改地址段</title><url>/posts/cli/docker/Docker-%E6%9B%B4%E6%94%B9%E5%9C%B0%E5%9D%80%E6%AE%B5/</url><categories/><tags><tag>docker</tag></tags><content type="html"><![CDATA[  先说解决方案参考 Networking problems with WSL2 and Docker Desktop for windows，编辑 /etc/docker/daemon.json，加入 &quot;bip&quot;: &quot;192.168.200.1/24&quot;（根据实际情况替换），然后 systemctl 重载配置、重启 Docker 一通操作后用 ip route 和 ifconfig 验证一下变化。
为什么会有这个需求WSL2 的网段是 172.17 开头的，这恰好和 Docker 的默认网段撞了，导致 Docker 不能直接使用 WSL2 的网关 ip 前缀的系统代理（会被认为是 Docker 内部的网址）。每次都要根据 Windows 实际的局域网 ip 来写 http 代理，太麻烦了。修改 Docker 网段之后就可以继续使用系统代理（虽然还是得传递，但是可以直接在命令行上写 --build-arg HTTP_PROXY=$http_proxy --build-arg HTTPS_PROXY=$http_proxy 之类）。另外，由于网络代理请求是统一从 WSL2 的网关发起的，只需要在 Clash for Windows 中设置 inbounds 就能仅允许这些连接请求，这样就不必冒着裸奔的风险开启局域网内代理了。
inbounds: - &#34;http://172.17.xxx.yyy:zzz&#34; 相关文章Clash for Windows 相关
  ]]></content></entry><entry><title>libc++ 和 libstdc++ 中 basic_string 的 SSO 比较</title><url>/posts/programming/cpp/libc++-%E5%92%8C-libstdc++-%E4%B8%AD-basic_string-%E7%9A%84-SSO-%E6%AF%94%E8%BE%83/</url><categories/><tags><tag>cpp</tag><tag>libcxx</tag><tag>libstdcxx</tag></tags><content type="html"><![CDATA[  参考https://joellaity.com/2020/01/31/string.html
std::string 是 std::basic_string&amp;lt;&amp;gt; 的一个特化，该类的 value_type 是 char。本文虽然是讨论 std::basic_string&amp;lt;&amp;gt; 的实现方式，但是为了方便，假设 value_type 是 char、假设目标平台是 64 位，讨论时也将把 std::basic_string&amp;lt;&amp;gt; 和 std::string 互用。
libstdc++libstdc++ 是 gcc 所用的标准库实现，也是 clang 在不提供 -stdlib=... 选项下的默认标准库实现。在 64 位环境下，libstdc++ 中的 std::string 占用 32 个字节。
Tip
std::vector&amp;lt;&amp;gt; 的大小（std::vector&amp;lt;bool&amp;gt; 有特化，所以是例外，在 测试 看到 libstdc++ 和 libc++ 中 std::vector&amp;lt;bool&amp;gt; 的大小分别是 40 和 24 字节）是 24 字节，因为它也需要 capacity + size + pointer 三元组。
std::string 把 capacity + size + pointer 三元组的 capacity 改成了 buffer 和 capacity 的联合体，其中 buffer 大小为 16 字节，可以容纳除去 \0 的 15 个字符。当 size 小于等于临界值时，联合体存储的就是 buffer，否则是 capacity。
pointer + union{buffer(16B), capacity} + size Note
这里给定的表示方式不代表各数据域的实际排列顺序，下同。
在这样的实现下，std::string 最终的大小是 32 字节，SSO 容量为 15 个字节。访问 capacity 需要先确定是否是本地存储，有条件判断的过程；访问 size 和 pointer 则是直接获取，当字符串本地存储时 pointer 指向字符串内的 buffer。
libc++libc++ 中 std::string 有 long mode 和 short mode 两种模式，因此有一个模式标记 …  ]]></content></entry><entry><title>如何提技术问题？</title><url>/posts/collaboration/%E5%A6%82%E4%BD%95%E6%8F%90%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98/</url><categories/><tags><tag>collaboration</tag></tags><content type="html">  我在做什么？你想要最终达成什么（目标）？你采用了什么样的路径来达成它（途径）？
Tip
有可能你的目标是不现实的，或者是假想出来的替代目标，换一个目标同样能解决你的困难，但是解决起来容易很多。也可能你的路径是有错误的。
例子：我希望调用接口 A 来加载目录 B 下的所有图片，供程序的其他组件使用。
预期结果按照你的理解，你觉得代码或者软件配置应该引发什么行为？
例子：调用接口从目录下加载得到的图片数量和目录下的真实图片数量相等，有 14 张图片就应该得到 1 个长度为 14 的图片数据的向量。
实际结果……（描述了预期结果，）但是实际结果是什么？你应该尽可能详细地说明情况，有图配文字是比较好的。
不要用预期结果的反面来描述实际结果，或者用实际结果的反面来描述预期结果。如果两者可以用反面描述的方式相互补充地话，那么就没有同时回答这两个问题的必要了。
Tip
反面描述比正面描述更加含糊，不利于被提问者理解问题。尤其是图片或日志文件中出现大量字符串时，按照反面排除的方法很难让被提问者找到出问题的字符串。即便图片中有划线、墨迹和画圈的标注信息，如果不明确描述，被提问者仍然可能错误理解标注的含义。
指代要明确。比如：计算结果为 1，是什么的计算结果为 1？如果有表达式的话，应该指出是第几张图中，第几行的表达式，其代码字符串为 g(f(expr), magic_number))。如果在循环中，要指出是在第几次迭代的时候出现了问题。
Note
不要说“如图，……”！图上的信息太多了，让人难以抓住重点。检查描述是否完整的方法之一是验证被提问者看不到图片时是否能理解问题。
例子：给接口传入一个放置了 14 张图片的目录，但是返回的向量长度只有 1（不要说返回的长度不为 14）。（提供相关图片。）
你凭什么认为实际的结果和你的描述相符？你是怎么检查出实际结果的？你是怎么写调试代码的（如何打印或者显示）？此问题有没有稳定的复现方式？
信息要给全，不要用提问者的思路去帮被提问者过滤“你认为不重要”的信息。
例子：（提供相关图片和代码文件。）我在 xx 位置循环打印了 data.A 和 data.B 的值，从命令行输出中可以看出来每一行的输出分别是 data.A 和 data.B，data.A 就是接口返回向量的长度，始终为 1。
我如何解释这个现象这一节应该非常简要，甚至可以略 …  </content></entry><entry><title>Docker 配置镜像源</title><url>/posts/cli/docker/Docker-%E9%85%8D%E7%BD%AE%E9%95%9C%E5%83%8F%E6%BA%90/</url><categories/><tags><tag>docker</tag></tags><content type="html">  资源可用 Docker Hub 镜像加速器列表见 Docker Hub 镜像加速器。
修改方式网络上有不少教程是先修改 /etc/docker/daemon.json，然后：
sudo systemctl daemon-reload sudo systemctl restart docker 但是这样需要重启 Docker。虽然可以先给 Docker 加上 live-store 属性，但是我也不敢冒这个风险。
查了相关资料之后我发现：让 docker 重新加载配置只需要向其发送一个信号。如果是用 systemctl 管理 docker，可以直接这样做（参考这篇文章）：
sudo systemctl reload docker 然后用 docker info 看是否成功即可。
Tip
daemon-reload 只是让 systemctl 重新加载 /lib/systemd/system/*.service 中的配置文件而已，这样 restart / reload / stop / start 等功能的含义才会发生变化，在这个例子里面，我们只是修改了 docker 自己的配置文件，并没有修改 docker 的运作方式，因此不需要让 systemctl 重新加载配置。
不过到这里还没有结束，还得禁用 BuildKit，见下面一节。
BuildKit 不读取镜像源网上也有很多人反映这一点，比如 https://github.com/moby/buildkit/issues/606
可以通过禁用 BuildKit 来解决：
sudo DOCKER_BUILDKIT=0 docker &amp;lt;其他参数...&amp;gt; 我是这样才能最终完成下载的。另外，使用 BuildKit 就不用给 docker 命令 root 权限，不用 BuildKit 就要给 root 权限，应该是两者的运行方式不同。
  </content></entry><entry><title>language/implicit_conversion 限定性类型转换</title><url>/posts/programming/cpp/%E9%9A%90%E5%BC%8F%E8%BD%AC%E6%8D%A2%E4%B8%AD%E7%9A%84%E9%99%90%E5%AE%9A%E6%80%A7%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2/</url><categories><category>cpp-language</category></categories><tags><tag>cpp</tag><tag>cppreference</tag></tags><content type="html">  写在前面内容见 implicit conversion。
限定性转换指的是和 cv 属性有关的类型转换，它的发生必须满足一定的条件。
相似类型忽略掉各层的 cv 属性，如果两个类型形式相同，就是相似类型。比如 const int* volatile * 和 int** const。
Important
函数指针对应函数的参数和返回值类型的 cv 属性不可以忽略。可见原页面的例子，这里略去。
限定性分解合并限定性和类型转换规则规则说明C++20 之前 T1 到 T2 的类型转换规则和限定性组合类型是分开定义的，而 C++20 之后类型转换规则是借由限定性组合类型定义的。 限定性组合类型的两个参数类型是有顺序的，A 和 B 的限定性组合类型、B 和 A 的限定性组合类型是两码事。 C++20 中，限定性组合类型的定义改变了，但是类型转换的规则没有变： 要求限定性组合类型是无 cv 限定的 T2，说明这个类型和 T2 相似，同时它又必须和 T1 相似（第一排），所以 C++20 之前 T1 和 T2 相似的要求没有变。 “cv3_i 是 cv1_i 和 cv2_i 的并集” 是对 “对于每个非零 i，如果 cv1_i 中有 const，……”的转述。 限定性组合类型新增的对于 Pj_i 的描述不会影响类型转换的判断，因为 T1 和 T2 必须相似，所以对于固定的 i，Pj_i（$j=1, 2, 3$）必须相同。 C 和 C++ 的不同之处char** p = 0; char * const* p1 = p; // C 与 C++ 中 OK const char* const * p2 = p; // C 中错误，C++ 中 OK Note
即便是在 C++ 中加上 extern &amp;quot;C&amp;quot;，依然是用 C++ 的语法检查，而不会用 C 的语法检查。另外，在这个问题上，C 语言编译器虽然认为有错误，但是依然可能会继续编译，比如 gcc 只是会给出不兼容类型转换的警告。
简单地说明转换规则定义 1：将靠近变量名的一侧称为内层，最内层、0 层都是指这一层，而向外层数逐渐增大。
定义 2：对于两个相似类型 T1 和 T2，T1 比 T2 在某一层更严格指的是 T1 在 T2 某一层 cv 限定符的基础上，增加了 const 或者 volatile 属性。
想要 T1 转换成 T2：
两者必须相似。 忽略 0 层的 cv 限定符，T2 每一层的类型要相同严格、或者更严格。 从最外层起到第 1 层（包含），令 T2 第一个更严格的层为 j，需要 j 不存在、或者 [i, j) 中都有 const 属性（在 C++ 中） / j 为 1（在 C 中）。 代码例子：
void f() { char ** const p = nullptr; char volatile * const *p1 = p; // char volatile **p2 = p; // 第 2 层有了 volatile，所以 [1, 2) 层（也就是第 1 层）需要加 const }   </content></entry><entry><title>关于</title><url>/about/</url><categories/><tags/><content type="html">  本博客内容这里存放的都是个人笔记，主要是零散笔记，walkthroughs 也有一点。
内容可能出现以下问题：
创建日期错误：一些笔记多次在不同平台迁移造成的，迁入新平台时，有些信息会丢失。我先后的迁移过程基本上是 Markdown 文件夹 → Notion → Obsidian。 代码文本或者链接错误：链接转换工具错误地将代码识别为链接导致的。换过好多工具了，总会在莫名其妙的时候被坑到。一些例子：C++ 里的 [[ 是 attributes 的开始标志，一些插件却觉得这是 wiki 链接的开始标志；lambda 语法中的 [捕获列表](参数) 更是像极了 markdown 链接。有时候连 shell 脚本都不能幸免，比如 if [[ ... ]] 条件测试。2025/4/18 还有一种情况是，Obsidian 的相对路径前面没有加上 ./，所以如果 markdown 文件在仓库根目录，那么先移动图片后移动文件可能导致文件仍然使用相当于仓库根目录的路径，构建成博客之后找不到。 图片模糊：为了节省空间对某些图片进行了压缩…… 内容被移除：部分有错误的内容会直接更新，还有一些错误或者我有疑问（因为不想误导大家）的内容会（暂时或永久）撤下，链接生成方式也可能因为博客布局变化而变动，因此链接地址是不稳定的。 如果你不想看主页的琐碎内容，这些系列都可以点左边的小标单独订阅。从 2024 年 10 月 17 日起本站不再提供 Atom 订阅。
🔍 发现每周上网冲浪看到的趣闻和搜刮的资源 📕 看书以下内容也已经加入首页。
C++ Templates: The Complete Guide CUDA by Example Pro Git Modern CMake for C++ Inside the C++ Object Model The Linux Programing Interface C++ Concurrency in Action 没有加入主页的：
Advanced Programming in the UNIX Environment：没看完转去看 TLPI 了。 📺 看视频Cppcon 的一些演讲 🧪 做实验在 Compiler Explorer 上的一些代码片段 🤖 由 LLM 生成这些内容被加入博客是因为有些内容需要补充，但是分享链接并不是在所有 …  </content></entry><entry><title>(CppCon 2023) Great C++ is_trivial</title><url>/cppcon-talks/CppCon-2023-Great-C++-is_trivial/</url><categories><category>cppcon</category></categories><tags><tag>cpp</tag><tag>cppcon</tag></tags><content type="html"><![CDATA[  写在前面参考链接 https://www.youtube.com/watch?v=bpF1LKQBgBQ
这篇演讲有关 C++ 中的 trivial 概念。并且提到当对象 trivially copyable 时，参数传递和返回值都会变得更容易优化。
返回值优化第 2 段代码在 C++20 之前不能被优化是因为结构化绑定的分量是结构体的一部分，作为返回值时不能被直接建在调用者的栈上。
Trivial 的概念Note
有虚函数或者虚基类（也就是需要 vptr），就不满足平凡构造/赋值/拷贝了。如果没有给出析构函数，还是可以平凡析构的。
std::is_trivially_destructable 空 destructor（~T() {}）是不满足的。 = default 是满足的。 std::is_trivially_constructible：除了第 1 个类型参数之外，后面还能加更多参数，用来判断是否可以用给定的类型完成 trivial 构造。可以看这个例子和图 1。 空 constructor 是不满足的（T() {}）。 成员有值初始化是不满足的（struct S { int i{}; };）。 用户提供的构造函数都不适用这一点。 std::is_trivially_default_constructible：相当于单参数的 std::is_trivially_constructible。 std::is_trivially_copy_constructible：限定了拷贝构造（std::is_trivially_constructible&amp;lt;T, const T&amp;amp;&amp;gt;）。其他条件满足时，成员有值初始化也可以（struct S { int i{}; };）。 std::is_trivially_move_constructible：限定了移动构造（std::is_trivially_constructible&amp;lt;T, T&amp;amp;&amp;amp;&amp;gt;）。 std::is_trivially_assignable：得分从哪里 assign，所以图 2 的类型 S 从 const S&amp;amp; 是可以的，但是从 const int 就不能 trivially assign。 用户提供的 assign operator 都不适用这一点。 同样 …  ]]></content></entry><entry><title>Empty Member Optimization with C++20's `[[no_unique_address]]`</title><url>/compiler-explorer-experiments/2024-04-03-Empty-Member-Optimization-with-no_unique_address/</url><categories><category>compiler-explorer-experiments</category></categories><tags><tag>cpp</tag><tag>compiler-explorer-experiments</tag></tags><content type="html">  Open in Compiler Explorer
[[no_unique_address]] makes the empty subobject (of type EmptySubobject) potentially overlapping. It&amp;rsquo;s implementation-defined whether its size should be 0 (see https://en.cppreference.com/w/cpp/language/object, section size). Apparently, x64 MSVC v19.38 hasn&amp;rsquo;t implemented the optimization.
  </content></entry><entry><title>Copy elision</title><url>/posts/programming/cpp/Copy-elision/</url><categories><category>cpp-language</category></categories><tags><tag>cpp</tag><tag>cppreference</tag></tags><content type="html"><![CDATA[  参考https://en.cppreference.com/w/cpp/language/copy_elision https://www.youtube.com/watch?v=PTCFddZfnXc 2024 年 6 月 26 日：这个视频讲了 GCC 的新 -Wnrvo 编译参数。 C++17 prvalue semantics (&amp;ldquo;guaranteed copy elision&amp;rdquo;)返回值（或函数参数）的位置，如果表达式是纯右值，且返回值（或函数参数）需要的也是同一类型的纯右值，那么标准就要求省略复制和移动。不过，为了让语义检查通过，要构造对象的析构函数必须在此处可以访问，尽管在完成优化之后并不会用到析构函数。
T f() { return U(); // constructs a temporary of type U, // then initializes the returned T from the temporary } T g() { return T(); // constructs the returned T directly; no move } T x = T(T(f())); // x is initialized by the result of f() directly; no move The C++17 core language specification of prvalues and temporaries is fundamentally different from that of earlier C++ revisions: there is no longer a temporary to copy/move from. Another way to describe C++17 mechanics is &amp;ldquo;unmaterialized value passing&amp;rdquo; or &amp;ldquo;deferred temporary materialization&amp;rdquo;: prvalues are returned and used without ever materializing a temporary.
非强制的 copy/move elision编译器 …  ]]></content></entry><entry><title>VS Code gdb 不能 pretty-printing</title><url>/posts/developer/vscode/VS-Code-gdb-%E4%B8%8D%E8%83%BD-pretty-printing/</url><categories/><tags/><content type="html"><![CDATA[  这个问题在 Windows MSYS2 中没有出现，但是在 WSL 上出现了。在调试时对 std::vector 的显示如下：
本来我是用的 CMake 上的调试启动功能的，StackOverflow 上面让用 .vscode/launch.json，我也试了，但是同样不行。这是我写的启动文件内容，主要是在 setupCommands 中打开了 pretty-printing 功能：
{ // Use IntelliSense to learn about possible attributes. // Hover to view descriptions of existing attributes. &#34;version&#34;: &#34;0.2.0&#34;, &#34;configurations&#34;: [ { &#34;name&#34;: &#34;gdb - debug active file&#34;, &#34;type&#34;: &#34;cppdbg&#34;, &#34;request&#34;: &#34;launch&#34;, &#34;program&#34;: &#34;${workspaceFolder}/build/main&#34;, &#34;args&#34;: [], &#34;stopAtEntry&#34;: false, &#34;cwd&#34;: &#34;${workspaceFolder}&#34;, &#34;environment&#34;: [], &#34;externalConsole&#34;: false, &#34;MIMode&#34;: &#34;gdb&#34;, &#34;miDebuggerPath&#34;: &#34;gdb&#34;, &#34;setupCommands&#34;: [ { // Display content in STL containers pretty &#34;description&#34;: &#34;Enable pretty-printing for gdb&#34;, &#34;text&#34;: &#34;-enable-pretty-printing&#34;, &#34;ignoreFailures&#34;: true } ], // &#34;preLaunchTask&#34;: &#34;C/C++: g++ build active file&#34; } ] } 按照 StackOverflow 的 回答 1，我在 gdb 中用 info pretty-printer 看当前支持的 pretty-printer。结果：
global pretty-printers: builtin mpx_bound128 然后参考 回答 2 手动注册 /usr/share/gcc/python/libstdcxx/v6/printers.py 之后果然就能看到标准库一堆 STL 类型的 pretty-printers 了。但是我在 PATH 中加上 /usr/share/gcc/python 或者 /usr/share/gcc/python/libstdcxx/v6 都不能实现自动注册。没办法，只能在 ~/.gdbinit 中放上启动脚本：
python import sys sys.path.insert(0, &#39;/usr/share/gcc/python&#39;) from libstdcxx.v6.printers import register_libstdcxx_printers register_libstdcxx_printers (None) end 现在 STL 的调试时显示已经能够正常工作了：
Tip
一开始怀疑是 gdb 版本问题，我的 gcc 版本是 12.2，而 gdb 版本是 13.1。但是网上说两者是分开更新的，不需要是同一个版本，一般只要 gdb 版本比 gcc 新即可。
  ]]></content></entry><entry><title>NVIDIA 显卡显存占用高但是 nvidia-smi 查不到</title><url>/posts/systems/Linux/NVIDIA-%E6%98%BE%E5%8D%A1%E6%98%BE%E5%AD%98%E5%8D%A0%E7%94%A8%E9%AB%98%E4%BD%86%E6%98%AF-nvidia-smi-%E6%9F%A5%E4%B8%8D%E5%88%B0/</url><categories/><tags><tag>linux</tag><tag>gpu</tag></tags><content type="html">  解决方案假设是 3 号卡，用 sudo lsof /dev/nvidia3 看看有哪些进程正在使用这个设备。然后用各种手段查看各个可疑进程的信息（假设进程号是 66666）：
ps ww 66666（BSD 风格的 ps，而不是 System V）。 cat /proc/66666/status 查看进程状态。除了 status 之外，还有其他信息可以在 /proc 下查看。 htop -p 66666 或者 top -p 66666。 确定进程没用之后，就可以根据 PID 杀掉进程了。
Tip
除了 lsof 之外，还可以用 fuser 查找正打开文件或者 socket 的进程。根据 https://unix.stackexchange.com/a/60497/ ，lsof 更适合找一个进程打开的所有的文件，而 fuser 更适合找特定文件被什么进程打开了，比如 fuser -uv，详见刚刚的链接。
在 Debian 下使用 fuser 需要安装 psmisc（pstree 也是这个包）。
如果不给管理员权限，lsof 可能会输出错误信息并遗漏内容，fuser 则可能会静默失败。
现象分析现象：在 nvidia-smi 上查不到，在 nvitop 上能查到但显示“No Such Process”。
当时服务器上占用资源较多的几个进程都在 S（sleep）或者 T（stopped）状态，可能是因为不活跃所以才在 nvidia-smi 查不到？它们主要占的是内存和显存，而不占用 CPU 和 GPU 的计算性能，但是 nvidia-smi 结果中的 GPU util 数值却是 100%。参考 understanding-gpu-performance 这篇文章，nvidia-smi 给出的 GPU util 是按占用时间来算的（比如 1 秒中有多少时间显卡没有完全闲下来，但凡带一点任务都算在使用），而不是按照负载算的，可能是进程正在执行 CUDA kernel 的时候就停住了，占用了 SM？
相关链接有一个 Stack Overflow 问题和这里的情况一模一样： https://stackoverflow.com/questions/71433347/no-such-process-consumes-gpu-memory 其中有个链接点进去还建议可以尝试使用 sudo nvidia-smi --gpu-reset -i 0 的方式重置 GPU。
https://github.com/XuehaiPan/nvitop/issues/75 提到当上游的 nvidia-ml-py 版本和显卡驱动版本不匹配的时候，就会得到错误的进程号，导致显示“No Such Process”。但是服务器上的包已经是最新了，显卡驱动也不好随意更改，这件事情就不了了之了。
  </content></entry><entry><title>C++: Rule of 3/5/0</title><url>/posts/programming/cpp/C++-Rule-of-3-5-0/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  https://en.cppreference.com/w/cpp/language/rule_of_three
Rule of 3析构函数、拷贝构造、拷贝赋值三者要是定义了其一，最好把其他两个都补上，因为编译生成的很可能不是我们想要的。此外，定义三者之一会导致移动构造、移动赋值被删除。
Note
显式删除拷贝构造函数（MyClass(const MyClass&amp;amp;) = delete;）也是一种声明，这样会导致移动构造函数被删除，如果有移动尝试则会匹配上（被删除的）拷贝构造函数，从而编译失败。
Tip
复制 / 移动赋值操作符可以用复制 / 移动构造函数 + std::swap 实现。
Rule of 5还要加上移动构造和移动赋值（如果这个类不需要移动，或者移动和拷贝的过程完全一样，那就算了）。C++ Core Guidelines C.21 中建议在碰了其中一个时，将它们全部删除或者全部定义。
Unlike Rule of Three, failing to provide move constructor and move assignment is usually not an error, but a missed optimization opportunity.
Rule of 0析构函数、拷贝 / 移动构造、拷贝 / 移动赋值都不碰。如果要实现上允许，请尽可能这样做。
特殊成员函数的生成规则见 Special_member_functions：
提供任何构造函数会禁止编译器生成默认构造函数。 提供移动构造函数 / 赋值操作符禁用拷贝构造函数、拷贝赋值操作符。 提供 Rule of 5 中相关的任何一个会禁用编译器生成的移动构造函数、移动赋值操作符。 提供析构函数会导致拷贝构造函数、拷贝赋值操作符被标记为过时。（就算用了也是不符合 Rule of 3 的。） 简记：
有构造，禁默认构造。 有移动，禁拷贝。 有任何，禁移动。 有析构，拷贝过时。 Tip
顺带一提，如果要 delete 的指针关联类型和指向对象的真实类型不同，那么当前类型必须有虚析构函数，否则是未定义行为。 https://stackoverflow.com/questions/461203/when-to-use-virtual-destructors
  </content></entry><entry><title>(CppCon 2023) C++ Memory Model - from C++11 to C++23 - Alex Dathskovsky</title><url>/cppcon-talks/CppCon-2023-C++-Memory-Model-from-C++11-to-C++23-Alex-Dathskovsky/</url><categories><category>cppcon</category></categories><tags><tag>cpp</tag><tag>cppcon</tag></tags><content type="html"><![CDATA[  视频链接 https://www.youtube.com/watch?v=SVEYNEWZLo4
不要用 Volatile 来同步Note
顺带一提：C++20 中，有不少和 volatile 相关的操作都已经被标记为过时。详见 https://en.cppreference.com/w/cpp/language/cv
#include &amp;lt;tuple&amp;gt; int main() { volatile int x = 0; //! C++20 //! 1.1 函数参数不能用 volatile 类型 // auto f1 = [](volatile int) {}; //! 1.2 函数返回值不能 volatile 类型 // auto f2 = []() -&amp;gt; volatile int { return 0; }; // int y = (x = 6); //! 2 自增、自减运算符不能在 volatile 变量上操作 // x++; //! 3. 结构化绑定不能用 volatile // auto volatile [a, b] = std::tuple{1, 3}; //! 4. 不能基于 volatile 变量连续赋值，除非是在不评估的环境中 //! 错误 // int z = (x = 5); //! 会有 -Wunevaluated-expression 警告，正确但是不推荐 using T = decltype((x = 5)); } 可以用来同步的机制：
汇编级别的内存屏障指令（见下方图片） 原子变量和锁 Memory BarriersAcquire / Release 语义：Read-Acquire 可以构成下文内容不超过当前 acquire 屏障的保证；而 Write-Release 可以构成上文内容不超过当前 release 屏障的保证。两者结合起来可以构成 full barrier，使得两个线程可以达成同步关系。
原子读写的代价load在 x86 系统上，对 32 位数据的原子加载只是一次普通的加载。观察 https://godbolt.org/z/1Erq1Ters 中的汇编，没有特殊的指令被使用。
std::atomic&amp;lt;int&amp;gt; a(0); int b = a.load(); 但是在其他系统上，这样的操作可 …  ]]></content></entry><entry><title>Docker attach 之后不能退出</title><url>/posts/cli/docker/Docker-attach-%E4%B9%8B%E5%90%8E%E4%B8%8D%E8%83%BD%E9%80%80%E5%87%BA/</url><categories/><tags><tag>docker</tag></tags><content type="html"><![CDATA[  Docker 不能用 CTRL + p，CTRL + q 退出的解决方案：登录后先用 tty 看自己的终端。然后用另外一个连接 ps -af 看想要终止的 docker 命令的 pid 是多少，然后用 kill -9 强杀。因为杀的是客户端而不是守护进程，所以不需要担心其他正在运行的容器受到影响。
Warning
不能用 kill（不带参数），因为 kill 会让 docker 连接优雅退出，所以容器也会被关闭！
这样能更快找到 docker 命令：
ps -af|grep -iE &#39;(pid|docker)&#39; --color=always|grep -v &#34;grep --color=&#34;   ]]></content></entry><entry><title>Docker 查询和管理</title><url>/posts/cli/docker/Docker-%E6%9F%A5%E8%AF%A2%E5%92%8C%E7%AE%A1%E7%90%86/</url><categories/><tags><tag>docker</tag></tags><content type="html">  查看所有容器的资源占用docker stats 可以实时刷新所有容器的占用情况。用 docker stats --no-stream 只看最近一次，而不像 top 一样刷新。不知道哪个容器占用多的时候可以使用这个命令。
找到进程属于哪一个容器我们实验室的不同学生使用不同的容器作为开发环境。现在的问题是，当我们从 htop 或者 top 中发现某个进程消耗了大量资源时，我们需要确定这个进程是由哪个容器启动的，怎么做呢？
用 pstree -sg 找到进程的父进程，然后在运行的容器中找有没有谁的进程号是能对应的上的。
经过学长提醒，我认识到还可以用 cat /proc/&amp;lt;pid&amp;gt;/cgroup 来查看进程关联信息的方法。如果进程是在容器内运行，输出路径中会包含容器的 id。
  </content></entry><entry><title>不同编译器如何处理 C 语言函数名？</title><url>/posts/programming/cpp/%E4%B8%8D%E5%90%8C%E7%BC%96%E8%AF%91%E5%99%A8%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86-C-%E8%AF%AD%E8%A8%80%E5%87%BD%E6%95%B0%E5%90%8D/</url><categories/><tags><tag>c</tag></tags><content type="html">  https://godbolt.org/z/YrzsWbMh8
在以下几种编译器上都尝试了：
x86-64 gcc 13.2 x86-64 clang 18.1.0 x64 msvc v19.38 x86 msvc v19.38 发现只有 x86 msvc v19.38 给函数名前面加了下划线，其他几种编译器都是尊重函数定义的名字。以前做川合秀实的 30 天自制操作系统时，还以为所有编译器都会固定地给 C 语言函数名前面加上下划线，所以汇编中引用时有一些区别。现在看来只是因为平台不同，所以编译器处理方式也不同。
  </content></entry><entry><title>创建内网 Overleaf</title><url>/posts/systems/Linux/%E5%88%9B%E5%BB%BA%E5%86%85%E7%BD%91-Overleaf/</url><categories/><tags><tag>docker</tag><tag>overleaf</tag><tag>latex</tag></tags><content type="html">  有两种方案，推荐第 2 种。
方案 1：docker-compose截至 2024 年 3 月 14 日 最新的 docker-compose 文件是 https://raw.githubusercontent.com/overleaf/overleaf/408e1dccd7c0cb58fe02c5eb9ef983312ad9b244/docker-compose.yml
首先把 docker-compose 配置文件下载下来修改好 sharelatex 的端口、sharelatex/redis/mongo 的映射路径。
❗ 问题：连接不上 redis。这是因为 sharelatex 仍在使用 SHARELATEX 开头的环境变量，所以要把 OVERLEAF 开头的环境变量复制一份改个前缀。改好之后又提示 mongo 连接不上，还是同样的改法。
❗ 问题：登陆网页创建账户，提示请联系管理员。找到 https://github.com/overleaf/overleaf/wiki/Creating-and-managing-users 发现我用的是 legacy 的方法。后面也有解决方案，但是我没有继续往下走了。考虑到过时方法还可能出现别的问题，就换成使用 toolkit 了。
方案 2：Overleaf/toolkithttps://github.com/overleaf/toolkit/blob/master/doc/quick-start-guide.md
这个新的工具包用的配置都是相对路径，所以只需要改端口，不需要改映射路径了。然后按照说明注册管理员账号，有了管理员账号才能注册普通账户。
Overleaf 的一些限制可上传 zip 大小只有 52.4M。解决方案：先打包一部分上传，然后将剩下的文件夹逐个上传。 一次只能上传 40 个文件。 而且大量上传会受到限制，提示：Too many files uploaded, your uploads have been throttled for short period. Please wait 15 minutes and try again. 这说明超大型项目（文件数量极多、总体积也很大）还是用不了 Overleaf 的。
  </content></entry><entry><title>记录一次 LaTeX 不能编译的解决过程</title><url>/posts/latex/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1-LaTeX-%E4%B8%8D%E8%83%BD%E7%BC%96%E8%AF%91%E7%9A%84%E8%A7%A3%E5%86%B3%E8%BF%87%E7%A8%8B/</url><categories/><tags><tag>latex</tag></tags><content type="html">  同学把 LaTeX 源码文件夹从 Windows 电脑上拷贝给我，但是无法编译，说是里面有几个字体找不到。我改了 fontspec 的几个设置，包括 \setmainfont 等，向其中用 Path= 选项添加了 fonts/ 的路径（之前没有路径，找的是系统字体）。但是还是不能编译！
然后又慢慢排查，发现是 \maketitle 导致的不能编译，而且也是字体问题，只不过报错的位置变了，一时没看到。点进去看，cls 文件使用了 \arial，而这个字体是这样定义的：
\DeclareRobustCommand{\arial}{\fontspec{Arial}} 虽然 cls 文件设置了文件夹中的 Arial 字体为主字体，但是没有将其声明为一个可以被引用的字体。但是我尝试添加字体的声明也不能成功：
\newfontfamily\arial[Path=extrafonts/]{Arial} 之后我又改成如下才成功：
\DeclareRobustCommand{\arial}{\fontspec[Path=extrafonts/]{Arial}} https://texdoc.org/serve/fontspec/0
官方文档也有说 \fontspec 尽量不要用。
The plain \fontspec command is not generally recommended for document use. It is an ad hoc command best suited for testing and loading fonts on a one-off basis
  </content></entry><entry><title>C++20 之前向下转换到有符号数无法表示时是实现定义</title><url>/posts/programming/cpp/C++20-%E4%B9%8B%E5%89%8D%E5%90%91%E4%B8%8B%E8%BD%AC%E6%8D%A2%E5%88%B0%E6%9C%89%E7%AC%A6%E5%8F%B7%E6%95%B0%E6%97%A0%E6%B3%95%E8%A1%A8%E7%A4%BA%E6%97%B6%E6%98%AF%E5%AE%9E%E7%8E%B0%E5%AE%9A%E4%B9%89/</url><categories><category>cpp-language</category></categories><tags><tag>cpp</tag><tag>cppreference</tag></tags><content type="html"><![CDATA[  什么是向下转换向下转换是可能出现溢出的转换。检查是否为向下转换：
template &lt;typename To, typename From, typename = void&gt; struct NotNarrowing: std::false_type {}; template &lt;typename To, typename From&gt; struct NotNarrowing&lt;To, From, std::void_t&lt;decltype(To{std::declval&lt;From&gt;()})&gt;&gt;: std::true_type {}; 其中 To{std::declval&lt;From&gt;()} 这一步如果用在具体的类型上（比如说 int 和 unsigned），编译器是只给警告，不会报错。如果能够在编译期推导出来数值，则会根据数值来选择通过或报错。比如 char{'a'}; 是正常编译的，但是 char{300}; 是会报错的。
向下转换溢出的判断标准是真实的表数范围：
无符号数和对应的有符号数互转都算是溢出。 范围较小的无符号数转向范围较大的有符号数是不溢出的。 任何有符号数转向无符号数都会溢出，因为无符号数不能表示负数。 向下转换无法表示时的定义情况向下转换无法表示时只有在 unsigned 类型上有定义，在浮点数上无定义，在 signed 整数上是 implementation-defined（C++17）或模除定义（C++20，同 unsigned）。见 cppreference.com implicit conversion 页面中 Integral conversions 小节。
Caution
Operator arithmetic 页面 的 Overflows 小节说明：算术运算的溢出是未定义行为。要注意算术运算和向下类型转换是两个不同的场合。
因此，虽然可能会溢出，大范围的数字转向任意范围的无符号数都有良好定义。大范围的数字转向小范围的有符号数，在无法表示的时候仅在 C++20 以上有良好定义（否则是实现定义）。
{ // implementation-defined in C++17 extern long long f(); signed a = f(); } { // well-defined extern long long f(); unsigned a = f(); } { // won&#39;t compile extern long long f(); unsigned a{ f() }; } std::numeric_limits&lt;T&gt;::is_modulo 可以检查这种溢出是否是被定义为模除。但是对于有符号整数来说，不保证值都是 true（C++17），但如果具体实现将其定义为模除，这个值可以为 true。
is_modulo is false for signed integer types, unless the implementation defines signed integer overflow to wrap. (Before LWG 2422)
is_modulo is false for signed integer types (6.8.2 basic.fundamental) unless an implementation, as an extension to this International Standard, defines signed integer overflow to wrap.
  ]]></content></entry><entry><title>自定义 ostream</title><url>/posts/programming/cpp/%E8%87%AA%E5%AE%9A%E4%B9%89-ostream/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  下面的代码继承了 std::streambuf 改变了 ostream 的行为，并自定义了打印操作将结果送到 stdout，而不是 std::cout 中（当然也可以更改逻辑修改打印的细节）。
其中的 print 函数是仿 C++23 std::print 的，功能仅仅是打印参数，在笔记 实现简单的花括号插值打印 中实现。
struct membuf : std::streambuf { membuf(char *p, size_t n) { setg(p, p, p + n); // set read pointers setp(p, p + n); } void flush() { auto p = pbase(), e = pptr(); fwrite(p, 1, e - p, stdout); setp(p, e); // reset write pointers } private: int overflow(int c) override { flush(); if (c != &#39;\0&#39;) fputc(c, stdout); return c; } }; // A little slower since we have to maintain a different buffer. template &lt;class... Ts&gt; void print_stdout(const char *s, Ts... args) { char buf[512]; membuf mbuf(buf, sizeof(buf)); std::ostream os(&amp;mbuf); print(os, s, args...); mbuf.flush(); }   ]]></content></entry><entry><title>(CppCon 2018) 105 STL Algorithms in Less Than an Hour</title><url>/cppcon-talks/CppCon-2018-105-STL-Algorithms-in-Less-Than-an-Hour/</url><categories><category>cppcon</category></categories><tags><tag>cpp</tag><tag>cppcon</tag></tags><content type="html"><![CDATA[   为了简单，下面都不用 std 名字空间了。而且实际上 begin 和 end 是有 ADL 的。 有一些算法是在 numeric 头文件中的。 https://www.youtube.com/watch?v=2olsGf6JIkU
1 Not Classified (2)1. transform 下面这种重载有点像先 zip 再 transform，但是没有 zip 灵活。
2. for_each 不关心选用的函数的返回值类型，主要配合有 side effects 的函数使用。 在现在有 for(*:*) 语法的情况下，for_each 也并不是完全没用。 1. 在需要按照一定顺序遍历，比如倒序遍历的时候，可以用 rbegin/rend/for_each 来完成。 2. for_each 可以指定执行策略，比如并行执行。 2 Permutations (17)（逻辑）连续空间上的元素易位。
2.1 Heaps (4)// 1: make_heap make_heap(begin(v), end(v)); // 2. push_heap v.push_back(4); push_heap(begin(v), end(v)); // 3. pop_heap pop_heap(begin(v), end(v)); v.pop_back(); // 4. sort_heap // 相当于不停调用 pop_heap，但是每次不移除元素，而是将尾范围前进一个元素 sort_heap(begin(v), end(v)); 2.2 Sorting (4)// 1. sort // 省略 // 2. partial_sort // 找到 middle-first 个最小的元素放在前面，一般会用堆排序来实现 // 下面展示了函数重载之一 template&amp;lt; class RandomIt &amp;gt; void partial_sort( RandomIt first, RandomIt middle, RandomIt last ); // 3. nth_element template&amp;lt; class RandomIt &amp;gt; void nth_element( RandomIt first, RandomIt nth, RandomIt last ); // 4. …  ]]></content></entry><entry><title>(CppCon 2023) Lock-free Atomic Shared Pointers Without a Split Reference Count</title><url>/cppcon-talks/CppCon-2023-Lock-free-Atomic-Shared-Pointers-Without-a-Split-Reference-Count/</url><categories><category>cppcon</category></categories><tags><tag>cpp</tag><tag>cppcon</tag></tags><content type="html"><![CDATA[  https://youtu.be/lNPZV9Iqo3U?si=lS1hf2ND4SS-6ELB by Daniel Anderson
幻灯片链接： https://raw.githubusercontent.com/CppCon/CppCon2023/main/Presentations/lock_free_atomic_shared_ptr_cppcon2023.pptx
共享指针是线程安全的吗？std::shared_ptr 的控制块是线程安全的（其实也就是析构是线程安全的， https://en.cppreference.com/w/cpp/memory/shared_ptr/atomic2 中有 “Note that the control block of a shared_ptr is thread-safe&amp;hellip;” 这句话），但是：
对它指向的对象的访问不是线程安全的。 对它本身的读写不是线程安全的。 这个 lecture 主要考虑第 2 点。
Daniel 提到了一种情况：如果一个共享指针正在被析构导致引用计数归零（比如给某个共享指针赋值为一个另一对象的共享指针），此时另外一个线程正复制这个共享指针，则可能会出现内存安全问题。这其实是在两个线程中未做保护地对同一个共享指针读写。大多数情况下，我们可以在线程创建的时候将共享指针拷贝给另外一个线程，避免使用同一个实例。
为什么有时候希望共享指针本身也能线程安全？有些时候我们仍然希望多个线程访问同一个共享指针，而不是共享指针的多份拷贝。明明只要跨线程正确复制共享指针就能保证共享指针内存管理的安全性，为什么还非要使用共享指针的同一个引用呢？在无锁编程中，有一个常见场景是用原子操作和链表实现一个无锁的队列 / 栈。这时，多个消费者（以及生产者）就可能会访问相同的链表结点（比如 head）。此时，我们需要能安全地修改指针本身的值。要注意的是：共享指针只是内存管理手段，并不是 lock-free 手段。
下面是 Daniel 给出的一种无锁栈的一种错误实现，他指出问题是：std::atomic&amp;lt;std::shared_ptr&amp;lt;T&amp;gt;&amp;gt; 这个类型并不是 lock-free 的。
标准库中对共享指针的原子操作支持参考 libstdc++ 对共享指针原子操作的支持 这一篇笔记 👀。 …  ]]></content></entry><entry><title>CUDA 程序第一次运行很慢</title><url>/posts/programming/cuda/CUDA-%E7%A8%8B%E5%BA%8F%E7%AC%AC%E4%B8%80%E6%AC%A1%E8%BF%90%E8%A1%8C%E5%BE%88%E6%85%A2/</url><categories/><tags><tag>cuda</tag></tags><content type="html"><![CDATA[  https://developer.nvidia.com/blog/cuda-pro-tip-understand-fat-binaries-jit-caching/
CUDA 程序有两种代码：一是设备无关的 PTX，二是设备有关的二进制代码。在运行之前将 PTX 编译成二进制代码就是 JIT 过程。（当然，nvcc 会在文件系统里面存储 cache。）用 -arch=sm_xx 可以只为给定的架构编译，从而运行时不需要 JIT 这一步。
禁用 cache（不允许本次运行读取和写入 cache）：
export CUDA_CACHE_DISABLE=1 然后分别使用 -arch=native 选项和不使用，可以明显感受到程序在启动速度上的差别。
nvcc --help:
nvcc embeds a compiled code image in the resulting executable for each specified &lt;code&gt; architecture, which is a true binary load image for each &lsquo;real&rsquo; architecture (such as sm_50), and PTX code for the &lsquo;virtual&rsquo; architecture (such as compute_50). During runtime, such embedded PTX code is dynamically compiled by the CUDA runtime system if no binary load image is found for the &lsquo;current&rsquo; GPU.
Note
-arch 选项生成二进制代码，而 -code 选项生成虚拟的 PTX 代码。
  ]]></content></entry><entry><title>7.8 Git Tools - Advanced Merging</title><url>/pro-git-the-book/7.8-Git-Tools-Advanced-Merging/</url><categories><category>pro-git-the-book</category></categories><tags><tag>git</tag><tag>pro-git-the-book</tag></tags><content type="html"><![CDATA[  终止合并可以用 git merge --abort，就不要用 git reset --hard 了。
合并的时候忽略空白字符git merge 时加入参数 -Xignore-all-space or -Xignore-space-change。
最好还是不用，因为这样容易出现混合的换行方式（\n 和 \r\n）。
手动 re-merging讲的是 git merge-file 的用法。和手动修改相比，这样做更容易脚本化，因为很多命令行工具只能对没有 conflict markers 的源码处理。
首先，冲突已经发生。我们获取冲突文件的三个版本：
$ git show :1:hello.rb &amp;gt; hello.common.rb $ git show :2:hello.rb &amp;gt; hello.ours.rb $ git show :3:hello.rb &amp;gt; hello.theirs.rb The :1:hello.rb is just a shorthand for looking up that blob SHA-1.
获得这样三份文件之后，我们可以修改 hello.theirs.rb 的内容，然后做一次合并（注意文件的出现顺序是 &amp;lt;current-file&amp;gt; &amp;lt;base-file&amp;gt; &amp;lt;other-file&amp;gt;）：
$ git merge-file -p hello.ours.rb hello.common.rb hello.theirs.rb &amp;gt; hello.rb -p 选项是将结果写入标准输出流，而不是直接改当前文件（当前文件是 hello.ours.rb，但是这显然不是我们最终要修改的文件）。
这个做法比直接使用忽略空白字符更好，因为我们转换了整个文件，不会出现混合的换行风格。
In fact, this actually works better than the ignore-space-change option because this actually fixes the whitespace changes before merge instead of simply ignoring them. In the ignore-space-change merge, we actually …  ]]></content></entry><entry><title>7.9 Git Tools - Rerere</title><url>/pro-git-the-book/7.9-Git-Tools-Rerere/</url><categories><category>pro-git-the-book</category></categories><tags><tag>git</tag><tag>pro-git-the-book</tag></tags><content type="html"><![CDATA[  https://git-scm.com/book/en/v2/Git-Tools-Rerere
rerere 的一些性质rerere 没有默认开启。
rerere 是在前一步骤合并冲突，生成了含有冲突 markers 的文件之后，根据记录的结果重新应用冲突解决方案的。因而可以手动对冲突了的文件（通过 git checkout --conflict=merge -- &lt;files&gt; 创建）应用 git rerere。
rerere 可以自动解决冲突，但是解决过程发生在冲突之后，也不会自动提交，因此 rerere 在实现上更像一个钩子。这样也可以给使用者再次检查的机会。解决冲突之后把 unmerged paths 加入到 index，然后用 git commit 或者 git rebase --continue 来确认。
rerere 的缺点rerere 不知道什么合并方式是正确的、什么是错误的，因而会一律记录下来。比如有时候合并错误需要退回，这个时候重新合并，rerere 就会用错误的方式解决冲突。使用 git rerere forget &lt;pathspec&gt; 可以让 rerere 删除错误的合并方式，将 &lt;pathspec&gt; 换成 . 就是删除本文件夹的所有冲突解决方式（注意当前是否在 git 仓库的根目录）。见 https://stackoverflow.com/questions/5519244/are-there-any-downsides-to-enabling-git-rerere 。
还有人指出：
Rerere can reuse previous resolution even though you were merging two branches with different contents than the one you resolved earlier.
好像合并方式是按照 chunks 来的，所以即便是文本内容不同，但是片段相同，也可以使用相同的方式合并？
可以用 git rerere gc 来删除一些比较老的解决方式的缓存，默认情况下未解决的是 15 天，解决的是 60 天。这个可以通过配置修改。
  ]]></content></entry><entry><title>deb 包里面装的是什么？</title><url>/posts/systems/Linux/deb-%E5%8C%85%E9%87%8C%E9%9D%A2%E8%A3%85%E7%9A%84%E6%98%AF%E4%BB%80%E4%B9%88/</url><categories/><tags><tag>linux</tag><tag>debian</tag></tags><content type="html">  格式解析根据维基百科，deb 包是一个标准的 ar 归档。
因此，对于 Modern CMake for C++ 中示例代码用 CPack 创建的包 CPackPackage-1.2.3-Linux.deb，可以直接解压。
ar x CPackPackage-1.2.3-Linux.deb 解压可以得到三个东西：
. ├── control.tar.gz ├── data.tar.gz └── debian-binary 其中 debian-binary 是个文本文件，我这里里面填写的信息是字符串 2.0。
control.tar.gz 解压之后有两个文件：control 和 md5sums，前者记录了包的基本信息：
Architecture: amd64 Description: Simple Calculator Maintainer: email@example.com Package: cpackpackage Priority: optional Section: devel Version: 1.2.3 Installed-Size: 33 后者记录了 data.tar.gz 中每个文件的校验和。
data.tar.gz 解压之后：
$ mkdir data &amp;amp;&amp;amp; tar -C data -zxf data.tar.gz $ tree data data └── usr ├── include │ └── calc │ └── calc.h └── lib ├── calc │ └── cmake │ ├── CalcConfig.cmake │ ├── CalcTargets.cmake │ └── CalcTargets-debug.cmake └── libcalc.a 说明 data.tar.gz 里面放的是标准的压缩数据，和以压缩文件方式导出是一样的。
用工具查看在不解压、不安装的情况下查看 deb 包的文件可以使用 dpkg 的 -c 选项。
dpkg 提供了一个 --fsys-tarfile 选项，这个选项可以将 deb 包输出为 tar 包，从而允许将 deb 包提取到文件（提取之前肯定是要用 -c 选项去看有哪些文件的），或者和 tar 程序建立管道执行文件提取等功能。比如：
dpkg --fsys-tarfile somepackage.deb | tar -xO ./usr/include/a/b/c.hpp | less   </content></entry><entry><title>tar</title><url>/posts/cli/common/tar/</url><categories/><tags><tag>shell</tag><tag>linux</tag></tags><content type="html">  tar 的时候可以指定压缩，要注意打包的时候如果用了压缩，解包的时候需要用同样的算法来解压。这个并不是自动识别的。比如：
tar -zcf xxx.tar.gz files 对应于 tar -zxf xxx.tar.gz。
而且，如果不压缩就不要用 .tar.gz 来命名，而是用 .tar。（如果是其他压缩格式就用其他的命名方式。）
tar -C targetFolder ... 可以将文件解压到目标目录，但是要求目标目录首先存在。tar 命令不会帮助我们创建目录。
  </content></entry><entry><title>wget</title><url>/posts/cli/common/wget/</url><categories/><tags><tag>shell</tag><tag>linux</tag></tags><content type="html">  下载整个站点# https://stackoverflow.com/a/11514515/ wget -r -p -np -k ${URL}   </content></entry><entry><title>CMake 代码风格</title><url>/posts/cli/cmake/CMake-%E4%BB%A3%E7%A0%81%E9%A3%8E%E6%A0%BC/</url><categories/><tags><tag>cmake</tag></tags><content type="html">  感觉 CMake 的语法不是很容易格式化，感觉怎么都别扭。现在我看到一种格式的思路比较好，就是把命令的每个选项都当成 yaml 配置文件去写，比如：
install(FILES src/include/calc/calc.h src/include/calc/nested/calc_extended.h DESTINATION ${CMAKE_INSTALL_INCLUDEDIR}/calc ) 这种列表就换行+缩进。
  </content></entry><entry><title>CUDA by Example: Appendex</title><url>/cuda-by-example/CUDA-by-Example-%E9%99%84%E5%BD%95/</url><categories><category>cuda-by-example</category></categories><tags><tag>cuda</tag><tag>cuda-by-example</tag></tags><content type="html">  再次考虑 dot 计算在第 5 章的 dot 计算中，我们在每个块上做完 reduction 之后就将数据拷贝回到 CPU 了，然后让 CPU 做最后的加法。
为什么在 compute capability 2.0 之前，atomicAdd 只支持整数？因为原子加法是不能指定计算的发生顺序的，因而每个计算都必须遵守结合律，也就是 $(A+B)+C$ 必须等于 $A+(B+C)$。但是浮点数因为中间结果的舍入问题，并不能保证这一点！！
本节接下来是讲解用原子操作实现一个忙等待的 mutex，用于同步多个 CUDA 线程（因为在写书的时候浮点数的原子加法还没有受到设备的广泛支持）。atomicCAS 就是 CUDA 上的比较并交换。
// mutex 的类型是 int *，而且是分配在 GPU 上的 __device__ void lock( void ) { while( atomicCAS( mutex, 0, 1 ) != 0 ); } __device__ void unlock( void ) { atomicExch( mutex, 1 ); } Note
这里的 unlock 方法并不是直接对 *mutex 赋值为 1，因为 CUDA 中原子操作和普通的内存访问经过的路径不同，所以应该在 unlock 的时候也统一使用原子操作。
最后的 dot 核函数：
__global__ void dot( Lock lock, float *a, float *b, float *c ) { __shared__ float cache[threadsPerBlock]; int tid = threadIdx.x + blockIdx.x * blockDim.x; int cacheIndex = threadIdx.x; float temp = 0; while (tid &amp;amp;lt; N) { temp += a[tid] * b[tid]; tid += blockDim.x * gridDim.x; } // set the cache values cache[cacheIndex] = temp; // synchronize threads in this block __syncthreads(); // for reductions, …  </content></entry><entry><title>CUDA by Example: Chapter 01-05</title><url>/cuda-by-example/CUDA-by-Example-chapter01-05/</url><categories><category>cuda-by-example</category></categories><tags><tag>cuda</tag><tag>cuda-by-example</tag></tags><content type="html">  源码可以参考 https://github.com/yottaawesome/cuda-by-example/ ，官网的源码链接挂了。
书中的代码有些需要用 opengl 来跑。安装了 freeglut3-dev 和 mesa-utils。（不确定 libgl1-mesa-dev 是否是必要的。）然后 cmake 规则中要 link 对应的库：
cmake_minimum_required(VERSION 3.20.1) project(chapter3 LANGUAGES CXX CUDA) set(CMAKE_CUDA_STANDARD 17) set(CMAKE_CUDA_STANDARD_REQUIRED ON) set(CMAKE_CUDA_EXTENSIONS OFF) add_executable(ray ray_global.cu) target_link_libraries(ray GL glut) # ^^^^^^^ 第 3 章 CUDA 源文件用 nvcc 编译时不需要为 cuda 内置函数额外包含头文件。这些头文件是在 host 端才需要的。
https://stackoverflow.com/questions/6302695/difference-between-cuda-h-cuda-runtime-h-cuda-runtime-api-h
In very broad terms:
cuda.h defines the public host functions and types for the CUDA driver API. cuda_runtime_api.h defines the public host functions and types for the CUDA runtime API cuda_runtime.h defines everything cuda_runtime_api.h does, as well as built-in type definitions and function overlays for the CUDA language extensions and device intrinsic functions. If you were writing host code to be …  </content></entry><entry><title>CUDA by Example: Chapter 06-08</title><url>/cuda-by-example/CUDA-by-Example-chapter06-08/</url><categories><category>cuda-by-example</category></categories><tags><tag>cuda</tag><tag>cuda-by-example</tag></tags><content type="html">  第 6 章 Constant Memory and Events常量内存常量内存是在全局区域声明的。如果漏掉了 __constant__ 关键字，就会将其定义在全局内存区域，尽管存储方式、分配的时机和用 cudaMalloc 申请的内存有一些差异。
__constant__ Sphere s[SPHERES]; 常量内存的内存拷贝方法比较特殊：
HANDLE_ERROR( cudaMemcpyToSymbol( s, temp_s, sizeof(Sphere) * SPHERES) ); CUDA 线程对常量内存是只读的，也就是只有 host 能操作常量内存。通过将反复读取的数据移动到常量内存区域而不是全局内存，可以加速。但是要注意常量内存的大小非常有限（）。书中的例子只是对 20 个球体做光线追踪。
常量内存为什么快：
有 constant cache。 对常量内存的读取可以被广播到临近的线程。节省读取次数。 什么叫做临近线程？GPU 中线程执行是按照 warp 分组的。如果同一组的都需要同一个 constant memory 中的数据，那么 GPU 只会产生一个访问请求，这样会很节省带宽。（需要全局内存时难道不能用这个方法节省带宽吗？）
In the CUDA Architecture, a warp refers to a collection of 32 threads that are &amp;amp;ldquo;woven together&amp;amp;rdquo; and get executed in lockstep. At every line in your program, each thread in a warp executes the same instruction on different data.
When it comes to handling constant memory, NVIDIA hardware can broadcast a single memory read to each half-warp. A half-warp—not nearly as creatively named as a warp—is a group of 16 threads: half of a 32-thread warp. If every …  </content></entry><entry><title>find</title><url>/posts/cli/common/find/</url><categories/><tags><tag>shell</tag><tag>linux</tag></tags><content type="html"><![CDATA[  find 的 -exec 选项中，以 ; 结尾（注意 shell 转义）是对每个文件单独运行命令。而 + 结尾是对所有文件用 xargs 的形式运行命令。可以从以下例子看出：
$ find . -name &#39;*.cu&#39; -exec echo {} + ./basic_interop.cu ./ripple.cu ./heat.cu $ find . -name &#39;*.cu&#39; -exec echo {} \; ./basic_interop.cu ./ripple.cu ./heat.cu -depth 选项让 find 以深度优先的顺序访问文件，这样文件夹就一定比其包含的子文件后访问，这对于删除等工作非常重要。
find 有一些 global options，要在正确位置使用，不清楚可以 man find 查一下。比如 -mindepth、-maxdepth 和 -depth 都是 global options。
To prevent confusion, global options should specified on the command-line after the list of start points, just before the first test, positional option or action.
  ]]></content></entry><entry><title>bash 行编辑</title><url>/posts/cli/bash/bash-%E8%A1%8C%E7%BC%96%E8%BE%91/</url><categories/><tags><tag>bash</tag></tags><content type="html">  默认的是 emacs 模式的行编辑。
ctrl _ yank ctrl y yank ctrl / undo alt f word-level forward alt b word-level backward alt d word-level delete 这个可能会更好用，因为 d 按键更近 alt backspace word-level backspace   </content></entry><entry><title>CUDA by Example: Chapter 09-12</title><url>/cuda-by-example/CUDA-by-Example-chapter09-12/</url><categories><category>cuda-by-example</category></categories><tags><tag>cuda</tag><tag>cuda-by-example</tag></tags><content type="html">  第 9 章 原子操作You should know that atomic operations on global memory are supported only on GPUs of compute capability 1.1 or higher. Furthermore, atomic operations on shared memory require a GPU of compute capability 1.2 or higher.
指定计算能力：
nvcc -arch=sm_11 这样就指定了计算能力是 1.1，当有些指令是只有 1.1 才能编译时加这个参数可以确保编译。同时，有了更加精确的生成目标，nvcc 可以执行一些和硬件相关的优化手段，这些优化手段在更早的架构上可能没有。
但是一个硬件上不一定支持给定的计算能力。通过 -arch-ls 可以列出设备支持的计算能力：
$ nvcc -arch-ls compute_50 compute_52 compute_53 compute_60 compute_61 compute_62 compute_70 compute_72 compute_75 compute_80 compute_86 compute_87 compute_89 compute_90 例子是直方图计算，也就是统计各个值的元素的数量。书中的例子是对随机填充生成的字符数组的计数，每个字符值不超过 256。
可以用 prop.multiProcessorCount 来查询设备有的 SM 的数量。我们实验室项目则是直接对 blocks 数量使用了一个定数，没有查询 SM 数量。
第一个直方图的尝试是用 atomicAdd 直接在全局内存上做原子加法。但是这样的性能相当差，甚至在书中所用的硬件上比 CPU 上的计算慢了好几倍。用自己的设备测试，则 CPU、全局内存原子加法、共享内存原子加法耗时分别为 182ms 、62.5ms、30ms。虽然全局内存上的原子加法开销没有那么离谱，但是也比共享内存上的加法慢了很多。
计算直方图的可以用共享内存优化，先在各个块内用原子加法计算好块中的每个元素的数量，然后一口气用原子加法加到全局内存上去。虽然计算的过程多了，使用原子加法的次数也看起来变多了，但实际上却能节省很多时间！ …  </content></entry><entry><title>git-blame-ignore-revs</title><url>/posts/cli/git/git-blame-ignore-revs/</url><categories/><tags><tag>git</tag></tags><content type="html">  LLVM 项目中有个文件：.git-blame-ignore-revs
说明是：
# Since version 2.23 (released in August 2019), git-blame has a feature # to ignore or bypass certain commits. # # This file contains a list of commits that are not likely what you # are looking for in a blame, such as mass reformatting or renaming. # You can set this file as a default ignore file for blame by running # the following command. # # $ git config blame.ignoreRevsFile .git-blame-ignore-revs 这个文件可以指定要在 blame 时忽略的那些提交（比如对工程整体的格式化）。因为 git 配置是本地的，所以需要手动跑一次。
  </content></entry><entry><title>VS Code 错误：Remote Extension host terminated unexpectedly 3 times within the last 5 minutes.</title><url>/posts/developer/vscode/VS-Code-%E9%94%99%E8%AF%AFRemote-Extension-host-terminated-unexpectedly-3-times-within-the-last-5-minutes./</url><categories/><tags><tag>vscode</tag></tags><content type="html">  可能是因为上次对 wsl2 vdisk compact 之后造成的？还是因为升级之后造成的？
尝试过以下方法：
删除 ~/.vscode 和 ~/.vscode-server 里面的所有东西然后重新下载。不行。 禁用所有扩展，不行。 发现在 vscode 的终端使用 code 打开文件夹就有问题，但是在 code 之外的终端用 code 命令就没有问题。一看在 vscode 终端中的 code 命令竟然还是 windows 文件系统中的 code 命令，并不是 vscode-server 提供的 code 命令。
后来发现是我在 ~/.bashrc 中提供了 CLEAN_PATH（一个我预设的包含了大多数重要路径的 PATH），本来是想要解决多次载入 ~/.bashrc 因此 PATH 被反复追加的问题，但是这也让 vscode-server 设置好的 PATH 丢失了。同时我还在 PATH 的前面添加了 windows 文件系统的 code 命令，而不是在后面追加，这也是有问题的地方。
  </content></entry><entry><title>chapter01 - basic</title><url>/modern-cmake-for-cpp/chapter01-basic/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html"><![CDATA[  三个 stages：配置、生成、构建。
配置会生成 CMakeCache。生成是用它去生成 build tree 的其他内容。
Generating a Build System生成 build tree：
cmake -B build/ -S source/ 最好不要使用无参数的 cmake。
选择生成器：
cmake -G &amp;lt;generator&amp;gt; 也可以使用环境变量 CMAKE_GENERATOR。但是要注意大小写：
CMAKE_GENERATOR=Ninja cmake -B build 对一个已经指定了生成器的 build tree 设置新的 CMAKE_GENERATOR 并重新配置是无效的，这个时候环境变量会背忽略。而使用 -G 指定则提示有冲突。
指定 cache：
cmake -C &amp;lt;dir-of-CMakeCache.txt&amp;gt; cmake 会先读 cache 再去进行接下来的配置。
cmake -L[A][H] &amp;lt;path-to-source&amp;gt;：在配置的时候还会列举出配置。
(py310) xxx /data/modern-cmake/examples/chapter01/01-hello $ cmake -B build -L -- Configuring done -- Generating done -- Build files have been written to: /data/modern-cmake/examples/chapter01/01-hello/build -- Cache values CMAKE_BUILD_TYPE:STRING= CMAKE_INSTALL_PREFIX:PATH=/usr/local 可以看到当前有两个选项可以通过 cache 或者命令行的 -D 选项更改。
-A 使得被标记为 ADVANCED 的变量也被列出。
-D 用来定义变量，-U 用来移除变量。
cmake --system-information 用来打印系统信息。
--log-level 指定日志等级。
--log-context 可以提供更多信息，比如调用栈。
CMakePresets.json
一个用来提供预设配置的文件。命令行 优先于 预设配置 优先于 环境变量 优先于 默认值。
相关命令： …  ]]></content></entry><entry><title>chapter02 - cmake language</title><url>/modern-cmake-for-cpp/chapter02-cmake-language/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html"><![CDATA[  Comments使用 # 使用 #[=[ 和 #]=]（这种块注释是可以嵌套的） 如果 #[=[ 前面还有 #，那么块注释开始标志本身被注释了。后续的块注释结束标志被认为是普通的单行注释。
##[=[ message(&amp;#34;I&amp;#39;m not commented&amp;#34;) #]=] Command命令名是大小写不敏感的，但是一般用小写。
命令不是表达式，没有返回值。
commands 分类：
唯一的数据类型：string
message 命令会将所有的参数无 separator 拼接起来打印。
参数第一种：bracket arguments
用来表示字符串字面量，尊重换行和空格。由 [[ 开启。其中双左括号中可以有零个或多个任意数量的 = 符号。比如
message([[multiline bracket argument ]]) message([==[ because we used two equal-signs &amp;#34;==&amp;#34; following is still a single argument: { &amp;#34;petsArray&amp;#34; = [[&amp;#34;mouse&amp;#34;,&amp;#34;cat&amp;#34;]] } ]==]) 因为第二个字符串中包含了 ]] 本身，所以再使用 [ 和 ] 就不合适了（会导致字符串提前结束！）。换用不同的开始和结束标志可以帮助转义。这一点和 shell 的 Here Document 一样。
第二种：quoted arguments
可以用 ${Var} 完成字符串插值。
message(&amp;#34;1. escape sequence: \&amp;#34; \n in a quoted argument&amp;#34;) message(&amp;#34;2. multi... line&amp;#34;) message(&amp;#34;3. and a variable reference: ${CMAKE_VERSION}&amp;#34;) 没想到第二条 message 真的能换行，和 bracket arguments 相比只有转义的区别。
第三种：unquoted arguments
空白字符和分号可以分割参数：
而且圆括号比如成对才能出现在裸参数中。
message(a\ single\ argument) …  ]]></content></entry><entry><title>chapter02.a - 总结常用的 CMake 变量</title><url>/modern-cmake-for-cpp/chapter02.a-%E6%80%BB%E7%BB%93%E5%B8%B8%E7%94%A8%E7%9A%84-CMake-%E5%8F%98%E9%87%8F/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html">  PROJECT_*PROJECT_SOURCE_DIR PROJECT_BINARY_DIR 不存在 PROJECT_LIST_DIR。
PROJECT_* 变量会随着 project 命令的出现而变更。
CMAKE_*CMAKE_SOURCE_DIR CMAKE_BINARY_DIR 也不存在 CMAKE_LIST_DIR。
和本次 cmake 命令有关。
CMAKE_CURRENT_*通过 VS Code 补全可以看到有很多变量：
其中 LIST 和 SOURCE 的区别是：include 会直接将 cmake 文件插入进来，这个时候不会改变 SOURCE，但是会改变 LIST。所以为了表示文件的相对位置一般还是用 LIST 吧？
同理，函数定义处和调用处可能是不同的，想要获取函数定义处的信息，需要使用 CMAKE_CURRENT_FUNCTION_*。
  </content></entry><entry><title>chapter03 - first cmake project</title><url>/modern-cmake-for-cpp/chapter03-first-cmake-project/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html">  cmake_minimal_requiredcmake_minimal_required(VERSION xxx) 是项目都应该有的说明。因为它指定了最小的版本，而且还会隐式去调用 cmake_policy，这样即便 cmake 版本更新了，policy 没变，旧项目仍然可以正常构建。
Note
cmake policy 是每次 cmake 有不向后兼容的改动时增加的标志。
VERSION 可以是一个范围 a...b，如果只有一个值则是最小版本要求。
projectproject 命令用来设置项目名、版本、还有语言等。
默认的语言是 C 和 CXX 两个（不包含 CUDA）。对于 C++ 项目设置语言为 CXX 的好处是 cmake 不再会为所有语言检查编译器的存在情况，配置时间会短一些（对于 hello-world 项目，在 6 core Intel(R) Core(TM) i7-8750H CPU @ 2.20GHz + wsl2 中 CXX 的配置时间是 200 ms，C 和 CXX 的配置时间是 345 ms）。
也可以用 enable_language 添加语言，这不会设置任何元变量。
最小项目cmake_minimum_required(VERSION 3.20.0) # 默认语言是 C 和 CXX project(hello VERSION 1.0 LANGUAGES CXX) add_executable(hello hello.cpp) 添加子目录作为项目的一部分add_subdirectory(source_dir [binary_dir] [EXCLUDE_FROM_ALL])
EXCLUDE_FROM_ALL 可以使得子目录的目标不作为默认目标加入本列表（比如 examples 和 tests）。这样就能尽可能少地编译。如果要用这个，一般情况下说明这个子目录也应该有自己的 project 命令，可以被独立地编译。
推荐的工程结构doc 目录是构建文档的代码，而不是文档本身。 extern 是第三方。 cmake 放宏和函数、find_modules、脚本。 src/libn 应该也可以是纯头文件的库吧？ test &amp;amp;ldquo;contains code for automated tests&amp;amp;rdquo; …  </content></entry><entry><title>chapter04 - targets</title><url>/modern-cmake-for-cpp/chapter04-targets/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html">  创建 target三种方式：
add_executable # 默认在 ALL 中 add_library # 默认在 ALL 中 add_custom_target # 默认不在 ALL 中 # add_custom_command 是创建文件的方式，但是不是创建 target add_library: https://cmake.org/cmake/help/latest/command/add_library.html#object-libraries
Normal library: 如果不指定 STATIC/SHARED/MODULE，add_library 会根据 BUILD_SHARED_LIBS 变量去决定是否使用 SHARED 还是 STATIC。 Object library: 生成目标文件。 Interface library：不生成文件。用来打包传播属性。 Imported library：IMPORTED 属性和 STATIC 等是可以叠加的。IMPORTED 库是已经被编译好的库，不需要另外编译，但是需要用 set_target_property 来设置其位置。 Alias library add_custom_target 可以有多条命令，而且不一定有产物。add_custom_target 创建的 target 是默认不 ALL 的！和 add_custom_command 的对比看后文。
可以手动用 add_dependencies 创建新的依赖关系。主要是用来维护编译顺序的（比如检查 checksum 的自定义任务必须得在目标已经生成之后）。
target 的依赖声明可以不按照顺序，cmake 会扫描整个文件再去构建依赖。
读写 target 的属性set_target_properties get_target_property cmake 的有些命令是等价的，但是存在一层封装关系。比如用 get_property 和 set_property 也可以，但是不如上面的命令方便。
set_property 除了设置 target 还能设置 source 的属性。
其实用 add_dependencies 添加依赖关系也只是写入了 target 的属性，因而依赖是属性的一种。
属性传播传播（propagation）有几种方式： …  </content></entry><entry><title>chapter04.a - 梳理依赖是如何创建的</title><url>/modern-cmake-for-cpp/chapter04.a-%E6%A2%B3%E7%90%86%E4%BE%9D%E8%B5%96%E6%98%AF%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E7%9A%84/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html">  我认为的依赖有两种：
文件依赖（sources）既有同级依赖（比如 add_custom_command 的 DEPENDS 参数），又有 targets 到 sources 的依赖。 target 依赖是一种 targets 之间的同级依赖关系。 Target 依赖创建 target 可以用 add_executable/add_library/add_custom_target。前面两个都默认包含在 all 中，而最后一个默认不包含在 all 中。此外，add_custom_target 如果给的是命令，而不是依赖文件，则创建的 targets 永远处于“需要被构建”的状态；如果给的是文件，则就只是文件依赖。
可以用 add_dependencies 来创建 targets 之间的依赖。
文件依赖如果 target 或者 command（由 add_custom_command 创建）依赖一个源文件，这个文件找不到、但是又被标记了 GENERATED 属性，则会想办法去生成这个文件。
创建 target 的时候没有给全源文件不要紧，可以用 去追加源文件。
在源文件中添加头文件看似没有意义，实际上是增加了依赖文件，在这个文件需要由自定义命令在构建时生成时很有用。
Note
使用 add_custom_target 和 add_custom_command 时一定要正确写上 OUTPUT/DEPENDS/BYPRODUCTS。
Warning
文件依赖在跨目录时不太好用，处理起来很棘手。最好是在当前目录解决。
文件依赖中给出的文件既可以相对于本文件夹对应的 build 目录，又可以相对于本文件夹对应的 source 目录。CMake 更偏好前者。
文件依赖并不是很好处理，幸运的是，我们随时可以将文件依赖转换成 target 依赖！
https://stackoverflow.com/questions/46795065/cmake-have-a-target-depend-on-a-generated-file-in-a-subdirectory 网页给的代码中依赖了 subdir/foo.{h,cpp}，但实际上因为有 target 的出现，对 subdir/foo.h 的依赖是多余的。不过对 .cpp 文件还是得有源码依赖，否则不能正常生成。最好的处理方法其实还是在子文件夹编译成目标文件，直接在当前目录的 CMakeLists.txt 中写链接规则。
  </content></entry><entry><title>chapter05 - compiling c++ sources</title><url>/modern-cmake-for-cpp/chapter05-compiling-c++-sources/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html"><![CDATA[  Initial configurationtarget_sources # 追加源码 target_include_directories target_compile_definitions target_compile_options # 不能跨平台 target_compile_features # 对编译器要求某种特性 target_precompile_headers 用 target_sources 中添加了头文件是会被过滤掉的，会形成依赖，但是不会真正被编译。 target_compile_features 的特性非常多。一般也就只用 cxx_std_{98,11,14,17,20,23} 这种语言标准，而不是具体的标准。 Preprocessor configurationtarget_compile_definitions 能够自动去除多加的 -D，不过最好还是不要加，因为这个命令本来就是用于跨平台的，不加风格更统一。
通过 execute_process 和 宏定义，可以将当前的最新 commit 传入源码，这样源码就能自己计算最新版本，而不需要每次都手动更改！然后提交的代码通过 CD 就能够自动构建了。特别是在用户只有产品时，能够获得具体的 commit sha1 能够很方便定位出问题的版本。 configure_file(&lt;input&gt; &lt;output&gt;) 能够从模板（比如 configure.h.in）中生成各种诸多宏定义的头文件。
Configuring the optimizer-O0 -O1 -O2 -O3 gcc 的描述： Optimize yet more. -O3 turns on all optimizations specified by -O2 and also turns on the -finline-functions and -frename-registers options. -Os 为速度优化 -Ofast 比 -O3 更激进，浮点数可以不遵循 IEEE754 标准，还有一些别的优化。 虽然说 -finline-functions 是 -O3 开启的，-O1 也是能够将简单函数内联的： https://godbolt.org/z/3GxxKGEWT
默认 flag：
CMAKE_CXX_FLAGS_DEBUG equals -g CMAKE_CXX_FLAGS_RELEASE equals -03 -DNDEBUG 可以手动添加 flag： https://stackoverflow.com/a/48114415/ Managing the process of compilation个人感觉这里最有意思的点是预编译头文件。module 支持本书写时还没有出现。
&hellip;since version 3.16, CMake offers a command to enable header precompilation.
The list of added headers is stored in the PRECOMPILE_HEADERS target property.
一般的 header 都是用 PUBLIC 或者 INTERFACE 比较好，但是对于预编译的头文件，最好是 PRIVATE。
第二种用 [[ 和 ]] 是想要生成字面量，也就是包含双引号：
也可以从别的 target 借用预编译头文件。
Debugging the buildgcc 和 clang 的 -save-temps 选项能够在编译时保存中间产物，比如预处理结果和汇编。
-H 选项能够打印每个被包含头文件的位置。
  ]]></content></entry><entry><title>chapter06 - linking</title><url>/modern-cmake-for-cpp/chapter06-linking/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html">  程序分段.text section: Machine code, with all the instructions to be executed by the processor
.data section: All values of the initialized global and static objects (variables)
.bss section: All values of the uninitialized global and static objects (variables), which will be initialized to zero on program start
.rodata section: All values of the constants (read-only data)
.strtab section: 常量字符串的表
.shstrtab section: 每个 section 的名称字符串的表
可执行文件有一些差异，其中之一就是 program header，它描述了创建进程镜像的信息。 库的分类CMake 支持的有 STATIC, SHARED, MODULE：
MODULE不应该将 MODULE 链接到其他文件。成为 MODULE 的库需要在运行时被显式链接。
Position-independent codeCMake checks the POSITION_INDEPENDENT_CODE property of targets and appropriately adds compiler-specific compilation flags such as -fPIC for gcc or clang.
PIC will add a new section to our output - the Global Offset Table (GOT). Eventually, this section will become a segment containing runtime addresses for all the symbols needed by shared libraries.
感觉这里没有自动传播 POSITION_INDEPENDENT_CODE 是一个设计上的问题？不过 cmake 可以通过这个属性在传播目标上的一致性做冲突检查。
Dynamically linked duplicated symbols动态链接时出现符号冲突，那么最终使用的符号和链接的顺序有关，而不是直接报错！
The order of linking and unresolved symbolsLinker 是比较笨的。只是简单按顺序从库中找到当前 unresolved 的符号，但是在处理库的时候可能会增加新的 unresolved 符号。如果在链接一个库时新增了 unresolved 符号，但是提供这个符号的库早就已经被 link 过了，而且后面也没有再次出现，那么就会出现问题。
这个时候要么更换顺序：
target_link_libraries(main outer nested) 要么 link 多次：
target_link_libraries(main nested outer nested) 还可以用特殊的 linker 选项：
Separating main() for testing感觉不是很方便啊？
  </content></entry><entry><title>chapter07 - managing dependencies</title><url>/modern-cmake-for-cpp/chapter07-managing-dependencies/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html"><![CDATA[  Best option: find_packagehttps://cmake.org/cmake/help/latest/command/find_package.html
有三种工作模式。
Module modeFind&amp;lt;PackageName&amp;gt;.cmake
主要是包外提供，比如 CMake、操作系统、或者写当前工程的人提供的试探性地去搜索库的方式。先找 CMAKE_MODULE_PATH，然后就是 cmake 的安装目录。
我们实验室项目不少路径都是硬编码的，感觉写 Find Module 会更合适。
Config modeIn this mode, CMake searches for a file called &amp;lt;lowercasePackageName&amp;gt;-config.cmake or &amp;lt;PackageName&amp;gt;Config.cmake. It will also look for &amp;lt;lowercasePackageName&amp;gt;-config-version.cmake or &amp;lt;PackageName&amp;gt;ConfigVersion.cmake if version details were specified.
这些文件是由作者提供。由于作者知道包的结构，所以一般搜索起来更加直接。
Config 模式下 cmake find_package比较复杂。
FetchContent redirection modecmake version 3.24 出现。find_package 在 config 模式下可以内在转换成对 FetchContent 的调用。
See link and link for further details.
如何工作？When the link is used, the command searches in Module mode first. If the package is not found, the search falls back to Config mode. A user may set the link variable to true to reverse the priority and direct CMake to search using …  ]]></content></entry><entry><title>chapter08 - testing</title><url>/modern-cmake-for-cpp/chapter08-testing/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html"><![CDATA[  CTest基本用法要使用 CTest 和相关的东西需要调用 enable_testing。
ctest 是要在 build tree 执行的。
ctest 也能直接编译和运行（两步合为一步），但是要手动提供测试命令（有点奇怪）。
Dry run：
CTest offers an -N option, which disables execution and only prints a list.
将测试用标签分组（之前我在实验室项目里面只用了 NAME 关键字）：
CTest also offers a mechanism to group tests with LABELS keyword.
也可以在测试添加完成之后再通过更改属性改变 LABELS：
set_tests_properties(&amp;lt;name&amp;gt; PROPERTIES LABELS &amp;#34;&amp;lt;label&amp;gt;&amp;#34;) 从单词复数形式来看应该是能够添加多个标签。
过滤测试可以用正则表达式对 label 或者 name 匹配、反向匹配。
用 --schedule-random 可以打乱顺序测试，提高测试的稳定性，避免前一个测试干扰后一个测试。
用 –-repeat 选项能够重复测试，直到测试成功、失败、超时或者达到最大测试数量。
用 -j 可以指定并发测试，这样测试速度更快。
用 -C 或者 --build-config 可以指定要测试的 config（对 multi-config generator 有效）。
用 --test-load 控制 CPU 的占用。
用 --timeout 指定单个测试的超时时间。
一般的使用方式不要在 main 函数中留太多逻辑，把主要逻辑包装在一个新的函数中。然后通过静态链接不同 main 函数实现构建测试程序或者部署要使用的程序。
说起来比较复杂，其实我们一直都是这么做的。
Catch2略。Catch2 比较好的是它提供的是 CHECK 宏，能够直接展开其中的逻辑表达，符合人的习惯，不用专门区分 EQ/GE/LE 等多种情况。
GTestgtest_maintest/CMakeLists.txt
include(FetchContent) FetchContent_Declare( googletest GIT_REPOSITORY …  ]]></content></entry><entry><title>chapter09 - program analysis tools</title><url>/modern-cmake-for-cpp/chapter09-program-analysis-tools/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html"><![CDATA[  说明这一章节是作者将一些分析工具以函数或内置支持的形式自动化地加入到了 CMake 构建工程的过程中了。
格式化clang-format
静态检查clang-tidy cpplint（按照 Google Coding Style 检查） cppcheck include-what-you-use link what you use（CMake 内置） 静态检查受到 CMake 的直接支持：
All we need to do is set an appropriate target property to a semicolon-separated list containing the path to the checker&rsquo;s executable, followed by any command-line options that should be forwarded to the checker.
&lt;LANG&gt;_CLANG_TIDY &lt;LANG&gt;_CPPCHECK &lt;LANG&gt;_CPPLINT &lt;LANG&gt;_INCLUDE_WHAT_YOU_USE LINK_WHAT_YOU_USE 比如：
set(CMAKE_CXX_CLANG_TIDY /usr/bin/clang-tidy-3.9;-checks=*) 以 clang-tidy 为例，除了设置全局的 CMAKE_&lt;LANG&gt;_CLANG_TIDY 之外，还能对 target 设置 &lt;LANG&gt;_CLANG_TIDY 属性：
function(AddClangTidy target) find_program(CLANG-TIDY_PATH clang-tidy REQUIRED) set_target_properties(${target} PROPERTIES CXX_CLANG_TIDY &#34;${CLANG-TIDY_PATH};-checks=*;--warnings-as-errors=*&#34; ) endfunction() 这样在构建的时候就会自动检查，不过这也会使得构建变得很慢。
用 valgrind 动态检查valgrind 介绍使用方式：
valgrind [valgrind-options] tested-binary [binary-options] 使用 memcheck 直接省略 options 即可，因为它是默认的工具，当然也可以显式指定：
valgrind --tool=memcheck tested-binary 实际上它的功能还有很多：
Some of the tools are as follows:
Memcheck – detects memory-management problems Cachegrind – profiles CPU caches, and pinpoints cache misses and other cache issues Callgrind – an extension of Cachegrind with extra information on call graphs Massif – a heap profiler that shows which parts of the program use heap over time Helgrind – a thread debugger, which helps with data race issues DRD – a lighter, limited version of Helgrind valgrind 除了命令行之外还按照顺序读取以下配置：
家目录下的 ~/.valgrindrc 文件 $VALGRIND_OPTS 环境变量 当前路径的 .valgrindrc 文件，并且 &ldquo;will only be considered if it belongs to the current user, is a regular file, and isn&rsquo;t marked as world-writable&quot;。 Memcheck可以把 valgrind 作为一个自定义的 target 加入到 CMake 工程中。
Memcheck-Cover一个可以将 valgrind 输出文件用 html 显示出来的软件。
  ]]></content></entry><entry><title>chapter10 - documents</title><url>/modern-cmake-for-cpp/chapter10-documents/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html">  Adding Doxygen to your project安装必要软件包：
apt-get install doxygen graphviz 然后就能在 CMake 中引入 Doxygen 包并使用 doxygen_add_docs。
Since CMake 3.9, we can use the doxygen_add_docs() function from FindDoxygen find-module, which sets the documentation target up.
注意 FindDoxygen module 推荐使用方式是 find_package，虽然可以 include 但是不推荐。
doxygen 用的是 Javadoc 的格式。
通过设置 DOXYGEN_HTML_EXTRA_STYLESHEET 选项可以修改输出文档的样式。比如 https://github.com/jothepro/doxygen-awesome-css 就是一个比较现代化的样式。
  </content></entry><entry><title>chapter11 - installing and packaging</title><url>/modern-cmake-for-cpp/chapter11-installing-and-packaging/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html"><![CDATA[  Exporting without installation使用 export 命令可以创建导出文件，然后其他工程只要 include 这个导出文件就能使用当前这个包中的 target，而不需要先将这个包用 install 安装在系统里。
export(TARGETS [target1 [target2 [...]]] [NAMESPACE &amp;lt;namespace&amp;gt;] [APPEND] FILE &amp;lt;path&amp;gt; [EXPORT_LINK_INTERFACE_LIBRARIES] NAMESPACE is recommended as a hint, stating that the target has been imported from other projects.
APPEND tells CMake that it shouldn&amp;rsquo;t erase the contents of the file before writing. 也就是说本身会按照 FILE 来覆写文件，但是 APPEND 使得写入方式变成追加。
EXPORT_LINK_INTERFACE_LIBRARIES will export target link dependencies (including imported and config-specific variants).
例子：
cmake_minimum_required(VERSION 3.20.0) project(ExportCalcCXX) add_subdirectory(src bin) set(EXPORT_DIR &amp;#34;${CMAKE_CURRENT_BINARY_DIR}/cmake&amp;#34;) export(TARGETS calc FILE &amp;#34;${EXPORT_DIR}/CalcTargets.cmake&amp;#34; NAMESPACE Calc:: ) ... 这段代码将导出文件生成在了 binary tree 里面，这样的文件不会污染系统，但是可以被其他工程包含进去。还要注意 CMake 在 build tree 中导出的 target export file 里用的是绝对路径，所以不能轻易移动。上面代码还用到了一个名字空间 Calc::， …  ]]></content></entry><entry><title>chapter11.a - 对比 export 和 install 命令</title><url>/modern-cmake-for-cpp/chapter11.a-%E5%AF%B9%E6%AF%94-export-%E5%92%8C-install-%E5%91%BD%E4%BB%A4/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html"><![CDATA[  export 和 install 命令都有 TARGETS 和 EXPORT 两种参数形式，所以容易混淆：
export (TARGETS ...) 将给定的 targets 导出到 target export file，不会创建 named export install(TARGETS ... [EXPORT] ...) 如果有 EXPORT，除了安装之外，还会顺便从 targets 创建 named export（有两个作用！！这个是我是检查了 cmake_install.cmake 的） export (EXPORT ...) 将 named export 导出到文件，可以指定名字空间 install(EXPORT ...) 将 named export 安装到系统，和 export(EXPORT ...) 有相似的参数，同样可以指定名字空间 export 命令用来导出 target export file。install 命令用来安装文件到系统。在 target export file 的场景下，两者都能用于“安装”，但是前者一般是用在安装在临时路径上（参考 Exporting without installation），而后者是用来安装进系统的。
例子：unnamed export VS named export
# unnamed export export(TARGETS calc FILE &#34;${EXPORT_DIR}/CalcTargets.cmake&#34; NAMESPACE Calc:: ) #[=[ named export，同时还有 install(TARGETS calc) 的副作用。因而代码相当于： install(TARGETS calc) export(TARGETS calc FILE &#34;${EXPORT_DIR}/CalcTargets2.cmake&#34; NAMESPACE Calc:: ) #]=] install(TARGETS calc EXPORT CalcTargets) export(EXPORT CalcTargets FILE &#34;${EXPORT_DIR}/CalcTargets2.cmake&#34; NAMESPACE Calc:: ) 这样生成的两个 target export file 的内容是一模一样的。
  ]]></content></entry><entry><title>chapter12 - full project</title><url>/modern-cmake-for-cpp/chapter12-full-project/</url><categories><category>modern-cmake-for-cpp</category></categories><tags><tag>cmake</tag><tag>cpp</tag><tag>modern-cmake-for-cpp</tag></tags><content type="html"><![CDATA[  总体结构一些文件的分析chapter12/01-full-project/src/calc/CMakeLists.txt
add_library(calc_obj OBJECT calc.cpp) target_include_directories(calc_obj INTERFACE &#34;$&lt;BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}/include&gt;&#34; &#34;$&lt;INSTALL_INTERFACE:${CMAKE_INSTALL_INCLUDEDIR}&gt;&#34; ) set_target_properties(calc_obj PROPERTIES PUBLIC_HEADER src/calc/include/calc/calc.h POSITION_INDEPENDENT_CODE 1 ) add_library(calc_shared SHARED) target_link_libraries(calc_shared calc_obj) add_library(calc_static STATIC) target_link_libraries(calc_static calc_obj) 一些要点：
target_include_directories 使用生成器表达式为 build 和 install 之后指定了不同的包含路径。导出 target export file 的话这个细节非常重要。 然后是设置对象的属性。因为我们的库不是 SHARED 类型而是 OBJECT 类型，所以不是默认 PIC 的。需要正确设置 POSITION_INDEPENDENT_CODE 属性（我们实验室项目是在全局编译选项中加入 -fPIC 保证这一点的）。 chapter12/01-full-project/cmake/GetFTXUI.cmake
include(FetchContent) FetchContent_Declare( FTXTUI GIT_REPOSITORY https://github.com/ArthurSonzogni/FTXUI.git GIT_TAG v0.11 ) option(FTXUI_ENABLE_INSTALL &#34;&#34; OFF) option(FTXUI_BUILD_EXAMPLES &#34;&#34; OFF) option(FTXUI_BUILD_DOCS &#34;&#34; OFF) FetchContent_MakeAvailable(FTXTUI) 要点：FetchContent 模块将 FetchContent_Declare 和 FetchContent_MakeAvailable 分成了两步，这样能够在导入之前设置一些属性。
chapter-12/01-full-project/cmake/BuildInfo.cmake
# ... set(BUILDINFO_TEMPLATE_DIR ${CMAKE_CURRENT_LIST_DIR}) set(DESTINATION &#34;${CMAKE_CURRENT_BINARY_DIR}/buildinfo&#34;) string(TIMESTAMP TIMESTAMP) find_program(GIT_PATH git REQUIRED) execute_process(COMMAND ${GIT_PATH} log --pretty=format:&#39;%h&#39; -n 1 OUTPUT_VARIABLE COMMIT_SHA) configure_file( &#34;${BUILDINFO_TEMPLATE_DIR}/buildinfo.h.in&#34; &#34;${DESTINATION}/buildinfo.h&#34; @ONLY ) # ... configure_file 函数可以将 CMake 中的变量用 @VAR@ 的方式传入到模板中，然后生成源码文件（这里被用来生成头文件了，但是实际上也可以用来生成其他文件）：
struct BuildInfo { static inline const std::string CommitSHA = &#34;@COMMIT_SHA@&#34;; static inline const std::string Timestamp = &#34;@TIMESTAMP@&#34;; static inline const std::string Version = &#34;@PROJECT_VERSION@&#34;; }; 这样就能动态嵌入 commit 和时间、版本等信息，不会出现更新内容后忘记更新源码各处散落的版本的情况。
configure_file 允许的替换有：@VAR@, ${VAR}, $CACHE{VAR} 和 $ENV{VAR} 这四种。使用 @ONLY 参数将只启用第一种。使用 COPYONLY 参数将不会进行任何替换。
此外 #cmakedefine VAR ... 会被替换成 #define VAR ... 或者 /* #undef VAR */，而 #cmakedefine01 VAR 将会被替换成 #define VAR 0 或者 #define VAR 1。
  ]]></content></entry><entry><title>C++ 模板显式实例化</title><url>/posts/programming/cpp/C++-%E6%A8%A1%E6%9D%BF%E6%98%BE%E5%BC%8F%E5%AE%9E%E4%BE%8B%E5%8C%96/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  头文件：template.hpp
#ifndef TEMPLATE_HPP #define TEMPLATE_HPP template &lt;typename T&gt; void println(T t); #endif 源文件：main.cpp
#include &#34;template.hpp&#34; int main() { println(9); println(-7); } 源文件：instantiation.cpp
#include &lt;iostream&gt; #include &#34;template.hpp&#34; template &lt;typename T&gt; void println(T t) { std::cout &lt;&lt; t &lt;&lt; &#34;\n&#34;; } // 特化声明：失败，因为没有定义 // template &lt;&gt; // void println&lt;int&gt;(int); // 显式实例化：成功 template void println&lt;int&gt;(int); // template void println(int); // 如果能够从函数参数中推导出模板参数，也可以省略模板参数 // 特化定义：成功 // template &lt;&gt; // void println&lt;int&gt;(int t) { // std::cout &lt;&lt; &#34;instantiation.cpp: &#34; &lt;&lt; t &lt;&lt; &#34;\n&#34;; // } 翻译单元 A 要调用模板函数：
如果它能看到模板函数的特化定义，就会直接使用。 如果它只能看到模板函数的定义（即便是看到了特化函数的声明也不行），但是看不到特化的定义，就会去生成。 如果只能看到模板函数的声明，则没办法生成，就只能等待链接。 所以想要节省编译时间只能在头文件中留下声明，不能留定义。
在实例化的时候也要注意，首先是对每一个类型都写一遍函数体太累了，可以直接在源文件中提供定义，然后显式实例化或者特化。两者关系如下：
显式实例化和特化不能一起出现。显式实例化在特化之前则会报错，在特化之后会没有效果（相当于没有使用显式实例化）。 写法上有区别：注意特化是要加 template &lt;&gt; 的，而显式实例化是加的 template，没有 &lt;&gt;。 显式实例化不能提供定义（函数体），特化可以有定义也可以没有（在和显式实例化进行对比的这种场景下，我们希望特化有定义，否则函数无法生成，链接不能成功）。 Warning
特化函数只声明不定义没有意义。如果所在翻译单元能看到 primary 模板的定义，则会自己生成，如果看不到则会延迟到链接阶段去解决符号查找问题，是否有特化函数声明没有影响。
为什么需要显式实例化？因为模板实例化是按需进行的，显式实例化就是告诉编译器这个函数之后会被用到，所以先实例化出来方便链接。
  ]]></content></entry><entry><title>C++ 重定向输出的几种方案：iostream rdbuf、stdio freopen、unix fd</title><url>/posts/programming/cpp/C++-%E9%87%8D%E5%AE%9A%E5%90%91%E8%BE%93%E5%87%BA%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%A1%88iostream-rdbufstdio-freopenunix-fd/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  在看 Modern CMake for C++ 的时候看到了这段代码：
void RunOutputsCorrectEquations() { string expected {&#34;2 + 2 = 4\n3 * 3 = 9\n&#34;}; stringstream buffer; // redirect cout auto prevcoutbuf = cout.rdbuf(buffer.rdbuf()); run(); auto output = buffer.str(); // restore original buffer cout.rdbuf(prevcoutbuf); if (expected != output) exit(1); } 看起来 stdio 的 FILE 也能重定向（但是不能保存之前的关联，因而恢复到 stdout 不能跨平台）：
https://stackoverflow.com/a/29154180/
// 重定向 freopen(&#34;output.txt&#34;, &#34;a+&#34;, stdout); // 恢复到终端输出 freopen(&#34;/dev/tty&#34;, &#34;w&#34;, stdout); /*for gcc, ubuntu*/ // or freopen(&#34;CON&#34;, &#34;w&#34;, stdout); /*Mingw C++; Windows*/ 没办法保存之前的输出！
不能直接给 stdout 赋值，因为 stdout 不保证是可写的变量。
而 *nix 的 fd 倒是很方便重定向。
  ]]></content></entry><entry><title>CMake CONFIG 生成器表达式</title><url>/posts/cli/cmake/CMake-CONFIG-%E7%94%9F%E6%88%90%E5%99%A8%E8%A1%A8%E8%BE%BE%E5%BC%8F/</url><categories/><tags><tag>cmake</tag></tags><content type="html"><![CDATA[  cmake 的 CONFIG 生成器表达式有两种形式，一种是不接受参数、输出当前的 CONFIG 值，还有一种是判断当前的 CONFIG 是否属于几者之一。在判断 Debug 模式的时候一定要小心，因为使用 Makefile 作为生成器时，不传入 CMAKE_BUILD_TYPE 时使用的 CONFIG 为空。
target_compile_options(YourTarget PRIVATE -Wall $&lt;$&lt;CONFIG:,Debug&gt;:-g3&gt; ) 不过，也可以通过显式设置 CMAKE_BUILD_TYPE 来防范就是了：
if (NOT CMAKE_BUILD_TYPE) set(CMAKE_BUILD_TYPE &#34;Debug&#34;) endif() 这样之后再用生成表达式创建自定义 target 打印 $&lt;CONFIG&gt; 的结果就是 Debug。
如果不显式设置，则会使用编译器特定的默认编译模式，这个就说不清楚了。
  ]]></content></entry><entry><title>CMake 学过又忘记的写法</title><url>/posts/cli/cmake/CMake-%E5%AD%A6%E8%BF%87%E5%8F%88%E5%BF%98%E8%AE%B0%E7%9A%84%E5%86%99%E6%B3%95/</url><categories/><tags><tag>cmake</tag></tags><content type="html">  这篇用来记录学过但是不容易记住的写法。
CMake language
add_subdirectory(source_dir [binary_dir] [EXCLUDE_FROM_ALL] [SYSTEM]) ^^^^^^^^^ e.g. add_subdirectory(src bin) 这个操作是可以给单个文件设置不同的编译选项，而不是对 target 设置。控制的粒度就更细了。
if(MSVC AND NOT CLANG_CL) set_source_files_properties(CompileCommands.cpp PROPERTIES COMPILE_FLAGS -wd4130) # disables C4130: logical operation on address of string constant endif() CMake command line
cmake -S . -B build -G &amp;#34;Ninja Multi-Config&amp;#34;   </content></entry><entry><title>CMake 并行编译</title><url>/posts/cli/cmake/CMake-%E5%B9%B6%E8%A1%8C%E7%BC%96%E8%AF%91/</url><categories/><tags><tag>cmake</tag></tags><content type="html">  CMake 在 3.12 之后有 -j 选项了，无参数则表示不受限。
常用的两个 generators：
Unix Makefiles 默认使用 1 个线程，支持 -j 选项。
Ninja 也支持 -j 选项，如果不指定则使用默认线程数。可以用 ninja --help 来查看。
ninja --help 2&amp;gt;&amp;amp;1|grep -- -j 输出：
-j N run N jobs in parallel (0 means infinity) [default=8 on this system] 这个默认核心数似乎是 nproc 结果 + 2。
  </content></entry><entry><title>限制 Docker 容器使用的 CPU</title><url>/posts/cli/docker/%E9%99%90%E5%88%B6-Docker-%E5%AE%B9%E5%99%A8%E4%BD%BF%E7%94%A8%E7%9A%84-CPU/</url><categories/><tags><tag>docker</tag></tags><content type="html">  在 docker run 创建容器的时候用 --cpuset-cpus 0-3 可以限制 CPU 在 0-3 这四个核心上，实测 nproc 的结果已经改变了。
在 docker build 的时候也可以用同样的参数，比如 docker build . --cpuset-cpus 0-3，这能够被正常识别，但是 nproc 的结果没有改变，也不知道是否正常限制了。
  </content></entry><entry><title>括号的英文叫法</title><url>/posts/unsorted/%E6%8B%AC%E5%8F%B7%E7%9A%84%E8%8B%B1%E6%96%87%E5%8F%AB%E6%B3%95/</url><categories/><tags><tag>term</tag></tags><content type="html">  (parentheses) [brackets] {braces} &amp;lt;angled brackets&amp;gt;   </content></entry><entry><title>LaTeX 中裁剪图片</title><url>/posts/latex/LaTeX-%E4%B8%AD%E8%A3%81%E5%89%AA%E5%9B%BE%E7%89%87/</url><categories/><tags><tag>latex</tag></tags><content type="html">  \begin{document} % Answer: [trim={left bottom right top},clip] % Ex. 1: trim from left edge \includegraphics[trim={5cm 0 0 0},clip]{example-image-a} % Ex. 2: trim from right edge \includegraphics[trim={0 0 5cm 0},clip]{example-image-a} \end{document} 顺序是左下右上。和 css 中的 margin 的指定是相反的顺序。（css 中是上右下左。css 这个好记忆，就是初始位置在最上面，然后顺时针。）
  </content></entry><entry><title>bash 数字大小比较</title><url>/posts/cli/bash/bash-%E6%95%B0%E5%AD%97%E5%A4%A7%E5%B0%8F%E6%AF%94%E8%BE%83/</url><categories/><tags><tag>bash</tag></tags><content type="html">  对于整数，可以用 [[]] 和 (()) 来比较。
对于浮点数，可以用 bc，但是 bc 不是每个环境都有。
还有一种方法是 perl（如果装了 perl 但是没有装 bc）：perl -e &amp;quot;exit(1) if not $a &amp;gt; $b&amp;quot;，这样可以用返回值标志是否成功。
  </content></entry><entry><title>bash 语法总结</title><url>/posts/cli/bash/bash-%E8%AF%AD%E6%B3%95%E6%80%BB%E7%BB%93/</url><categories/><tags><tag>bash</tag></tags><content type="html"><![CDATA[  重新加载 PATH 中的可执行文件hash -r：用于解决在 PATH 中加入可执行文件后找不到的情况。
用 ** 匹配多级目录（find 不能匹配双星号）shopt -s globstar set +o pipefail clang-tidy -p build/ ./{src,include}/**/*.{h,hpp,cc,cpp,cu} 第一句是打开 ** 选项，第二句是忽略 pipefail（-o 和 +o 相反）不然第三句的 pipe 可能出错，第三句 2&gt;/dev/null 是忽略错误信息。
* 和 ** 都不能直接匹配 *nix 上的隐藏文件，即用 . 开头的文件。
上述命令的功能：clang-tidy 会找到 .clang-tidy 和 build/ 下的 compile_commands.json 配置并对代码进行分析。
bash 的 += 运算符https://stackoverflow.com/a/18041780/
# 拼接字符串 s=&#34;hello&#34; s+=&#34; world&#34; echo $s # ==&gt; &#34;hello world&#34; # 整数加法 int=1 ((int+=3)) echo $int # ==&gt; 4 # 数组拼接 declare -a arr=&#39;([0]=&#34;3&#34; [1]=&#34;3&#34;)&#39; arr+=(12 20) echo &#34;${arr[@]}&#34; # ==&gt; 3 3 12 20 bash 正则bash 正则用的是部分匹配：
# 检查结果是否为空白 if [[ &#34;$result&#34; =~ ^[[:space:]]*$ ]]; then echo OK fi 为了严格匹配，有必要加上 ^ 和 $ 符号。
bash 命令的分隔符; 表示上一条命令前台运行。&amp; 表示上一条命令后台运行。
注意，&amp; 并不是单纯表示放在后台的意思，因为 &amp;; 是错误的用法，这会让 bash 读到一条空命令从而报错。
在 bash 退出的时候继续运行任务tmux、nohup 都行。下面说一下 disown。
disown 是让给定的任务或当前的任务从 bash 的工作组中移除。而 disown -h 是让任务保持在工作组，但是在 bash 退出的时候不向其发送 HUP 信号。但这并不是说任务就能正常运行，因为如果任务和 interactive terminal 的输入流或者输出流相连，那么就会出现 broken pipe 的错误进而导致程序异常退出。
cdcd 在没有参数的时候会检查 $HOME 环境变量，如果该环境变量不为空，则会将其作为参数；如果为空，命令不会生效。
  ]]></content></entry><entry><title>cp</title><url>/posts/cli/common/cp/</url><categories/><tags><tag>shell</tag><tag>linux</tag></tags><content type="html">  SYNOPSIS cp [OPTION]... [-T] SOURCE DEST cp [OPTION]... SOURCE... DIRECTORY cp [OPTION]... -t DIRECTORY SOURCE... 其实 cp 的选项比我想象中的要多很多。
其他选项：
创建硬链接（-l）而不是拷贝。 -L 则会先解引用符号链接。 -n 不会覆盖旧文件。 -a 先归档再拷贝，也就是保留所有属性。 -r 递归拷贝（文件夹）。 -u 只拷贝时间上更新的文件。 在 shell 中合并两个目录可以用 rsync：
rsync -auvh A/ B au 选项 cp 也有，h 表示用人类可读单位显示体积，v 表示 verbose。注意：
如果 A 后面没有斜杠，无论 B 是否存在，都会将 A 作为子文件夹拷贝进去。 如果用 A/*，则匹配不到隐藏文件。 B 后面有没有斜杠应该是不影响。 rsync 用于文件夹合并时，-r 选项是必须要加的，也就是至少需要 rsync -r A/ B。加 -a 也能满足这一点，因为 -a/--archive 和 -rlptgoD 是等价的。（-r 表示递归，-l 表示以符号链接形式拷贝符号链接，-p 表示保留权限，-t 表示保留时间，-g 表示保留 group，-o 表示保留 owner，-D 等价于 --devices --specials，即保留块设备和特殊设备（FIFO、socket 等）。） 如何用 cp 来模拟这种行为？
首先假设源文件 A 存在，B 可能不存在。B 如果存在且为普通文件则报错。
方案 1：使用 cp -r A B
❌ 不加 * 时，若目标文件夹存在，源文件夹本身被复制成为子文件夹。
$ rm -rf A B $ mkdir -p A/1/2/3 B $ cp -r A B $ tree B B └── A └── 1 └── 2 └── 3 5 directories, 0 files ✔️ 若目标文件夹不存在，相当于使用 cp -r A B
$ rm -rf A B $ mkdir -p A/1/2/3 $ cp -r A B $ tree B B └── 1 └── 2 └── 3 4 directories, 0 files 方案 2：使用 cp -r A/* B
缺点：* 不能匹配上 Linux 的隐藏文件！
✔️ 若目标文件夹存在，工作正常。
$ rm -rf A B $ mkdir -p A/1/2/3 B $ cp -r A/* B $ tree B B └── 1 └── 2 └── 3 4 directories, 0 files ❌ 若目标文件夹不存在，而源文件夹的子文件夹又恰好只有一个，则把子文件夹当成源文件夹拷贝。
$ rm -rf A B $ mkdir -p A/1/2/3 $ cp -r A/* B $ tree B B └── 2 └── 3 3 directories, 0 files ❌ 如果目标文件夹不存在，且源文件夹的子文件夹有多个，则会失败：
$ rm -rf A B $ mkdir -p A/1/2/3 $ mkdir -p A/4/2/3 $ cp -r A/* B cp: target &amp;#39;B&amp;#39;: No such file or directory 加了 -t 选项之后会加上文件夹存在性检查，并在两种情况下都直接报错。
思考：所谓合并，就是目标文件夹可能存在，也可能不存在。存在时拷贝子文件夹，不存在时拷贝整个文件夹。
比较稳妥的模拟 rsync 效果的方法是？
find 的 + 模式并不会对每个输出都发起命令，而是将所有输出汇总后才发出。同时如果没有输出则会忽略这个命令，因而可以用来达到和 rsync 类似的效果。
mkdir -p B find A -mindepth 1 -maxdepth 1 -exec cp -r -t B {} + 用 find 而不是 cp 的好处是也能找到隐藏文件。
  </content></entry><entry><title>ssh 配置</title><url>/posts/cli/ssh/ssh-%E9%85%8D%E7%BD%AE/</url><categories/><tags><tag>ssh</tag></tags><content type="html"><![CDATA[  样例Windows 下是 %userprofile%\.ssh\config。Linux 下自己对应一下。
含有 ForwardAgent 选项表示启用代理转发，相当于在连接它时自动添加了参数 -A。 含有 ProxyJump 表示先通过跳板机再连接到此主机，相当于在连接它时自动添加了参数 -J。 样例：
Host github HostName github.com IdentityFile ~/.ssh/id_rsa Host jump HostName &amp;lt;能访问的 IP&amp;gt; User &amp;lt;用户&amp;gt; Port &amp;lt;能访问的端口&amp;gt; IdentityFile ~/.ssh/id_rsa Host jump_docker ProxyJump jump HostName localhost User root Port 22275 其中 jump_docker 在局域网中，我们必须通过跳板 jump 来访问。这里 jump_docker 没有写 IdentityFile，如果默认的密钥文件（比如 ~/.ssh/id_rsa 等）匹配不了，那么就只能通过密码登陆。
转发代理（-A）不如代理跳转安全Man page 的说法man ssh-agent：
它是一个在启动时记录私钥的程序，这样方便匹配公钥验证。
Connections to ssh-agent may be forwarded from further remote hosts using the -A option to ssh(1) (but see the caveats documented therein), avoiding the need for authentication data to be stored on other machines.
什么是 ssh-agentssh-agent 在内存中记录私钥，然后完成公钥指纹匹配请求。根据文章 https://www.cnblogs.com/f-ck-need-u/p/10484531.html，如果密钥不是规范密钥（比如 ~/.ssh/id_rsa），就要手动指定具体的 IdentityFile，否则可以考虑使用 ssh-agent。
Behind the scenes, ssh-agent binds …  ]]></content></entry><entry><title>在 Dockerfile 中合并两个目录</title><url>/posts/cli/docker/%E5%9C%A8-Dockerfile-%E4%B8%AD%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E7%9B%AE%E5%BD%95/</url><categories/><tags><tag>docker</tag><tag>dockerfile</tag></tags><content type="html">  dockerfile 中合并两个目录：
COPY folderA folderB 不要在文件夹后面加 /。
  </content></entry><entry><title>📌Linux 主机检查 💻</title><url>/posts/systems/Linux/Linux-%E4%B8%BB%E6%9C%BA%E8%B5%84%E6%BA%90%E7%9B%91%E6%8E%A7%E5%92%8C%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/</url><categories/><tags><tag>linux</tag><tag>cheatsheet</tag></tags><content type="html">  常用功能子项目命令其他CPU-htopGPU-nvidia-smi还可以用 gpustat/ nvitop磁盘-iostat新版本的 htop 同样可以监控磁盘 I/O（在 3.2.2 版本上测试可以，老版本 2.2.0 上实测不行）网络-↑端口sudo netstat -pnltu还可以用 sudo ss -nltup，快得多（不加 sudo 可能会少显示一些程序的端口号、名字等）↑不同连接的网速sudo iftop↑具体接口的不同连接的网速sudo tcptrack -i eno1↑具体端口的网络活动tcpdump -i any port 53210注意 docker 容器内的端口号和容器外的端口号是不同的。
2025/4/14 推荐 btop，不需要 root 权限就能查看当前网速。btop 也还有其他的功能，看起来想和 htop 争。
2025/4/18 推荐 安装 sysstat 获取 CPU/ 磁盘 / 网络统计日志，防患于未然。
GPUnvidia-smi 就不说了，N 家自己的工具。默认的会读很多信息，如果只需要显存信息，可以用 nvidia-smi --query-compute-apps=pid,process_name,used_memory --format=csv，这样输出的速度也更快，差不多 87 ms。
gpustat 来自同名 pip 包，最主要的好处是它显示的方式更加紧凑，便于配合 watch 命令在小窗口不断刷新（偷懒不用 nsys / nsight-sys 而是直接看显卡整体情况）。比如 watch -n 0.5 -c gpustat -cp --color。而 nvidia-smi 就会遇到显示不下，只能看到窗口上半部分的情况。不过 gpustat 的速度较慢，在 7 卡的服务器上测试，nvidia-smi 输出耗时 210 ms，而 gpustat 输出耗时 930 ms，因此可能会跟不上 watch 指定的执行频率（watch 的逻辑是执行完当前命令之后等待给定的 interval，然后再执行新程序，所以并不会出现进程启动过多的问题；同样地，如果进程速度太慢，间隔应该给 0.1，这也是 watch 支持的最低间隔时间了）。
nvitop 也来自于同名 pip  …  </content></entry><entry><title>ssh 代理转发，让服务器上外网</title><url>/posts/cli/ssh/ssh-%E4%BB%A3%E7%90%86%E8%BD%AC%E5%8F%91%E8%AE%A9%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E5%A4%96%E7%BD%91/</url><categories/><tags><tag>ssh</tag></tags><content type="html">  由于是自己的电脑充当代理，所以需要用 -R 选项。
ssh -N -n -R 0.0.0.0:11625:127.0.0.1:12341 服务器 这是将远程的一个端口连到本地的端口。-N 表示不要执行命令，仅仅转发端口。-n 表示将 stdin 重定向到 /dev/null。
但是如果想要把这个代理用到 docker 构建中，又会有一点问题。因为 docker 容器本身有不同的网段，不能写 localhost，而是要写 host 的 ip。
sshd_config 里要打开 AllowTcpForwarding 选项，否则 -R 远程端口转发会失败。
默认转发到远程主机上的端口绑定的是 127.0.0.1，如要绑定 0.0.0.0 需要打开 sshd_config 里的 GatewayPorts 选项。这个选项如果由于权限没法打开也有办法，可配合 ssh -L 将端口绑定到 0.0.0.0。
改完记得用 systemctl 重载配置。（不清楚 daemon-reload 是不是必须的）
然后 docker 构建时要显式传入参数：
docker build . \ --build-arg HTTP_PROXY=http://192.168.236.148:11625 \ --build-arg HTTPS_PROXY=http://192.168.236.148:11625   </content></entry><entry><title>VS Code 上写 LaTeX</title><url>/posts/developer/vscode/VS-Code-%E4%B8%8A%E5%86%99-LaTeX/</url><categories/><tags><tag>vscode</tag><tag>latex</tag></tags><content type="html"><![CDATA[  消除烦人的错误提示如果是自动保存，则会有烦人的错误提示。即便是打开勿扰模式也会提示错误消息。
需要在设置中关闭 LaTeX 相关的消息。
无法编译中文在 &quot;latex-workshop.latex.tools&quot; 中改一个参数。
每次保存之后不自动使用中文：在 VS Code 的设置中加入这一行并重启。
&#34;latex-workshop.latex.recipe.default&#34;: &#34;latexmk (xelatex)&#34;, 尝试过 lualatex，不能用 xeCJK 包。
一些 LaTeX 坑公式&amp; 不能放在 \left 和 \right 里。
minted 包minted 高亮包需要额外安装 python 包，而且必须在 VS Code 中正确设置编译参数（每个编译 recipe 前面都要加 -shell-escape）。只有加了这个，latex 相关编译工具才能执行外部命令。
注意 minted 的使用方法是 \begin{minted}{python3}。代码语言参数用的是花括号而不是中括号。
字体相关的命令fc-list 能列举字体，其中路径后面的二元组冒号前的字符串可以作为 setmainfont 或者 setCJKmainfont 的参数使用。 fc-list :lang=zh 只列举中文。 用 fc-match 来尝试搜索字体，会给一个推荐字体。   ]]></content></entry><entry><title>VS Code 终端快捷键冲突</title><url>/posts/developer/vscode/VS-Code-%E7%BB%88%E7%AB%AF%E5%BF%AB%E6%8D%B7%E9%94%AE%E5%86%B2%E7%AA%81/</url><categories/><tags><tag>vscode</tag></tags><content type="html"><![CDATA[  ctrl + e 不能传进 shell在自定义的快捷键配置中给 ctrl+e 删掉默认的 command。
// 将键绑定放在此文件中以覆盖默认值 [ { &#34;key&#34;: &#34;ctrl+e&#34;, &#34;command&#34;: &#34;-workbench.action.quickOpen&#34; }, ]   ]]></content></entry><entry><title>VS Code 终端字符间距过宽</title><url>/posts/developer/vscode/VS-Code-%E7%BB%88%E7%AB%AF%E5%AD%97%E7%AC%A6%E9%97%B4%E8%B7%9D%E8%BF%87%E5%AE%BD/</url><categories/><tags><tag>vscode</tag></tags><content type="html">  终端字体间距过宽有时候恢复终端就会出现这种情况（比如显示屏分辨率变化）。暂且尝试的方法是显式设置终端字体（而不是把终端字体留空，让其隐式使用编辑器字体）。感觉还是没有用！
https://github.com/microsoft/vscode/issues/120004
将 terminal.integrated.letterSpacing 改成别的值再改回 0（默认值）就能恢复。
“终端字体间距过宽”的复现：
首先 VS Code 在使用独显。 禁用独显，VS Code 被迫使用核显。 终端当前活跃的 tab 恢复正常，但是不活跃的 tab 字符间距过宽。 再研究发现并不只是显卡切换，而是渲染方式切换后，非活跃的 tab 就会出现字距过宽的问题。包括：
on =&amp;gt; off canvas =&amp;gt; off   </content></entry><entry><title>VS Code + CMake: Allow building in different directories per build type</title><url>/posts/developer/vscode/VS-Code-+-CMakeAllow-building-in-different-directories-per-build-type/</url><categories/><tags><tag>cmake</tag><tag>vscode</tag></tags><content type="html"><![CDATA[  https://github.com/microsoft/vscode-cmake-tools/issues/151
&#34;cmake.buildDirectory&#34; : &#34;${workspaceRoot}/build/${buildType}&#34;   ]]></content></entry><entry><title>CMake execute_process</title><url>/posts/cli/cmake/CMake-execute_process/</url><categories/><tags><tag>cmake</tag></tags><content type="html">  和 add_custom_command / add_custom_target 不同，这个是在配置时就运行，但是一定要注意给对工作路径，否则运行结果出乎意料（或者以为没有运行）。
示例：
execute_process(COMMAND ./utils/pre-commit-cmake.sh WORKING_DIRECTORY ${CMAKE_CURRENT_SOURCE_DIR} )   </content></entry><entry><title>pybind11 CMake 不能编译和运行</title><url>/posts/cli/cmake/pybind11-CMake-%E4%B8%8D%E8%83%BD%E7%BC%96%E8%AF%91%E5%92%8C%E8%BF%90%E8%A1%8C/</url><categories/><tags><tag>cmake</tag><tag>pybind11</tag></tags><content type="html">  主要问题：加了 add_subdirectory 但是仍然无法找到头文件。
解决方案：先加上 find_package(Python3 COMPONENTS Interpreter Development) 再添加 pybind11 子文件夹。不然 pybind11 找到的 python 版本可能不对。
  </content></entry><entry><title>git 仓库中，对不再存在的文件的体积进行统计</title><url>/posts/cli/git/git-%E4%BB%93%E5%BA%93%E4%B8%AD%E5%AF%B9%E4%B8%8D%E5%86%8D%E5%AD%98%E5%9C%A8%E7%9A%84%E6%96%87%E4%BB%B6%E7%9A%84%E4%BD%93%E7%A7%AF%E8%BF%9B%E8%A1%8C%E7%BB%9F%E8%AE%A1/</url><categories/><tags><tag>git</tag></tags><content type="html"><![CDATA[  首先必须处在仓库中，然后用 https://stackoverflow.com/a/42544963/ 提供的方法提取出每个文件的大小，最后用 perl 计算总的体积。
git rev-list --objects --all | git cat-file --batch-check=&#39;%(objecttype) %(objectname) %(objectsize) %(rest)&#39; | sed -n &#39;s/^blob //p&#39; | grep -vF --file=&lt;(git ls-tree -r HEAD | awk &#39;{print $3}&#39;) | sort --numeric-sort --key=2 | cut -c 1-12,41- | $(command -v gnumfmt || echo numfmt) --field=2 --to=iec-i --suffix=B --padding=7 --round=nearest &gt; legacy.txt perl -ne &#39;BEGIN{my $sum=0} s/.* (.*) .*/$1/g; s/B//g;s/Ki/*1024/g;s/Mi/*1024*1024/g;s/Gi/*1024*1024*1024/g;$sum+=eval($_); END{printf &#34;%.1f MiB\n&#34;, $sum/1024/1024}&#39; legacy.txt 把上面的 objectsize 换成 objectsize:disk 就能看到压缩后的文件总体积，在我们仓库中大概是 2216.4 MiB，而压缩前大概是 7304.1 MiB。
What this script displays is the size each file would have in the working directory. If you want to see how much space a file occupies if not checked out, you can use %(objectsize:disk) instead of %(objectsize). However, mind that this metric also has its caveats, as is mentioned in the documentation.
另外 git-filter-repo 也很好用，速度非常快。需要注意：
默认给出的分析文件不是按文件大小排序的，而是按照压缩后的文件大小排序的，所以按照文件大小筛选可能会意外删除一些文件。按照路径过滤是最靠谱的。 过滤的含义是保留，如果需要删除要加 --invert-paths 选项。   ]]></content></entry><entry><title>Linux 上字体相关的环境变量</title><url>/posts/systems/Linux/Linux-%E4%B8%8A%E5%AD%97%E4%BD%93%E7%9B%B8%E5%85%B3%E7%9A%84%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F/</url><categories/><tags><tag>linux</tag></tags><content type="html">  https://www.gnu.org/software/gettext/manual/html_node/Locale-Environment-Variables.html#Locale-Environment-Variables
gettext 的优先级：
LANGUAGE LC_ALL LC_xxx, according to selected locale category: LC_CTYPE, LC_NUMERIC, LC_TIME, LC_COLLATE, LC_MONETARY, LC_MESSAGES, &amp;hellip; LANG 算是一个 fallback $LANGUAGE is not part of the C locales, but specific to GNU gettext. If set it is given precedence over anything else.
所以设置 LANGUAGE 不通用，设置 LC_ALL 高优先级，如果系统里面什么都没有设置，LANG 就足够了。
  </content></entry><entry><title>inttypes.h</title><url>/posts/programming/cpp/inttypes.h/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  包含了 stdint.h，同时还有一些格式字符串宏帮助写可移植的 scanf/printf 代码。
  </content></entry><entry><title>zsh 中新命令不参与插件补全</title><url>/posts/cli/zsh/zsh-%E4%B8%AD%E6%96%B0%E5%91%BD%E4%BB%A4%E4%B8%8D%E5%8F%82%E4%B8%8E%E6%8F%92%E4%BB%B6%E8%A1%A5%E5%85%A8/</url><categories/><tags><tag>zsh</tag></tags><content type="html">  zsh 在 PATH 路径中添加的新命令可以使用 zsh-syntax-highlighting，但是不能用 tab 补全。使用 rehash 命令让 zsh 重新检查命令，就能补全了。
如果是 bash，则要用 hash -r。
在 zsh 的 tab 补全中自动使用 rehash，可以在 ~/.zshrc 中加入：
zstyle &amp;#39;:completion:*&amp;#39; rehash true   </content></entry><entry><title>切换默认 shell</title><url>/posts/systems/Linux/%E5%88%87%E6%8D%A2%E9%BB%98%E8%AE%A4-shell/</url><categories/><tags><tag>shell</tag><tag>linux</tag></tags><content type="html">  sudo usermod -s /bin/bash $(whoami) chsh 也有同样的功能。两者都是改变了 /etc/passwd 的记录项达到切换登陆 shell 的。
注意，如果用 chsh，必须先切换到要更改 shell 的用户，比如给当前用户切换 shell 则是：
chsh -s /bin/bash 这里没有 sudo，不是 root 的话会提示输入密码的。如果使用 sudo chsh 就成了给 root 修改登录 shell，含义不一样了！
  </content></entry><entry><title>bash 中的 BASH_SOURCE</title><url>/posts/cli/bash/bash-%E4%B8%AD%E7%9A%84-BASH_SOURCE/</url><categories/><tags><tag>bash</tag></tags><content type="html">  这个变量表示 bash 真正的入口程序。这个变量的必要性体现在 source 某个 bash 脚本的时候 $0 不能准确反映入口程序。
#!/bin/bash echo &amp;#34;[$0] vs. [${BASH_SOURCE[0]}]&amp;#34; $ bash ./foo [./foo] vs. [./foo] $ ./foo [./foo] vs. [./foo] $ . ./foo [bash] vs. [./foo] 参考 https://stackoverflow.com/a/35006505/
本来 BASH_SOURCE 是一个数组类型的变量。但是 bash 中使用 $ARR 相当于 ${ARR[0]}，所以也可以简写。
  </content></entry><entry><title>gitlab-runner 的创建</title><url>/posts/systems/Linux/gitlab/gitlab-runner-%E7%9A%84%E5%88%9B%E5%BB%BA/</url><categories/><tags><tag>gitlab-jh</tag></tags><content type="html"><![CDATA[  Important
gitlab-jh 和 gitlab-ce 的区别以及博客内容声明
创建 gitlab-runner 的容器Caution
如果要创建新的 runner，要记得先把旧的配置文件夹删掉（/srv/gitlab-runner/config），因为这里多加了映射，要小心残留影响（我之前遇到的一个问题是 runner 信息页面多出来一个 id 为 &lt;legacy&gt; 的 runner，会被 gitlab 分配任务，但是又不会实际执行，导致 jobs 永远无法执行完成）。
启用 runner：
docker run -d --name gitlab-runner --restart always \ -v /srv/gitlab-runner/config:/etc/gitlab-runner \ -v /var/run/docker.sock:/var/run/docker.sock \ gitlab/gitlab-runner:latest 注册：注意 token 每次都不一样，url 一定得用内网（如果可能）而不是从公网绕一圈，不然速度跟不上。
gitlab-runner register --url YOUR_URL --token YOUR_TOKEN 修改好 gitlab-runner 的默认镜像。
注册完成后确保 runner 允许 untagged 的任务。gitlab-runner status 这条命令的确是会报错，但是不用管，对结果没有影响。
修改 runner 配置：
sed -i &#39;s,concurrent = 1,concurrent = 2,&#39; /etc/gitlab-runner/config.toml sed -i -E &#39;s,volumes =.*,volumes = \[&#34;/cache&#34;\, &#34;/data/ci/data:/data:ro&#34;\],g&#39; /etc/gitlab-runner/config.toml sed -i -E &#39;s,\[runners.docker\].*,\[runners.docker\]\n gpus = &#34;all&#34;\n pull_policy = &#34;if-not-present&#34;,g&#39; /etc/gitlab-runner/config.toml 限制 GPU如果不选择全部的 GPU，那么一定要在 gpus 后面加上引号，否则 docker 不能正常识别：
[[runners]] [[runners.docker]] gpus = &#39;&#34;device=3,4,5,6&#34;&#39; 限制 CPU[[runners]] [[runners.docker]] cpus = &#34;16&#34; 2024 年 7 月 10 日：一定要用字符串！在配置中使用数字，然后在容器中直接重启服务是没有问题的，但是在容器重启的时候（比如机器断电导致容器关闭）就会有容器无法启动的问题。
  ]]></content></entry><entry><title>gitlab-jh 中一些和 external_url 相关的问题</title><url>/posts/systems/Linux/gitlab/gitlab-jh-%E4%B8%AD%E4%B8%80%E4%BA%9B%E5%92%8C-external_url-%E7%9B%B8%E5%85%B3%E7%9A%84%E9%97%AE%E9%A2%98/</url><categories/><tags><tag>gitlab-jh</tag></tags><content type="html">  Important
gitlab-jh 和 gitlab-ce 的区别以及博客内容声明
大部分都是因为 external_url 在外网导致的：
external_url 在外网时，下载 gitlab-sans 字体可能超时，这导致通过 url 进入网页时字体是细的，但刷新后或者进入其他页面后字体又会变粗（版本是 v16.3.0-jh）。内网也可能发生，但是概率较小。 external_url 在外网时，创建新的 gitlab runner 会自动配置成连接外网，需要手动修改。如果不修改，runner 克隆仓库等都要经过外网，不仅速度慢还容易受到外网服务器 NGINX 最大包体大小的限制使得 artifacts 无法保存。（本地有包大小上限的设置项，但是外网服务器上的 NGINX 也需要配置一下） external_url 为外网时，Web IDE 无法正常加载资源。可能是 NGINX 相关配置有问题。 换到内网之后就好了（当时我没有外网服务器的修改权限，无法对 NGINX 配置）。
  </content></entry><entry><title>Gitlab pipeline editor URL 的问题</title><url>/posts/systems/Linux/gitlab/Gitlab-pipeline-editor-URL-%E7%9A%84%E9%97%AE%E9%A2%98/</url><categories/><tags><tag>gitlab-jh</tag></tags><content type="html">  Important
gitlab-jh 和 gitlab-ce 的区别以及博客内容声明
能正常加载：
http://domain/user/project/-/ci/editor?branch_name=master 不能正常加载 yaml 格式信息：
http://domain/user/project/-/ci/editor?branch_name=refs%2Fheads%2Fmaster   </content></entry><entry><title>bash 文件描述符</title><url>/posts/cli/bash/bash-%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6/</url><categories/><tags><tag>bash</tag></tags><content type="html"><![CDATA[  例子：
$ echo A &gt;&amp;3 -bash: 3: Bad file descriptor $ echo A 3&gt;&amp;2 &gt;&amp;3|grep 8 A 第一行输出给描述符 3 相关的文件，但是没有这个文件，所以出错。
第二行把描述符 3 分配给了原先 2 的文件，然后又将输出导入到描述符 3 对应的文件中，也就是将结果输出到 stderr 中，所以 grep 8 不能拦截 echo 的输出（可以看到 A 被打印出来了）。
这种方法可以用来交换标准输入和输出流。
  ]]></content></entry><entry><title>Docker 配置代理</title><url>/posts/cli/docker/Docker-%E9%85%8D%E7%BD%AE%E4%BB%A3%E7%90%86/</url><categories/><tags><tag>docker</tag><tag>proxy</tag></tags><content type="html">  docker pulldocker pull 不会读取 http_proxy 环境变量，因为拉取请求是发给守护进程的（不清楚守护进程是否是经典的 listen-fork 模式），环境变量早就在启动时读入，需要专门配置 docker 守护进程并让它重新加载配置。可以参考： https://stackoverflow.com/a/71036185
根据 docker 官方文档 的说法，Docker Engine version 23.0 之前是需要让 daemon 启动时通过环境变量读取代理的（可以通过修改 systemctl 的 service 文件完成），现在也能通过修改 /etc/docker/daemon.json 文件来修改代理。尽管如此，我在 Docker Engine 24.0.7 上面测试，修改代理之后也需要完全重启 docker 才能让代理生效。这说明代理配置是在启动时读入，不可以运行时重载的。
如果条件允许，使用镜像源 是比配置代理更好的选择，它支持在运行时重载。
docker builddocker build 的时候应该要用 --build-arg 传代理，然后还得大写：
docker build . --build-arg HTTP_PROXY=$http_proxy --build-arg HTTPS_PROXY=$http_proxy ... https://docs.docker.com/network/proxy/#set-proxy-using-the-cli
HTTPS_PROXY 和 HTTP_PROXY 环境变量都得设置。只设置前者是不够的，因为有些连接需要 ssl。
根据 https://stackoverflow.com/a/28093517/ ：
Footnote regarding HTTP_PROXY vs. HTTPS_PROXY: for a long time, setting HTTP_PROXY alone has been good enough. But with version 20.10.8, Docker has moved on to Go 1.16, which changes the semantics of this variable:
https://go.dev/doc/go1.16#nethttppkgnethttp
The ProxyFromEnvironment function no longer returns the setting of the HTTP_PROXY environment variable for https:// URLs when HTTPS_PROXY is unset.
  </content></entry><entry><title>Docker 按容器 A 的启动参数创建新容器 B</title><url>/posts/cli/docker/Docker-%E6%8C%89%E5%AE%B9%E5%99%A8-A-%E7%9A%84%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0%E5%88%9B%E5%BB%BA%E6%96%B0%E5%AE%B9%E5%99%A8-B/</url><categories/><tags><tag>docker</tag></tags><content type="html"><![CDATA[  How to show the run command of a docker container - Stack Overflow
docker inspect --format &#34;$(curl -s \ https://gist.githubusercontent.com/efrecon/8ce9c75d518b6eb863f667442d7bc679/raw/run.tpl)&#34; \ {your_container} 得到的结果样例：
docker run \ --name &#34;/gitlab-runner-4&#34; \ --runtime &#34;runc&#34; \ --volume &#34;/srv/gitlab-runner/config:/etc/gitlab-runner&#34; \ --volume &#34;/var/run/docker.sock:/var/run/docker.sock&#34; \ --log-driver &#34;json-file&#34; \ --restart &#34;always&#34; \ --network &#34;bridge&#34; \ --env &#34;PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin&#34; \ --detach \ &#34;gitlab/gitlab-runner:latest&#34; \ &#34;run&#34; &#34;--user=gitlab-runner&#34; &#34;--working-directory=/home/gitlab-runner&#34; 还有一种方法是使用 https://github.com/lavie/runlike 提供的 pip 包 runlike。使用起来也比较方便，但是输出的结果里面有些参数还得再检查和调整一下。
  ]]></content></entry><entry><title>gitlab-jh 配置 CI 的问题</title><url>/posts/systems/Linux/gitlab/gitlab-jh-%E9%85%8D%E7%BD%AE-CI-%E7%9A%84%E9%97%AE%E9%A2%98/</url><categories/><tags><tag>gitlab-jh</tag></tags><content type="html"><![CDATA[  Important
gitlab-jh 和 gitlab-ce 的区别以及博客内容声明
在运行有 gitlab-jh 的服务器上启用 runner 没有效果要确保 runner 允许 untagged 的任务。gitlab-runner status 的确是会报错，但是不用管，对结果没有影响。
Runner 的配置gitlab-runner 容器中的配置文件是 /etc/gitlab-runner/config.toml。
concurrent = 4 check_interval = 0 [session_server] session_timeout = 1800 [runners] name = &amp;#34;xxx&amp;#34; url = &amp;#34;http://xxx.xxx.xxx.xxx:xxxx&amp;#34; # 要改成内网的，不然太慢，还受到外部服务器的 nginx 传输限制 token = &amp;#34;xxxxxxxx&amp;#34; # 要改 executor = &amp;#34;docker&amp;#34; [runners.custom_build_dir] [runners.cache] [runners.cache.s3] [runners.cache.gcs] [runners.cache.azure] [runners.docker] tls_verify = false image = &amp;#34;ubuntu&amp;#34; # default runner 其实不用改，因为 CI 任务可以指定不同的镜像 privileged = false disable_entrypoint_overwrite = false oom_kill_disable = false disable_cache = false volumes = [&amp;#34;/cache&amp;#34;] # 这里做路径映射，如果需要只读，用 ro 而不是 r shm_size = 0 gpus = &amp;#34;all&amp;#34; # 没有这个就不能运行 GPU pull_policy = &amp;#34;if-not-present&amp;#34; # 没有这个每次都会检查镜像是否最新，对国内网络不友好 git fetch 的时候遇到 lock 文件存在没有解决。删了也没成功。就把下载模式改成 git clone …  ]]></content></entry><entry><title>Windows cmd 转义</title><url>/posts/systems/Windows/Windows-cmd-%E8%BD%AC%E4%B9%89/</url><categories/><tags><tag>windows</tag><tag>cmd</tag></tags><content type="html"><![CDATA[  cmd 对 双引号中的 ^ 不会转义。由于单引号不是 cmd 认可的引用方式，单引号中的 ^ 会转义。
cmd 的 echo 命令并不会去掉双引号参数的双引号。例子：
C:\Users\xx&gt;echo &#34;6&#34; | C:\Users\xx\scoop\shims\bash.exe -c &#34;cat&#34; &#34;6&#34; 其他命令貌似会去掉双引号，比如 cd 和 set。外置命令就更不用说了，写 git show &ldquo;HEAD&rdquo; 能够正常运行，可能是因为 cmd 为非内置命令去掉了双引号。
  ]]></content></entry><entry><title>VS Code 友好的 pre-commit hook</title><url>/posts/developer/vscode/VS-Code-%E5%8F%8B%E5%A5%BD%E7%9A%84-pre-commit-hook/</url><categories/><tags><tag>vscode</tag><tag>git</tag></tags><content type="html"><![CDATA[  问题：加入 pre-commit 之后，在 VS Code 的侧边栏 git 模块中提交代码看似卡住，看不到 pre-commit 的输出，也无法和 pre-commit 交互。
将下面的 entry_point 函数替换成要执行的流程，然后作为 .git/hooks/pre-commit 的内容即可。其主要作用是判断当前是否在 VS Code 环境中，如果是，则将输出写到一个临时文件中，然后再用 VS Code 打开这个文件以观察输出。解决了看不到输出、进度的问题，但是还解决不了输入的问题。
#!/bin/bash is_inside_vscode() { if ([[ &#34;$TERM&#34; == &#34;&#34; ]] || [[ &#34;$TERM&#34; == &#34;dumb&#34; ]]) &amp;&amp; [[ &#34;$PATH&#34; == *&#34;.vscode-server/&#34;* ]]; then return 0 fi return 1 } print_header() { echo &#34;############################################################&#34; echo &#34;# This is the temp file for showing pre-commit output. #&#34; echo &#34;############################################################&#34; echo } entry_point() { :; } if is_inside_vscode; then tmp=$(mktemp) code $tmp print_header &gt;$tmp if ! entry_point &gt;&gt;$tmp 2&gt;&amp;1; then echo &#34;pre-commit failed, please check $tmp&#34; &amp;&amp; false fi else entry_point fi Warning
这样的脚本并不总是有效。比如我在 2024 年 3 月 30 日 发现 .vscode-server/bin 开头的路径已经改成了 .vscode-server/cli，所以又给 PATH 检查去掉了 bin 后缀。
  ]]></content></entry><entry><title>rsync</title><url>/posts/cli/common/rsync/</url><categories/><tags><tag>shell</tag><tag>linux</tag></tags><content type="html">  和 scp 相比可以断点续传。
$ rsync -avz -e ssh -r --info=progress2 --info=name0 coco/images/train2014.zip xxserver:/data/xxx/data/ 2024年2月8日：这里已经是 zip 了，感觉没必要压缩。
  </content></entry><entry><title>在 VS Code 中使用 clangd</title><url>/posts/developer/vscode/%E5%9C%A8-VS-Code-%E4%B8%AD%E4%BD%BF%E7%94%A8-clangd/</url><categories/><tags><tag>vscode</tag><tag>clangd</tag></tags><content type="html"><![CDATA[  设置 VS Code clangd 检查的语言标准为 C++17Set -std in the .yaml file and then reload window of VS Code.
CompileFlags: Add: [ --std=c++17, -Wno-documentation, -Wno-missing-prototypes, ] Diagnostics: ClangTidy: Add: [ performance-*, bugprone-*, modernize-*, clang-analyzer-*, readability-identifier*, ] CheckOptions: readability-identifier-naming.VariableCase: camelCase Clangd 找不到头文件macOS 自带的 /usr/local/bin 中的 clang 不能提供查询路径。要么把绝对路径改成 PATH 中的命令，要么添加 &quot;--query-driver=/usr/bin/clang++&quot; 在参数中。
Windows 下，如果用的是 MSYS2 的编译器，需要添加：
&#34;clangd.arguments&#34;: [ &#34;--query-driver=C:\\msys64\\mingw64\\bin\\g++.exe&#34; ] // ... 到配置文件中，否则跳转到的一直是 Visual Studio 的头文件。必须提供完整路径，相对路径没有效果。
有什么缺点？对 cuda 不友好。在 cuda 文件中找不到从基类继承来的方法和属性（可能是因为用了不同的编译器？）。
对工程外的文件和头文件支持也不好，很明显，头文件不会出现在 compile_commands.json 中！
找不到 &lt;omp.h&gt; 文件（来自第三方库），这个警告总是无法被禁用（手动包含这个路径又会带来其他问题）。
无法显示 doxygen 文档。这一点有可能会改变，可以参考这个 github issue。
多配置块在文件相互跳转的情况下无法真正工作。虽然 clangd 可以给不同的文件匹配不同的配置块，但从文件 A（打开状态）跳转到文件 B（关闭状态）时，会按照文件 A 匹配上的选项来进行分析。这导致了 CUDA 文件和 C++ 文件可能使用相同的配置。所以按照是否为 CUDA 文件提供不同的配置（编译选项不同）是不现实的。
Clangd 对于 CUDA 文件中子类从父类继承来的属性和方法的判断不对。这导致对 CRTP 的检查不能正常工作。
有哪些地方要小心？如果是使用 VS Code 进行远程开发，一定要设置好 clangd 在开发容器里的配置（比如给出空的 clangd.arguments 数组），不然 clangd 就会使用本地上的设置！例：
{ &#34;clangd.path&#34;: &#34;/usr/bin/clangd-17&#34;, &#34;clangd.arguments&#34;: [], // ... } 在 .clangd 配置文件中不能使用相对于工程根目录的路径。有人提交了 patch 但是现在没有回复。
VS Code 的 clangd 插件是在 build 目录下调用 clangd 分析的，所以可以用 -I../include/，前提是 build 目录就是工程根部的一个子目录。
CompileFlags: Add: - --cuda-path=/usr/local/cuda/ - -I../include/ Remove: - -forward-unknown-to-host-compiler - --generate-code* - --expt-relaxed-constexpr - -G 之前有时候用 -isystem 不成功是因为 .clangd 的选项是要一行一个。
... - -isystem a/include # × - -isystem # ✔ - a/include - -isystemb/include # ✔   ]]></content></entry><entry><title>EDITOR, PAGER, BROWSER</title><url>/posts/systems/Linux/EDITOR-PAGER-BROWSER/</url><categories/><tags><tag>linux</tag></tags><content type="html">  Where do EDITOR, PAGER, BROWSER environment variables come from? - Unix &amp;amp; Linux Stack Exchange
EDITOR, PAGER, BROWSER 这三个环境变量控制 linux 中很多工具展示输出的方式。还有 SUDO_EDITOR 可以设置 sudoedit 使用的编辑器。
  </content></entry><entry><title>Linux 创建新用户</title><url>/posts/systems/Linux/Linux-%E5%88%9B%E5%BB%BA%E6%96%B0%E7%94%A8%E6%88%B7/</url><categories/><tags><tag>linux</tag></tags><content type="html">  adduser 有交互过程，比 useradd 更友好。事实上，adduser 是 useradd 的 wrapper。
  </content></entry><entry><title>C 语言算术运算的类型提升</title><url>/posts/programming/cpp/C-%E8%AF%AD%E8%A8%80%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97%E7%9A%84%E7%B1%BB%E5%9E%8B%E6%8F%90%E5%8D%87/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  https://stackoverflow.com/a/5563131/
if: either is long double other is promoted &gt; long double either is double other is promoted &gt; double either is float other is promoted &gt; float either is long long unsigned int other is promoted &gt; long long unsigned int either is long long int other is promoted &gt; long long int either is long unsigned int other is promoted &gt; long unsigned int either is long int other is promoted &gt; long int either is unsigned int other is promoted &gt; unsigned int either is int other is promoted &gt; int Otherwise: both operands are promoted to int   ]]></content></entry><entry><title>初读 Pro Git</title><url>/pro-git-the-book/%E5%88%9D%E8%AF%BB-Pro-Git/</url><categories><category>pro-git-the-book</category></categories><tags><tag>pro-git-the-book</tag><tag>git</tag></tags><content type="html">  一些需要弄明白的名词：commit range/refspec。
git 基础git 的管理方式是记录每个文件的快照。
然后分成三个区：
git add如果一个文件改动了多个地方，但是只想要提交其中的部分行，可以用 git add --patch。这样 git 会启动一个交互式的程序，并询问用户每个 chunk 是否要加入。这种交互式环境提供多种操作，其中 e 操作允许用户使用编辑器精准编辑要添加的修改。
git statusgit status 可以显示当前工作区的状态。添加 -s 选项，即 git status -s，可以显示更简单（摘要）的状态（很像 VS Code 边栏上的信息）：
$ git status -s ?? .cache/ ?? .clang-tidy ?? utils/clang-tidy.py 输出的有些文件签名是双问号，表示 untracked。
git rm关于 git rm --cached 和 git restore --staged 的区别（https://stackoverflow.com/a/65434709/）：
git rm --cached file: removes the copy of the file from the index / staging-area, without touching the working tree copy. The proposed next commit now lacks the file. If the current commit has the file, and you do in fact make a next commit at this point, the difference between the previous commit and the new commit is that the file is gone.
git restore --staged file: Git copies the file from the HEAD commit into the index, without touching the working tree copy. The index copy and the HEAD copy now match, …  </content></entry><entry><title>git restore</title><url>/posts/cli/git/git-restore/</url><categories/><tags><tag>git</tag></tags><content type="html"><![CDATA[  在没有 --source 选项时，有 --staged 则默认使用 HEAD 来恢复，如果没有则默认使用 index。此时：
git restore 相当于 git restore --worktree。 git restore --staged 用 HEAD 的信息来恢复 index，不会改动 working tree。 git restore --worktree 用 index 的信息来恢复 working tree。 git restore --worktree --staged 同时恢复 working tree 和 index。git restore --source HEAD --worktree --staged 相当于 git reset --hard 对于单个文件的效果。（虽然按照官方的描述来说是默认 source 为 HEAD，但是在 git 2.25.1 中实测这种情况下的默认 source 是 index） -W link1; link2 link3 Specify the restore location. If neither option is specified, by default the working tree is restored. Specifying --staged will only restore the index. Specifying both restores both.
Torek insists on the fact git restore --source &lt;aCommit&gt; --worktree -- somefile is new (cannot be done with checkout): the ability to restore a file in the working tree without touching the index.Torek insists on the fact git restore --source &lt;aCommit&gt; --worktree -- somefile is new (cannot be done with checkout): the ability to restore a file in the working tree without touching the index.
这大概是说 git checkout 利用历史 commit 改动单个文件的同时也会改动 index。
git restore --staged file 相当于 git reset HEAD file。这是因为 git reset 默认是 --mixed 模式，只改变 index 但是不改变 working tree。
  ]]></content></entry><entry><title>inline namespace</title><url>/posts/programming/cpp/inline-namespace/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  Namespaces - cppreference.com
inline namespace 既本身存在，又将所有内容引入外围（enclosing）名字空间中。相当于名字空间后面加了一句：using namespace X;
例子：
inline namespace A { using Int = int; } int main() { A::Int a; Int b; // 也能成功 }   </content></entry><entry><title>描述颜色的术语：色相、饱和度、亮度</title><url>/posts/unsorted/%E6%8F%8F%E8%BF%B0%E9%A2%9C%E8%89%B2%E7%9A%84%E6%9C%AF%E8%AF%AD%E8%89%B2%E7%9B%B8%E9%A5%B1%E5%92%8C%E5%BA%A6%E4%BA%AE%E5%BA%A6/</url><categories/><tags><tag>term</tag></tags><content type="html"><![CDATA[  这三个单词的含义分别是色相、饱和度、亮度。
所有的粉色都是洋红色，所有的洋红色都是紫色。word choice - What is &lsquo;pink&rsquo; and what is &lsquo;magenta&rsquo;? - English Language &amp; Usage Stack Exchange
  ]]></content></entry><entry><title>bash 下不用转义符打印红色字符串</title><url>/posts/cli/bash/bash-%E4%B8%8B%E4%B8%8D%E7%94%A8%E8%BD%AC%E4%B9%89%E7%AC%A6%E6%89%93%E5%8D%B0%E7%BA%A2%E8%89%B2%E5%AD%97%E7%AC%A6%E4%B8%B2/</url><categories/><tags><tag>bash</tag><tag>grep</tag></tags><content type="html">  给一个必定匹配的模式让 grep 打印所有行：
... | grep -E &amp;#39;(^|pattern)&amp;#39; --color=always   </content></entry><entry><title>Python re.match</title><url>/posts/programming/python/Python-re.match/</url><categories/><tags><tag>python</tag></tags><content type="html">  Python 的正则表达式函数基本都是从第一个字符开始匹配的。不像 bash 和 JS 是任意位置匹配都行。所以要适当加上 .*。
  </content></entry><entry><title>Windows 下用 CMD 或 powershell 一键重启显卡驱动</title><url>/posts/systems/Windows/Windows-%E4%B8%8B%E7%94%A8-CMD-%E6%88%96-powershell-%E4%B8%80%E9%94%AE%E9%87%8D%E5%90%AF%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8/</url><categories/><tags><tag>windows</tag></tags><content type="html"><![CDATA[  主要是双显卡笔记本切换显示屏后，部分应用没有切换图形显示卡，导致未活跃的显卡时不时被唤醒，而每次唤醒会有一秒的卡顿。
创建 bat 文件（其中硬件驱动的实例路径需要在设备管理器上查看后根据实际修改）：
:: Run as admin @echo off %1 mshta vbscript:createobject(&#34;shell.application&#34;).shellexecute(&#34;%~s0&#34;,&#34;::&#34;,&#34;&#34;,&#34;runas&#34;,1)(window.close)&amp;exit cd /d %~dp0 :: 如果变量为空，整个分支判断会被静默掉，所以给个默认值 set &#34;Input=1&#34; set /p Input=Index of graphics card to reset? (0: Intel, 1: NVIDIA[default]) if %Input% equ 0 ( pnputil /disable-device &#34;PCI\VEN_8086&amp;DEV_3E9B&amp;SUBSYS_39FD17AA&amp;REV_00\3&amp;11583659&amp;0&amp;10&#34; pnputil /enable-device &#34;PCI\VEN_8086&amp;DEV_3E9B&amp;SUBSYS_39FD17AA&amp;REV_00\3&amp;11583659&amp;0&amp;10&#34; ) else if %Input% equ 1 ( pnputil /disable-device &#34;PCI\VEN_10DE&amp;DEV_1C8C&amp;SUBSYS_39FD17AA&amp;REV_A1\4&amp;77AC7CD&amp;0&amp;0008&#34; pnputil /enable-device &#34;PCI\VEN_10DE&amp;DEV_1C8C&amp;SUBSYS_39FD17AA&amp;REV_A1\4&amp;77AC7CD&amp;0&amp;0008&#34; ) else ( echo: echo|set /p _=&#34;&gt;&gt;&gt; Unknown choice! Exiting... &lt;&lt;&lt;&#34; echo: echo: pause ) 实际上在桌面上分开放两个脚本文件会比在脚本文件中选择要重启的显卡驱动更方便。因为在脚本中选择是一项额外操作。
  ]]></content></entry><entry><title>CUDA 调试</title><url>/posts/programming/cuda/CUDA-%E8%B0%83%E8%AF%95/</url><categories/><tags><tag>cuda</tag><tag>gdb</tag></tags><content type="html">  cuda-gdb 是 cuda 的调试工具，执行非常慢。
如果需要符号信息，nvcc 的编译选项需要加上 -g -G，其中 -g 是给 host 代码添加符号信息，而 -G 是给 device 侧代码添加符号信息。
  </content></entry><entry><title>VS Code 远程主机插件不能下载</title><url>/posts/developer/vscode/VS-Code-%E8%BF%9C%E7%A8%8B%E4%B8%BB%E6%9C%BA%E6%8F%92%E4%BB%B6%E4%B8%8D%E8%83%BD%E4%B8%8B%E8%BD%BD/</url><categories/><tags><tag>vscode</tag></tags><content type="html"><![CDATA[  提示 XHR failed。
找到插件的网页下载 Linux 版本，然后从文件资源管理器拖动文件到工作目录，拷贝文件后运行：
code --install-extension ./doxdocgen-1.4.0.vsix 也可能是本机的代理设置和远程主机的代理设置冲突了，可以修改远程主机的 &quot;http.proxy&quot; 为空：
{ &#34;http.proxy&#34;: &#34;&#34;, } 这个设置应该是立即生效的，删掉扩展搜索词重新输入试试。
  ]]></content></entry><entry><title>用 std::variant 的坑</title><url>/posts/programming/cpp/%E7%94%A8-variant-%E7%9A%84%E5%9D%91/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  decltype 推导可能带有 &amp;amp; 属性被 decltype 坑了很多次。推导出来可能有引用类型，想要值类型时需要先去掉！
不同的 variant 在 visitor 的参数里必须独立std::visit 的多个参数必须独立和模板参数匹配（或者 lambda 和 C++20 函数的 auto），所以即便是要求两个类型相等，也必须写成这样：
template &amp;lt;typename DType1, typename DType2&amp;gt; void f(DType1* input, DType2* output) { // DType1 and DType2 are actually the same type. } 如果确定两个类型一样，也可以少传入一个 variant，使用 void * 传入类型，然后手动做转换。
if constexpr 的编译问题if constexpr 只在模板代码中才有去除分支的作用，在普通代码中是不行的，此时不能用来剔除不能编译的分支。
  </content></entry><entry><title>Docker GPU 支持</title><url>/posts/cli/docker/Docker-GPU-%E6%94%AF%E6%8C%81/</url><categories/><tags><tag>docker</tag></tags><content type="html">  curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add - distribution=$(. /etc/os-release; echo $ID$VERSION_ID) # 如果 debian12 不支持可以改成 debian11 curl -s -L nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list sudo apt-get update sudo apt install -y nvidia-docker2 # 必须重启 docker sudo systemctl restart docker   </content></entry><entry><title>阻止一个模板类被实例化并给出错误信息</title><url>/posts/programming/cpp/%E9%98%BB%E6%AD%A2%E4%B8%80%E4%B8%AA%E6%A8%A1%E6%9D%BF%E7%B1%BB%E8%A2%AB%E5%AE%9E%E4%BE%8B%E5%8C%96%E5%B9%B6%E7%BB%99%E5%87%BA%E9%94%99%E8%AF%AF%E4%BF%A1%E6%81%AF/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  注意，这个类作为（不完整）类型出现在别的模板的参数中是可以的，只有访问成员才会出错。
template &lt;typename Target&gt; struct FindValue&lt;Target, TypeList&lt;&gt;&gt; { static inline constexpr bool ALWAYS_FALSE = sizeof(Target) == 0; static_assert(ALWAYS_FALSE, &#34;Unsupported type! Check `proj::detail::DataTypeList`.&#34;); }; https://stackoverflow.com/a/40472836/
任何类型要么是不完整类型，无法被 sizeof 评估（会报错），要么被评估为正整数（包括 void 也会被评估为 1）。用 -1 的话会有类型转换警告，所以用 0 就好了。
  ]]></content></entry><entry><title>ssh 命令的代理功能</title><url>/posts/cli/ssh/ssh-%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BB%A3%E7%90%86%E5%8A%9F%E8%83%BD/</url><categories/><tags><tag>ssh</tag></tags><content type="html">  几种模式模式有三种：
-L 将本地端口映射到远程（将客户端请求转给远程服务器） -R 将远程端口映射到本地（客户端和远程服务器抢请求） -D 动态代理，生成一个 socks 代理，支持 socks(4)/socks5 协议 -R 代理服务器连不上外网的时候常用这个。见 ssh 代理转发，让服务器上外网
-D 代理生成一个 socks 代理。如图，我创建代理之后，本地用这个代理去访问网站，实际上是远程服务器代我访问了网站。
-L 代理我能通过 ssh 连接到服务器，服务器能连接到私有的代码仓库，然后我可以通过本地的端口转发，然后在浏览器上通过 localhost:38930 访问代码仓库：
ssh -N -n -L38930:192.168.236.237:8930 服务器 -f 表示程序作为后台程序运行（fork），不怕会话关闭或者按键中断（这里我觉得不太好用，所以不加）。在 Linux 下程序就会直接返回，但是在 Windows 的 cmd 下不会，可能是因为 /dev/null 这个设备不存在？实测在 MSYS2 的 bash 环境中也能正常返回。 -N 表示不要执行命令，仅仅转发端口。 -n 表示从 /dev/null 中重定向输入。若有 -f，则这个选项是隐含的，使用 -t 来代替 -n 可以使得 ssh 重新读取终端的交互输入（但是管道不行）。 其他参考https://jeremyxu2010.github.io/2018/12/ssh%E7%9A%84%E4%B8%89%E7%A7%8D%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91/
  </content></entry><entry><title>查询一个网址的所有子域名</title><url>/posts/unsorted/%E6%9F%A5%E8%AF%A2%E4%B8%80%E4%B8%AA%E7%BD%91%E5%9D%80%E7%9A%84%E6%89%80%E6%9C%89%E5%AD%90%E5%9F%9F%E5%90%8D/</url><categories/><tags><tag>network</tag></tags><content type="html">  首先是 google 上能够搜到的所有答案。
如果用 dig axfr 搜不到，说明域名服务器没开 axfr，或者子域名不在同一个 zone。简单来说，axfr 是一个允许 client 下载整个 zone 信息的协议。
如果网站允许搜索引擎爬取，则可以用 google 的网站过滤来搜索，比如 site:xx.yy。
  </content></entry><entry><title>VS Code CMake 工程中 C++ 提示不正常</title><url>/posts/developer/vscode/VS-Code-CMake-%E5%B7%A5%E7%A8%8B%E4%B8%AD-C++-%E6%8F%90%E7%A4%BA%E4%B8%8D%E6%AD%A3%E5%B8%B8/</url><categories/><tags><tag>vscode</tag><tag>clangd</tag><tag>intellisense</tag><tag>cpp</tag></tags><content type="html"><![CDATA[  如果用 Intellisense以文件 .vscode/c_cpp_properties.json 中 configuration 的 configurationProvider 的值来分类。
ms-vscode.cmake-tools缺点：文件不在编译数据库中时 include 路径不正确（对新文件不友好）。
configurationProvider 是 ms-vscode.cmake-tools 时，compileCommands 和 includePath 设置是无效的。这个时候如果 compile_commands.json （编译数据库）中没有这个文件（尤其是 CMakeLists.txt 中可能尚未加入新编写的文件的情况），或者编译数据库尚未配置（需要先编译生成一次)，include 路径就不正确。
[10/26/2023, 7:45:25 PM] &#34;xxxx.cc&#34; not found in &#34;${workspaceFolder}/build/compile_commands.json&#34;. &#39;includePath&#39; from c_cpp_properties.json in folder &#39;proj&#39; will be used for this file instead.s 这段话的意思：由于文件（是新创建的，所以暂时）并不在 compile_commands.json 中，不会给文件应用和工程相同的 include 路径，而且怎么加都没有用！
ms-vscode.cpp-tools 或者未配置缺点：文件不在编译数据库中时 include 路径采用 includePath 的值（对新文件不友好，手工调整 includePath 又很累）+ 对宏的检查不准确。
configurationProvider 是 ms-vscode.cpp-tools 或者没有配置时，compileCommands 和 includePath 设置则是有效的。文件尚不在编译数据库中时会采用 includePath 的设置。只是想要解决找不到 cuda 的问题很简单：
但是这样有一个新的问题：include 需要在 c_cpp_properties.json 和 CMakeLists.txt 中维护两份。所以最好还是直接将文件及时加入到 CMakeLists.txt 中比较好。
另外，使用 ms-vscode.cpp-tools 作为配置提供者时，宏的定义往往不准确，不建议这么做。
如果用 clangd缺点：对 cuda 支持不好 + 比 intellisense 的搜索更加死板，暂时不支持 Doxygen。
Unsupported option &#39;--generate-code=arch=compute_61,code [compute_61,sm_61]&#39;clang(drv_unsupported_opt) 解决方案是给 .clangd 文件（可以本地，也可以全局）加上：
#CompileFlags: # Add: # - --cuda-path=/usr/local/cuda/ # 如果为空会自动检测 # - -L/usr/local/cuda-11.7/targets/x86_64-linux/lib/ # - -I/usr/local/cuda-11.7/targets/x86_64-linux/include/ CompileFlags: Add: - -std=gnu++17 - -L/usr/local/cuda-11.7/targets/x86_64-linux/lib/ - -I/usr/local/cuda-11.7/targets/x86_64-linux/include/ Remove: - -forward-unknown-to-host-compiler - --generate-code* - --expt-relaxed-constexpr 另外，.gitignore 里面要加上 .cache。
好处是即便文件不在 CMakeLists.txt 中，clangd 也能对文件提供一定的查找功能。
  ]]></content></entry><entry><title>使用 nodejs 启动文件服务器</title><url>/posts/systems/Linux/%E4%BD%BF%E7%94%A8-nodejs-%E5%90%AF%E5%8A%A8%E6%96%87%E4%BB%B6%E6%9C%8D%E5%8A%A1%E5%99%A8/</url><categories/><tags><tag>js</tag><tag>linux</tag></tags><content type="html">  apt install nodejs apt install npm # 校内可用 npm config set registry xxx npm install --global http-server http-server 默认的 serve 路径是 ./public，如果找不到则使用 . 这个路径。
  </content></entry><entry><title>top</title><url>/posts/cli/common/top/</url><categories/><tags><tag>shell</tag><tag>linux</tag></tags><content type="html">  top -H 显示人类能阅读的大小。
进入 top 之后：
shift + M：按照内存排序 shift + P：按照 CPU 使用排序 shift + T：按照时间排序 shift + N：按照 PID 排序 其实不是一定要按 shift，只要输入大写字母即可（比如用 CapsLk）
  </content></entry><entry><title>不同语言闭包的捕获方式</title><url>/posts/unsorted/%E4%B8%8D%E5%90%8C%E8%AF%AD%E8%A8%80%E9%97%AD%E5%8C%85%E7%9A%84%E6%8D%95%E8%8E%B7%E6%96%B9%E5%BC%8F/</url><categories/><tags><tag>cpp</tag><tag>go</tag><tag>java</tag><tag>js</tag><tag>python</tag></tags><content type="html"><![CDATA[  总览C++ 根据在捕获列表中标注的方式进行捕获。 Java 按照值捕获（而且 Java 在某些情况下还要求显式的 final 修饰符）。 JavaScript：见 JavaScript 捕获。 注意：捕获和传值是不同的！例如：JavaScript 在函数参数传递时仍然时按照值传递。 Python/Go 按照引用捕获，for 循环不会创造新的作用域。 JavaScript 捕获看上去是引用捕获，但是 for 循环的 let 和 const 绑定会创造新的作用域。
function generateSquaringFunctions() { const funcList = []; const values = [1, 2, 3]; for (var i of values) { // ^^^ // var: [9, 9, 9] // let/const: [1, 4, 9] const square = function () { return i * i; }; funcList.push(square); } return funcList; } const [square1, square2, square3] = generateSquaringFunctions(); console.log(square1(), square2(), square3()); 可以参考 Javascript&rsquo;s Hoisting（变量提升、函数提升、类提升）。
其他测试：
(() =&gt; { let download = async () =&gt; console.log(1); (() =&gt; { if (true) { download = async () =&gt; console.log(2); } })(); (async () =&gt; { await download(); })(); })(); // 2 唯独在 TamperMonkey 上看上去不是引用绑定，不知道为什么。测试发现在复杂判断条件下的赋值不 work。最后感觉可能是 TamperMonkey 在 CROS 脚本中运行的那套环境和主页面的运行环境不一样。
  ]]></content></entry><entry><title>WSL2 不能使用 code 打开 VS Code</title><url>/posts/systems/Windows/WSL2-%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8-code-%E6%89%93%E5%BC%80-VS-Code/</url><categories/><tags><tag>wsl</tag><tag>vscode</tag><tag>windows</tag></tags><content type="html"><![CDATA[  首先检查 /etc/wsl.conf 配置，如果设置了不追加 Windows 的 PATH，则需要自己额外添加 VS Code 的命令目录到 WSL 中。
# /etc/wsl.conf [boot] systemd=true [interop] appendWindowsPath=false # ~/.bashrc 或者其他配置文件 export PATH=&#34;/mnt/c/Users/xxx/AppData/Local/Programs/Microsoft VS Code/bin:$PATH&#34; 如果报错：
/mnt/c/Users/xxx/AppData/Local/Programs/Microsoft VS Code/bin/code: 61: /mnt/c/Users/xxx/AppData/Local/Programs/Microsoft VS Code/Code.exe: Exec format error 则可能是新版 WSL 的 systemd 打包问题。（参考 https://github.com/microsoft/WSL/issues/8952#issuecomment-1568212651）
sudo sh -c &#39;echo :WSLInterop:M::MZ::/init:PF &gt; /usr/lib/binfmt.d/WSLInterop.conf&#39; sudo systemctl restart systemd-binfmt   ]]></content></entry><entry><title>Javascript Spread Operator</title><url>/posts/programming/www/Javascript-Spread-Operator/</url><categories/><tags><tag>js</tag></tags><content type="html">  {...a, ...b} 相当于 Object.assign({}, a, b)。Object.assign 还能给已经存在的对象赋值，而且会触发 setter。Spread operator 是在创建对象，不会触发 setter。
[...a, ...b] 相当于 a.concat(b)。
Spread operator 的结果是浅拷贝，如果要深拷贝可以用 structuredClone。它能作用于数组字面量却不能作用于对象字面量，必须通过一个额外的变量来完成。（毕竟支持字面量的 spread 没有意义。）
一个非原生数组的对象想要在数组中展开，必须实现 Iterable 接口。
  </content></entry><entry><title>Javascript 中的迭代：ArrayLike, Symbol.iterator……</title><url>/posts/programming/www/Javascript-%E4%B8%AD%E7%9A%84%E8%BF%AD%E4%BB%A3ArrayLike-Symbol.iterator/</url><categories/><tags><tag>js</tag></tags><content type="html">  IterableSymbol.iterator 是个特殊的键，属于 Iterator 规范的一部分。实现了 Iterable 接口的对象是可以用 spread operator 迭代的。
ArrayLike有 length 属性，且在 [0, length) 范围内都可以访问的对象被称为 ArrayLike 的对象。ArrayLike 的对象可以使用诸如 Array.prototype.slice.call(obj, 2) 的方式来作为 Array 调用。
Array.from 既对 ArrayLike 有效，也对 Iterable 对象有效。
Array 系列方法，比如 map/filter/forEach需要先转换成 Array。
Array.prototype.slice.call：适用于 ArrayLike，可行时效率最高。 Array.from：适用于 ArrayLike 和 Iterable。 [...obj]：适用于 Iterable。 for-of需要对象实现 Iterable 接口。
for (const a of {length: 2}) { console.log(a) } // Uncaught TypeError: ({length:2}) is not iterable for-in只要是对象就可以。因为 for-in 会在对象上调用 Object.keys()。对于字符串和数组会返回数字下标序列。对于数字会返回空序列（不迭代）。
  </content></entry><entry><title>awk</title><url>/posts/cli/common/awk/</url><categories/><tags><tag>shell</tag><tag>linux</tag></tags><content type="html">  删除重复行可以用 awk '!x[$0]++'。
$ cat text aaaa bb bb aaaa c $ awk &amp;#39;!x[$0]++&amp;#39; text aaaa bb c   </content></entry><entry><title>Git 合集</title><url>/posts/cli/git/Git-%E5%90%88%E9%9B%86/</url><categories/><tags><tag>git</tag></tags><content type="html"><![CDATA[  git-confighttps://git-scm.com/docs/git-config#_configuration_file
git config --global --edit 能在命令行打开全局的配置文件，即 %userprofile%\.gitconfig 或 ~/.gitconfig 文件。
如果想要更换编辑器比如用 VS Code 编辑，可以用 EDITOR=code git config --global --edit。
配置文件的格式：
空白字符都被忽略（无论是 \t 还是空格都可以） 注释的开头可以是 # 和 ; git pull origin A:B需要本地有 B 才能成功拉取，不然会拉取到当前分支。拉取的时候会自动 merge。
创建 diff 和合并https://stackoverflow.com/a/21976357 讲的是如何 diff 文件和生成 patch。git format-patch -&amp;lt;n&amp;gt; &amp;lt;rev&amp;gt; 用来生成 diff，n 表示要包含几条，rev 表示某个 commit。
How can I generate a Git patch for a specific commit? - Stack Overflow 讲的是按 commit 生成 patch，并且提交。如果不想提交也可以生成 patch 之后按照上一个链接的方法 git apply 0001.patch（名字是举例）。
HEAD~1 和 HEAD^1~n 表示在当前分支上回退 n 次。^n 表示在当前岔路向第 n 条支路回退一次。
What&amp;rsquo;s the difference between HEAD^ and HEAD~ in Git? - Stack Overflow
将现在的项目推到另外一个仓库# 假设前一个 remote 名为 origin git fetch --all git remote add newremote &amp;lt;new-remote-url&amp;gt; git push newremote --tags refs/remotes/origin/*:refs/heads/* 打印 ref 的名称打印的结果可以用在 git branch -rD $(...) 等命令里，应该是不能在 $() 的 …  ]]></content></entry><entry><title>Android 内存管理</title><url>/posts/unsorted/Android-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/</url><categories/><tags><tag>android</tag></tags><content type="html">  内存不足时：
首先由 kswapd 尝试交换页面。 如果内存仍然不够，系统用 通知应用程序内存不足，希望应用主动减少内存使用。 如果内存仍然不够，使用 LMK 按照一定的优先级杀死应用。 交换kswapd 负责在内存不足时交换内存页面。zram 和 swap file 都是交换区的实现。狭义的交换指的是 disk swap。
Android 一般厂商都是开 zram，但不开 swap file，原因是 swap file 在闪存上，读取慢，而且移动设备的闪存寿命比电脑硬盘少。在 MIUI 13 的小米 12s Pro（12G）上，zram 的大小是 6G。据说 MIUI 14 的 12G 小米机型用的 zram 是 8G。我还在酷安看到了很多 16G 小米机型使用 14G zram 的例子。
占用方式上，zram 是动态增长的，并不是一开机就占满设定的大小。swap file 虽然是要在开启前就固定大小，但由于其在文件系统上，也可以轻易地删除和重新创建。Android 厂商鼓吹的内存融合很可能就是 swap file。
swap partition 是分区，调整起来比 swap file 要麻烦，现在应该很少被使用。而且没有迹象表明 swap file 性能明显低于 swap partition。
有人说 zram 可以超过内存大小，这违反了我的认知。scene 的确可以做这样的修改，但我认为在没有交换的情况下设置 zram 超过内存大小实际上永远装不满。
终止应用lmkd 是 Low Memory Killer Deamon，用于监控内存压力。其前驱为 lmk 驱动程序，但是由于大量问题转到了用户空间实现。而且在每次 Android 大版本的迭代中，lmkd 通常会有功能上的改进。
从内核 4.12 开始，LMK 驱动程序已从上游内核中移除，改由用户空间 lmkd 来执行内存监控和进程终止任务。
  </content></entry><entry><title>Javascript's Hoisting（变量提升、函数提升、类提升）</title><url>/posts/programming/www/Javascripts-Hoisting%E5%8F%98%E9%87%8F%E6%8F%90%E5%8D%87%E5%87%BD%E6%95%B0%E6%8F%90%E5%8D%87%E7%B1%BB%E6%8F%90%E5%8D%87/</url><categories/><tags><tag>js</tag></tags><content type="html"><![CDATA[  Function hoistingconst callerArrow = () =&gt; { return callee(); // 刚定义这个函数时，callee 的状态是：defined but uninitialized // 只要 callee 在调用这个函数之前初始化了就没有问题 }; // callee(); // 见不到定义，调用会出错 const callee = () =&gt; { console.log(&#34;Hello from callee!&#34;) }; callerArrow(); // callee 的定义出现了，可以调用 calleeRegular(); function calleeRegular() { console.log(&#34;Hello from calleeRegular!&#34;) } 在同一个词法定义域中的所有声明都是能被看见的。但如果声明是函数，则还能支持直接（向后）调用，即函数提升规则。如果是箭头函数，则只能引用，不能调用。
为什么箭头函数和普通函数有这样的区别？因为箭头函数没有用到 function 关键字，是按照变量的方式来定义的，遵循的是变量提升规则。
Variable hoistingconsole.log(a) a = 1 尝试修改第二行：
定义方式作用域hoisting?程序执行结果a = 1全局无ReferenceError: a is not definedvar a = 1局部有打印 undefined（因为 var 变量有默认值）let = 1局部有ReferenceError: Cannot access 'a' before initializationconst = 1局部有ReferenceError: Cannot access 'a' before initializationClass hoistingconst Dog = new Animal(&#34;Bingo&#34;) // ReferenceError: Cannot access &#39;Animal&#39; before initialization class Animal { constructor(name) { this.name = name } } 和用 const 定义的变量的提升规则一样。
总结提升能工作是因为解释器能看到对应的声明。如果是普通函数，能直接调用；如果是 var 声明的变量，在初始化时使用默认值 undefined。
  ]]></content></entry><entry><title>Clash 相关</title><url>/posts/systems/Windows/Clash-for-Windows-%E7%9B%B8%E5%85%B3/</url><categories/><tags><tag>windows</tag><tag>clash</tag><tag>proxy</tag></tags><content type="html">  写在前面现在是 2024 年 4 月 17 日，Clash 源码（包括内核和 Clash for Windows，即 CFW）已经没了，clash.wiki 仍然能访问，并且里面有一些下载资源。虽然 Clash 现在不支持新协议了，也不继续维护了，但是它的一系列客户端实在是太好用了……
以下配置都是按照 Clash for Windows 说明，不讨论其他 Clash 变体。
使用 IPv6 上网去年有一段时间和现在，实验室出现了一种非常诡异的现象：不打开 Clash 时能够正常上网（国内），打开 Clash 的系统代理之后不能正常上网，无论是国内国外都无法访问！最近发现是实验室无法使用 IPv4 访问校外网络。验证方法：ping IPv4 和 IPv6 的公共 DNS 服务器（Google 的可以，阿里云的也可以），发现 IPv4 不通，但是 IPv6 通。
附上 Google 的公共 DNS 服务器地址：
8.8.8.8 8.8.4.4 2001:4860:4860::8888 2001:4860:4860::8844 根据同学描述，打开 CFW 时，微信能正常上网，其他网页不能。我第一反应是 DNS 有问题，因为我觉得微信可能会自己去解析域名，然后通过 IP 直接访问服务，以提高速度或者防止 DNS 劫持。因此我尝试了设置公共 DNS 服务器，但是仍然无法访问网络。后来不知道怎么的脑袋灵光了，去 ping 了一下 DNS 服务器才发现了问题。
总的来说，我的配置有两个问题：1. 没有开启 IPv6 支持；2. 我的机场不支持 IPv6。微信默认不走系统代理，所以不会受到 CFW 的限制，能够正常访问网络。
在首页打开 IPv6 功能（对应于配置中的 ipv6: true）。
如果你自定义了 DNS，要确保开启 DNS 的 ipv6（dns.ipv6），并且提供支持 ipv6 的 DNS 服务器。我在 mixin 写的 content.dns = undefined（保证校园网能够正常解析校内服务），因此跳过这个设置。
然后在 Settings &amp;amp;gt; System Proxy &amp;amp;gt; Static Host 中，将默认的 127.0.0.1 改成 localhost。这样 localhost 还能被解析成 ::1。
现在测试一下在打开 Clash 的情 …  </content></entry><entry><title>Pointer Events 样式</title><url>/posts/programming/www/Pointer-Events-%E6%A0%B7%E5%BC%8F/</url><categories/><tags><tag>css</tag></tags><content type="html"><![CDATA[  在 &lt;a&gt; 中加上 style=&quot;pointer-events: none;&quot; 会使得标签本身不能点击，但是其子元素可以点击。而在 &lt;div&gt; 中加同样的样式，会使得标签本身和子元素都不能点击。
其他元素基本上都是只禁用本身，只有 &lt;div&gt; 元素会将子元素也禁用。
如果想要将子元素的鼠标事件开启，需要加上 style=&quot;pointer-events: auto;&quot;。
  ]]></content></entry><entry><title>Python dict 和 OrderedDict</title><url>/posts/programming/python/Python-dict-%E5%92%8C-OrderedDict/</url><categories/><tags><tag>python</tag></tags><content type="html">  有序性这里说的有序指的是维持键的插入顺序，并不是指使用二叉树维持键的大小关系。
As of Python version 3.7, dictionaries are ordered. In Python 3.6 and earlier, dictionaries are unordered.
而 OrderedDict 一直是有序的。
https://devdocs.io/python~3.11/library/collections#collections.OrderedDict
比较Python 内置的字典主要用于查询（但在 3.7 版本之后也附带了维持插入顺序的功能），如果要频繁使用排序的功能，OrderedDict 性能更好。 OrderedDict 有一些排序的接口，方便实现 LRU 缓存等。 OrderedDict 在相等比较时会额外比较键的顺序。 A regular can emulate the order sensitive equality test with : p == q and all(k1 == k2 for k1, k2 in zip(p, q)).
OrderedDict 的 popitem 有不同的签名，OrderedDict 还有一个 move_to_end 方法。   </content></entry><entry><title>Do53、DoT、DoH 速度比较</title><url>/posts/unsorted/Do53DoTDoH-%E9%80%9F%E5%BA%A6%E6%AF%94%E8%BE%83/</url><categories/><tags><tag>network</tag></tags><content type="html"><![CDATA[  测试方式用 Windows 电脑向阿里云的 223.5.5.5 服务器发送请求。本文只提供一个直观的比较，并不追求全面的讲解。
DOH端口号 443。
接口比较复杂，要求我们制作一个 dns 查询包，然后将其转换成 base64 编码，再去掉末尾多余的 =（base64 规定不足 4 字节的整数倍则需要补充 =）。然后将得到的字符串作为 dns 参数放在 url 中。返回的结果也是二进制数据。
curl -s -o output.txt https://223.5.5.5/dns-query?dns=A6QBAAABAAAAAAAAB2FsaWJhYmEDY29tAAABAAE -w &#34;%{time_total}s\n&#34; Windows 自带 curl：50 ms MSYS2 curl：80 ms WSL curl：65 ms 或者直接用 curl 完成查询（需要比较新的版本）：
curl -s --doh-url https://223.5.5.5/dns-query https://baidu.com -w &#34;%{time_namelookup}s\n&#34; -o output.txt Windows 自带 curl：55 ms MSYS2 curl：100 ms WSL curl：80 ms（要小心代理的影响，如果被代理则 dns 查询是微秒级别的时间） DoT端口号 853。
本机安装的 curl 都不支持 --dns-servers 选项，所以不能使用 curl 完成 DoT 和普通 DNS 的查询。用 WSL 的 dig 查询会在结果中输出请求时间，似乎精度只能达到 10 ms 级别。
# wsl dig @223.5.5.5 baidu.com +tls 耗时 60~70 ms。
Do53端口号 53。
# wsl dig @223.5.5.5 baidu.com 耗时 10~20 ms。
结论Do53 远远快于 DoT 和 DoH，DoT 略快于 DoH，但有些情况下 DoH 会比 DoT 快。
  ]]></content></entry><entry><title>Windows cmd 调用和退出</title><url>/posts/systems/Windows/Windows-cmd-%E8%B0%83%E7%94%A8%E5%92%8C%E9%80%80%E5%87%BA/</url><categories/><tags><tag>windows</tag><tag>cmd</tag></tags><content type="html">   exit：退出整个 cmd.exe。 exit /b：只退出当前的批处理脚本。 xx.bat：转去运行 xx.bat，不再返回。 call xx.bat：转去运行 xx.bat，结束后返回（除非调用了 exit 使得整个 cmd.exe 中止）。 cmd /c yy：执行 yy 命令，结束后在交互界面继续等待操作。 cmd /k yy：执行 yy 命令，结束后退出。 start zz：创建一个新的窗口运行 zz。 如果想要在子脚本有 exit（而不是 exit /b）的情况还能不退出，可以使用 cmd 或者 start 创建新的命令行提示符。
  </content></entry><entry><title>在 Windows 的 bat 脚本中写 python 代码</title><url>/posts/programming/python/%E5%9C%A8-Windows-%E7%9A%84-bat-%E8%84%9A%E6%9C%AC%E4%B8%AD%E5%86%99-python-%E4%BB%A3%E7%A0%81/</url><categories/><tags><tag>python</tag><tag>cmd</tag><tag>windows</tag></tags><content type="html"><![CDATA[  &#34;python&#34; &#34;%~dp0%~nx0&#34; exit &#34;&#34;&#34; 字符串对于 cmd 来说是外部命令或参数，对于 python 来说是可拼接的字面量。 exit 对 cmd 来说是退出，对于 python 来说是一个函数名。 exit 会中止调用者，但在桌面点击运行的环境下可以正常使用。 &#34;&#34;&#34; import uuid import subprocess def main(): while (input(&#39;Hit enter to generate another key: &#39;).strip() == &#39;&#39;): s = str(uuid.uuid4()) subprocess.run(&#34;clip&#34;, text=True, input=s) print(f&#39;{s} is sent to your clipboard!\n&#39;) if __name__ == &#39;__main__&#39;: try: main() except: pass input(&#39;\nYou entered something else. Program will end after your next input.&#39;)   ]]></content></entry><entry><title>Python 判断字符串是否为空</title><url>/posts/programming/python/Python-%E5%88%A4%E6%96%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%98%AF%E5%90%A6%E4%B8%BA%E7%A9%BA/</url><categories/><tags><tag>python</tag></tags><content type="html">  def empty(s): return s is None or len(s) == 0 or s.isblank()   </content></entry><entry><title>(libstdc++ vs libc++) std::tuple</title><url>/posts/programming/cpp/libstdc++-vs-libc++-std_tuple/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  列表构造顺序libstdc++ 用的是递归反向构造，尾部的参数先构造。与之对应，libc++ 用的是 parameter pack 继承，是正向构造。
下标编号两者都使用了下标编号。这样即便 std::tuple 的某两个参数类型相同，也能通过不同的下标把两个元素区分开。
EBCO两者都有 EBCO 技术。假定 Base&lt;T, bool = InheritableEmptyBase&lt;T&gt;::value&gt; 为两个库所用的元素包装类，Base 在参数为空类且能够被继承时，采用继承的方式存储元素，否则用成员变量存储元素。
但是由于元组参数构造顺序不同，两种库实现占用的空间也可能不同。考虑类型 std::tuple&lt;A, char, A, char, B&gt;，其中 A 和 B 都是空类型，它在 libc++ 中只需要占用 2 个字节。
而 libstdc++ 中同样的类型需要占用 3 个字节：
如图，最后一次继承的时候先继承 TupleImpl&lt;char, A, char, B&gt;（假设 TupleImpl 是递归继承功能的实现模板），后继承 Base&lt;A&gt;，但由于地址 0 处已经有 A 类型，所以只能放在地址 2 处。（EBCO 失效之后只能跨过整个基类，不能摆在基类的中间地址。）
get with indexget 模板的参数中有下标，而特定元组中的下标可以决定其基类的类型。两个库都巧妙利用了基类名唯一的特性，从结果来说是等效的。
libstdc++ 通过限定名获取元素：
_Tuple_impl&lt;__i, _Head, _Tail...&gt;::_M_head(__t); _M_head 是用来获取被包裹的元素的方法（实际上是个很短的、返回某个数据域的方法）。
libc++ 则将 *this 转换成基类指针再掉用获取元素的方法。
  ]]></content></entry><entry><title>(libstdc++) std::function</title><url>/posts/programming/cpp/libstdc++-std_function/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  涉及的 libstdc++ 源码文件：bits/std_function.h。
印象： std::function 做了小对象优化，同时在避免使用虚函数（尽管它可以用继承和虚函数来实现）。
关于成员指针，见 Pointer to Member。
存储结构首先看 std::function 的成员组成：
void swap(function&amp;amp;amp; __x) noexcept { std::swap(_M_functor, __x._M_functor); std::swap(_M_manager, __x._M_manager); std::swap(_M_invoker, __x._M_invoker); } // 模板太长了，成员定义很分散，抄起来很累；这个 swap 函数写的刚刚好 _M_functor 是一个 union 的 union（最外层的 union 是为了和 char 数组拼在一起方便取首地址，里面的 union 可以用来表示四种不同类型的指针）：
union _Nocopy_types { void* _M_object; const void* _M_const_object; void (*_M_function_pointer)(); void (_Undefined_class::*_M_member_pointer)(); // 这个在 64 位环境的 gcc 里面是 16 个字节 }; _M_manager 和 _M_invoker 都是普通函数指针，是用来管理函数对象的调用和生命周期的。
函子（functor）存储：
如果函子是普通函数指针或者成员函数指针，则能直接存储（因为有上面的 union 来专门存储）。 如果函子是具有调用操作符的对象，则先考虑 _M_functor 占用的空间能不能用来本地分配（gcc 里成员函数指针占用 16 个字节，拿来做小对象优化还蛮好的）。这叫小对象优化（SOO）。 如果函子是具有调用操作符的对象，且本地空间不够，则会动态申请内存。 调用开销（不考虑创建函数对象时的开销）我在 libstdc++ 实现里面没找到 std::function 对虚函数的使用？但是看到 std::function 调用有很多间接环节：
首先是读 _M_invoker 的值，然后才能调用其指向的函数，这涉及到读内存一 …  </content></entry><entry><title>(libstdc++) std::set</title><url>/posts/programming/cpp/libstdc++-std_set/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  相关文件：
include/set 头文件按顺序引入了 include/bits/stl_tree.h 和 include/bits/stl_set.h。 include/bits/stl_set.h 定义了 std::set，依赖了 include/bits/stl_tree.h 却没有明确包含它。 include/bits/stl_tree.h 定义了诸多类型，如未明确指出则默认下面提到的类型都是来自于这个头文件。 src/c++98/tree.cc 实现了红黑树用到的非模板算法。这个文件只有 400 多行。 std::set 将实现转发给 _Rb_tree 处理，而它又将实现转发给了 _Rb_tree_impl 处理。
_Rb_tree_impl 继承于：
_Node_allocator：是一个 typedef，实际类型是一个模板类，模板参数和 _Rb_tree 的参数有关。 _Rb_tree_key_compare：是一个模板类，模板参数和 _Rb_tree 有关。 _Rb_tree_header：非模板类。包含了 _Rb_tree_node_base 结构和 _Rb_tree_node_count。前者是表示红黑树结点的聚合类，包含了 parent/left/right/color 四个重要成员；后者是结点计数。初始化时，parent/left/right 都被设置为 header 本身的地址，而 color 被设置为红色，可见这个 header 就是标准库红黑树中的 nil 哨兵。另外，left 和 right 还有最小结点和最大结点的含义。 以插入算法举例，由于比较算子在模板中，所以需要用模板方法找到应该插入的位置，这些都在头文件 include/bits/stl_tree.h 中实现。接着调用插入并平衡的函数，该函数只操作指针，不关心结点中包含的值，所以这个部分可以在源文件 src/c++98/tree.cc 中实现，从而减少了代码膨胀。
按照上面的分析，可以解释以下未定义行为（但是不建议这么写）：
std::set&lt;int&gt; set; auto it = set.end(); ++it; // dead loop 由于 set.end() 返回了哨兵，初始化情况下三个指针都指向自己，所以按照自增算法会一直向右搜索，造成死循环。
std::set&lt;int&gt; set{1}; auto it = set.end(); ++it; assert(it != set.end()); ++it; assert(it == set.end()); 由于哨兵的 right 指针指向最大元素，因此自增之后回到了最大元素的位置。再自增一次又回到了哨兵的位置。
  ]]></content></entry><entry><title>📌 C++ 对象模型开销总结</title><url>/inside-the-cpp-object-model/C++-%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%E5%BC%80%E9%94%80%E6%80%BB%E7%BB%93/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html"><![CDATA[  下面都是在 Linux 上测试，处理器架构为 x86-64，用的 Itanium C++ ABI。
Caution
下面很多指针转整数用的是 long，实际上用 intptr_t 更严谨。
指向成员函数的指针：2 倍大小在 64 位下是 16 字节，因为需要支持虚函数调用。指向成员函数的指针会保存两部分数据：
ptr：非虚函数则存储函数地址。虚函数则存储虚表中偏置加 1（1 plus the virtual table offset (in bytes) of the function, represented as a ptrdiff_t）
adj：存储对 this 指针的调整量。
用 指向成员函数的指针 调用函数时，需要在传入的 this 指针上添加偏置（在多继承中有用），偏置信息就存储在该指针内。下一节“调用虚函数的开销”也描述了如何在跨平台 C++ ABI 上装配一个 指向成员函数的指针。
调用虚函数：多访存 2 次#include &amp;lt;cstdio&amp;gt; struct BaseObject { virtual int f() { return 13; } }; struct DerivedObject : BaseObject { int f() override { return 4000; } }; int main() { BaseObject *p = new DerivedObject; // 访存两次得到虚函数（感觉 long 类型比 char*/void* 模拟汇编更加合适） long vptr = *(long *)p; long func = *(long *)(vptr + 0); // 把 this 指针作为第一个参数传入 auto method = (int (*)(BaseObject *))func; int result = method(p); // 尽管也可以按照 Itanium C++ ABI 装配成员函数指针， // 但实际上调用时还是会动态查找，相当于上面的访存操作白做了。 // int (BaseObject::*method)(); // auto &amp;amp;manip = (long (&amp;amp;)[2])method; // manip[0] = (long)func; // manip[1] = …  ]]></content></entry><entry><title>📌 vtable</title><url>/inside-the-cpp-object-model/vtable/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html"><![CDATA[  TL;DR 性能开销在不开启优化选项时编译：
每次调用虚函数比普通函数多两次访存。 每次动态类型转换（除非类型精确命中）都是耗时的图搜索算法。 明确需要精确转换时用 std::type_index 和 static_cast 会更快。 相关代码下载：
git clone -n --depth=1 --filter=tree:0 https://github.com/gcc-mirror/gcc.git cd gcc git sparse-checkout set --no-cone &amp;#34;libstdc++-v3/libsupc++/&amp;#34; git checkout 虚表内存结构代码首先：在共享代码区域存储的虚表记录了特定类的信息。对象中的虚表指针其实是虚函数表指针，指向虚表中的一块位置。
Caution
这里我所称的虚表对应于 GCC 代码中的 vtable_prefix，虚函数表对应于 GCC 代码中的 vtable。可能不是很正规。
对于下面的代码，使用 gcc 13.1 编译：
#include &amp;lt;iostream&amp;gt; // 会存储一个虚表指针，8字节 struct A { virtual void f1() { std::cout &amp;lt;&amp;lt; &amp;#34;f1 from A\n&amp;#34;; } }; struct C { virtual void f2() { std::cout &amp;lt;&amp;lt; &amp;#34;f2 from C\n&amp;#34;; } }; struct D { virtual void f3() { std::cout &amp;lt;&amp;lt; &amp;#34;f3 from D\n&amp;#34;; } }; struct B: A, C, D { B() {} virtual void f1() override { std::cout &amp;lt;&amp;lt; &amp;#34;f1 from B\n&amp;#34;; } }; int main() { B *p = new B; p-&amp;gt;f1(); std::cout &amp;lt;&amp;lt; &amp;#34;sizeof(A) = &amp;#34; &amp;lt;&amp;lt; sizeof(A) &amp;lt;&amp;lt; &amp;#39;\n&amp;#39;; // 8 std::cout &amp;lt;&amp;lt; &amp;#34;sizeof(B) = …  ]]></content></entry><entry><title>📌 非自动变量初始化</title><url>/inside-the-cpp-object-model/%E9%9D%9E%E8%87%AA%E5%8A%A8%E5%8F%98%E9%87%8F%E5%88%9D%E5%A7%8B%E5%8C%96/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html">  C++ 和 C thread_local 的区别C++ 支持使用非常量表达式对全局或静态变量初始化 1。对于 static local 2 / thread_local 变量而言，这项功能需要在访问前检查变量是否已经完成初始化，thread_local 初始化不需要线程间同步，而 static local 变量的访问过程需要线程间的同步（__cxa_guard_acquire 和 __cxa_guard_release）。 C++ 的 thread_local 变量在函数作用域中自动具有 static 属性 3，而 C 要手动加。在 C 语言中，函数中的 thread_local 必须和 extern 或者 static 之一一起使用，例子为 https://godbolt.org/z/eKz71xh7a 。 C 的 thread_local 在 C23 之前是个宏。 从代价上来看 C++ 的几种变量初始化首先，不需要函数初始化的在编译期间就能完成工作，没有代价。所以以下讨论的都是通过函数或构造函数来初始化的变量。 其次，函数内 (static) thread_local 变量只需要在使用前检查一下，构造和使用都不用同步，代价很小。函数内 static 变量的构造和使用则需要线程之间同步。 函数外定义的普通变量和 thread_local 变量都不需要任何同步就能在静态初始化阶段完成初始化，使用时也不需要检查。 函数外定义的 inline 变量（C++17）在使用时不需要同步，但是在初始化的时候要检查是否已经初始化完成（为此有个 guard variable 标记）。见 https://godbolt.org/z/hYMjdbsxj ，这可能是因为 inline 变量可能被多个地方使用，每个地方都要提防重复初始化。 全局 (和 static) 变量最外围定义域定义的变量，可以具有 static 属性也可以没有。
不支持非常量初始化表达式（C 模型）编译器会抱怨：initializer element is not constant。
支持非常量初始化表达式，但只对对象生效（Cfront 1.0 模型）在用户程序真正运行前插入一段静态变量初始化代码。
Cfront 早期对 class object 支持了非常量的静态初始化，但标准类型（整数、指针等）的静态支 …  </content></entry><entry><title>Abominable Function</title><url>/posts/programming/cpp/Abominable-Function/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  在 Abominable Function Types (open-std.org) 中：
For the purposes of this paper, an abominable function type is the type produced by writing a function type followed by a cv-ref qualifier. Example: using regular = void(); using abominable = void() const volatile &amp;amp;&amp;amp;;
通过一些模板手段能把类中的成员函数转换成可憎函数（怎么翻译更合适？）。可憎函数形式复杂，模板匹配困难。C++23 explicit object parameter (deducing this) 可以一定程度上解决这个问题。
这个东西现在看来不该存在，是 this 指针设计的历史遗留问题。
  </content></entry><entry><title>ADL</title><url>/posts/programming/cpp/ADL/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  例子：
#include &lt;iostream&gt; #include &lt;numeric&gt; #include &lt;vector&gt; int main() { std::vector v{1, 3, 5}; // 模板类参数推导：T=int std::cout &lt;&lt; std::accumulate(begin(v), end(v), 0); // ^^ ^^ ^^ 都是ADL } 使用 begin、end、swap 等函数模板时，先引入其名字到当前空间中，然后再调用，有助于 ADL 查找到性能更优的函数实现：
{ using std::swap; swap(A, B); // 假设 A 和 B 是已经定义的同类型变量 } 博文 Should I use the two-step in non-generic code? 认为在非泛型代码中不必使用 using std::swap，直接使用 x.swap(y) 或者 std::swap（如果是内置类型或者 std 名字空间中的类型）即可。
  ]]></content></entry><entry><title>Aggregate</title><url>/posts/programming/cpp/Aggregate/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  注意，有 bit fields 或者 有成员默认值 或者 有匿名 union 成员 也可以是 aggregate。
对含有 union 成员的聚合类使用 花括号 或 默认的全参数构造函数 初始化时，初始化的是 union 的第一个元素（不管 union 是不是匿名的）。
(C++20) 隐式提供的的全参数构造函数#include &lt;iostream&gt; #include &lt;vector&gt; struct Point { double x; double y; }; int main() { std::vector&lt;Point&gt; points; // 可以省略类型，花括号自动推导。 points.push_back({1, 1}); // 必须要写Point类型。因为是模板参数，捕获的时候不知道目的类型，不能推导。 points.emplace_back(Point{1, 1}); // 下面两行在 C++20 可以编译： points.emplace_back(1, 2); auto some_point = Point(1, 2); } 注意这样的全参数构造函数是具有 explicit 属性的。所以下面的代码不能编译：
struct Id { int value; }; int main() { Id some_id = 4; } 作为模板的非类型参数？不是所有的聚合类都能作为非类型参数！一个反例：定义了析构函数的聚合类不能作为 NTTP。
这是类类型模板非类型参数（C++ 20）引入后，部分聚合类 作为特殊情况享受到的一种好处。
结构化绑定？不是所有的聚合类都能结构化绑定！ 反例是含有匿名 union 成员的聚合类不能被结构化绑定。
部分聚合类也能够使用结构化绑定。见 结构化绑定（Structured Binding）。
struct Point { double x{-1}; double y; }; int main() { auto [x, y] = Point{1.5, 2.0}; static_assert(std::is_aggregate_v&lt;Point&gt;); // true }   ]]></content></entry><entry><title>auto + decltype</title><url>/posts/programming/cpp/auto-+-decltype/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  用于标注函数返回值令人意外的是：C++14 加入的返回值推导是一种特殊的类型，和前向声明并不兼容。
int known(); auto known() { return 42; } // 错误：类型不兼容 // int known() { return 42; } // ok // auto known() -&amp;gt; int { return 42; } // ok 同样：
auto known(); int known() { return 42; } // 错误：类型不兼容 // auto known() { return 42; } // ok C++ 14 还加入了 decltype(auto)，这个组合不像单独的 auto，不能被 const 等继续修饰。
  </content></entry><entry><title>bash 配置</title><url>/posts/cli/bash/bash-%E9%85%8D%E7%BD%AE/</url><categories/><tags><tag>bash</tag></tags><content type="html"><![CDATA[  bash 的两个配置文件login 时只加载 .bash_profile（如果存在），其他时候只加载 .bashrc。
最好是把内容放在 .bashrc，然后让 ~/.bash_profile 去 source ~/.bashrc。
虽然 ~/.bashrc 是所有非登陆的 bash 都会读，但默认的 ~/.bashrc 的开头检查了当前是否为交互终端，如果不是则退出。如果非要绕过这个限制，可以强制一个终端为交互终端：bash -i。
Windows 的 Cygwin 目录下自己有 home。因此要让它的 ~/.bashrc 去 source Windows 用户目录的 ~/.bashrc，不然会出现两处配置不一致的情况。
bash 显示 git 分支parse_git_branch() { if ! [[ $(git rev-parse --is-bare-repository 2&gt;/dev/null) == true ]]; then local BRANCH=&#34;$(git branch 2&gt;/dev/null | sed -e &#39;/^[^*]/d&#39; -e &#39;s/* \(.*\)/\1/&#39;)&#34; [[ &#34;${BRANCH}&#34; == &#34;&#34; ]] &amp;&amp; return 0 local MSG=&#34;$(git status 2&gt; /dev/null | tail -n1)&#34; if [[ &#34;$MSG&#34; != &#34;nothing to commit&#34;* ]]; then echo -n &#34;(${BRANCH}*) &#34; else echo -n &#34;(${BRANCH}) &#34; fi fi } EXITCODE=&#39;$(code=$?; if (( code )); then echo -ne &#34;\[\e[91m\][$code]\[\e[00m\] &#34;; fi)&#39; export PS1=&#34;${EXITCODE}\u \[\e[32m\]\w \[\e[00m\]\[\e[91m\]\$(parse_git_branch)\[\e[00m\]$ &#34;   ]]></content></entry><entry><title>C/C++ 全局定义应该放在 .bss 还是 .data</title><url>/posts/programming/cpp/C-%E5%92%8C-C++-%E5%85%A8%E5%B1%80%E5%AE%9A%E4%B9%89%E5%BA%94%E8%AF%A5%E6%94%BE%E5%9C%A8-.bss-%E8%BF%98%E6%98%AF-.data/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  C/C++ 中全局定义/声明的区别无论在 C 还是 C++，想要仅声明而不在翻译单元中定义全局变量，都需要 extern。
C语言：（强弱是方便我叙述引出的概念）
int global = 1; // 强定义，和其他强定义互斥 int global; // 弱定义，可以和同文件其他定义兼容（最终只保留一份定义） int global; 能编译！但是上面的代码和其他目标文件一起链接时，若出现多次定义同样会引发重复定义的错误。
C++：（单个文件）
int global; // 强定义 int global; **&lt;source&gt;:2:5: error:** redefinition of &#39;**int global**&#39; 2 | int **global**; | **^~~~~~** **&lt;source&gt;:1:5: note:** &#39;**int global**&#39; previously declared here 1 | int **global**; | **^~~~~~** Compiler returned: 1 .bss 和 .data.bss 原本放的是有声明但是无显式定义的变量。只记录变量的名字和长度，不占用其他空间。一般这些变量会被初始化为 0（ISO C 也是这么要求）。但实际上gcc倾向于把显式赋值为全零的变量也放在.bss，有非零初始值的则放在 .data 区。（可以节约空间）
现在两者区别几乎只有表示方式上。在全零的时候 .bss 能够节省空间。
  ]]></content></entry><entry><title>C++ 几种新增类型转换的区别 + 标准库模板函数</title><url>/posts/programming/cpp/C++-%E5%87%A0%E7%A7%8D%E6%96%B0%E5%A2%9E%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E7%9A%84%E5%8C%BA%E5%88%AB-+-%E6%A0%87%E5%87%86%E5%BA%93%E6%A8%A1%E6%9D%BF%E5%87%BD%E6%95%B0/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  四大关键字static_cast 大多数转换，包括左右值转换、父子类指针/引用之间的转换（不进行安全检查，但会修正指针偏移）。 const_cast 也能进行 volatile 属性的修改！！ dynamic_cast 父子类指针/引用之间的转换。其中子类转向基类相当于使用 static_cast ，没有运行时安全检查。而基类转向子类则有运行时安全检查，而且要求基类是多态类，否则无法编译。 reinterpret_cast 标准库的共享指针转换模板标准库中还有针对于 std::shared_ptr 的类型转换模板。转换后返回一个共享指针，但其包裹的类型被转换成了对应的类型：
std::static_pointer_cast std::const_pointer_cast std::dynamic_pointer_cast 注意：这种转换算作指针的复制，所以共享指针对应的控制块引用计数加一（如果指针非空）。
举例：
struct A {}; struct B: A {}; auto sp = std::make_shared&lt;B&gt;(); if (auto sp2 = std::dynamic_pointer_cast&lt;A&gt;(sp)) { std::cout &lt;&lt; &#34;success\n&#34;; }   ]]></content></entry><entry><title>C++23 std::forward_like</title><url>/posts/programming/cpp/C++23-std_forward_like/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  std::forward 需要我们提供一个模板参数，它能把同类型（不包括值类别）的参数转发出去。
std::forward_like 则有两个模板参数，第一个参数需要显式提供，第二个参数从实参中推导。它从模板参数中获得转发需要使用的引用类型，并将实参转发出去。这意味着实参和模板参数的类型可以不一致！
std::forward_like 非常适合转发子对象的场合，因为它能让子对象和本身的左右值类型相同。比如在显式对象参数中可以使用。
  </content></entry><entry><title>Cfront 如何插入构造函数</title><url>/inside-the-cpp-object-model/Cfront-%E5%A6%82%E4%BD%95%E6%8F%92%E5%85%A5%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html">  实际上复制构造函数的插入比较困难，比如在函数返回和传参的时候。由于 C 语言是按位复制（而不是按成员），cfront 会在函数调用前插入返回值变量声明，在函数中使用局部变量运算，并在返回时调用复制构造函数从局部变量复制成员到返回值处。
NRVO (Named Return Value Optimization) 则能省略返回时的复制构造：
关于返回值优化RVO 的范畴很广，NRVO 是 RVO 的一种特例。
URVO（无名临时变量的优化）：
NRVO（具名局部变量的返回的优化）：
  </content></entry><entry><title>cppreference 协程例子理解</title><url>/posts/programming/cpp/cppreference-%E5%8D%8F%E7%A8%8B%E4%BE%8B%E5%AD%90%E7%90%86%E8%A7%A3/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  我的理解是：C++ 的协程是无栈的，这意味着协程只是计算任务，仅在运行时需要栈，在 suspend 之后就会保存状态并脱离栈。要想要跨线程转移计算任务（比如实现工作窃取池），只需要将离栈协程在另外一个线程上 resume 即可。
#include &lt;coroutine&gt; #include &lt;iostream&gt; #include &lt;stdexcept&gt; #include &lt;thread&gt; auto switch_to_new_thread(std::jthread&amp; out) { struct awaitable { std::jthread* p_out; bool await_ready() { return false; } void await_suspend(std::coroutine_handle&lt;&gt; h) { std::jthread&amp; out = *p_out; if (out.joinable()) throw std::runtime_error(&#34;Output jthread parameter not empty&#34;); out = std::jthread([h] { h.resume(); }); // Potential undefined behavior: accessing potentially destroyed *this // std::cout &lt;&lt; &#34;New thread ID: &#34; &lt;&lt; p_out-&gt;get_id() &lt;&lt; &#39;\n&#39;; std::cout &lt;&lt; &#34;New thread ID: &#34; &lt;&lt; out.get_id() &lt;&lt; &#39;\n&#39;; // this is OK } void await_resume() {} }; return awaitable{&amp;out}; } struct task { struct promise_type { task get_return_object() { return {}; } std::suspend_never initial_suspend() { return {}; } std::suspend_never final_suspend() noexcept { return {}; } void return_void() {} void unhandled_exception() {} }; }; task resuming_on_new_thread(std::jthread&amp; out) { std::cout &lt;&lt; &#34;Coroutine started on thread: &#34; &lt;&lt; std::this_thread::get_id() &lt;&lt; &#39;\n&#39;; co_await switch_to_new_thread(out); // awaiter destroyed here std::cout &lt;&lt; &#34;Coroutine resumed on thread: &#34; &lt;&lt; std::this_thread::get_id() &lt;&lt; &#39;\n&#39;; } int main() { std::jthread out; resuming_on_new_thread(out); } 可能结果：
Coroutine started on thread: 139972277602112 New thread ID: 139972267284224 Coroutine resumed on thread: 139972267284224   ]]></content></entry><entry><title>CTTCG 01 Function Templates</title><url>/cpp-templates-the-complete-guide/01-Function-Templates/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html">  2023 年 5 月 7 日
两个 type traitsstd::decay_t 可以去引用、去限定符、函数/数组变指针；std::common_type_t 用三元运算符获得更“宽泛”类型。
函数模板默认参数模板默认参数可以放在最前面，不像普通函数只能把带有默认值的参数放在最后。而且函数模板可以明确指定开头几个参数，让后面的参数由推导规则生成。
函数重载参数匹配优先级优先级排序perfect match decay，或者修改指针的内外层 const 属性（volatile 应该也算吧？） 比如 char * 到 char const * promotion，比 int 小的转到 int 或更大的整数，或者 float 到 double。 举例：bool 到 char 不是 promotion，而是 standard conversion standard conversion，包括 int to float，子类（值/引用/指针）向基类（值/引用/指针）转换 用户定义的转换，包括标准库的类 与可变长参数列表匹配，也就是 (...) 例外：f(...) 和 f(void) 参数类型是同级别的，因为没有提供参数，编译器不知道哪一个匹配更合适。 以上参数匹配不涉及到值类型、左引用、右引用的区别。只要引用属性能够匹配，就不区分优先级。比如同时匹配到 f(int) 和 f(int &amp;amp;amp;) 编译器就会抱怨函数调用 ambiguous。
各个参数匹配优先级有差异时：如果一个函数重载的参数组的优先级均不低于另一个函数重载，则前一个函数重载更优先。
各个参数匹配优先级一样时：
非模板函数比模板函数更优先。 特化程度高的模板函数比特化程度低的模板函数更优先。 一般模板函数比模板参数中带有 parameter pack（实际上匹配为空）的模板函数更优先。 在传递参数时最多允许一次用户定义转换。如果函数重载 A 的参数类型转换序列是 B 的子序列，则函数重载 A 的优先级更高。
standard conversion 中的指针转换转换成 bool 转换成 void * 子类指针向基类指针的转换 指向成员指针（pointers to members）从基类向子类的转换 这几类转换中优先级从 1 到 3 越来越高。第 3 点中，向基类指针转换时跨过的层级越少转换优先级越高。 …  </content></entry><entry><title>CTTCG 02 Class Templates</title><url>/cpp-templates-the-complete-guide/02-Class-Templates/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  2023 年 5 月 7 日
定义位置类模板只能在全局或者类声明中定义，不能在块或者函数中定义。
类模板外函数定义的写法类模板中定义函数，T 类型参数可以省略；在类模板中声明，但在外提供函数定义，就需要在定义处给出完整的类型参数：
template&amp;lt;typename T&amp;gt; void Stack&amp;lt;T /* 不能省略 */&amp;gt;::push (T const&amp;amp; elem) { /* impl */ }
一个例外是析构函数和构造函数的名称处，因为这里不表类型，而是表示函数名。
template&amp;lt;typename T&amp;gt; void Stack&amp;lt;T&amp;gt;::Stack() { /* impl */ } // ^^^^ 这里不能加参数T P30 处理友元函数，比如向输出流打印。最简单的还是直接在类模板中提供定义：
friend std::ostream&amp;amp; operator&amp;lt;&amp;lt;(std::ostream&amp;amp; os, Stack const&amp;amp; s) { for (auto const&amp;amp; i : s.elems) os &amp;lt;&amp;lt; i &amp;lt;&amp;lt; &amp;#39; &amp;#39;; return os; } 如果只在类模板中写声明，要么 ① 把函数写成模板函数，并使用不同的类型参数符号，然后在类外补上定义：
template &amp;lt;class U&amp;gt; friend std::ostream&amp;amp; operator&amp;lt;&amp;lt;(std::ostream&amp;amp; os, Stack&amp;lt;U&amp;gt; const&amp;amp; s);
② 要么先声明类模板，再声明这个模板函数，然后在类中写：
friend std::ostream&amp;amp; operator&amp;lt;&amp;lt; &amp;lt;&amp;gt;(std::ostream&amp;amp; os, Stack const&amp;amp; s);
其中&amp;lt;&amp;gt;表示函数需要匹配某个模板。最后在类外补上定义。
按需实例化类模板只会实例化那些被用到的成员函数。这虽然降低了空间开销，但也使得一些问题很难被发现，比如常常在添加新的功能（调用之前没被调用的函数）后才发现旧代码无法编译的问题。
特化可以用 template &amp;lt;&amp;gt; 特化类模板。若特 …  ]]></content></entry><entry><title>CTTCG 03 Nontype Template Parameters</title><url>/cpp-templates-the-complete-guide/03-Nontype-Template-Parameters/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  模板参数也可以不是类型，而是值。
非类型参数推导只对直接调用有效模板函数的类型推导只对立即调用有效，而对算法模板这类需要提前知道类型信息的场合无效。比如：
std::transform (source.begin(), source.end(), // start and end of source dest.begin(), // start of destination addValue&lt;5,int&gt;); // operation 上面代码中尽管 addValue 的参数可能可以推导出来，但由于 std::transform 要求提前知道函数的类型，去掉参数之后代码无法编译。
非类型参数的类型限制非类型参数不能是浮点数（未来可能可以）。只能是整数、nullptr、指针或左值引用。
2017 年的 P1714 提案建议增加浮点数，目前找不到后续。不过，gcc 13 在 -std=c++20 时已经提供了浮点数参数功能，clang 暂不支持。
作为对比，如今 C++20 中某些非 union class type 已经可以作为模板参数，但浮点数不能。
当参数是指针或引用时，不可以指向字符串字面量、临时值、数据成员或其他子对象；C++11 还要求对象有 external linkage，C++14 要求对象有 external linkage 或者 internal linkage，C++17 对 linkage 没有要求。
虽然不能使用字符串字面量，但可以使用编译期可定的字符数组的引用作为参数。
extern char const s03[] = &#34;hi&#34;; // external linkage char const s11[] = &#34;hi&#34;; // internal linkage int main() { Message&lt;s03&gt; m03; // OK (all versions) Message&lt;s11&gt; m11; // OK since C++11 static char const s17[] = &#34;hi&#34;; // no linkage Message&lt;s17&gt; m17; // OK since C++17 } 非类型参数可能需要括号包裹模板参数中出现表达式时，要使用括号，否则容易出现尖括号被理解成模板参数结束标志，导致无法编译的情况：C&lt;42, sizeof(int) &gt; 4&gt; c; ，应该改成 C&lt;42, (sizeof(int) &gt; 4)&gt; c;
auto 作为非类型参数由于非类型参数的通用限制，auto &amp;&amp; 是不允许使用的（非类型参数不能有右值）。允许的有：auto / auto &amp; / auto const &amp; / decltype(auto)。当实际类型为引用时，要求传入的值在编译期具有可计算出的不变地址（全局常量和变量符合要求、纯右值的数字字面量不符合要求）。当实际类型为值时，需要传入的值在编译器有可计算出的不变值（全局常量和数字字面量符合要求）。
指定非类型参数的类型是 auto 时，仍然可以通过 decltype 手段获得参数，也有了自动推导类型的优势。比如可以编写一个原地分配内存的 Stack 类：
Stack&lt;int, 20u&gt; stk1; Stack&lt;int, 20&gt; stk2; 这样两个 Stack 对象的 size_type 不同。
另外， decltype(auto) 可以表示类型完美转发的场景。
template&lt;decltype(auto) N&gt; class C { //... }; int i; C&lt;(i)&gt; x; // N is int&amp; 上面的代码如果写成 C&lt;i&gt; x 或者模板参数是 auto N，N 的类型就是 int 而不是引用类型。
💡 既然模板参数要求编译期计算完成，好像在参数中传递引用没有什么意义？
  ]]></content></entry><entry><title>CTTCG 04 Variadic Templates</title><url>/cpp-templates-the-complete-guide/04-Variadic-Templates/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  可变长表达式可以对参数包逐个处理。与折叠表达式（相当于函数式编程中的 reduce，但如果用上逗号表达式就能表达 foreach）不同，可变长表达式（相当于函数式编程中的 map）不会改变参数数量，允许的形式也比折叠表达式宽松一点。
参数包（Parameter Pack）和可变长模板模板函数可以指定参数包，用 sizeof…() 运算符可以获得参数包的数量。至少有一个参数包的模板称为可变长模板（variadic template）。
0 Pack Expansion：参数传递参数传递。
Note
2024 年 2 月 20 日：除了作为函数参数之外，还能用作初始化列表（花括号）的参数。
1 递归：逐个处理#include &amp;lt;iostream&amp;gt; void print () { } template&amp;lt;typename T, typename... Types&amp;gt; void print (T firstArg, Types... args) { std::cout &amp;lt;&amp;lt; firstArg &amp;lt;&amp;lt; &amp;#39;\n&amp;#39;; // print first argument print(args...); // call print() for remaining arguments } 还要留一个非模板的单参数或者零参数的函数收尾。如果收尾的函数是零参数的，可以使用 if constexpr 判断剩余参数数量，从而避免多写一个函数。
2 折叠表达式：一次性处理Note
warning: fold-expressions only available with &amp;lsquo;-std=c++17&amp;rsquo; or &amp;lsquo;-std=gnu++17&amp;rsquo; (-Wc++17-extensions)
这是折叠表达式的一个例子：
template&amp;lt;typename... T&amp;gt; auto foldSum (T... s) { return (... + s); // ((s1 + s2) + s3) ... } 折叠表达式可以将参数包变成一个表达式，一下子利用完了所有参数，而递归函数模板是把参数数量逐次减 1，直到计算完成。
注意折叠表达式的形式有限制：
省略号、op、pack 三者紧紧连接，省略号的位置 …  ]]></content></entry><entry><title>CTTCG 05 Tricky Basics</title><url>/cpp-templates-the-complete-guide/05-Tricky-Basics/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  1 使用关键字引导编译器了解成员类型template&amp;lt;typename T&amp;gt; class MyClass { public: void foo() { typename T::SubType* ptr; } } 上面的的代码中加了 typename 关键字用来表示 SubType 这个成员是一个类型。否则由于缺乏类型信息，编译器会认为该成员是某个数据域，从而构成了乘法表达式。
template&amp;lt;unsigned long N&amp;gt; void printBitset (std::bitset&amp;lt;N&amp;gt; const&amp;amp; bs) { std::cout &amp;lt;&amp;lt; bs.template to_string&amp;lt;char, std::char_traits&amp;lt;char&amp;gt;, std::allocator&amp;lt;char&amp;gt;&amp;gt;(); } 上面的 template 关键字在 to_string 前作解释，表示 to_string 是一个函数模板，否则后面的尖括号会被认为是小于运算符，而不是函数模板参数的开始标志。
2 正确初始化模板类的成员在模板类中为了保证成员被正确初始化，应该使用 {} 初始化的语法，因为无论 T 是什么类型，这种初始化方式都是可行的。此外 {} 也能用在数据成员定义处，或者构造函数初始化列表中：
template&amp;lt;typename T&amp;gt; class MyClass { private: T x; T y{}; public: MyClass() : x{} { // ensures that x is initialized even for built-in types } }; 这里 x 是在构造函数中初始化的，y 是在定义处初始化的。如果两处都写了初始化方式，构造函数的初始化会覆盖原来的初始化。个人认为在数据成员定义处给出初始化可以减少遗漏。
3 this 指针失效？template&amp;lt;typename T&amp;gt; class Base { public: void bar(); }; template&amp;lt;typename T&amp;gt; class Derived : Base&amp;lt;T&amp;gt; { public: void foo() { // bar(); // …  ]]></content></entry><entry><title>CTTCG 06 Move Semantics and enable_if</title><url>/cpp-templates-the-complete-guide/06-Move-Semantics-and-enable_if/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  Perfect forwarding:
template&lt;typename T&gt; void f (T&amp;&amp; val) { g(std::forward&lt;T&gt;(val)); // perfect forward val to g() } 注意，完美转发只对模板参数有效，对依赖于模板参数的类型也是无效的，比如：typename T::iterator&amp;&amp; 是无效的，仍表示严格的右值引用。
完美转发也不能加 const 属性。添加 const 属性后表示常右值引用（而且这种形式很少被使用）。
尝试用完美转发简化代码设想一个 Person 类，里面只有一个 std::string 类型的 name 数据。已经实现了复制构造函数和移动构造函数。从数据的构造函数有 std::string &amp;&amp; 和 std::string const &amp; 两个重载版本。使用完美转发可以同时写出匹配这两种参数的函数模板，减少代码量。
💡 事实上，代码量并不会减少，反而会变得复杂。在这种必定需要复制的场合，最好的方式还是接受 std::string 的值类型。下面的讨论假定必须使用模板实现。
问题在哪里？
完美转发匹配的优先级太高了，在传入一个 Person &amp; 对象的时候，Person const &amp; 复制构造函数匹配优先度低，从而调用的是函数模板。而给定的函数模板是为字符串类型写的，显然 Person 不能用于初始化 std::string，因而无法编译。
可以用 std::enable_if 来要求参数必须是字符串。在 C++20 中，可以用 concept 来加限制。
💡 std::enable_if_t 这样形式的 _t 后缀是 C++14 引入的。而 std::is_convertable_v 这样的 _v 后缀是 C++17 引入的。
函数模板还有什么问题？若为类中的特殊函数提供函数模板，默认的特殊函数并不会被删除。在都能够匹配的场合中，默认的特殊函数优先级更高。因而有时候需要显式 delete。
但是最好还是不要为特殊函数提供模板。
  ]]></content></entry><entry><title>CTTCG 07 By Value or by Reference</title><url>/cpp-templates-the-complete-guide/07-By-Value-or-by-Reference/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  传值：T有 decay。
传左值引用：T &amp;注意遇到数组时可能需要 decay。
注意 T 类型可能是常量，导致 T &amp; 其实是常引用。这样的参数不能被修改，因而不能作为传出参数。可以使用 concept 限定参数非常量：
传转发引用：T &amp;&amp;这是 T 唯一可能匹配到引用类型的情况。如果 T 本身就是引用类型，就不能用它创建值类型的同类数据。解决方法有：① 用 type traits 去除引用属性 ② 使用 auto，因为 auto 默认不会匹配到引用。
传 std::ref 和 std::cref这两个模板函数返回的类型是 std::reference_wrapper&lt;T&gt;，这也是传值的一种，但有其特殊性。该模板类只提供了一个 get() 方法获得原引用和一个隐式转换成原引用的行为，即如果参数是 std::reference_wrapper&lt;T&gt;，就不能直接使用其成员（包括成员函数和成员运算符重载）。
C++ 标准库内置模板类对这种情况做出了处理：使用一个 type traits 去掉外层的 std::reference_wrapper 包装。但是这个 type trait 并没有提供给用户。
  ]]></content></entry><entry><title>CTTCG 08 Compile-Time Programming</title><url>/cpp-templates-the-complete-guide/08-Compile-Time-Programming/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  模板元编程略。
constexpr 函数在 C++11 中只能使用一条语句，而在 C++14 之后可以使用的语句变得丰富。constexpr 函数允许编译期优化，但不阻止运行期使用。作为对比，C++20 consteval 只能在编译期使用。
应用：e.g. 常量表达式函数可以计算出一些基本信息，比如判断一个整数是否为素数，以此做为另一个模板类偏特化的依据。
SFINAEsubstitution failure is not an error
有一些地方需要注意：寻找函数 candidates 时只会考虑函数模板的函数签名，不会考虑函数体。用 C++14 auto 省略掉返回值类型之后，也不会考虑返回值类型。如果匹配完成之后函数体不能编译，编译器就会报错。
Case 1：在返回值中携带约束信息如果注释掉行 [1]，代码将无法编译，这是因为第一个版本被选择了，但是它的函数体编译失败了。留下含 decltype 的箭头返回值声明可以对参数 t 提出更具体的要求。
Case 2：在返回值中携带约束的一般写法上面的代码要求了 T 中有一个类型别名为 size_type。还要求有一个函数 T::size()。注意第一个参数前面被转换成了 void，否则可能因为用户重载了逗号运算符而出现意外的错误。
虽然现在 C++20 已经能够用约束处理此类问题，但是要求”**某类型具有某成员“**的约束需要 requires 体（而不是 requires 条件），也就是必须在 concept 中定义。这样会出现很多意义不是很明显的小 concept（同样也是命名危机）。
用 requires 可以做到类似的存在性检测：
template &lt;typename T&gt; auto len(T const&amp; t) requires(decltype((void)std::declval&lt;typename T::size_type&gt;(), // (void)t.size(), true){true}) (void)t.size(), 0){}, true) // 这两种写法都可以，前面是存在性检测， // 后面的true是其他条件，可以更换成concept组成的表达式 { return t.size(); } if constexpr (…)略。
  ]]></content></entry><entry><title>CTTCG 09 Using Templates in Practice</title><url>/cpp-templates-the-complete-guide/09-Using-Templates-in-Practice/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  包含模型 - The Inclusion Model通常模板需要被包含在头文件中工作。
注意：函数模板完全特化之后也需要 inline 才能够在头文件中使用，否则会出现不同的翻译单元有重复定义的情况。
改进一：precompiled headers可以把 pch 理解为编译器中间工作状态的一个 dump。编译器可以在读取到某些源代码之后保存其状态，包括符号表等。如果两个文件中有公共的前缀代码（比如一个标准库的头文件就包含了数千行公共代码），编译器就可以读取预先保存的状态，从而跳过对于这些代码的处理。
很遗憾的是前缀的判定是必须完全相同，即便改变头文件的包含顺序，其中与宏相关的定义也可能结果不同。由于宏无法从模块中导出，模块将可能解决这一痛点。
改进二：explicit template instantiation只在头文件中留模板函数的声明，而不是定义。然后在其他的源文件中提供特化的定义。
// base.hpp template &lt;class T&gt; T foo(T t); // second.cpp #include &#34;./base.hpp&#34; template &lt;&gt; int foo&lt;int&gt;(int t) { return t; } // main.cpp #include &#34;./base.hpp&#34; int main() { auto x = foo(1); std::cout &lt;&lt; x &lt;&lt; &#39;\n&#39;; } 这样不用所有用到函数模板的翻译单元都去编译一遍函数。缺点是只能依赖枚举提供特化。
注意：在 second.cpp 中只提供通用模板函数定义是无法链接的，因为模板函数只是生成规则，并不是具体的函数，会无法匹配。同时，只在 base.hpp 声明特化的函数而不给出定义，试图依赖 second.cpp 的规则去生成函数也是无法链接的。
// base.hpp template &lt;class T&gt; T foo(T t) { return t;} template &lt;&gt; int foo&lt;int&gt;(int t); // second.cpp #include &lt;iostream&gt; #include &#34;./base.hpp&#34; template &lt;&gt; int foo&lt;int&gt;(int t) { std::cout &lt;&lt; &#34;int foo&lt;int&gt;(int t) is called!\n&#34;; return t; } // main.cpp #include &#34;./base.hpp&#34; int main() { auto x = foo(1); std::cout &lt;&lt; x &lt;&lt; &#39;\n&#39;; } 打印结果：
int foo&lt;int&gt;(int t) is called! 1 这说明如果存在函数特化的声明，则不会使用模板函数的规则去在自己的翻译单元生成这个特化的函数。同样，如果注释掉了 second.cpp 中特化函数的定义，将会链接失败。使用这种方式，既可以避免枚举覆盖面的不完善，又能够为通用的一些函数节约编译时间。
改进三：modules略。
  ]]></content></entry><entry><title>CTTCG 10 Basic Template Terminology</title><url>/cpp-templates-the-complete-guide/10-Basic-Template-Terminology/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html">  Class Template v.s. Template Class前者是生成类的模板，后者既可以指模板，又可以指从模板生成的类。
Substitution, Instantiation, and Specialization参数替代是模板生成相应对象（即实例化）的一个中间环节。 实例化是从模板生成相应对象的动作。 特化是和模板形式相似但匹配程度更高的对象。特化分为实例化（生成式特化）和显式特化（explicit specialization，即人为提供特化函数）。 Declarations versus Definitions函数、类或变量等有了名字，但是定义不完整，就算作声明。
对变量初始化，或者缺少 extern 修饰符（specifier）时，声明就变成了定义。
The One-Definition Rule（ODR）Ordinary (i.e., not templates) noninline functions and member functions, as well as (noninline) global variables and static data members should be defined only once across the whole program. 非内联函数和成员函数、（非内联的）全局和（非内联的）静态变量在整个程序中只能定义一次。 Class types (including structs and unions), templates (including partial specializations but not full specializations), and inline functions and variables should be defined at most once per translation unit, and all these definitions should be identical. 类和不完整的模板、内联函数和变量每个翻译单元中最多定义一次，整个程序中的多个定义必须完全相等。 Global and static variables and data members can be defined as inline since C++17. This removes the requirement that they be defined in exactly one translation unit. C++17 之后全局和静态变量是可以用 inline 修饰的。
Template Arguments versus Template Parameters前者指实参，后者指形参。另外 template-id 指的是 模板名&amp;lt;Arg1, Arg2&amp;gt;。
  </content></entry><entry><title>CTTCG 11 Generic Libraries</title><url>/cpp-templates-the-complete-guide/11-Generic-Libraries/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  CallablesCallable 有很多：函数、函数指针、成员函数、lambda 表达式（函数对象特例）、函数对象（Functor）等。
lambda 表达式lambda 是函数对象。当捕获列表没有参数的时候，lambda 还有一个转换成一般函数指针的隐式转换操作符。在无捕获列表的 lambda 前加上 + 符号，能使得 lambda 变成函数指针也就是这个道理。
std::invoke支持 Callable 并不简单，因为需要考虑到成员函数的调用需要通过 this 指针来完成。C++17 提供了 std::invoke 来将这些操作统一起来，只需要把 this 指针当作第一个参数传入。
Surrogate Function - 从类型隐式转换得来Dummy/Surrogate function（哑函数/替代函数）指的是某一个函数对象还具有一个到普通函数引用或者普通函数指针的隐式转换，这个转换好的函数就是替代函数。替代函数用到了一次隐式转换，所以在参数匹配均不优于函数对象的其他()操作符重载时不会被选中。但若替代函数是更好的替代，将出现函数使用 ambiguous 的情况。
class IndirectFunctor { public: void operator()(double, double) const {} operator auto () const { return +[](double, int) {}; }; }; void activate(IndirectFunctor const&amp;amp; funcObj) { funcObj(3, 5); // ERROR: ambiguous } 上面的代码若将 operator auto() const 中的 lambda 表达式的参数类型改成 (double, double)，该函数就会因为需要一次额外的隐式转换而落选，代码能够正常编译。
Type Traitsstd::decay_t&amp;lt;int const&amp;amp;&amp;gt; → int
remove_const 不能去掉引用的 const 属性，但是 decay 可以。
std::add_rvalue_reference_t&amp;lt;int const&amp;amp;&amp;gt; → int const &amp;amp;
左值引用的右值引用还是左值引 …  ]]></content></entry><entry><title>CTTCG 12 Fundamentals in Depth</title><url>/cpp-templates-the-complete-guide/12-Fundamentals-in-Depth/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  1 参数化声明模板分类模板有四类：类模板、函数模板、变量模板、别名模板。其中别名模板是：
变量模板其实可以不需要 inline（但是最好加上）C++17 中静态和全局变量都能够用 inline 来修饰。这也意味着类中的静态变量不必在类中声明、类外初始化（非头文件），而是可以在类中直接写 inline。之前笔记里面提到的问题里，inline 加不加都没有关系，因为变量模板本身可以在多个翻译单元中出现。P179
嵌套模板的非原地定义想要给类模板中的模板在类外提供定义是比较复杂的，需要嵌套模板参数描述：
这里为了给 Handle 函数模板提供定义写了两次 template 参数列表。
构造函数模板会覆盖默认构造函数虽然类模板的特殊函数模板不会覆盖掉类的同类函数的默认版本，但是如果提供了其他的构造函数模板，默认的构造函数也将不会被定义。这是由默认构造函数的特殊性决定的。
Union templates函数模板默认参数如果调用的时候提供了参数，那么 T const &amp;amp;=T{} 这一句不会被实例化，这意味着即便是 T 没有默认构造函数，在用户了解 fill 函数用法并传入了合法的 T 类型值时，编译也不会失败。
虚函数不支持模板因为虚函数要写入虚表，在编译后必须大小确定，但是模板的实例化是按需进行的，只有链接完成后才能确定函数模板的特化数目。
模板的 linkage函数模板的 linkage 只能是 C++ 类型。如果外围没有 extern &amp;quot;C&amp;quot;，这里的 extern 可以不写。
int const zero_int = int{}; 按照 const 的全局变量规定，是 internal linkage。但是 template&amp;lt;typename T&amp;gt; int const max_volume = 11; 按照变量模板的规定，是 external linkage。
原始模板（Primary template）没有任何参数被特化的模板是原始模板；参数有偏特化就是非原始模板（但因为有参数没有被确定下来因而还是模板）。
2 模板形参（Parameters）模板声明中参数名有时可以省略模板声明就像函数声明，没用到参数名的时候可以省略参数名。比如 template &amp;lt;typename, int&amp;gt; class …  ]]></content></entry><entry><title>CTTCG 13 Names in Templates</title><url>/cpp-templates-the-complete-guide/13-Names-in-Templates/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html">  名字查找：普通查找和 ADL普通查找和 ADL 是同时进行的，不存在优先级差异。这些被找到的函数被放在一起参与重载决议。如果没有因为一般性的重载决议规则决出优劣，则会引发 ambiguous 指代错误。
Ordinary lookup: 内部名称遮盖外部名称的规则ADL: 考虑参数类型所在名字空间的函数和操作符重载相关类型有很多规则，比如指针会引入其指向类型的名字空间、类会引入外围类（如果是一个内部类）和基类的名字空间、函数会引入其参数和返回值的名字空间等（P219）。特例是 hidden friends，可以直接定义在类中。
ADL 失效的情况：① 调用前给函数名加上括号，这样就必须先找到函数。② 函数模板在 C++20 之前除非在外部声明函数模板（参数列表可以不同），否则也无法被找到。因为在还没有看参数的情况下，函数模板没有被引入；还没有看参数列表的情况下不知道这个是函数模板；不知道这个是函数模板的情况下会把参数列表的头尾理解成大于和小于操作符。这是一种鸡生蛋蛋生鸡的问题。③ ADL 会忽略 using 声明，只考虑真正存在于名字空间的函数。
ADL 只会通过参数（也就是显式调用）引入额外的函数和操作符，其他情况下这些名称是不会被自动引入的，比如取一个和参数相关的函数指针。
名称注入术语在名字查找中，enclosing scope 指外围作用域。
非限定名（non-qualified）指的是前面没有 :: 的名称。限定名相反。
Friend Name Injection（友元函数）hidden friends 就是友元名注入中完全把函数定义写在类中的特例。但事实上 friend name injection 只对 ADL 有效，并不会真的注入到 enclosing scope 中。
Class Name Injection定义一个类时，类名会作为非限定名被向内注入到类的定义体中（限定名 T::T 则用来表示构造函数名）。
BTW，sizeof 优先找到变量名而不是类名：
类模板的情况会复杂一些。向内注入的非限定名既可以指模板，又可以指模板类。如果想要显式表示模板，可以使用限定名。
Current Instantiation 和 Unknown Specialization💡 current instantiation 对模板参数有依赖（ …  </content></entry><entry><title>CTTCG 15 Template Argument Deduction</title><url>/cpp-templates-the-complete-guide/15-Template-Argument-Deduction/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  2023 年 5 月 17 日
推导上下文：Deduced ContextP272 书上
依赖于模板类型的子类型不是推导上下文。比如 typename X&amp;lt;N&amp;gt;::I 不是。而 X&amp;lt;N&amp;gt;::* 这样的指向成员的指针没有用到子类型，所以是推导上下文。 非类型模板参数的非平凡表达式不是推导上下文。比如模板 S 和参数 I，S&amp;lt;I+1&amp;gt; 无法提供推导信息。 如何推导出模板参数从参数列表中推导（推导能力是有限制的，比如不能从 typename T::iterator 参数中推出 T 的类型） 函数模板被取地址时，可以从要求的返回值类型推导： template&amp;lt;typename T&amp;gt; void f(T, T); void (*pf)(char, char) = &amp;amp;f; // f的参数T由函数指针的类型确定 隐式转换操作符模板的类型参数 T 由需要转换时所需的类型决定。 模板尝试匹配的时候不适用 common type。 比如两个 T 类型分别被认为是 int 和 double 时，会导致模板替换失败，而不是把 T 认为是 double。比如
template &amp;lt;class T&amp;gt; T max(T a, T b) { return a &amp;gt; b ? a : b; } 调用 max(1, 3.0) 就会失败，而调用 max&amp;lt;double&amp;gt;(1, 3.0) 才能成功（模板参数被人为指定之后就允许隐式类型转换了）。
特例：初始化列表初始化列表没有确定的类型，因此不能绑定在参数类型 T 上面。但是如果参数类型为 std::initializer_list&amp;lt;T&amp;gt;，则能够尝试绑定（当所有元素类型相同时成功）。
#include &amp;lt;initializer_list&amp;gt; // 如果把参数类型从初始化列表改成 T 就会推导失败 template&amp;lt;typename T&amp;gt; void f(std::initializer_list&amp;lt;T&amp;gt;) {} int main() { f({2, 3, 5, 7, 9}); // OK: T is deduced to int f({’a’, ’e’, ’i’, ’o’, ’u’, 42}); // ERROR: T deduced …  ]]></content></entry><entry><title>CTTCG 16 Specializations and Overloading</title><url>/cpp-templates-the-complete-guide/16-Specializations-and-Overloading/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html">  大部分都不需要专门总结，因此这一小节为空。
  </content></entry><entry><title>CTTCG 17 Future Directions</title><url>/cpp-templates-the-complete-guide/17-Future-Directions/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html">  这一章讲的是对未来的展望。
浮点数和字符串作为模板参数浮点数在 gcc C++20 是可以作为非类型模板参数（NTTP）的；clang 不支持。目前 C++ compiler support - cppreference.com 上也看不到相关的支持项目。
字符串字面量在 C++20 只能通过隐式转换成简单的对象实现模板参数。15/特例：变参列表/参数包 一节有描述。字符数组则是早就可以作为模板参数，尽管作为引用其 linkage 在 C++11 和 C++14 有额外的要求。
当前 class type 和浮点数没有作为非模板参数得到全面的支持，原因很可能是相等性比较在链接阶段很难进行（浮点数的标准可能不同，或者因为精度缺失会误判；类可能会重载比较操作符）。
减少类模板 pack expansion 的限制目前不能在类模板参数中使用多个 pack expansion，而且使用时也必须把它放在最末尾的位置；不仅模板参数声明是这样，填充类模板参数也是这样。
将 void 作为一种常态类型其他章节中提到了当函数返回值是 void 时，不能将其绑定在变量上，即便这个变量今后不会被使用。Kotlin 就用了 Unit 类型来处理这个问题，C++ 很难改这一点了。
  </content></entry><entry><title>CTTCG 18 The Polymorphic Power of Templates</title><url>/cpp-templates-the-complete-guide/18-The-Polymorphic-Power-of-Templates/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html">  C++ 的多态有两类：bounded dynamic polymorphism 和 unbounded static polymorphism。前者 bounded 指的是虚函数有基类的接口，其行为有一定约束；后者 unbounded 指的是模板采用类型替换的方式生成代码。为了给静态多态提供约束，可以使用 enable_if 或 concept。
  </content></entry><entry><title>CTTCG 19 Implementing Traits</title><url>/cpp-templates-the-complete-guide/19-Implementing-Traits/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html">  Trait 分类不一定大家都这么叫，但是为了方便，我规定下面的术语：
Type Trait：包含一个 type alias。 Value Trait：包含一个 value 静态成员，可以是任何基本类型，含义和具体 Trait 相关。 Predicate Trait：包含一个 value 静态成员，类型为 bool，含义为条件是否被满足。 书中有分为 property trait 和 policy trait 两大类。前者包含我所称的 type trait 和 value trait，含义是类型本身的固有信息；后者表示根据一个特定类型选择某种映射，其含义和要实现的行为有关，文中的例子是对 size 小的参数选择原类型，对 size 大的参数选择引用类型。
Traits v.s. Policies例子是累加算法的模板实现。
Traits 一般表示和类型有关的静态的信息；Policies 表示行为。累加例子中 Traits 包含加法结果的类型，而 Policies 则包含了加法的执行过程。
std::iterator_traits标准库中的一个工具类模板。
可以看出它能提供迭代器的各种信息，方便我们用函数模板实现算法。
Transformation Traits可以加减引用（加引用的时候需要区分左右引用，去引用的时候不区分）、volatile、const、decay 等等。 C++20 新增了 std::remove_cvref_t，是对原来 std::remove_reference_t 和 std::remove_cv_t 的组合。 std::decay_t 相当于：函数退化 + 数组退化 + std::remove_cvref_t 技巧：通过 public 继承减少代码量由于 type 或者 value 这些在 type traits 中需要的属性是作为静态成员提供的，因此可以提前写好 trait 可能的几种匹配结果，然后用 public 继承简化代码，这样基类的 trait 属性就会在子类（提供出来的接口）中可见。
Predicate Traits可以获取 true 或 false 的值。就算不获取值，其包装类型 的 std::true_type 和 std::false_type 也可以进行 tag dispatching。需要注意 C++17 才引 …  </content></entry><entry><title>CTTCG 19.1 用 SFINAE 实现 Traits</title><url>/cpp-templates-the-complete-guide/19.1-%E7%94%A8-SFINAE-%E5%AE%9E%E7%8E%B0-Traits/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html">  原理是用 SFINAE 机制安全地匹配几个函数或函数模板，然后再通过函数匹配信息将结果（true or false）嵌入 Trait 类中。Trait 约束条件被包含在函数模板的声明中。
实现 traits 最核心的要点是模拟被替换类型的行为，然后让行为不满足的那些替换被 SFINAE 筛掉。
函数返回基本类型 → 静态常量定义类模板实例化时会调用 test 函数，如果条件命中则优先匹配 char test(void *)，否则匹配另外一个。通过判断匹配到的函数的返回值类型可以确定条件是否被命中。这里的条件是类型 T 可以默认构造。
⚠ 如果把第一个 test 的参数 U 去掉，默认参数改成 typename = decltype(T())，就无法编译。因为 T 会在实例化时被替代过去，导致函数模板本身定义有错误。这个过程没有发生在函数模板匹配阶段，不会受到 SFINAE 的保护。
也有通过判断返回值的类型大小确认是否命中的实现。但是在有些低性能设备上所有的整型可能具有相同的大小，因此有必要使用 char 和 char (&amp;amp;amp;)[2] 等手段来保证返回值的大小不同。
函数返回标准库的常量 Trait → alias 模板这里的 IsDefaultConstructibleHelper 包装了 Type。所以还需要继承一次取得和 C++ 标准库相同形式的 Trait 类。
如果上面的工具方法裸露在外面，就能用 alias template 直接得到 Trait 类：
打印的结果是 0 和 1（各占一行）。
（最简单）偏特化 + 继承常量 Trait这种用法也是在标准库中大量出现的。
上面通过偏特化和继承直接达到了目的。这种写法更加简单，因为判断只有二元性，因此只需要提供原始模板 1 次，然后偏特化 1 次。C++17 已经有了 std::void_t 模板，能够达到和上面的 VoidT 相似的效果。
在这个原始模板中，模板参数默认值可以直接写成 typename = void，不用写 typename = VoidT&amp;amp;lt;&amp;amp;gt;。
__cpp_lib_void_t 是一个编译器宏。C++标准倡导编译器使用类似的宏以标志是否已经实现某一个语言特性。
（最通用）用 generic lambda 构造 Traits …  </content></entry><entry><title>CTTCG 20 Overloading on Type Properties</title><url>/cpp-templates-the-complete-guide/20-Overloading-on-Type-Properties/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  TLDR：几种 SFINAE 的模式对于函数参数列表非空的函数模板，可以用非 varargs 函数实现功能，varargs 作为 fallback。 类模板可以用偏特化实现功能重载，用带模板默认参数的原始模板作为 fallback。 模板用 tag dispatching 不会有重复定义的问题。 std::enable_if 用在函数模板的模板默认参数上表达更简洁，但用在返回值上可避免重复定义。对比起来，类模板虽然能支持偏特化，但是也没有用返回值 SFINAE 避免重复的好处。（不过 C++20 有了 requires 就无所谓了。） concept、constexpr if 等。 1 和 2 其实分别适应了函数模板和类模板的特点：函数模板不能偏特化，类模板不是函数因而不能使用 varargs。
几个难点：
找不到能匹配的函数：需要设计 fallback。 找到了多个能匹配且优先级不能区分的函数（ambiguous）：需要设计互斥条件。 重复定义同一模板（只有模板默认参数不同）：std::enable_if 使用不当。可以再增加一个默认参数缓解问题，或者把 std::enable_if 放在返回值位置上。 函数模板的重载简单提供参数不同的重载这种方式只能直接对类型本身匹配，不能对行为或类型背后的含义提出要求。
Tag Dispatching 和 std::enable_if本节讨论了两者的在算法特化场景下的区别。前者能够做到完全互斥，但是写起来可能会比较冗长。后者判断更加灵活，但是需要注意保证互斥性（否则 ambiguous），每次添加一个新的特化都要去检查之前的特化是否需要修改；同时还要考虑重复声明的问题。
举例是标准库的迭代器就有 5 类，而且还有继承关系。这意味着我们可以用 std::is_convertible 作条件。
std::enable_if 的重复声明问题默认参数的指定在函数模板定义时是不被考虑的。如果有两个模板函数使用了 template &amp;lt;typename T, typename = std::enable_if_t&amp;lt;...&amp;gt;&amp;gt; 的模板参数，就会有重定义错误。一个缓解的方法是再加一个默认参数：
是不是可以结合两者的优势做一个适配器 Trait，将几种 Trait 用 std::conditional 嵌套归类（ …  ]]></content></entry><entry><title>CTTCG 21 Templates and Inheritance</title><url>/cpp-templates-the-complete-guide/21-Templates-and-Inheritance/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  零开销继承：空基类优化（EBCO）The Empty Base Class Optimization (EBCO)
C++ 没有真正零大小的类，因为在数组等场景需要用地址区分元素。一般编译器上空类的大小是 1 个字节。不过，当基类为空时，EBCO 会使得基类在子类中不占空间。但是 EBCO 的适用有条件。下面的场景是从实践中观察出来的，可能并没有被标准定义，但它演示了 EBCO 失效：
定义“空基类组”的概念：如果空类型 B 继承了空类型 A，那么 B 和 A 可以存在于同一个空基类组（看成并查集会比较好理解）。和其他空类型不相关的类型可以认为自为一组。 某类型 C 继承了一个大小为 N 的空基类组，那么它至少具有 N 个字节。如果这个类型 C 不是空类型，则还有对齐要求。 继承多个空基类组，对子类对象所占用空间的要求等效于继承于最大的那个空基类组。 struct E1 {}; struct E2 : E1 {}; struct E20 {}; struct E21 : E20 {}; struct E22 : E20 {}; struct E23 : E20 {}; struct E24 : E20 {}; struct B : E1, E2, E20, E21, E22 { // int a; }; int main() { std::cout &amp;lt;&amp;lt; &amp;#34;sizeof(d): &amp;#34; &amp;lt;&amp;lt; sizeof(B) &amp;lt;&amp;lt; &amp;#39;\n&amp;#39;; // 输出为 3 // 如果 B 中还有个整形元素 a，输出为 4 // 如果 B 中还有个整形元素 a，并再继承空类 E23 和 E24，输出为 8（5对齐到4的倍数） } 空成员优化如果类中有一个空类的对象，那么它将无法适用 EBCO。将其改造为继承可以节约空间。
类模板由于事先不能确定参数类型，很难保证能够安全继承参数类型（比如参数类型可能是不可继承的、多个参数的实际类型相同因而引发了多次继承的编译错误等）。
下面的类模板把一个参数作为基类，一个参数作为成员，避免了多次继承同一类型的错误。而且这个类型也是可以被继承的。唯一的要求就是 Base 对应的类型可以继承。
第 25 章的元组实现会继续探讨相似的话题。
The Curiously Recurring …  ]]></content></entry><entry><title>CTTCG 22 Bridging Static and Dynamic Polymorphism</title><url>/cpp-templates-the-complete-guide/22-Bridging-Static-and-Dynamic-Polymorphism/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  类型擦除主要讲的是类型擦除，例子是 std::function 类模板。特殊情况：std::function&lt;void(void)&gt; 和 std::function&lt;void()&gt; 是同一个类型。
实现思路std::function 原始模板捕获了函数类型。 template&lt;typename Signature&gt; class FunctionPtr; std::function 的偏特化能够获得函数的返回值和函数参数包的类型。 template&lt;typename R, typename... Args&gt; class FunctionPtr&lt;R(Args...)&gt; { ... } std::function 包含了一个函数对象基类的指针，这个基类指针有一个 invoke 虚函数，返回值和函数参数类型与模板参数对应。std::function 被调用时，会将调用转发到这个函数对象上。 实现构造模板函数、赋值模板操作符时，捕获传入的对象，生成一个继承于函数对象基类（之前提到过）的子类对象，其 invoke 虚函数的实现就是转而调用这个对象的 () 操作符。 template&lt;typename Functor, typename R, typename... Args&gt; class SpecificFunctorBridge : public FunctorBridge&lt;R, Args...&gt; { Functor functor; ... } 子类对象就是通过上面的模板创建的。模板参数 Functor 对应于捕获对象的存储类型，书中的定义为 using Functor = std::decay_t&lt;F&gt;（F 为捕获对象的真实类型）。
书中还实现了 FunctionPtr 的比较操作符，当捕获对象不支持 == 时，将会在运行时抛出异常。std::function 只对和空指针的比较实现了 == 操作符。
性能主要考虑动态分配内存和虚函数调用两个环节。
约束检查类型擦除不代表将静态语言变成动态语言。使用 Boost 的 TypeErasure 库：
using AnyPrintable = any&lt;mpl::vector&lt; copy_constructible&lt;&gt;, typeid_&lt;&gt;, ostreamable&lt;&gt; &gt;&gt;; 这对里面可包含的类型进行了约束检查，不满足约束的类型赋值（或构造）会在编译期被拒绝。
实现细节: 用 swap 实现赋值操作符可以复用构造函数：
创建临时对象（在移动赋值且参数类型与目的类型相同时可以省略这一步） 引入 std::swap（可选） 调用 swap libstdc++ 中的 std::function 实现参考另外一篇笔记。
一个简单的实现https://godbolt.org/z/dqTWW4733
#include &lt;iostream&gt; #include &lt;memory&gt; template &lt;typename FuncT&gt; struct Function; template &lt;typename R, typename... Args&gt; class Function&lt;R(Args...)&gt; { public: Function() = default; template &lt;typename T&gt; Function(T obj) { reset(std::move(obj)); } // TODO: operator=. // TODO: move/copy constructors. R operator()(Args &amp;&amp;...args) { if (!impl) { throw std::runtime_error{&#34;no associated function object&#34;}; } return impl-&gt;operator()(std::forward&lt;Args&gt;(args)...); } private: template &lt;typename R1, typename... Args1&gt; struct Impl { virtual R1 operator()(Args1 &amp;&amp;...args) = 0; virtual ~Impl() = default; }; template &lt;typename T&gt; void reset(T obj) { struct DerivedImpl : Impl&lt;R, Args...&gt; { DerivedImpl(T obj) : obj_(std::move(obj)) {} R operator()(Args &amp;&amp;...args) override { return obj_(std::forward&lt;Args&gt;(args)...); }; T obj_; }; //- TODO: handle exception. //- impl.reset((Impl&lt;R, Args...&gt; *)new DerivedImpl{std::move(obj)}); //+ std::unique_ptr&lt;Base&gt; 可以从 std::unique_ptr&lt;Derived&gt; 转换而来！ impl = std::make_unique&lt;DerivedImpl&gt;(std::move(obj)); } std::unique_ptr&lt;Impl&lt;R, Args...&gt;&gt; impl; }; int main(int argc, char **argv) { Function&lt;int(int)&gt; identity = [](int a) { return a; }; Function&lt;int(int)&gt; twice = [](int a) { return a * 2; }; std::cout &lt;&lt; identity(3) &lt;&lt; std::endl; std::cout &lt;&lt; twice(3) &lt;&lt; std::endl; Function&lt;void(std::string const &amp;)&gt; println = [](std::string const &amp;s) { std::cout &lt;&lt; s &lt;&lt; std::endl; }; println(&#34;hello&#34;); }   ]]></content></entry><entry><title>CTTCG 23 Metaprogramming</title><url>/cpp-templates-the-complete-guide/23-Metaprogramming/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  分类现在值元编程已经能够很好地被 constexpr 函数取代。
类型元编程例子：std::chrono 中的时间单位用分数表示，两个时间单位的加和的单位可以在运行时确定——尽管分母很可能会变化。
混合元编程例子：
时间的相加。时间单位可以最终确定，但是由于给单位施加的量在运行时确定，所以需要运行时计算。同时除了量之外，其他的表达式都可以在编译期得到简化。 强制循环展开。比如： template &lt;typename T, std::size_t N&gt; struct DotProductT { static inline T result(T *a, T *b) { return *a * *b + DotProductT&lt;T, N-1&gt;::result(a+1, b+1); } } template &lt;typename T&gt; struct DotProductT&lt;T, 0&gt; { // 偏特化 static inline T result(T *, T *) { return T{}; } } 在这个例子中尽管 a 和 b 两个数组的值是不知道的，但是能够知道迭代的次数（N），从而将 result 函数展开为一个非常长的计算表达式（这个函数本身是内联函数）。当然手动循环展开可能不如编译器决定更有效，而且 inline 也不一定能保证必定内联。
模板递归实例化的代价对于二分查找的模板，递归复杂度按理来为 O(log(N))。但决定分支的时候需要注意：
static inline constexpr auto value = std::conditional&lt;(N &lt; mid * mid), Sqrt&lt;N, LO, mid-1&gt;::value, Sqrt&lt;N, mid, HI&gt;::value&gt;; 上面直接访问 value 的做法会导致两边都全实例化（full instantiation）。结果不只是实例化数量加倍，而是实例化数量变成 O(N) 级别！因为不被选中的一边会继续向下实例化。所以要尽可能避免这种写法。
嵌套递归实例化的代价更大。嵌套递归实例化指的是上层递归使用了下层作为其参数中的一个。这样会导致模板名变得很长，在以前编译器对内部表示名没有特殊优化时这会通过更长的字符串加重编译器的负担。
enum早期的模板元编程中 enum 是生成编译期间常量的唯一方式，因为枚举项一定是纯右值，不用担心传入接受常引用的函数中时编译器老老实实传地址不给优化。
C++11 加入了 constexpr，被广泛使用。C++17 允许 static inline，这解决了地址问题。
  ]]></content></entry><entry><title>CTTCG 24 Typelists</title><url>/cpp-templates-the-complete-guide/24-Typelists/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  本章介绍了构建类型列表的技巧。既然类型列表可以使用这类技巧，值列表当然也可以在编译期完成类似的计算。
类型列表一开始是用可变长参数列表定义的。
template &lt;typename... Elements&gt; class Typelist {}; 很容易使用偏特化手段为 Typelist 定义 Front trait，以此获得列表的第一个元素。当然这要求类型列表非空，否则不能完成实例化。
类似地，可以定义下面一系列操作：
PopFront：获得列表去掉第一个元素的剩余列表 PushFront：为列表前面添加一个元素得到新的列表 Back：获得最后一个元素 PopBack：去掉最后一个元素的剩余列表 PushBack：为列表后面添加一个元素得到新的列表 IsEmpty：检查列表是否为空，这将被用来进行派发操作，比如：template&lt;typename List, bool Empty = IsEmpty&lt;List&gt;::value&gt; class LargestTypeT; 作为原始模板，不提供定义。然后分别为两种情况提供偏特化定义。 Transform：使用一个类模板作为参数，用这个类模板将列表中的每个类型进行类型转换。这可以用递归实现，也能使用更高效的折叠表达式实现。 NthElement：递归去掉列表的头 N 个元素，新列表的第 0 个元素就是要找的元素。 Select：通过下标列表和 NthElement，使用折叠表达式和拼接操作，选出类型列表的子序列。 InsertionSort：取下列表的第 0 个元素，和列表的第 1 个元素进行比较，决定拼接和排序的顺序。 非类型列表：将数值信息作为参数嵌入到类型中。比如：CTValue&lt;int, 2&gt; 中携带了类型和常量数字 2。
在变长参数模板出现之前，类型列表通常使用 Lisp Cons 的方式定义。 这样做会让模板名因为模板嵌套变得很长，可读性降低。
  ]]></content></entry><entry><title>CTTCG 25 Tuples</title><url>/cpp-templates-the-complete-guide/25-Tuples/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html">  类型计算可以在编译期间完成，取值的部分仍然是运行时操作。在 libc++ 中被实现成多继承+反序构造，在 libstdc++ 中被实现成双继承+正序构造。
Base将元素包裹在 Base 中再继承可以利用到 EBCO（可优化时继承元素，不可优化时将元素作为成员）。通过给 Base 类模板添加下标作为参数，可以区分类型相同的元素。
get 函数按下标获取：无论是 parameter pack 继承还是递归继承，由于有编号的存在，每个元素被存储位置的对应类型都是可以区分的。将 *this 转换成基类的引用再调用对应的 get() 方法（这个是 Base 的 get() 方法，不是元组的），或者直接用基类名作为限定名调用对应方法就能实现 get。
按类型获取：逐个比较类型，直到类型相符。然后得到对应位置的下标，调用“按下标获取”的 get 重载版本。如果被指定的类型出现了多次，则应该造成编译失败。
reverse（反转元组）尽管可以像上一章实现 Typelist 一样频繁拼接，但 Typelist 的拼接是在编译期间完成的，而元组的拼接是运行时操作，会造成多次数据拷贝（而且越靠近中间的数据拷贝次数越多）。
比较好的做法是构造从 N-1 到 0 的整数序列（C++ 标准库有构造从 0 到 N-1 的增序列的模板，却没有提供反向的），然后用 get 函数和 fold expression 构造参数列表，再传给元组的构造函数以便构造。这个过程只需要拷贝一次数据。
unpack / expandingstd::apply （C++17）可以将 std::tuple 解包传入函数。
  </content></entry><entry><title>CTTCG 26 Discriminated Unions</title><url>/cpp-templates-the-complete-guide/26-Discriminated-Unions/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  本章想要实现的类模板相当于 std::variant。 可以用递归 union 模板，也可以用字符数组存储，本章选用的是后者。
使用字符数组存储未知元素，需要注意：
使用 alignas(Types...) 属性标识字符数组的对齐大小，否则强制类型转换后对齐大小和目的类型可能不相符。
使用 返回 后的指针。std::launder 可以提示编译器某个地址中的值发生了改变，甚至类型都可能变化了，以避免编译器分析变量的生命周期并进行激进的优化。
https://stackoverflow.com/a/39382728/
[basic.life]/8 tells us that, if you allocate a new object in the storage of the old one, you cannot access the new object through pointers to the old. launder allows us to side-step that.
数据结构书中的实现是让 Variant 继承了 VariantStorage 模板和 VariantChoice 模板。
前者提供存储空间、discriminator（标识当前存储的是哪个类型）和转换成任何指针的能力（通过 std::launder 禁止激进优化）。 后者使用 CRTP 提供一堆构造、赋值函数（Variant 中需要用 using pack expansion 导入），以及析构所用的 destory() 函数。为了让 CRTP 正常工作，Variant 模板需要将 VariantChoice 模板声明为友元。 Each VariantChoice base class is responsible for handling the initialization, assignment, and destruction when the active value has type T.
功能实现is&amp;lt;T&amp;gt;()用来判断是否为对应类型。获取 discriminator 和 T 类型所在的 index 比较即可（找一个类型所在的 index 和在 Typelist 和 Tuple 实现是一样的）。
get&amp;lt;T&amp;gt;()用来获取某个类型的值。首先检查 …  ]]></content></entry><entry><title>CTTCG 27 Expression Templates</title><url>/cpp-templates-the-complete-guide/27-Expression-Templates/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html">  表达式模板解决了什么问题表达式模板主要用在大数组的计算上。以相加为例，应该支持的操作有：同长度的数组相加、数组和标量的相加。有时候表达式比较复杂，会涉及多个操作，这种场景下，手工编写代码效率高，但是需要自己控制循环；使用模板编写代码则需要想办法把操作一次性完成，避免多次内存分配和内存访问。
标准库中的 std::valarray 就是想要解决这一类问题，但是其实现因为历史原因可能算不上高效。
例子：
Array&amp;lt;double&amp;gt; x(1000), y(1000); ... x = 1.2*x + x*y; 如何设计上面的代码？
反面例子：
tmp1 = 1.2*x; // loop of 1,000 operations // plus creation and destruction of tmp1 tmp2 = x*y; // loop of 1,000 operations // plus creation and destruction of tmp2 tmp3 = tmp1+tmp2; // loop of 1,000 operations // plus creation and destruction of tmp3 x = tmp3; // 1,000 read operations and 1,000 write operations 这种模式把几个操作符的计算分开，不仅每次都要分配大量内存，而且还需要访存多趟（趟：pass，指对所有元素遍历一次）。
解决方案：使用代理类模板（本章节说的表达式模板），对表达式的下标运算符重载，使得嵌套后外层的下标访问能够实际指代一个对应位置的表达式。表达式模板本身不存储数据，而且对对应位置也只需要一趟访存，因而效率很高。对于上面的例子，表达式模板的结构可能是这样的：
其中 Array 模板有两个参数，分别是元素类型 T 和表示类型 Rep。通过 Rep 参数，我们可以把表达式模板（本身不存储值）和数组模板统一在一起定义操作。
表达式模板的局限性本章节涉及的表达式模板只能解决一趟遍历，新元素值只依赖于当前元素或（和）当前元素之前的元素的问题。矩阵运算这样的新元素依赖多个不同位置元素值的问题不能用表达式模板解决，因为表达式模板本身不存储值，改写今后要使用的元素会让结果不正确。
  </content></entry><entry><title>CTTCG 28 Debugging Templates</title><url>/cpp-templates-the-complete-guide/28-Debugging-Templates/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  Shallow Instantiation作用：早点暴露参数校验错误，避免在一堆模板实例化失败的信息中找错误。
可以用 static_assert 或者定义无用类：
这样在实例化 shell 函数的时候还会实例化其中的 ShallowChecks 类，从而确保参数能够解引用。
Archetypes作用：测试文档的描述是否精确定义了模板算法对参数的要求。
原型是模拟文档中描述的行为的最小类型。比如文档可能如下：
// T must be EqualityComparable, meaning: // two objects of type T can be compared with == and the result converted to bool template&lt;typename T&gt; int find(T const* array, int n, T const&amp; value); 而实现可能如下：
template&lt;typename T&gt; int find(T const* array, int n, T const&amp; value) { int i = 0; while(i != n &amp;&amp; array[i] != value) ++i; return i; } 实际上使用的是 != 操作符，这需要被检查出来。如果改成：
template&lt;typename T&gt; int find(T const* array, int n, T const&amp; value) { int i = 0; while(!(i == n) &amp;&amp; !(array[i] == value)) ++i; return i; } 又需要保证比较的结果能够使用 ! 单目运算符，同时结果还能上下文转换成 bool 类型。如果比较结果可以转换成 bool 类型，但是其 ! 运算符被显式删除，则不能满足上述条件。写 Archetype 其实就是在写测试。
Tracers / Oracles作用：收集信息，检查模板算法的执行流程，评估模板算法的性能等。
都指的是能满足约束的参数，而且这种参数具有收集信息的功能：
class SortTracer { private: int value; // integer value to be sorted int generation; // generation of this tracer inline static long n_created = 0; // number of constructor calls inline static long n_destroyed = 0; // number of destructor calls inline static long n_assigned = 0; // number of assignments inline static long n_compared = 0; // number of comparisons inline static long n_max_live = 0; // maximum of existing objects ... public: // constructor SortTracer (int v = 0) : value(v), generation(1) { ++n_created; update_max_live(); std::cerr &lt;&lt; &#34;SortTracer #&#34; &lt;&lt; n_created &lt;&lt; &#34;, created generation &#34; &lt;&lt; generation &lt;&lt; &#34; (total: &#34; &lt;&lt; n_created - n_destroyed &lt;&lt; &#34;)\n&#34;; } // copy constructor SortTracer (SortTracer const&amp; b) : value(b.value), generation(b.generation+1) { ++n_created; update_max_live(); std::cerr &lt;&lt; &#34;SortTracer #&#34; &lt;&lt; n_created &lt;&lt; &#34;, copied as generation &#34; &lt;&lt; generation &lt;&lt; &#34; (total: &#34; &lt;&lt; n_created - n_destroyed &lt;&lt; &#34;)\n&#34;; } // destructor ~SortTracer() { ++n_destroyed; update_max_live(); std::cerr &lt;&lt; &#34;SortTracer generation &#34; &lt;&lt; generation &lt;&lt; &#34; destroyed (total: &#34; &lt;&lt; n_created - n_destroyed &lt;&lt; &#34;)\n&#34;; } ... 如果某个算法模板使用了上面的构造、析构等功能，这个类型的静态属性就能收集到数据。在算法运行前后统计数据的差值就能知道算法对各操作符或特殊函数的调用次数。
  ]]></content></entry><entry><title>CTTCG 附录 B Value Categories</title><url>/cpp-templates-the-complete-guide/0-B-Value-Categories/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  对于变量而言，其括号表达式的值类别是左值引用。但由于 decltype 有特殊效果，直接对变量 x 使用 decltype(x) 并不遵循这一点，为此可以按照下面说的使用 decltype((x))。
With the keyword decltype (introduced in C++11), it is possible to check the value category of any C++ expression. For any expression x, decltype((x)) (note the double parentheses) yields:
type if x is a prvalue type&amp; if x is an lvalue type&amp;&amp; if x is an xvalue The double parentheses in decltype((x)) are needed to avoid producing the declared type of a named entity in case where the expression x does indeed name an entity (in other cases, the paren-theses have no effect). For example, if the expression x simply names a variable v, the construct without parentheses becomes decltype(v), which produces the type of the variable v rather than a type reﬂecting the value category of the expression x referring to that variable.
例子：
#include &lt;iostream&gt; template&lt;typename T&gt; struct value_category { static constexpr auto value = &#34;prvalue&#34;; }; template&lt;typename T&gt; struct value_category&lt;T&amp;&gt; { static constexpr auto value = &#34;lvalue&#34;; }; template&lt;typename T&gt; struct value_category&lt;T&amp;&amp;&gt; { static constexpr auto value = &#34;xvalue&#34;; }; // Get value category of an expression #define VALUE_CATEGORY(expr) value_category&lt;decltype((expr))&gt;::value #define PRINT(expr) printf(&#34;(%s) : %s\n&#34;, #expr, VALUE_CATEGORY(expr)) int main() { PRINT(4); // prvalue int x; int &amp;y = x; int &amp;&amp;z = (int &amp;&amp;)x; PRINT(x); // lvalue PRINT(y); // lvalue PRINT(z); // lvalue PRINT(x+1); // prvalue }   ]]></content></entry><entry><title>CTTCG 附录 D Standard Type Utilities</title><url>/cpp-templates-the-complete-guide/0-D-Standard-Type-Utilities/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html">  这一章介绍的大都是用来查询类型属性的 type traits。还有一些其他的工具。
按数据概念分类下面是基本（primary）类型，范围都是互斥的，而且任何一个类型必然使得下面中的一个且仅有一个评估为真：
（C++14 之前没有 is_null_pointer，所以那个时候 nullptr 的类型 std:: nullptr_t 是个特例。）
上面的类型判断的时候会忽略外层的 cv 属性。图来自书中 Table D.1. Traits to Check the Primary Type Category。
还有一些复合分类，这里省略。
Table D.2. Traits to Check for Composite Type Category
查询特定属性Table D.3. Traits to Test Simple Type Properties
比如判断是否为 pod、抽象类、final 类等。
std::is_pod 被标记为过时，建议使用 is_standard_layout_v &amp;amp;&amp;amp; is_trivial_v 两个 trait 组合起来判断。
查询是否具有某个特定操作Table D.4. Traits to Check for Speciﬁc Operations
比如能够复制构造、能够复制赋值等。
判断类型之间关系Table D.5. Traits to Test Type Relationships
比如 std::is_base_of。
类型构造Table D.6. Traits for Type Construction
比如加引用、去掉 cv 属性之类的。得到的是新类型，而不是 true 或 false 的回答。
其他图出自 Table D.7. Other Type Traits。
逻辑运算图来自 PDF 第 770 页（书中页码 735 页）。
非类型萃取工具前者用于创建对应类型的对象用于非评估环境的类型计算；后者用于获取对象的真实地址。
  </content></entry><entry><title>CTTCG 附录 E Concept</title><url>/cpp-templates-the-complete-guide/0-E-Concept/</url><categories><category>cpp-templates-the-complete-guide</category></categories><tags><tag>cpp</tag><tag>cpp-templates-the-complete-guide</tag></tags><content type="html"><![CDATA[  定义和使用 concept下面演示了几种 C++20 支持的定义 concept 的方式，每一条约束都是以下之一，然后用分号结尾：
类型 表达式 { 表达式 } noexcept -&gt; 检查返回类型是否满足其他约束（这个 noexcept 可以不要） 引入其他 requires 表达式 template &lt;typename T&gt; concept StringConcept = requires(T t) { typename T::iterator; // 1. 检查类型存在性 t.data(); // 2. 检查表达式合法性 // 3. 将表达式作为 concept 的第一个参数，要求 concept 成立（额外参数从第二个参数起放置） { t.c_str() } -&gt; std::same_as&lt;char const *&gt;; // 4. 用 requires 语句引入子条件 requires std::is_pointer_v&lt;decltype(t.data())&gt;; // 5. 除了 requires 体之外还能用其他编译期常量表达式做约束 } &amp;&amp; (sizeof(T) &gt; 8) &amp;&amp; !std::is_aggregate_v&lt;T&gt;; template&lt;StringConcept Str&gt; void takeString(Str const &amp;s) { } int main() { takeString(std::string{&#34;hello&#34;}); } 在模板中加上 requires 条件则相对比较简单。只需要在 模板参数后，函数返回值前面，或者 函数体前面 加上 requires 约束。requires 约束能使用一般的条件表达式，也能把 concept 当成 type trait 使用。比如：
template &lt;typename T&gt; requires HasPlus&lt;T&gt; int f(T p) {} template &lt;typename T&gt; int g(T p) requires HasPlus&lt;T&gt; {} // 注意 requires 约束的位置比较灵活 上方代码中 template&lt;StringConcept Str&gt; 是对 template&lt;typename Str&gt; requires StringConcept&lt;Str&gt; 的缩写。只有单参数 concept 可以用这种简写方法。（是的，concept 可以有多个参数！）
requires 表达式可以作为函数 requires 要求的一部分，形式上有两个连着的 requires 关键字，但是它们的含义不同：
template&lt;typename T&gt; void f(T) requires requires(T t) { t + t; } {} concept 下的重载选择如果一个 concept 中显式使用了另外一个 concept（可以通过 requires 体中的 requires 语句，也可以通过 concept 定义中的 &amp;&amp; 逻辑连词），则前者比后者严格。如果两个 concept 都能启用模板，则更严格的那个被选择。
  ]]></content></entry><entry><title>enum class</title><url>/posts/programming/cpp/enum-class/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  C 风格枚举和 C++ 新增的 enum class：
enum { ITEM_A1, ITEM_A2 }; enum B { ITEM_B1, ITEM_B2 }; // 从 C 沿用来的语法： // 1. 底层类型默认为int，但也能手动指定 // 2. 枚举名裸露在外 // 区别： // C 允许前向声明 enum // C++ 允许枚举列表为空；允许在表示类型时省略 enum 关键字；虽然枚举名裸露但也能通过限定名访问 // C++ 新增 enum class enum C { ITEM_C1, ITEM_C2 }; // 类型不再裸露，需要使用限定名访问 // 没有默认底层类型，但是可以手动指定 C++ enum class 禁止了隐式转换，但是用来表示 id 还是不太方便：
#include &lt;type_traits&gt; enum A: int { ITEM_1 }; enum { ITEM_2 }; enum class B: int { ITEM_3 }; // 即便底层类型相同，实际类型也不同 static_assert(! std::is_same_v&lt;int, A&gt;); static_assert(sizeof(int) == sizeof(A)); static_assert(sizeof(int) == sizeof(ITEM_2)); // 枚举不是聚合类 static_assert(! std::is_aggregate_v&lt;A&gt;); static_assert(! std::is_aggregate_v&lt;B&gt;); int main() { [](int){}(ITEM_1); [](int){}(ITEM_2); int b3 = (int)B::ITEM_3; // [](int){}(B::ITEM_3); // no conversion from B to int // [](B){}(b3); // no conversion from int to B [](B){}(B {b3}); // [](B){}( {b3} ); // 即便是花括号也不能推导，因为枚举不是类 // 强类型整数还是用 aggregate 做比较好： // 虽然整数到枚举可以使用构造的方式描述，但枚举到整数只能强制转换 // 作为对比，aggregate 直接访问成员即可 }   ]]></content></entry><entry><title>explicit</title><url>/posts/programming/cpp/explicit/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  一般认为 explicit 是用在单参数构造函数 上防止隐式类型转换的。但如果参数有多个，explicit 关键字也有其他的作用。
explicit 可以阻止 {} 推导https://stackoverflow.com/a/39122237/
可以参考另一篇文章：{ } Syntax。
struct Foo { Foo(int, int) {} }; struct Bar { explicit Bar(int, int) {} }; Foo f1(1, 1); // ok Foo f2 {1, 1}; // ok Foo f3 = {1, 1}; // ok Bar b1(1, 1); // ok Bar b2 {1, 1}; // ok Bar b3 = {1, 1}; // NOT OKAY Bar many_bars[] = { {1, 1} }; // ERROR explicit阻止了 {1, 1} 被推导成 Bar{1, 1} Bar many_bars2[] = { Bar{1, 1} }; // okay 阻止“去掉默认值是单参数构造函数”的隐式转换如果将来某个构造函数除了第一个参数之外的其他参数有了默认值，则会引起和单参数构造函数一样的隐式转换问题。
class A { public: A( int b, int c=0 ) {} // A 可以从 int 隐式转换而来 };   </content></entry><entry><title>Heterogeneous Lookup</title><url>/posts/programming/cpp/Heterogeneous-Lookup/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  https://www.cppstories.com/2021/heterogeneous-access-cpp20/
C++ 14 加入了对有序容器的异质查找用户的工作量很小，对标准库中的类型，只需要加上第三个模板参数：std::less&lt;&gt;（它的默认参数是 void）。std::less&lt;void&gt; 类中申明了 is_transparent 类型，所以可以用于异质查找。
std::map&lt;std::string, int&gt; intMap { { &#34;Hello Super Long String&#34;, 1 }, { &#34;Another Longish String&#34;, 2 }, { &#34;This cannot fall into SSO buffer&#34;, 3 } }; std::cout &lt;&lt; &#34;Lookup in intMap with by const char*:\\n&#34;; std::cout &lt;&lt; intMap.contains(&#34;Hello Super Long String&#34;) &lt;&lt; &#39;\\n&#39;; // std::map&lt;std::string, int, std::less&lt;&gt;&gt; trIntMap { { &#34;Hello Super Long String&#34;, 1 }, { &#34;Another Longish String&#34;, 2 }, {&#34;This cannot fall into SSO buffer&#34;, 3 } }; std::cout &lt;&lt; &#34;Lookup in trIntMap by const char*: \\n&#34;; std::cout &lt;&lt; trIntMap.contains(&#34;Hello Super Long String&#34;) &lt;&lt; &#39;\\n&#39;; C++ 20 加入了对无序容器的异质查找需要提供标注 is_transparent 的 hash 算子和等于算子。等于算子一般可以直接用 std::equal_to&lt;&gt;，但 hash 算子常常需要我们自己提供。
struct string_hash { using is_transparent = void; [[nodiscard]] size_t operator()(const char *txt) const { // 对指针的hash只考虑了地址，所以要选用string_view的hash return std::hash&lt;std::string_view&gt;{}(txt); } [[nodiscard]] size_t operator()(std::string_view txt) const { return std::hash&lt;std::string_view&gt;{}(txt); } [[nodiscard]] size_t operator()(const std::string &amp;txt) const { // string和string_view的hash方式一样 // 但用string的特化会减少一次从string到string_view的构造 return std::hash&lt;std::string&gt;{}(txt); } }; std::unordered_map&lt;std::string, int, string_hash, std::equal_to&lt;&gt;&gt; intMapTransparent { { &#34;Hello Super Long String&#34;, 1 }, { &#34;Another Longish String&#34;, 2 }, {&#34;This cannot fall into SSO buffer&#34;, 3 } }; bool found = intMapTransparent.contains(&#34;Hello Super Long String&#34;); std::cout &lt;&lt; &#34;Found: &#34; &lt;&lt; std::boolalpha &lt;&lt; found &lt;&lt; &#39;\\n&#39;; 为什么 C++ 不把异质容器的查找作为默认？同质查找是先转换类型，再多次比较。异质查找是多次比较，每次比较时调用的算子可能会做类型转换操作。如果算子没有对异质查找优化，每次比较时都构建临时对象开销非常大。
标准库的 string / string_view / const char * 是一个很好的可以使用异质查找的例子，因为他们之间的相互比较都有良好的无需临时构造对象的操作符。
  ]]></content></entry><entry><title>Hidden Friends</title><url>/posts/programming/cpp/Hidden-Friends/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  下面的代码中，Bar 能够隐式转换成 Foo。想要重载 Foo 的等于运算符至少有三种方案：
重载全局的 == 运算符 重载 Foo 中的 hidden friend，即 friend bool operator==(Foo const &amp;a, Foo const &amp;b) 重载 bool operator==(Foo const &amp;a) const 第一种方案会污染全局的名字空间，使得 Bar 和 Bar 之间也能通过转换两个参数进行比较；第三种方案允许第二个参数的隐式类型转换，但要求第一个参数必须是 Foo 类型；第二种方案只要求任一个参数为 Foo 类型，使得 ADL 能够参与找到这个函数，另一个参数则可以通过隐式类型转换来得到。
成员函数的劣势是由于查找方式和 this 指针的存在，函数失去了对称性。全局函数的劣势则是没有用上 ADL 的优势，hidden friends 在这种情况比较好。
https://godbolt.org/z/6sxdno3Yh
#include &lt;iostream&gt; #define HIDDEN_FEIDEND 1 struct Foo { int value{}; #ifdef HIDDEN_FEIDEND friend bool operator==(Foo const &amp;a, Foo const &amp;b) { return a.value == b.value; } #endif }; struct Bar { int value{}; // Bar can be converted implicitly to Foo. // `explicit` keyword makes the conversion explicit. // explicit operator Foo() const { return Foo{value}; } }; #ifndef HIDDEN_FEIDEND // Normal operator overload that can be found in global scope bool operator==(Foo const &amp;a, Foo const &amp;b) { return a.value == b.value; } #endif int main() { Bar a{-4}, b{1}; Foo c{2}; // std::cout &lt;&lt; std::boolalpha &lt;&lt; (a == b) &lt;&lt; &#34;\\n&#34;; // ok if no HIDDEN_FEIDEND std::cout &lt;&lt; std::boolalpha &lt;&lt; (a == c) &lt;&lt; &#34;\\n&#34;; // ok std::cout &lt;&lt; std::boolalpha &lt;&lt; (c == a) &lt;&lt; &#34;\\n&#34;; // ok }   ]]></content></entry><entry><title>Inheritance</title><url>/posts/programming/cpp/Inheritance/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  publicprotectedprivate共有继承publicprotected不可见私有继承privateprivate不可见保护继承protectedprotected不可见可见继承属性就是对于来自基类的 public 和 protected 成员进行一个取最小权限的操作（定义权限 public &amp;gt; protected &amp;gt; private）。
struct 和 class 的数据定义没有区别。语法上区别是：struct 定义默认继承种类是 public，class 定义默认继承类型是 private，这和基类用 struct 还是 class 声明的无关。
继承多个类时，需要给不同的基类分别指定访问限定符。
子类继承父类的 protected 属性/方法之后，可以通过子类的指针去访问；子类也不能通过父类指针访问 protected 的成员。
  </content></entry><entry><title>Javascript 从 DOMNodeInserted 到 MutationObserver</title><url>/posts/programming/www/Javascript-%E4%BB%8E-DOMNodeInserted-%E5%88%B0-MutationObserver/</url><categories/><tags><tag>js</tag></tags><content type="html"><![CDATA[  这段代码是在 Tamper Monkey 的 content.js 中发现的。被浏览器警告应该替换掉这种写法。
bn.addEventListener(&#34;DOMNodeInserted&#34;, o, s) 替换成
var [adder, remover] = ((bn, o, s) =&gt; { var helper = { remove : () =&gt; {}, add : () =&gt; {} } var observer = new MutationObserver(function(mutations) { mutations.forEach(function(mutation) { var nodes = Array.prototype.slice.call(mutation.addedNodes); nodes.forEach((node_) =&gt; { o(); helper.remove() }); }); }); helper.remove = () =&gt; observer.disconnect(); helper.add = () =&gt; observer.observe(bn, { childList: true, subtree: true, }; return [helper.add, helper.remove]; })(bn, o, s); adder() bn.removeEventListener(&#34;DOMNodeInserted&#34;, o, s) 替换成
remover()   ]]></content></entry><entry><title>Lambda 在各 C++ 版本的演进</title><url>/posts/programming/cpp/Lambda-%E5%9C%A8%E5%90%84-C++-%E7%89%88%E6%9C%AC%E7%9A%84%E6%BC%94%E8%BF%9B/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  C++11虽然有了 auto 关键字，但是用起来还是需要 trailing return type 声明。
C++14可以省略尾部声明（以下两种写法都是要 C++14 才能支持）：
auto f() { return 42; } // #1 auto f() -&amp;gt; auto { return 42; } // #2，相当于 #1 Note
例外：在 C++23 explicit object parameter 可用之前，构造递归 lambda 时需要显式声明返回值类型，否则无法成功推导（或者先用 function 模板类存储起来，类型也就能从 function 中推导）。
同时 C++14 还支持 generic lambda，即使用 auto 作为函数参数的类型。
decltype(auto) 也是 C++14 加入的。
C++20支持给 lambda 声明模板参数比如：auto f = []&amp;lt;typename T&amp;gt;( T t ) {};。
这样 f 对象内部就有一个调用操作符模板。可以使用 f.template operator()&amp;lt;T&amp;gt;(t) 访问，当 T 能被推导时模板参数列表可以省略。与之前的 auto 类型参数相比，这项改动使得我们可以添加一些不能从函数参数中推导出来的模板参数（想一想 std::make_shared 函数模板也无法得知将要创建的对象类型，因而需要手动指定）。
有了这个功能，现在就可以用 decltype + lambda 去干以前类模板偏特化才能做到的匹配工作（本来用函数模板也可以，但是为了做一次匹配就要给函数模板取一个名字，比较麻烦）：
#include &amp;lt;cstddef&amp;gt; #include &amp;lt;utility&amp;gt; #include &amp;lt;variant&amp;gt; template &amp;lt;size_t N&amp;gt; struct A {}; template &amp;lt;size_t N&amp;gt; using VariantOfEmptyClasses = decltype([]&amp;lt;size_t... Ns&amp;gt;(std::index_sequence&amp;lt;Ns...&amp;gt;) { return std::variant&amp;lt;A&amp;lt;Ns&amp;gt;...&amp;gt;{}; …  ]]></content></entry><entry><title>Makefile</title><url>/posts/cli/Makefile/</url><categories/><tags><tag>make</tag></tags><content type="html"><![CDATA[  $() 和 ${}除了 $ 之外，$() 和 ${} 都是 make 替换变量的语法。但是 ${} 还能被某些 shell（比如 bash）继续替换。
此外，它们也能调用 make 提供的命令，比如字符串替换、过滤和调用 shell。
Shell 函数无法正常传递 * 参数是因为 make 传参的时候将引号去掉了，导致星号又被 shell 解释了一次（我用的 MSYS2）。
$ cat Makefile all: echo \&#39;*\&#39; $ make echo \&#39;*\&#39; &#39;*&#39; $ nvim Makefile $ cat Makefile all: echo &#39;*&#39; $ make echo &#39;*&#39; Makefile 兼容性使用 ./ 来表示路径，不要使用 .\。（但是这样 cmd 解释不了，得用 bash 才行） 使用命令名来调用，不要使用 .exe 后缀。 这是一种处理兼容性的方式：
/=/ ifeq ($(OS),Windows_NT) /=\\ endif all: echo &#34;C:$/Users$/userA$/Downloads&#34;   ]]></content></entry><entry><title>new 和 delete</title><url>/inside-the-cpp-object-model/new-%E5%92%8C-delete/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html"><![CDATA[  new用 new 申请的内存最少占用 1 个字节——尽管我们申请的可能是 0 个字节。
delete/delete[]delete 和 delete[] 都会归还空间，但是 delete[] 会询问元素数量，并析构数组中的每个元素，而 delete 只会析构一个元素。
尽管虚析构函数允许我们正常 delete 掉指向子类对象的基类指针，但是在基类指针上使用 delete[] 可能是有错的：
#include &lt;cstdio&gt; struct A { double a; virtual ~A() { puts(&#34;~A()&#34;); fflush(stdout); } }; struct B : A { double b; ~B() override { puts(&#34;~B()&#34;); fflush(stdout); } }; static_assert(sizeof(A) == 16); static_assert(sizeof(B) == 24); int main() { A *array_of_A = new B[2]; delete [] array_of_A; // &lt;-- 大问题！ } 上述代码在 Compiler Explorer 上编译后返回 139。这里应用 delete[]，程序会将数组当成 A 数组来析构，把 A 的大小作为步长分割申请的空间，然后在每个”对象“上调用析构函数。这显然是不正确的，因为真正的步长是 B 的大小。
如果注释掉 B 类中的 double b; 声明，让 A 和 B 的大小一致，那么析构过程不会引发程序错误。但是非常不建议这么做！这对程序修改的容错不友好。
Placement new一般不用于在已有对象上重新构造，毕竟那样可以直接赋值。可以用于在 arena（一块足够大的、连续的空间）上初始化对象，但是需要记得自行析构。
  ]]></content></entry><entry><title>noexcept + throw</title><url>/posts/programming/cpp/noexcept-+-throw/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  noexcept 有几个用法：
在编译期返回一个常量布尔值，评估其表达式是否会抛出异常。 用于标志一个函数是否能抛出异常，需要一个编译期布尔常量作为参数。 标志函数不会抛出异常。相当于 noexcept(true)。 // whether foo is declared noexcept depends on if the expression // T() will throw any exceptions template&lt;class T&gt; void foo() noexcept(noexcept(T())) {} void bar() noexcept(true) {} void baz() noexcept { throw 42; } // noexcept is the same as noexcept(true) int main() { foo&lt;int&gt;(); // noexcept(noexcept(int())) =&gt; noexcept(true), so this is fine bar(); // fine baz(); // compiles, but at runtime this calls std::terminate } C++17 已经禁用 throw 的显式异常声明。（被称为 Dynamic exception specification）
  ]]></content></entry><entry><title>OpenJDK: ConcurrentHashMap</title><url>/posts/programming/java/ConcurrentHashMap/</url><categories/><tags><tag>java</tag><tag>openjdk</tag></tags><content type="html">  现在已经没有 Segment 概念，并发系数不生效。能支持高效的并发：
支持懒初始化，第一次写的时候发生，可能需要自旋但不需要加锁。 读的时候可能需要自旋，不需要加锁。 写的时候如果遇到正在扩容，则加入一起扩容；如果写时槽位为空，则只需要原子操作；写时操作非空，且不处在特殊状态，则需要加对象锁。因而读写互不阻塞、不同槽位的写不会阻塞、扩容不会阻塞（因为扩容时其他竞争线程也会被分配任务）、仅有单个槽位的多写需要阻塞。 为了节省空间，在 Node[] 中用 hash 为负的头结点来表示该拉链处于特殊状态：树结点、转移中、预留等。
转移的时候会以槽为单位进行，如果看到槽位正在转移中，则当前线程不会去抢夺工作，除非两个线程刚好看到了同一个槽位需要转移，这时会加对象锁处理。在遍历时会按照 (hash_of_key: ph &amp;amp; capacity_of_old_table: n) 计算出给定位，以此来分组（理想的情况会对半分），然后用头插法生成两条新链表转移到 nextTable。
💡 这当中有个优化过程：计算 lastRun，称链表尾部一连串对应 bit 相同的结点的起始位置为 lastRun，这系列结点将会被转移到 nextTable 的相同位置，因此会直接被转移，而不会对每个结点重新用头插法插入。头插法不仅需要遍历这一系列结点，还要对每个结点申请空间。
如果线程 A 正在转移 table 到 nextTable，线程 B 读写链上的结点都会直接反映在被转移到的 nextTable 中。但如果线程 B 新创建了一个链（table[i] 从 null 变成有效），线程 A 如何看到？转移是从大下标开始，向小下标转移。转移后会在上面 CAS 放置 ForwardingNode，这样后来者可以直接写到其中，前来者写的结果会被转移。
添加或者删除的时候怎么办？
为什么不允许键值为空？键值为空实在是无意义。在 putVal 方法中还检查了结点的键值，即便是普通结点也确保 K/V 不为空才进行操作，即存在完善的空检查，所以从效率或实现角度解释不成立。 get 方法无法通过返回值 null 区分是不存在元素还是值为 null，并发环境下 containsKey 返回的结果在下一次写入时可能就不成立了，因而从 API 设计上 value 最好不是 null。   </content></entry><entry><title>OpenJDK: CopyOnWriteArrayList</title><url>/posts/programming/java/CopyOnWriteArrayList/</url><categories/><tags><tag>java</tag><tag>openjdk</tag></tags><content type="html">  写的时候加锁（因为要替换 array 数组的引用，而且复制的过程比较耗时，不宜自旋），读的时候不用加锁。替换的安全性由 Java volatile 保证。
  </content></entry><entry><title>OpenJDK: Java Memory Order</title><url>/posts/programming/java/Java-Memory-Order/</url><categories/><tags><tag>java</tag><tag>openjdk</tag></tags><content type="html"><![CDATA[  CPU 内存屏障：https://sf-zhou.github.io/programming/memory_barrier.html
volatile 与内存屏障总结： https://zhuanlan.zhihu.com/p/43526907
X86-64 下仅支持一种指令重排：Store-Load ，即读操作可能会重排到写操作前面，同时不同线程的写操作并没有保证全局可见，例子见《Intel® 64 and IA-32 Architectures Software Developer’s Manual》手册 8.6.1、8.2.3.7 节。要注意的是这个问题只能用 mfence 解决，不能靠组合 sfence 和 lfence 解决。（用 sfence+lfence 组合仅可以解决重排问题，但不能解决全局可见性问题，简单理解不如视为 sfence 和 lfence 本身也能乱序重排）
X86-64 一般情况根本不会需要使用 lfence 与 sfence 这两个指令，除非操作 Write-Through 内存或使用 non-temporal 指令（NT 指令，属于 SSE 指令集），比如 movntdq, movnti, maskmovq，这些指令也使用 Write-Through 内存策略，通常使用在图形学或视频处理，Linux 编程里就需要使用 GNC 提供的专门的函数（例子见参考资料 13：Memory part 5: What programmers can do）。
下面是 GNU 中的三种内存屏障定义方法，结合了编译器屏障和三种 CPU 屏障指令：
#define lfence() __asm__ __volatile__(&amp;#34;lfence&amp;#34;: : :&amp;#34;memory&amp;#34;) #define sfence() __asm__ __volatile__(&amp;#34;sfence&amp;#34;: : :&amp;#34;memory&amp;#34;) #define mfence() __asm__ __volatile__(&amp;#34;mfence&amp;#34;: : :&amp;#34;memory&amp;#34;) 代码中仍然使用 lfence() 与 sfence() 这两个内存屏障应该也是一种长远的考虑。按照 Interface 写代码是最保险的， …  ]]></content></entry><entry><title>OpenJDK: JUC locks</title><url>/posts/programming/java/JUC-locks/</url><categories/><tags><tag>java</tag><tag>openjdk</tag></tags><content type="html">  ReentrantLock 公平锁和非公平锁的实现如果需要长时间等待，AQS 总是会将等待线程加入到队列尾部，唤醒时总是唤醒队首线程。这样做能够保证已经被睡眠的线程必定按照顺序唤醒。这样做难道不是永远都是公平锁？
不是！NonfairSync 在 tryAcquire() 时不会检查是否为队首。这意味着如果有队列之外的线程尝试获取锁（发生在刚刚调用 ReentrantLock.lock() 的阶段），可能会先于队首线程获得锁。虽然这种情况的发生非常需要巧合，但也是不公平的； FairSync 对这一巧合下的公平性做出了更高的要求。
公平和不公平的主要区别在于等待队列外的线程和等待队列上的线程之间的公平性。
CountDownLatch只有 countDown() 被调用给定的次数后，await() 才能被唤醒。
synchronize 关键字synchronize 关键字对应的对象锁是不公平的。锁的是对象，信息存储在对象头中。有锁升级过程：偏向锁（JDK 15 中已废弃）、轻量锁、重量锁。
AQS 实现可重入锁AQS 维护了一个 int 类型的 state 和一个双端等待队列。state 含义随实现不同而不同。在可重入场景下，state 数值表示已重入的次数，比如 state 为 2 表示已经重入了 2 次，为 0 表示尚未加锁。
  </content></entry><entry><title>OpenJDK: Project Loom</title><url>/posts/programming/java/Project-Loom/</url><categories/><tags><tag>java</tag><tag>openjdk</tag></tags><content type="html">  互斥：锁现在对象锁不尊重虚拟线程，但是 JUC 下的锁是尊重虚拟线程的。
共享：ScopedValueThreadLocal 和虚拟线程配合的不是很好，尽管功能上 ThreadLocal 是支持虚拟线程的，但是由于虚拟线程数量众多、生命周期短，使用 ThreadLocal 时虽然保证了线程安全，却创建了大量对象——这个问题在平台线程上就不明显。JEP 429 ScopedValues (Java 20) 是为了解决这个问题的。
💡 ThreadLocal 和线程池配合的也不是很好，因此短期任务结束后，将线程放回池中之前要及时清理数据。
ScopedValue 用 where 绑定共享变量，用 call 来启动虚拟线程，这样虚拟线程及子虚拟线程能够在调用环境中通过之前捕获的键（图中为 KEY）来获取值，这里使用方式也类似于之前的 ThreadLocal 查表。于是，一些本可以共享的变量实现了共享。
另外，ScopedValue 没有 remove() 方法，因为 .call() 返回后 KEY 就随着虚拟线程结束而解绑了。如果直接获取而对应值不存在，则会抛出异常；有必要时用 isBound() 来检查。
ScopedValue 要么是 unbound，要么是在创建虚拟线程之前就已经确定下来，并且引用不可更改。
同步：StructuredTaskScope用来组织一组任务，可以调用 join() 来等待 scope 完成任务。这样能够达到类似于 await/async 的逻辑。
  </content></entry><entry><title>P2266R3: Simpler implicit move 对 C++23 函数返回表达式值类别的改变</title><url>/posts/programming/cpp/P2266R3-Simpler-implicit-move-%E5%AF%B9-C++23-%E5%87%BD%E6%95%B0%E8%BF%94%E5%9B%9E%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%80%BC%E7%B1%BB%E5%88%AB%E7%9A%84%E6%94%B9%E5%8F%98/</url><categories><category>cpp-language</category></categories><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  写在前面本篇内容参考提案 Simpler implicit move。
隐式移动是函数返回值优化的一种，在 C++ 不同版本有不同的规则，这篇文章主要讲隐式移动，不涉及其他返回值优化的内容。
变量表达式（id-expression）指的是仅由变量名组成的表达式，比如 x 或者 (x)。虽然变量本身可能是值类型或者右值引用类型，但是变量表达式是左值。
值类别可见 Value Categories。
隐式移动的设计难题隐式移动使得函数可以在更多的场景用移动构造函数来构造返回对象，从而避免拷贝。但是，隐式移动通常要求编译器在特定的条件下改变返回的表达式的值类别（lvalue / rvalue），这使得一些函数表现出让人意外的语义。
隐式移动的历史C++11 允许构造返回对象时隐式移动值类型表达式如果函数返回的是值类型的表达式，且函数声明的返回值类型是一个值类型，则编译器会将返回的表达式隐式转换成亡值（不必我们写 return std::move(x)）用于匹配移动构造函数。
struct Widget { Widget(Widget&amp;amp;&amp;amp;); // Widget 只能移动，不能复制 }; struct RRefTaker { RRefTaker(Widget&amp;amp;&amp;amp;); }; RRefTaker two(Widget w) { return w; // OK since C++11 + CWG1579 } C++20 允许构造返回对象时隐式移动亡值变量表达式参考 P0527 和 P1155。
C++11 时，亡值变量表达式由于是变量表达式的一种，因而在返回时被当成左值看待，这可能导致不必要的拷贝：比如返回一个 std::string &amp;amp;&amp;amp; 类型的变量，但是函数返回值被声明为 std::string 类型。
C++20 允许亡值变量表达式在用来构造返回对象时的隐式移动。这虽然解决了上一段提到的问题，但是仍然不允许亡值变量表达式在函数返回右值引用类型时的隐式移动：这个时候仍然需要手动添加 std::move，否则无法编译（左值引用不能绑定在右值引用上）。
RRefTaker three(Widget&amp;amp;&amp;amp; w) { return w; // OK since C++20 because of P0527 //  …  ]]></content></entry><entry><title>POD</title><url>/posts/programming/cpp/POD/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  Plain Old Data
https://stackoverflow.com/a/4178176
成为 POD 的条件：
所有的标准类型都是 POD（尽管不是 aggregate）。 数组要成为 POD 的条件是每个元素都是 POD。 一个类要成为 POD，则必须首先是 aggregate，然后： 没有用户定义的赋值运算符。 没有析构函数。 所有成员都是 POD（递归定义）。   </content></entry><entry><title>Pointer to Member</title><url>/posts/programming/cpp/Pointer-to-Member/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  数据成员指针存储的是偏移#include &lt;iostream&gt; using namespace std; struct Foo { int x; int y; }; int main() { Foo x{2}; int Foo::* px = &amp;Foo::x; int Foo::* py = &amp;Foo::y; cout &lt;&lt; (unsigned long &amp;)px &lt;&lt; endl; // 输出0 cout &lt;&lt; (unsigned long &amp;)py &lt;&lt; endl; // 输出4 cout &lt;&lt; sizeof(px) &lt;&lt; endl; // gcc输出8 } 数据成员指针的大小和实现相关。
成员函数指针比一般指针占用更多空间和编译器相关。gcc 里成员函数指针在 64 位机器下是 16 字节。
如果成员函数不是虚函数：函数地址固定；this 指针偏移也可以通过类型在编译时计算出来。先偏移后调用，应该只需要 8 个字节。
如果成员函数是虚函数：
解释：
https://stackoverflow.com/a/12006882/
存储一个偏移难道还不够吗？
MSVC 的更奇怪，多继承指针比单继承指针的体积大：
#include &lt;iostream&gt; #include &lt;cassert&gt; using namespace std; struct A { void x() {} }; struct B { void y() {} }; struct C: A, B { void z() {} }; struct D { int z; }; int main() { // x86模式编译 // static_assert(sizeof(&amp;A::x) == sizeof(&amp;B::y)); // static_assert(sizeof(&amp;A::x) == 4); // static_assert(sizeof(&amp;C::z) == 8); // static_assert(sizeof(&amp;D::z) == 4); // x64模式编译 static_assert(sizeof(&amp;A::x) == sizeof(&amp;B::y)); static_assert(sizeof(&amp;A::x) == 8); static_assert(sizeof(&amp;C::z) == 16); static_assert(sizeof(&amp;D::z) == 4); } 使用成员指针访问成员观察：
#include &lt;iostream&gt; using namespace std; struct Foo { int x; int y; }; int main() { Foo x{2, 7}; int Foo::* px = &amp;Foo::x; int Foo::* py = &amp;Foo::y; cout &lt;&lt; ((&amp;x) -&gt;* px) &lt;&lt; endl; // 2 cout &lt;&lt; (x .* py) &lt;&lt; endl; // 7 } 可以看出 .* 和 -&gt;* 是特殊的访问操作符（这里为了体现其特殊性加了空格，实际上倾向于不加空格书写）。
  ]]></content></entry><entry><title>Python __pycache__</title><url>/posts/programming/python/Python-__pycache__/</url><categories/><tags><tag>python</tag></tags><content type="html">  工作原理https://peps.python.org/pep-3147/#python-behavior
每次 import 的时候，解释器检查当前目录下的 __pycache__ 文件夹，读取和 Python 版本对应的 cache，然后读取 cache 中库的修改时间（cache 文件中记录着源码的修改时间，并不是 cache 文件本身的修改时间）。将这个时间和源码的时间比较，如果这个时间不存在，或者比源码的时间新，就加载 .pyc 而不必加载源码。
问题：在 Windows 和 WSL 上测试，解释器总是能够发现最新的源码，好像没有读取字节码一样。原因是除了时间之外，pycache 还存储了源文件的长度（验证后发现确实是这样，修改代码时既不改变文件时间又不改变长度，就能复用 cache）。
[link](https://docs.python.org/3/reference/import.html###%205.4.7.%20Cached%20bytecode%20invalidation%5D(https://docs.python.org/3/reference/import.html###%205.4.7.%20Cached%20bytecode%20invalidation%5D(https://docs.python.org/3/reference/import.html#cached-bytecode-invalidation%20%22Permalink%20to%20this%20headline%22)
Before Python loads cached bytecode from a .pyc file, it checks whether the cache is up-to-date with the source .py file. By default, Python does this by storing the source&amp;rsquo;s last-modified timestamp and size in the cache file when writing it. At runtime, the import system then validates the cache file by checking the stored metadata in the cache file against the source’s metadata.
Python 3.2 引入了 __pycache__，之前是在文件旁边直接生成对应的 .pyc 文件（加了 c 后缀），而不组织在文件夹中。
作用加速了后续进程的 import。（同一个进程中是有模块缓存的，第二次 import 不会真正去读文件，除非缓存记录被 del。）
  </content></entry><entry><title>Python __slots__</title><url>/posts/programming/python/Python-__slots__/</url><categories/><tags><tag>python</tag></tags><content type="html"><![CDATA[  定义了 __slots__ 静态属性的类没有 __dict__ 属性。而且只能添加存在于槽中的属性（可以少加，不能多加）。
class Point: __slots__ = [&#39;x&#39;, &#39;y&#39;] def __init__(self, x, y): self.x = x self.y = y p = Point(1, 2) print(p.__dict__) # 输出: AttributeError: &#39;Point&#39; object has no attribute &#39;__dict__&#39; 槽最大的意义在于节省空间：共享 __slots__，每个对象没有自己的 __dict__。节省了字典的空间。对于属性较多的对象，使用槽访问速度可能会下降。
&gt;&gt;&gt; import sys &gt;&gt;&gt; class Foo: ... def __init__(self, x): self.x = x ... &gt;&gt;&gt; sys.getsizeof(Foo(1)) 56 &gt;&gt;&gt; sys.getsizeof(Foo(1)) + sys.getsizeof(Foo(1).__dict__) 336 &gt;&gt;&gt; class Bar: ... __slots__ = &#39;x&#39;, # 这里表示的是一个元组 ... def __init__(self, x): self.x = x ... &gt;&gt;&gt; sys.getsizeof(Bar(1)) 40 有些属性可能既不存在于 __slots__ 中，又不存在于 __dict__ 中。这些属性是方法，能从 dir(obj) 中看到。而且标注了 @property 的方法能够直接像其他属性一样访问。
  ]]></content></entry><entry><title>Python sys vs os</title><url>/posts/programming/python/Python-sys-vs-os/</url><categories/><tags><tag>python</tag></tags><content type="html">  sys 可以访问解释器（运行时功能）和系统特定功能（系统有关功能）。os 提供了操作系统上的统一抽象（系统无关功能）。
解释器功能：比如 sys.argv 访问命令行参数，sys.exit() 退出程序，sys.path 是 python 包的查询路径，sys.stdin/sys.stdout/sys.stderr 分别表示三个系统管道。 系统有关功能：比如 sys.getwindowsversion 可以得到 windows 的大小版本号。sys.platform 可以获得操作系统平台。sys.version 是 python 安装信息。 系统无关功能：操作文件系统，path 分隔符，环境变量等。   </content></entry><entry><title>Python 转置矩阵</title><url>/posts/programming/python/Python-%E8%BD%AC%E7%BD%AE%E7%9F%A9%E9%98%B5/</url><categories/><tags/><content type="html">  transpose = lambda listA: list(list(t) for t in zip(*listA))   </content></entry><entry><title>range-for</title><url>/posts/programming/cpp/range-for/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  以前容易出现引用悬挂的问题。在新的语言标准中得到了改进。
C++11 只是简单的语法糖，只能保证表达式返回值被临时变量接受并保留到循环结束：(https://stackoverflow.com/a/51440883)
{ auto&amp;&amp; __range = f()[5]; // (*) auto __begin = __range.begin(); // not exactly, but close enough auto __end = __range.end(); // in C++17, these types can be different for (; __begin != __end; ++__begin) { auto e = *__begin; // rest of body } } C++20 range-for 生命周期规则一样，不过可以在里面创建临时对象，避免后面引用过程中的悬挂：
#include &lt;iostream&gt; int main() { for (auto lst = {1, 2, 5, 1, 71}; auto i : lst) { std::cout &lt;&lt; i &lt;&lt; &#39;\n&#39;; } } C++23 则要求在 range-for 括号中创建的临时对象生命周期延长到整个循环结束后。不过截至 2023 年 6 月 3 日，没有编译器实现。
  ]]></content></entry><entry><title>Rust 程序设计语言 第一印象</title><url>/posts/programming/rust/Rust-%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E8%AF%AD%E8%A8%80-%E7%AC%AC%E4%B8%80%E5%8D%B0%E8%B1%A1/</url><categories/><tags><tag>rust</tag></tags><content type="html"><![CDATA[  首先看这个：
C++中在 C++14 之后可以使用 &#39; 来分隔数字字面量。而 Java 和 Rust 在设计阶段很早的时候就支持了用 _ 来分隔数字。
个人感受：
处处充斥强制移动语义。相关的是 Drop Trait，而基本类型还实现了 Copy Trait。（所有权和 C++ RAII 想要解决的问题相似） 默认定义是常量，包括引用默认是常引用。（和 C++ 相反） 允许同一个作用域内 shadow，试图把变量名当成真正的标签来用（类似 Python）。 错误处理用 expect，比 try-catch 简洁。 内置元组和 range、if 条件不需要加括号。 很多实用包都得用 crate，在标准库中没提供…… 认识所有权同一生存期，对对象 A 的可变引用将排斥任何对对象 A 的其他引用。当且仅当所有引用都是常量引用时编译才能够通过。一个引用的作用域从声明的地方开始一直持续到最后一次使用为止。编译器能够把这一点检查出来。如果最后一次使用结束了，就不参与和其他引用的排斥行为了。
Note
str 类型好像见不到，只能见到 str&amp;amp; 类型。由于是引用，它自己没有所有权。
String 类型动态分配空间，String 这样类型的赋值行为都是移动语义。要创建一个拷贝，需要使用 clone() 方法。
对 String 切片引用得到的类型是 &amp;amp;str：
fn first_word(s: &amp;amp;String) -&amp;gt; &amp;amp;str { let bytes = s.as_bytes(); for (i, &amp;amp;item) in bytes.iter().enumerate() { if item == b&amp;#39; &amp;#39; { return &amp;amp;s[0..i]; } } &amp;amp;s[..] } fn main() { let mut s = String::from(&amp;#34;hello world&amp;#34;); let word = first_word(&amp;amp;s); s.clear(); // 错误! println!(&amp;#34;the first word is: {}&amp;#34;, word); } 因为 first_word 使用了 s 的不可变引用，返回的结果保存在 word 中。所以认为 word 也带有了对 s 的 …  ]]></content></entry><entry><title>sizeof</title><url>/posts/programming/cpp/sizeof/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  下面几个表达式相等：
sizeof(T&amp;amp;) sizeof(T&amp;amp;&amp;amp;) sizeof(T) 也就是说 sizeof 会去掉引用。忘记出处了，twitter 上有人提过一个 quiz，什么类型 T 能满足 struct {T x;} 和 T 的 sizeof 结果不相等，引用类型就满足这样的情况。
  </content></entry><entry><title>std::lower_bound/upper_bound</title><url>/posts/programming/cpp/std-lower_bound-upper_bound/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  class Solution { public: vector&lt;int&gt; searchRange(vector&lt;int&gt;&amp; nums, int target) { int n = (int)nums.size(); // lower_bound 的可能实现 auto lowerbound = [&amp;](auto &amp;&amp;less) { int lo = 0, hi = n; while (lo &lt; hi) { int mid = (lo + hi) / 2; if (less(nums[mid], target)) lo = mid + 1; else hi = mid; } return lo; }; // std::lower_bound int left = lowerbound(std::less&lt;&gt;{}); // std::upper_bound int right = lowerbound(std::less_equal&lt;&gt;{}); return (left &lt; n &amp;&amp; nums[left] == target) ? vector&lt;int&gt;{left, right-1} : vector&lt;int&gt;{-1, -1}; } };   ]]></content></entry><entry><title>Strict Aliasing</title><url>/posts/programming/cpp/Strict-Aliasing/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  文章：What is Strict Aliasing and Why do we Care? (github.com)
所谓 Strict Aliasing 就是指为 aliasing 设定条件，使得编译器大多数场景下认为代码没有 aliasing，从而可以激进优化代码。
#include &amp;lt;iostream&amp;gt; int foo( float *f, int *i ) { *i = 1; *f = 0.f; return *i; } int main() { int x = 0; std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; &amp;#34;\n&amp;#34;; // Expect 0 x = foo(reinterpret_cast&amp;lt;float*&amp;gt;(&amp;amp;x), &amp;amp;x); std::cout &amp;lt;&amp;lt; x &amp;lt;&amp;lt; &amp;#34;\n&amp;#34;; // Expect 0? } 上述代码在 gcc 13.1 -O2 下编译，第二行打印结果为 1。编译器认为 f 和 i 指针必定不重合，所以直接返回了 1。
什么时候 Aliasing 是允许的？比较复杂，而且 C 和 C++ 的要求不同。在 alias 可用时，编译器不会像上面那样激进优化。下面只提到了一部分规则。
允许同类指针，而且两者都允许给指针加 cv 限定，但是 C++17 还允许 unsigned 和 signed 对应类型之间的别名，C11 不允许（尽管 gcc 和 clang 都是按照允许的方式实现的）。
最基本的保证是：无论指针如何变化，只要目的类型是对象的真实类型，就能正常使用。但是如何开启一个新对象的生命周期则有区别。C 语言中只要写入就已经可以按照写入类型启用一个新的生命周期。而在 C++ 必须保存用于写入的指针并在之后始终使用该指针！（C++17 新增了 std::launder，可以不必再保存指针但是要洗一下）
问题：保存 memcpy 返回的指针可以吗？
C 语言的 restrict 关键字https://stackoverflow.com/a/30827311/
restrict 关键字是指针的属性，写在指针的右侧、变量名之前，它保证了一个指针和其他指针变量没有重叠（没有 aliasing），以便编译器在 aliasing 可用时仍激 …  ]]></content></entry><entry><title>Three-way Comparison =</title><url>/posts/programming/cpp/Three-way-Comparison/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  含义C++ 20 加入了 &lt;=&gt; 操作符，该操作符会按布局顺序比较成员，比较时会递归使用 &lt;=&gt; 操作符。对于类类型来说，即便默认的 &lt;=&gt; 操作符可用，也必须显式声明为 = default，否则不能使用。
如果需要在 B 类中包含 A 类，同时声明 B 类的默认 &lt;=&gt; 操作符以便比较 B 类对象，则必须同时在 A 类中声明默认的 &lt;=&gt; 操作符。
Three-way comparison operator 的返回值可以是偏序、弱序或强序。体现在 C++ 语言中是：
偏序：弱序 或者 不可比较。 弱序：a 和 b 的关系只能是小于、等于、大于之一。比较相等性时常用 !(a &lt; b) &amp;&amp; !(b &lt; a) 的形式。相等的值可以拥有不同的身份。 强序：a 和 b 的关系只能是小于、等于、大于之一。可以直接用 == 比较相等性，相等则意味着完全一致，可以相互替代。 https://news.ycombinator.com/item?id=20550902
In a strong ordering, two objects can only by one smaller, equal or larger than the other. If they are equal, it means that they are substitutable.
In a weak ordering, two objects can only be one smaller, equivalent or larger than the other. No substitutability is implied.
In a partial ordering, two objects can be one smaller, equivalent or larger than the other, or just not comparable. Again, no substitutability is implied.
默认 &lt;=&gt; 存在的条件https://en.cppreference.com/w/cpp/language/default_comparisons
对引用类型成员的处理当类中包含类型为引用的成员时，该类默认的 &lt;=&gt; 被删除（而不是被隐藏），除非人为定义否则不能被用户使用。
尽管“提出类类型作为模板参数”的论文使用 &lt;=&gt; 的规则描述类 NTTP 的要求，并建议禁用那些带有引用成员的类作为参数，但实际上 gcc 会使用地址比较允许这样的类型。
  ]]></content></entry><entry><title>tmux</title><url>/posts/cli/common/tmux/</url><categories/><tags><tag>shell</tag><tag>linux</tag></tags><content type="html">  配置文件在 ~/.tmux.conf。
开启鼠标（可能是最正常的操作逻辑了）：
set -g mouse on 打开之后能够支持切换 window、panel，调整 panel 之间的相对大小。右键还有一些便捷操作。比如 mark 提供复制功能。
ctrl + b 是默认的 prefix 按键，先按这个 prefix 键然后按其他按键可以使用特殊功能 d 是 detach % 是左右分屏（产生新的 panel） &amp;quot; 是上下分屏（产生新的 panel） z 是暂时最大化 c 是创建新的窗口（window） 对正在运行的 tmux 重载配置： https://unix.stackexchange.com/questions/516800/how-do-i-enable-tmux-mouse-support
逻辑层级是 Session &amp;gt; window &amp;gt; panel。
重命名 window 和 panel
重命名 session
  </content></entry><entry><title>type_index</title><url>/posts/programming/cpp/type_index/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  例子：bustub lab 0
可以和 📌vtable 联系起来看。
dynamic_cast 何时可以使用？使用要求：① 目标是类的指针或引用 ② 目标类含虚表
我最初在 bustub lab 0 的实现中使用了向下转型的操作：在 Get 操作中，当一个 TrieNode 有值的时候，就尝试向下转型为 TrieNodeWithValue&amp;lt;T&amp;gt;，这一步仍然正确就说明类型也正确，可以取出返回。
在 Compiler Explorer 中实现相似操作：
struct A {}; template &amp;lt;class T&amp;gt; struct B: A { T t; }; int main() { auto *p = new A; if (auto pb = dynamic_cast&amp;lt;B&amp;lt;int&amp;gt; *&amp;gt;(p)) {} } 结果说 A 没有多态性：
&amp;lt;source&amp;gt;: In function &amp;#39;int main()&amp;#39;: &amp;lt;source&amp;gt;:12:19:error:cannot &amp;#39;dynamic_cast&amp;#39; &amp;#39;p&amp;#39; (of type &amp;#39;struct A*&amp;#39;) to type &amp;#39;struct B&amp;lt;int&amp;gt;*&amp;#39; (source type is not polymorphic) 12 | if (auto pb =dynamic_cast&amp;lt;B&amp;lt;int&amp;gt; *&amp;gt;(p)) {} |^~~~~~~~~~~~~~~~~~~~~~~~~ ASM generation compiler returned: 1 &amp;lt;source&amp;gt;: In function &amp;#39;int main()&amp;#39;: &amp;lt;source&amp;gt;:12:19:error:cannot &amp;#39;dynamic_cast&amp;#39; &amp;#39;p&amp;#39; (of type &amp;#39;struct A*&amp;#39;) to type &amp;#39;struct B&amp;lt;int&amp;gt;*&amp;#39; (source type is not polymorphic) 12 | if (auto pb …  ]]></content></entry><entry><title>UB</title><url>/posts/programming/cpp/UB/</url><categories/><tags><tag>cpp</tag></tags><content type="html">  Undefined behavior - cppreference.com
ill-formed：有语法错误，或者能被检查出的语义错误。必须提供诊断（编译错误）。
ill-formed, no diagnostic required：正常编译，但有 UB。
implementation-defined behavior：正常编译，行为由实现定义，一个具体实现必须列出其文档。
unspecified behavior：能正常编译，行为在不同实现中有区别。一个具体实现不需要列出文档。
undefined behavior：可以编译，尽管可能有警告。行为是未定义的。
种类诊断行为ill-formed有不能编译ill-formed, no diagnostic required无未定义implementation-defined behavior无实现相关，有文档unspecified behavior无实现相关，无文档undefined behavior可能有若能编译则未定义UB 这一行看起来很像是 ill-formed 两行合起来。
  </content></entry><entry><title>Value Categories</title><url>/posts/programming/cpp/Value-Categories/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  Value categories - cppreference.com 有更详细的说明。
分类lvalue / rvalue / xvalue 是互斥的，C++ 表达式只能是三者之一。glvalue 和 rvalue 都是复合类别：glvalue 包括 lvalue 和 xvalue，rvalue 包括 prvalue 和 xvalue。在翻译上，xvalue 叫（将）亡值，glvalue 叫泛左值。
一部分规则（一些理所当然的就在这里略去）：
类型规则lvalue具名的数据是 lvalue，比如变量名、函数名、template parameter object 名（C++ 20，见下方代码块）、左值引用类型的 NTTP 名。还有字符串字面量。prvalue字面量、枚举名、lambda 表达式等。标量类型的 NTTP 名。C++ 20 后 requires 表达式和 concept 的特化也是 prvalue。xvaluervalue 的成员访问（. / .* / -&amp;gt; / -&amp;gt;*）是 xvalue。Template Parameter Object在 C++ 20 中被改为 lvalue。
#include &amp;lt;iostream&amp;gt; struct Foo {}; template &amp;lt;Foo v&amp;gt; void set() { // 这里要求 v 是 lvalue，C++20 可以编译，C++17 不行 std::cout &amp;lt;&amp;lt; &amp;amp;v &amp;lt;&amp;lt; &amp;#34;\n&amp;#34;; } void foo() { set&amp;lt;Foo{}&amp;gt;(); } Concept 特化template &amp;lt;typename T&amp;gt; struct is_int { enum { value = false }; }; template &amp;lt;&amp;gt; struct is_int&amp;lt;int&amp;gt; { enum { value = true }; }; static_assert(is_lvalue&amp;lt;decltype((std::is_scalar_v&amp;lt;int&amp;gt;))&amp;gt;::value); …  ]]></content></entry><entry><title>vim</title><url>/posts/cli/common/vim/</url><categories/><tags><tag>shell</tag><tag>linux</tag></tags><content type="html"><![CDATA[  vim 配置文件位置使用 :scriptnames 查看。
neovim + Windows 的配置文件：%userprofile%\AppData\Local\nvim\init.vim
macOS 和 Linux：~/.config/nvim/init.vim
自用基础配置set number set relativenumber set expandtab set ss=4 set tabstop=4 set shiftwidth=4 在打开文件之前执行命令vim &#34;+set ff=unix&#34; &#34;+wq&#34; 文件名 如果不提供文件名，则相当于打开空白的 vim。
难记的单按键命令= 表示格式化，=a{ 能将所在花括号中的内容格式化。 % 跳转到匹配的括号处。 w 表示成词单词，W 表示非空白。 按下 q 记录宏，按下 @ 回放宏。 视图模式下按 J 可以将多行拼接在一起，可用于将数组元素格式化到同一行。 复杂命令自动补全：编辑模式下按 ctrl + p/n。 buffers: :bn 表示下一个缓冲区，:bp 表示上一个缓冲区，:ls / :buffers 可以查看当前所有缓冲区，:b4 可以前往 4 号缓冲区。（切换缓冲区前必须先保存或舍弃当前内容，第 6 点同。） 用 :norm 在命令模式下模拟连续按键。 用 :! command 执行命令。 用 :gx 打开链接，用 :gf 打开文件到新缓冲区，用 ctrl + w, ctrl + f 打开文件到新的窗口。 AutoSource：根据当前文件类型自动加载相应配置。 Spell Checking：略。 算数：ctrl + a +1，ctrl + x -1。 对行排序：先选中要排序的行，然后用命令 :'&lt;,'&gt; !sort 调用系统命令 sort。（叹号前的标记表示修改只适用于选中内容） 从 openvim.com 上学到的重复输入 n 次字符串。
找到某个字符第 n 次出现的位置。
用 % 跳转到匹配的括号。
以当前的单词为搜索词跳转：
重复上次的命令用 .
  ]]></content></entry><entry><title>Windows 11 禁用笔记本键盘</title><url>/posts/systems/Windows/Windows-11-%E7%A6%81%E7%94%A8%E7%AC%94%E8%AE%B0%E6%9C%AC%E9%94%AE%E7%9B%98/</url><categories/><tags><tag>windows</tag></tags><content type="html">  禁用：sc.exe config i8042prt start= disabled
启用：sc.exe config i8042prt start= auto
需要重启。
  </content></entry><entry><title>Windows 查找已经修改过的组策略</title><url>/posts/systems/Windows/Windows-%E6%9F%A5%E6%89%BE%E5%B7%B2%E7%BB%8F%E4%BF%AE%E6%94%B9%E8%BF%87%E7%9A%84%E7%BB%84%E7%AD%96%E7%95%A5/</url><categories/><tags><tag>windows</tag><tag>group-policy</tag></tags><content type="html">  在所有设置中点排序。
  </content></entry><entry><title>Windows 窗口栏在屏幕外不能移动</title><url>/posts/systems/Windows/Windows-%E7%AA%97%E5%8F%A3%E6%A0%8F%E5%9C%A8%E5%B1%8F%E5%B9%95%E5%A4%96%E4%B8%8D%E8%83%BD%E7%A7%BB%E5%8A%A8/</url><categories/><tags><tag>windows</tag></tags><content type="html">  先把窗口激活（放到最前面）然后按 Alt + Space，就能出现菜单选择 最大化/最小化/移动。
如果不行，也可以把任何一个其他的窗口拖动到左屏，右侧选择位置不正确的窗口组成双栏分屏，然后将其拖出来恢复成正常窗口。
  </content></entry><entry><title>Windows 合集</title><url>/posts/systems/Windows/Windows-%E5%90%88%E9%9B%86/</url><categories/><tags><tag>windows</tag></tags><content type="html"><![CDATA[  🚩必做关闭实时保护 关闭自动更新 定时创建还原点 如果系统驱动有问题、难以修复而且没有创建还原点，全新安装新系统也可以，Windows 不会抹除所有数据，受影响的只有注册表和 C:\Windows 文件夹下的数据。用户文件夹会被备份到 C:\Windows.old 中，QQ 和微信聊天数据、ssh/clash 等配置文件夹可以从其中复制过来。程序需要重新安装。
通过任务计划程序创建还原点参考这个 博客。
开启系统还原可以在 Windows 开始菜单搜索中搜索“还原”，找到“创建还原点”，也可以找到“系统属性 &amp;gt; 系统保护”，这两个方式都能来到同一个功能面板，对系统驱动器启用系统还原即可。
创建任务计划可以在 Windows 开始菜单搜索中搜索“计划”，找到“任务计划程序”进入。
点击右侧的“创建计划任务”，选择“不管用户是否登录都要运行”，启用最高权限，配置别动（不要选 Windows 10！会导致配置失效）。别急着点确定，翻到第二页“触发器”，选择“启动时”，点击确定。
创建触发器之后应该和下面一样：
接下来选择操作，选择“启动程序”，程序填 powershell.exe（不用浏览，PATH 里面肯定能找到），参数填：
-ExecutionPolicy Bypass -Command &amp;#34;Checkpoint-Computer -Description &amp;#34;Startup RestorePoint &amp;#34; -RestorePointType &amp;#34;MODIFY_SETTINGS&amp;#34;&amp;#34; 接下来在“条件”选项卡里面关闭唤醒时启动（这样是不是每次开机才跑一次而不是每次唤醒就跑一次？）和不充电时不启动，然后点击确定，输入账户密码（可能时因为设置了更高权限运行）即可创建。因为我创建的位置是在根，所以能在下图找到我计划的任务。
可以重启电脑检查一下是否有新的还原点创建。
组策略和注册表的关联组策略和注册表的内容是分别存储的，修改组策略并不会直接修改注册表。仅仅是在组策略刷新时，策略文件中的内容会被同步到注册表中。而且，组策略只维持自己的缓存，从不读取注册表中的值！
当注册表不经过组策略编辑器被改动时，如果想要使用组策略管理相关项，可能需要先显式设置组策略中的项目为另外一个值，然后再改过来。 …  ]]></content></entry><entry><title>Windows 回退驱动或给已经删除的设备添加驱动</title><url>/posts/systems/Windows/Windows-%E5%9B%9E%E9%80%80%E9%A9%B1%E5%8A%A8%E6%88%96%E7%BB%99%E5%B7%B2%E7%BB%8F%E5%88%A0%E9%99%A4%E7%9A%84%E8%AE%BE%E5%A4%87%E6%B7%BB%E5%8A%A0%E9%A9%B1%E5%8A%A8/</url><categories/><tags><tag>windows</tag><tag>drivers</tag></tags><content type="html">  如果想要恢复到曾经安装过的驱动。可以按照下面步骤操作：
首先在设备管理器中选择添加过时硬件。
看到首页之后点下一页。然后选中手动安装，再点一次下一页。
找到 显示适配器，再点下一页。
选择要安装的驱动，这里能找到和我的显卡匹配的两个版本的驱动。
  </content></entry><entry><title>Windows 提示被管理员禁止安装核显驱动、WSL 也无法启动</title><url>/posts/systems/Windows/Windows-%E6%8F%90%E7%A4%BA%E8%A2%AB%E7%AE%A1%E7%90%86%E5%91%98%E7%A6%81%E6%AD%A2%E5%AE%89%E8%A3%85%E6%A0%B8%E6%98%BE%E9%A9%B1%E5%8A%A8WSL-%E4%B9%9F%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8/</url><categories/><tags><tag>windows</tag><tag>wsl</tag><tag>drivers</tag><tag>group-policy</tag></tags><content type="html">  原因是很早之前按照知乎的说法启用了这个设置，本想禁用系统更新时自动安装旧版本的核显驱动，但也使得我的电脑核显驱动坏掉且不能自行安装。
恢复核显驱动首先应该关闭这项，然后去下载对应驱动安装，或者回退到旧的驱动。
这项配置启用时，我的 WSL 也无法正常进入！
  </content></entry><entry><title>WSL 合集</title><url>/posts/systems/Windows/WSL-%E5%90%88%E9%9B%86/</url><categories/><tags><tag>windows</tag><tag>wsl</tag></tags><content type="html"><![CDATA[  常见问题设置 apt 代理。编辑 /etc/apt/apt.conf，格式如下（ip 会变）：
// 很奇怪，注释竟然是//开头，而不是# Acquire::http::Proxy &#34;http://192.168.1.56:12366/&#34;; Acquire::https::Proxy &#34;http://192.168.1.56:12366/&#34;; sudo 没有 $http_proxy 代理的原因是默认不传递环境变量，使用 -E 选项传递环境变量就可以不设置上面的代理。
清华大学开源软件镜像站 https://mirrors.tuna.tsinghua.edu.cn/help/debian/
先用自己电脑给 apt 开代理，然后改镜像，安装一些 https 源需要的东西，然后 apt update。之后安装 build-essential mlocate 等等。
mlocate 安装之后：/etc/updatedb.conf 里面排除 /mnt 和 /usr/lib/wsl 以防止扫描 C 盘和 WSL 的驱动文件（体量很大）。然后 sudo updatedb
(2025/2/13) 我新装的环境里面 update.conf 文件的内容不生效，原因不明，最后只能用命令行手动排除 Windows 的文件：sudo updatedb --prunepaths=/mnt。
neovim 的配置：~/.config/nvim/init.vim
set number set relativenumber set expandtab set ss=4 set tabstop=4 set shiftwidth=4 VS Code 扩展运行慢设置通过 localhost 连接 wsl（跳过检查代理以及通过代理连接 wsl 的 vscode server）。
打开 systemd 支持后启动慢可能是 dbus 有问题，比如我之前没有 /usr/bin/dbus-daemon，可以用 apt install --reinstall dbus 重新安装。
保持永远运行先 tmux 然后使用 ctrl+b, d 来 detach。这样就模拟了一个前台任务了。
Bash改 bash 的补全：~/.inputrc
set completion-ignore-case on 加载 ~/.bashrc 的配置：~/.bash_profile
if [ -f ~/.bashrc ]; then . ~/.bashrc fi 环境变量https://unix.stackexchange.com/a/64260/527050
Also a side note, /etc/profile is sourced by all shells, not just bash. The bash specific configuration file is bashrc and only sourced for interactive shells.
由于默认的 /etc/profile 有这样一段：
if [ -d /etc/profile.d ]; then for i in /etc/profile.d/*.sh; do if [ -r $i ]; then . $i fi done unset i fi 因此可以新建 /etc/profile.d/environ.sh，放入环境变量相关代码。但是该配置只在会话开始时导入，不能简单重启 bash 来更新。必要时可以自行 source。
取消 Windows 的 PATHsudoedit /etc/wsl.conf
[interop] appendWindowsPath = false 这样 PATH 就不会有 Windows 的了，而且 manpath 的输出结果也没有 Windows 目录。这样做 man 速度显著提升。至于 VS Code 等软件的命令，可以单独加入 PATH。
网络代理WSL2 获取主机的 ip：（WSL1 用 http://localhost 就好）
cat /etc/resolv.conf | grep nameserver | cut -d &#39; &#39; -f 2 (2025/2/13) 在重新安装的机器上没用，下面这种有用👇。
还有一种使用 ip 命令的方案：
CLASH_IP=&#34;$(ip route show|sed -n -E &#39;s,default via (\S+).*,\1,p&#39;)&#34; # 用 grep + cut 来代替 sed 也可以 git 协议（ssh）不使用 $http_proxy 代理，需要修改 ~/.ssh/config，添加
Host github.com User git ProxyCommand nc -x ${http_proxy##http://} -Xconnect %h %p 其中 nc 工具在 netcat 包中。这样 git 自己的配置文件就不用配置代理了。
  ]]></content></entry><entry><title>按需合成构造函数</title><url>/inside-the-cpp-object-model/%E6%8C%89%E9%9C%80%E5%90%88%E6%88%90%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html">  复制、默认构造都是按需生成的。对于平凡的情况不需要生成，只是在语意上满足“拥有构造函数”的含义。
x86-64 gcc 13.1 -std=c++20
struct Point { int x; int y; Point() = default; // 即便显式声明了默认构造函数，也不会合成 }; int main() { auto some_point = Point{}; // {}初始化对聚合类有清零的效果 } main: push rbp mov rbp, rsp mov DWORD PTR [rbp-8], 0 mov DWORD PTR [rbp-4], 0 mov eax, 0 pop rbp ret 修改 Point 的定义：
struct Point { int x{}; // 只修改了这里，结果合成了默认构造函数 int y; Point() = default; }; int main() { auto some_point = Point{}; } Point::Point() [base object constructor]: push rbp mov rbp, rsp mov QWORD PTR [rbp-8], rdi mov rax, QWORD PTR [rbp-8] mov DWORD PTR [rax], 0 nop pop rbp ret main: push rbp mov rbp, rsp sub rsp, 16 mov DWORD PTR [rbp-8], 0 mov DWORD PTR [rbp-4], 0 lea rax, [rbp-8] mov rdi, rax call Point::Point() [complete object constructor] mov eax, 0 leave ret 接下来删掉默认构造函数的声明：
struct Point { int x{}; int y; // 删掉了默认构造函数声明，结果不再合成默认构造函数 }; int main() { auto some_point = Point{}; } main: push rbp mov rbp, rsp mov QWORD PTR [rbp-8], 0 mov eax, 0 pop rbp ret 构造函数和成员默认值同时出现时，就会合成默认构造函数。这个和书中的描述是相符的，因为有成员默认值时，默认构造函数需要特别处理一些内容。
接下来：
struct Point { int x{}; int y; }; int main() { auto some_point = Point(); // 注意花括号变成了圆括号 } Point::Point() [base object constructor]: push rbp mov rbp, rsp mov QWORD PTR [rbp-8], rdi mov rax, QWORD PTR [rbp-8] mov DWORD PTR [rax], 0 nop pop rbp ret main: push rbp mov rbp, rsp sub rsp, 16 mov DWORD PTR [rbp-8], 0 mov DWORD PTR [rbp-4], 0 lea rax, [rbp-8] mov rdi, rax call Point::Point() [complete object constructor] mov eax, 0 leave ret 显式使用构造函数相当于声明了构造函数。
不过但凡用上 -O1 级别的优化，空的默认构造函数就可以被内联。
  </content></entry><entry><title>读 On Java 8</title><url>/posts/programming/java/%E8%AF%BB-On-Java-8/</url><categories/><tags><tag>java</tag><tag>on-java-8</tag></tags><content type="html">  Chapter 00-11Java 对象构造顺序：1、基类 2、所有域 3、初始化块 4、自身的构造函数
jshell&amp;amp;gt; a = new Foo() Value initialization Initialization block Constructor 为接口提供默认实现：
逆变、协变、不变的关系：
在 Java 的子类中 override 了父类的方法，返回一个协变类型也是可以的。比如基类规定的是返回 Object，重写的方法里面是可以写返回任意对象的。
接口中的属性自动是 final 和 static 的。比如：S 自动就是 final 和 static 的，因为它是在接口中定义的。也正因为这样，接口曾用来方便地定义一组常量，不过 Java5 之后可以用 enum 替代 interface 实现部分功能了。
这个特性还能用来做测试。比如我根本不想给每个常量域提供冗长的 private static 前缀：（main 仍然要加 static，否则就不能被识别成类中可以运行的 main 方法，而是成为一个接口中的方法）
可惜的是，如果在接口外使用这些常量，就需要把接口名也加上了，这样用起来就长了好多。另外一种思路是：其实在 main 中烦人的是只能使用静态的域，权限则无关紧要。可以把数据作为实例的域。然后申请一个对象在 main 中操作。缺点是在对象实例中放常量总觉得十分奇怪。
在 Class 中套 Test interface 的另外一个好处是：可以只保留一个主文件 Main.java，不需要修改文件本身的名称。
Read MANIFEST from .jar file:
unzip -q -c $(JARFILE) META-INF/MANIFEST.MF Chapter 12-14链表 LinkedListLinkedList 也像 ArrayList 一样实现了基本的 List 接口，但它在 List 中间执行插入和删除操作时比 ArrayList 更高效。然而,它在随机访问操作效率方面却要逊色一些。
LinkedList 还添加了一些方法，使其可以被用作栈、队列或双端队列（deque） 。在这些方法中，有些彼此之间可能只是名称有些差异，或者只存在些许差异，以使得这些名字在特定用法的上下文环境中更加适用（特别是在 Queue 中）。例如： …  </content></entry><entry><title>对象布局</title><url>/inside-the-cpp-object-model/%E5%AF%B9%E8%B1%A1%E5%B8%83%E5%B1%80/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html"><![CDATA[  关于 access section不同 access section 数据不保证按序布局。
我在 Compiler Explorer 上测试了 gcc 和 clang，他们都是忽略 access 权限，将各个 access section 的变量布局直接拼接在一起的。
注：同一个权限也可以是不同的 access section：
具体（concrete）继承布局基类对象直接嵌入到子类中。如果基类中有 padding，默认布局下也不会利用。
struct A1 { int x; virtual void f() {} // vptr 加上 int 值，本来只有 12 个字节但还有 4 字节的 padding }; // 如果把 y 放在 A1 的 padding 的位置，就只需要 24 字节，但很遗憾不能这么布局 struct B1: virtual A1 { int y; }; static_assert(sizeof(A1) == 16); static_assert(sizeof(B1) == 32); 虚拟（virtual）继承布局虚拟继承的数据放在具体继承基类和非静态数据的后面：
vptr：如果可能，从基类列表中选择第一个具体继承的、带有 vptr 的基类，将它提到最前面，保持其他基类的次序不变。这样该基类和子类的 vptr 可以共享，从而对象直接由基类开始，没有额外的 vptr。 虚拟继承的基类不会被考虑 vptr 共享，因为它们始终被放在对象的最后位置。 被选择的基类的 vptr 可以是因为虚拟继承得到的（即可以不是多态类）。 如果需要 vptr 但又不能共享，则在开头添加额外的 vptr。 具体继承基类子对象 本类非静态数据 虚基类子对象 第一个基类子对象的 vptr 和本身的 vptr 尽可能重合（相当于不额外增加 vptr）。多继承的后续基类子对象要单独存储 vptr。
下面的 Cat 的 vptr 和 Garfield 的 vptr 重合。
改变继承的先后顺序可以节省空间：
下面的代码能印证上面的推理：
#include &lt;cstdint&gt; #include &lt;cstdio&gt; struct A { uint64_t x; }; struct B { int b; virtual void foo() {} }; struct C { int c; virtual void foo() {} }; struct D : A, B, C { uint64_t y; void foo() override {} }; int main() { D *p = new D; A *q = p; B *r = p; C *t = p; // printf 打印指针有没有 0x 前缀得看实现 // std::cout 打印指针会增加 0x 前缀而且默认不打印前导零 printf(&#34;%p\n&#34;, p); // 0000020128496730 printf(&#34;%p\n&#34;, q); // 0000020128496740 printf(&#34;%p\n&#34;, r); // 0000020128496730 printf(&#34;%p\n&#34;, t); // 0000020128496748 }   ]]></content></entry><entry><title>多继承给 C++ 带来了哪些设计负担？</title><url>/inside-the-cpp-object-model/%E5%A4%9A%E7%BB%A7%E6%89%BF%E7%BB%99-C++-%E5%B8%A6%E6%9D%A5%E4%BA%86%E5%93%AA%E4%BA%9B%E8%AE%BE%E8%AE%A1%E8%B4%9F%E6%8B%85/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html">   指针偏移本身有少量开销，若需要偏移则得先判空，这样才能保证空指针永远为空。 指针偏移对设计虚函数表带来了困难。例如 thunk 技术用来对 this 指针做适配再调用对应函数。 指针偏移让指向成员函数的指针携带了 this 偏移量，变成了胖指针。 多继承引入了菱形继承困境，进而又引入了虚拟继承。 虚拟继承使得 vtable 中还要存储虚基类子对象的偏移。由于不同继承结构中 vtable 里虚基类子对象的偏移可能不同，又引入了 VTT，让子类调用基类构造函数时为基类的构造函数提供 vptr 参数。   </content></entry><entry><title>多继承下的虚函数</title><url>/inside-the-cpp-object-model/%E5%A4%9A%E7%BB%A7%E6%89%BF%E4%B8%8B%E7%9A%84%E8%99%9A%E5%87%BD%E6%95%B0/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html"><![CDATA[  多继承下重载签名相同的函数结果是会把基类同签名的所有非 final 虚函数都重写了，而且实现方式相同。尽管基类的虚函数签名一样，但是他们没有关联性，所以在子类的虚表中占两个槽（slots）（一个槽是一个指针）。同样的，如果 Interface 中有虚函数 foo，而 A 和 B 都继承了 Interface，C 继承了 A 和 B。如果 A 和 B 没有虚拟继承 Interface，那么在 C 的对象调用函数 foo 时将出现 ambiguous 指代错误。如果 C 重写了 foo 函数，那么指代就还是明确的。或者，如果 A 和 B 都是虚拟继承自 Interface，那么也不会有编译错误。但这样通过指针/引用调用虚函数 foo 就需要先取虚基类子对象 this 的偏移，修改 this 之后再从 vptr 中读虚函数 foo，开销是 4 次访存（将虚拟继承和虚函数调用的代价累加起来了） 。
多继承下调用虚函数时修正 this 指针为什么需要修正 this 指针？重写签名相同的虚函数时，生成的函数代码只能对其中一个基类的虚函数做 this 修正。
#include &amp;lt;cstdio&amp;gt; using namespace std; struct A { int x; virtual void foo() { printf(&amp;#34;A::foo() x=%d\n&amp;#34;, x); } }; struct B { virtual void foo() { printf(&amp;#34;B::foo()\n&amp;#34;); } }; struct C : A, B { void foo() override { printf(&amp;#34;C::foo()\n&amp;#34;); } }; int main() { C c; A *p = &amp;amp;c; // &amp;lt;-- p-&amp;gt;foo(); A *q = new A; q-&amp;gt;foo(); B *r = new C; // &amp;lt;-- r-&amp;gt;foo(); } 首先 C::foo() 代码只有一份（生成多份太浪费了），通过上面 p 指针调用 foo()，会从 vtable 中选中 C::foo()，然后用 C 的 this（这是因为 A 和 C 的 this 是重合的，不需要修改）。如果用 r 指针调 …  ]]></content></entry><entry><title>多继承下的指针转换</title><url>/inside-the-cpp-object-model/%E5%A4%9A%E7%BB%A7%E6%89%BF%E4%B8%8B%E7%9A%84%E6%8C%87%E9%92%88%E8%BD%AC%E6%8D%A2/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html">  要注意空指针是特殊情况：
  </content></entry><entry><title>复制构造和赋值运算符</title><url>/inside-the-cpp-object-model/%E5%A4%8D%E5%88%B6%E6%9E%84%E9%80%A0%E5%92%8C%E8%B5%8B%E5%80%BC%E8%BF%90%E7%AE%97%E7%AC%A6/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html"><![CDATA[  vptr这个小节没有提到 vptr 的处理。
对于复制构造函数，其本质还是构造，所以和一般的构造函数流程相似，会正确设置好 vptr。 对于赋值运算符，原有 vptr 和新的 vptr 是一样的，不需要修改。 怎么写复制构造/赋值？写复制构造函数和复制赋值操作符的时候要记得把基类和成员都正确初始化（用默认的最好）。复制构造函数也算是构造函数，所以要使用成员初始化列表来正确初始化。
复制赋值操作符对基类赋值需要先将 *this 转换成基类的引用，然后用赋值表达式调用基类的赋值操作符。毕竟赋值操作符也不是构造函数，构造过程需要手写的部分有很多还容易写错！这也是为什么复制构造临时对象 + swap 的方法很受欢迎。
#include &lt;cstdio&gt; struct A { int a; A() = default; A(A const &amp;) { puts(&#34;A(const A &amp;)&#34;); } A &amp;operator=(A const &amp;) { puts(&#34;A &amp;operator=(A const &amp;)&#34;); return *this; } }; struct B { int b; B() = default; B(B const &amp;) { puts(&#34;B(const B &amp;)&#34;); } B &amp;operator=(B const &amp;) { puts(&#34;B &amp;operator=(B const &amp;)&#34;); return *this; } }; struct D { int d; D() = default; D(D const &amp;) { puts(&#34;D(const D &amp;)&#34;); } D &amp;operator=(D const &amp;) { puts(&#34;D &amp;operator=(D const &amp;)&#34;); return *this; } }; struct C : A, B { int c; D d; C() = default; // 错误写法：（没有通过初始化列表对基类和成员起到复制作用，它们被默认构造） // C(const C &amp;) { // } // 等效于默认的复制构造函数 C(const C &amp;other) : A(other), B(other), d{other.d} {} // 等效于默认的赋值操作符 // 很麻烦，不如先复制构造再swap C &amp;operator=(C const &amp;other) { if (this == &amp;other) { return *this; } // 右边的 other 会隐式转换成对应类型 static_cast&lt;A &amp;&gt;(*this) = other; static_cast&lt;B &amp;&gt;(*this) = other; d = other.d; return *this; } }; int main() { C c; puts(&#34;copy construction&#34;); C c1 = c; puts(&#34;copy assignment&#34;); c1 = c; } 输出为：
copy construction A(const A &amp;) B(const B &amp;) D(const D &amp;) copy assignment A &amp;operator=(A const &amp;) B &amp;operator=(B const &amp;) D &amp;operator=(D const &amp;)   ]]></content></entry><entry><title>构造函数的成员初始化列表</title><url>/inside-the-cpp-object-model/%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E7%9A%84%E6%88%90%E5%91%98%E5%88%9D%E5%A7%8B%E5%8C%96%E5%88%97%E8%A1%A8/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html">  初始化会按照变量声明的顺序进行。因此虽然下面的代码想要用 j 的新值初始化 i，但实际上是 i(j) 先被执行，然后才是 j(val)。
不过，构造函数代码块中的初始化过程始终发生于成员初始化列表之后。
  </content></entry><entry><title>静态成员函数</title><url>/inside-the-cpp-object-model/%E9%9D%99%E6%80%81%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html">  静态成员函数出现之前很久以前没有静态成员函数（直到 Cfront 2.0 才加入），那个时候静态方法可以用这种方式调用：
该方法没有通过 this 访存，因而不会出现段错误。尽管这种方法还在某些编译器上能够使用，但这种写法在现在是未定义行为。
在表达式上调用静态成员函数可以在一个表达式上调用静态成员函数。表达式的返回值被忽略，但是有副作用；另外表达式的返回值类型帮助确定了静态成员函数应该在哪里寻找。
  </content></entry><entry><title>类定义中的类型名可见性</title><url>/inside-the-cpp-object-model/%E7%B1%BB%E5%AE%9A%E4%B9%89%E4%B8%AD%E7%9A%84%E7%B1%BB%E5%9E%8B%E5%90%8D%E5%8F%AF%E8%A7%81%E6%80%A7/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html"><![CDATA[  尽管现在的编译器能够正确理解数据成员（含有隐式的 this 指针）的使用，并在看到整个类定义之后再查找名字，类型名的查找则发生的很早，导致使用时可能看不到、或者使用了错误的类型声明。
所以，应该尽可能在类定义的开头写好类型别名。
#include &lt;iostream&gt; #include &lt;type_traits&gt; typedef int length; class Point3d { public: **void mumble(length val) { _val = val; } length mumble() { return _val; } static_assert(std::is_same_v&lt;length, int&gt;); private: typedef float length; length _val; }; int main() {}   ]]></content></entry><entry><title>实现简单的花括号插值打印</title><url>/posts/programming/cpp/%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E8%8A%B1%E6%8B%AC%E5%8F%B7%E6%8F%92%E5%80%BC%E6%89%93%E5%8D%B0/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  #include &lt;iostream&gt; void print(std::ostream &amp;os, const char *s) { while (*s) { char ch = *s++; // Treat &#34;{}&#34; as a normal substring when no arguments are left // if (ch == &#39;{&#39; &amp;&amp; *s == &#39;}&#39;) { // } if ((ch == &#39;{&#39; &amp;&amp; *s == &#39;{&#39;) || (ch == &#39;}&#39; &amp;&amp; *s == &#39;}&#39;)) { os &lt;&lt; *s++; } else { os &lt;&lt; ch; } } } template &lt;class A, class... Ts&gt; void print(std::ostream &amp;os, const char *s, A &amp;&amp;a, Ts &amp;&amp;...args) { while (*s) { char ch = *s++; if (ch == &#39;{&#39; &amp;&amp; *s == &#39;}&#39;) { os &lt;&lt; a; break; } else if ((ch == &#39;{&#39; &amp;&amp; *s == &#39;{&#39;) || (ch == &#39;}&#39; &amp;&amp; *s == &#39;}&#39;)) { os &lt;&lt; *s++; } else { os &lt;&lt; ch; } } if (*s) print(os, s + 1, std::forward&lt;Ts&gt;(args)...); } int main(int argc, char **argv) { std::cout &lt;&lt; std::unitbuf; print(std::cout, &#34;numbers : {} {} {}\\n&#34;, 10, 5, -7); } 上面的写法依赖了 std::ostream，而且不支持格式指定符。如果能够构造一个模板类 PrintArg 包装 1 个任意类型参数和 1 个输出说明字符串，然后重载 std::ostream 的 &lt;&lt; 操作符，那么可以不用动 print 函数的逻辑。
  ]]></content></entry><entry><title>使用 Iosevka（等距更纱黑体） 字体的坑</title><url>/posts/unsorted/%E4%BD%BF%E7%94%A8-Iosevka%E7%AD%89%E8%B7%9D%E6%9B%B4%E7%BA%B1%E9%BB%91%E4%BD%93-%E5%AD%97%E4%BD%93%E7%9A%84%E5%9D%91/</url><categories/><tags><tag>font</tag></tags><content type="html">  虽然展开字体在预览中描述的是 Extended，但是实际使用时需要写成 Expanded。
  </content></entry><entry><title>完整构造函数的初始化顺序</title><url>/inside-the-cpp-object-model/%E5%AE%8C%E6%95%B4%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E9%A1%BA%E5%BA%8F/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html"><![CDATA[  构造函数分为完整构造函数（Complete Object Constructor）和基类构造函数（Base Object Constructor）。
初始化顺序显式构造一个对象的时候调用的是完整构造函数。该函数执行的初始化流程如下：
初始化所有基类子对象。基类子对象包括有直接关系的具体继承基类，也包括有直接或间接关系的虚基类。其中虚基类先于具体基类被初始化，尽管虚基类子对象被放在对象的最后面。 初始化自己的 vptr。 按声明顺序初始化成员。若在初始化列表中提供了初始化规则，则使用；否则，如果在声明时给出了初始化表达式，则使用；否则，采用默认初始化。 执行用户提供的代码块中的代码。 可以参考书中第 216 页。
如何初始化虚基类对于每个直接或间接拥有虚基类的类，其构造函数都必须在成员初始化列表中调用虚基类的构造函数来初始化它。如果不显式调用虚基类构造函数，则视为使用其默认构造函数。下面的代码中取消注释 VirtualBase() = default; 并删掉 C(): A(), B(), VirtualBase(&quot;C&quot;) {} 中的 VirtualBase(&quot;C&quot;)，则代码仍能编译。
#include &lt;iostream&gt; struct VirtualBase { VirtualBase(const char *s) { printf(&#34;VirtualBase(%s)\n&#34;, s); } // VirtualBase() = default; }; struct A : virtual VirtualBase { A(): VirtualBase(&#34;A&#34;) { puts(&#34;A()&#34;); } }; struct B : virtual VirtualBase { B(): VirtualBase(&#34;B&#34;){ puts(&#34;B()&#34;); } }; struct C : A, B { C(): A(), B(), VirtualBase(&#34;C&#34;) {} }; int main() { C c; } vptr由于构造函数和析构函数执行过程中会逐层修改 vptr，这两类函数中调用的虚函数只能使用同类型函数版本。编译器甚至可以优化代码，去掉经由 vptr 的虚函数调用操作（反正通过虚函数调用机制能得到的函数也是可确定的）。
  ]]></content></entry><entry><title>析构函数</title><url>/inside-the-cpp-object-model/%E6%9E%90%E6%9E%84%E5%87%BD%E6%95%B0/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html">  析构函数和构造函数一样，也分完整析构函数和基类析构函数两种。而且析构函数的工作流程和构造函数相反。
如果一个类的基类有未实现的析构函数（未提供定义或者是纯虚函数），会导致链接失败。这是因为子类的析构函数有调用基类析构函数的逻辑！
什么时候需要虚析构函数https://stackoverflow.com/a/461237
Declare destructors virtual in polymorphic base classes. This is Item 7 in Scott Meyers&amp;amp;rsquo; Effective C++. Meyers goes on to summarize that if a class has any virtual function, it should have a virtual destructor, and that classes not designed to be base classes or not designed to be used polymorphically should not declare virtual destructors.
**自动生成的析构函数不是虚函数，但是可以显式声明其为 virtual 然后用 = default 引入。**从基类继承的析构函数后虚实性质保持不变。
有了虚析构函数，才能正确地通过非本类的指针 / 引用析构或 delete 某个对象。
虚析构函数如何工作？虚析构函数是给类型增加 vptr 的一种方法。有了虚析构函数就能通过不匹配的指针和 delete 关键字删除曾经 new 出的对象。
complete object destuctor：该类型对象退出作用域时调用（由于可能会通过指针 / 引用人为调用析构函数——比如说 STL 里面——所以完整析构函数也会记录在虚表）。 base object destructor：该类型对象被子类处理的时候调用。（在一些场景下和完整析构函数是同一个） deleting destructor：该类型指针被使用 delete 时调用的、通过虚表机制查找到的虚函数。deleting destructor 要负责修正 this 指针，调用 complete object destructor 来析构对象本身，并最终使用无类型 new …  </content></entry><entry><title>虚拟继承</title><url>/inside-the-cpp-object-model/%E8%99%9A%E6%8B%9F%E7%BB%A7%E6%89%BF/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html"><![CDATA[  基本概念cfront 实现
#include &amp;lt;iostream&amp;gt; struct X { public: int i; }; // size: 4 struct A: virtual X { int j; }; // size: 16 struct B: virtual X { double d; }; // size: 24 struct C: A, B { int k; }; // size: 40 int main() { C c; std::cout &amp;lt;&amp;lt; c.i &amp;lt;&amp;lt; &amp;#39;\n&amp;#39;; } 如果把 A 或者 B 的 virtual 继承属性删除就会出现 ambiguous 指代错误。因为 virtual 继承只保存基类的一份数据，删掉之后自然就有多份变量 i 了。不过，virtual 继承并不代表该类为多态类（可用 type traits 判断）。
同样的，如果 Interface 中有虚函数 foo，而 A 和 B 都继承了 Interface，C 继承了 A 和 B。如果 A 和 B 没有虚拟继承 Interface，那么在 C 的对象调用函数 foo 时将出现 ambiguous 指代错误。如果 C 重写了 foo 函数，那么指代就还是明确的。或者，如果 A 和 B 都是虚拟继承自 Interface，那么也不会有编译错误。但这样通过指针/引用调用虚函数 foo 就需要先取虚基类子对象 this 的偏移，修改 this 之后再从 vptr 中读虚函数 foo，开销是 4 次访存（将虚拟继承和虚函数调用的代价累加起来了）。
虚拟继承下的对象构造https://quuxplusone.github.io/blog/2019/09/30/what-is-the-vtt/#when-we-are-constructing-a-lion
文章讨论的是 Itanium C++ ABI。Itanium C++ ABI 是事实上的跨平台 C++ ABI，除了 MSVC 之外的大部分编译器都使用它。
类的构造函数分两种。第一种是 base object constructor，这是一个类型作为基类的时候，子类需要负责调用的构造函数；第二种是 complete object constructor，这是构造一个含虚基类的 …  ]]></content></entry><entry><title>虚拟继承和虚函数对比</title><url>/inside-the-cpp-object-model/%E8%99%9A%E6%8B%9F%E7%BB%A7%E6%89%BF%E5%92%8C%E8%99%9A%E5%87%BD%E6%95%B0%E5%AF%B9%E6%AF%94/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html">  目的不同虚拟继承用来动态访问数据（节约存储空间或保证数据地址唯一），虚函数用来动态访问方法。
虚表的访问方式如果 A 类有虚函数，那么 A 类已经有 vptr、是多态类，通过 A 类指针/引用访问虚函数则需要查找虚表。
如果 A 类是普通类并且被虚拟继承，那么 vptr 并不会放到 A 类中，通过 A 类指针/引用访问虚函数也不会查表。
考虑 A *pa = new B;，其中 B 类虚拟继承于 A 类，通过 A 类指针 pa 访问到的成员就是真正要找的 A 中的成员，因为从 B 类指针转换到 A 类指针时编译器已经正确处理好了指针偏移问题，从而不需要担心没有 vptr 导致访问不到正确的成员。
考虑菱形继承的情况：
struct A { /* ... */ }; struct B : virtual A { /* ... */ }; struct C : virtual A { /* ... */ }; struct D: B, C { /* ... */ }; 从指向 D 类真实对象的 B 类指针访问来自 A 中的成员，就会用上 B 类的 vptr 查找偏置信息。
和非虚拟对应物相比的额外代价以 Itanium C++ ABI 为例。
虚函数：首先读 vptr，再用编译时确定的下标去访表，相当于多访存两次才取得了函数指针。
虚拟继承得到的数据成员：首先读 vptr，然后从 vptr 减去一部分（减多少是在编译时确定下来的）得到新指针，访问这个位置指向的数据可以得到虚基类子对象在本类中的偏移量。而具体继承来的基类子对象的偏移是在编译时确定，所以虚拟继承相当于多访存了两次。可以参考 📌vtable 中的这张图片：
  </content></entry><entry><title>一些 macOS 和 GNU 的命令差异</title><url>/posts/systems/macOS/%E4%B8%80%E4%BA%9B-macOS-%E5%92%8C-GNU-%E7%9A%84%E5%91%BD%E4%BB%A4%E5%B7%AE%E5%BC%82/</url><categories/><tags><tag>linux</tag></tags><content type="html">  sed -imacOS sed 的 -i 需要指定参数，如果不需要备份文件，需要显式给出 sed -i ''。不然可以用 gsed 命令（用 brew 安装）。
xargs如果没有收到输入，就不会运行。而 GNU 的 xargs 在没有收到输入时会只运行右侧命令而不附带参数。要想 GNU xargs 在此时不运行命令，需要使用 -r 选项。
  </content></entry><entry><title>异常处理</title><url>/inside-the-cpp-object-model/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html">  有人说从 Cfront 转向专门的 C++ 编译器的一大原因就是支持异常处理，因为异常处理在 C 语言中很难做。
一个函数的指令区域分成三种：
try 以外，且没有活跃对象 try 以外，有活跃对象，发生异常时需要析构 try 以内 有一个活跃对象和两个活跃对象应该会有区别吧？这样制表/查表的压力很大。
发生异常时把 PC 寄存器（在 x64 上是 rip）的值拿去查表，若在 try 区段中且能够被接受则进入异常处理，否则析构活跃对象并退栈。然后到下一层检查是否能处理异常。
  </content></entry><entry><title>用构造函数和 swap 实现 operator=</title><url>/posts/programming/cpp/%E7%94%A8%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E5%92%8C-swap-%E5%AE%9E%E7%8E%B0-operator/</url><categories/><tags><tag>cpp</tag></tags><content type="html"><![CDATA[  代码展示先在参数的位置创建一个新的对象，然后和 *this 交换。
struct MyClass { MyClass&amp; operator=(MyClass other) { swap(*this, other); return *this; } friend void swap(MyClass &amp;a, MyClass &amp;b) noexcept; { using std::swap; swap(a.member1, b.member1); swap(a.member2, b.member2); } int member1; int member2; }; 这种实现既能够匹配 const MyClass &amp; 的情况，又能匹配 MyClass &amp;&amp; 的情况，而且代码行数更短。
注意点 1：必须自定义 swap 函数使用这种写法必须提供我们自己的 swap 函数，因为 std::swap 对一般类型的实现是使用了构造的，如果不提供我们自己的 swap 函数而去直接调用 std::swap，就会无限递归！std::swap 的相关代码如下：
void #endif swap(_Tp&amp; __a, _Tp&amp; __b) _GLIBCXX_NOEXCEPT_IF(__and_&lt;is_nothrow_move_constructible&lt;_Tp&gt;, is_nothrow_move_assignable&lt;_Tp&gt;&gt;::value) { #if __cplusplus &lt; 201103L // concept requirements __glibcxx_function_requires(_SGIAssignableConcept&lt;_Tp&gt;) #endif _Tp __tmp = _GLIBCXX_MOVE(__a); __a = _GLIBCXX_MOVE(__b); __b = _GLIBCXX_MOVE(__tmp); } 注意点 2：实现 swap 函数的时候避免使用 operator=同时，我们在实现 swap 函数的时候也不应该对本类型对象使用 = 操作符，这也会导致递归调用。swap 函数可以被实现为对本类型的数据成员逐个做 swap。
注意点 3：using std::swap如果直接使用 std::swap 就无法利用上 ADL，可能有些成员是有 swap 友元函数的类型，这个时候用 std::swap 的可能是低效、甚至有错误的。
先 using std::swap 然后直接使用 swap 就能利用上 ADL。
  ]]></content></entry><entry><title>指向成员的指针</title><url>/inside-the-cpp-object-model/%E6%8C%87%E5%90%91%E6%88%90%E5%91%98%E7%9A%84%E6%8C%87%E9%92%88/</url><categories><category>inside-the-cpp-object-model</category></categories><tags><tag>cpp</tag><tag>inside-the-cpp-object-model</tag></tags><content type="html"><![CDATA[  参考 https://itanium-cxx-abi.github.io/cxx-abi/abi.html#member-pointers。
向下转换的能力！和类的指针/引用的转换不同，指向成员的指针既可以向下转，又可以向上转！只需要目的类型拥有对应的成员即可。
struct A { long a; }; struct B: A { long b; }; int main() { // long (A::*p) = &amp;amp;B::b; // 错误，A 类型没有成员 B::b long (A::*q) = &amp;amp;B::a; // B::a 和 A::a 是相同的 long (B::*r) = &amp;amp;A::a; // 向下转 } 指向数据成员需要存储 this 偏置，按照 Itanium C++ ABI，存储的类型为 ptrdiff_t。一般数据成员指针就用其相对于开头的偏移作为指针的值，而空指针则用 -1 表示。
奇怪的现象：对指向数据成员指针的空初始化会将其置为空指针，也就是 -1！虽然含义为空，但是其比特位并不是全零的。
C++ 标准不允许跨越虚基类转换数据成员指针：
The C++ standard does not permit base-to-derived and derived-to-base conversions of member pointers to cross a virtual base relationship, and so a static offset is always known.
struct X { int x; }; struct Y : virtual X { int y; }; int main() { int (X::*p) = &amp;amp;Y::x; // ok int (Y::*q) = &amp;amp;X::x; // error: pointer to member conversion via virtual base &amp;#39;X&amp;#39; // X::x 是虚继承得到的，并不属于 Y 本身（通过具体继承就属于 Y 本身）。 // 也就是说**跨越了虚基类的、不属于本身的成员的指针**不能转换，这也包括重写了的虚函数， // 因为重写的虚函数相当于第二个版本。 } 下面是书中的描述： …  ]]></content></entry><entry><title>Windows 上 Docker 和 Hyper-V 的坑</title><url>/posts/cli/docker/Windows-%E4%B8%8A-Docker-%E5%92%8C-Hyper-V-%E7%9A%84%E5%9D%91/</url><categories/><tags/><content type="html">  这个写的时间比较早了，当时有的问题现在可能已经被弥补了。
bcdedit 和 hypervisor 相关，直接关掉 hypervisor 还不能够完全关闭。一些软件仍然不能够运行。
运行 bcdedit /set hypervisorlaunchtype off（需要管理员权限）后再重启可以关掉这个功能。直接使用 bcdedit 开始查看当前的配置状况。
  </content></entry></search>